<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[调用阿里云api获取阿里云数据同步服务（DTS）并且作图发送邮件的整个流程]]></title>
    <url>%2F2018%2F02%2F28%2F%E8%B0%83%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91api%E8%8E%B7%E5%8F%96%E9%98%BF%E9%87%8C%E4%BA%91%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1%EF%BC%88DTS%EF%BC%89%E5%B9%B6%E4%B8%94%E4%BD%9C%E5%9B%BE%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E7%9A%84%E6%95%B4%E4%B8%AA%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言在https://rorschachchan.github.io/2018/02/24/阿里云获取DTS服务延迟的脚本/ 文章里已经说了“领导要求每天查看阿里云dts同步的延迟情况和同步速率情况”，并且在https://rorschachchan.github.io/2018/02/27/使用matplotlib画图的一个脚本/ 里面也放了一个使用python matplotlib画图的demo，这篇文章的目的就是把整个过程实现，并且把dts图形以每日邮件的形式发送给领导的效果！ 实现需求的思路本次需求有四个动作，分别是获取一天以内的DTS延迟和同步速率、将获取到的DTS值做成PNG图像、将生成的PNG图像上传到阿里云云存储OSS、把图片展示到邮件里并发送给相关领导。由于第一步获取一天以内的DTS延迟和同步速率需要将这个脚本每小时执行一次，执行24次，才可以执行生成png图像这一步，所以后三个其实可以写成一个大脚本。不过在本文为了表述的清楚，就把各自不同用途写成了不同的脚本。 获取阿里云DTS延迟和同步速率的脚本这个脚本之前写过了，这里再拿出来晒一遍： 123456789101112131415161718192021222324252627282930313233#!/usr/bin/env python#coding=utf-8#这个脚本是用来获取dts延迟数字的from aliyunsdkcore import clientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionimport time,json,syssys.path.append('/解压缩路径/aliyunsdkdts/request/v20160801/') #这里看不懂去看https://rorschachchan.github.io/2018/02/24/阿里云获取DTS服务延迟的脚本/import DescribeSynchronizationJobStatusRequest# 创建 Client 实例clt = client.AcsClient('这里填写ak','这里填写sk','cn-shenzhen')# 创建 request，并设置参数request = DescribeSynchronizationJobStatusRequest.DescribeSynchronizationJobStatusRequest()request.set_SynchronizationJobId("这里填写DTS的ID号")response = clt.do_action_with_exception(request)delay = json.loads(response)rate = str(delay["Performance"]["FLOW"])[0:4] #由于同步速率默认是带单位的，这里就取前四位#用A.txt来存储延迟时长fd = open("/存储路径/A.txt","a")fd.write(str(delay["DataSynchronizationStatus"]["Delay"]))fd.write('\n')fd.close()#用B.txt来存储同步速率 fr = open("/存储路径/rate.txt","a")fr.write(rate)fr.write('\n')fr.close() 将获取到的值做成图片的脚本由于脚本执行环境是无图像的阿里云服务器，系统是centos 7，ps.slow这一步会爆错RuntimeError: could not open display，所以只能采取把生成的PNG图像文件保存到本地路径里的方法。脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/usr/bin/env python# -*- coding: utf-8 -*-import matplotlib as mplmpl.use('Agg') #在无法生成图像的环境下要添加了上面两句话import matplotlib.pyplot as pltimport numpy as npimport pylab as plx=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]#横坐标的内容labels=['10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','1','2','3','4','5','6','7','8','9']#y1是delay延迟时长with open('/存储路径/A.txt', 'r') as f: y1 = [] for line in f: lst = line.split('\n') #增加一个换行符，不然数字是不换行的 y1.append(float(lst[0]))#y2是rate同步速率with open('/存储路径/B.txt', 'r') as f: y2 = [] for line in f: lst = line.split('\n') y2.append(float(lst[0]))#输入对应的坐标，后面是颜色plot1,=pl.plot(x,y1,'r')plot2,=pl.plot(x,y2,'b')pl.xticks(x,labels)pl.title('这里写标题',size=20) #中文会显示乱码，推荐还是英文pl.xlabel('这里是X轴标题', size=14)pl.ylabel('这里写Y轴标题', size=14)pl.ylim(0.0,5.0)#曲线对应注释pl.legend([plot1,plot2],('Delay','Sync rate'),'best',numpoints=1)#开启网格pl.grid()#图片保存路径plt.savefig('/保存路径/图片名称.png', format='png') 将生成的图片上传到阿里云OSS的脚本由于不想让“领导去手动点开附件查看图像”，所以我们干脆把图片作为邮件的正文展示出来，那么就在html里就需要img src=图片的网络地址的方法。于是就把刚刚生成的图片上传到阿里云OSS里，这样就可以获得图片的网络地址。而且阿里云OSS是“相同文件名会覆盖”，所以不用再去删除。整个脚本内容如下： 1234567891011121314151617# -*- coding: utf-8 -*-import osimport shutilimport oss2access_key_id = os.getenv('OSS_TEST_ACCESS_KEY_ID', '这里填写ak')access_key_secret = os.getenv('OSS_TEST_ACCESS_KEY_SECRET', '这里填写sk')bucket_name = os.getenv('OSS_TEST_BUCKET', '这里填写bucket名称')endpoint = os.getenv('OSS_TEST_ENDPOINT', '这里填写内网end-point')# 确认上面的参数都填写正确了for param in (access_key_id, access_key_secret, bucket_name, endpoint): assert '&lt;' not in param, '请设置参数：' + param# 创建Bucket对象，所有Object相关的接口都可以通过Bucket对象来进行bucket = oss2.Bucket(oss2.Auth(access_key_id, access_key_secret), endpoint, bucket_name)bucket.put_object_from_file('上传到OSS的图片名称.png', '/服务器保存路径/图片名称.png') 将图片作为内容发邮件的脚本整个脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#!/usr/bin/env python# -*- coding: UTF-8 -*-import os,time,re,smtplib,loggingfrom email.mime.text import MIMETextfrom email.header import Headerdef send_mail(to_list, cc_list, html, sub): me = mail_user msg = MIMEText(html, _subtype='html', _charset='utf-8') # 格式化邮件内容为html，编码为utf-8 msg['Subject'] = sub # 邮件主题 msg['From'] = me # 发件人 msg['To'] = ";".join(to_list) # 收件人，将列表转换为字符串 msg['Cc'] = ";".join(cc_list) # 抄送人，将列表转换为字符串 try: send_smtp = smtplib.SMTP() # 实例化 send_smtp.connect(mail_host) # 连接smtp服务器 send_smtp.login(mail_user, mail_pass) # 使用定义的账号密码进行登录 send_smtp.sendmail(me, to_list+cc_list, msg.as_string()) # 发送邮件 send_smtp.close() # 关闭连接 return True except Exception, e: logging.basicConfig(filename='logger.log', level=logging.DEBUG) logging.debug(e) print ("ERROR!!!!") return Falseif __name__ == '__main__': mail_host = 'mail.dahuatech.com' mail_user = '这里填写发件人地址' mail_pass = '填写对应的密码' mailto_list = ['收件人邮箱地址'] mailcc_list = ['抄送人1的邮箱地址'，'抄送人2的邮箱地址'] html = """ &lt;body&gt; &lt;br&gt;&lt;img src="这里填写的是图片的http地址"&gt;&lt;/br&gt; &lt;table color="CCCC33" width="800" border="1" cellspacing="0" cellpadding="5" text-align="center"&gt; &lt;tr&gt; &lt;td test-align="center"&gt;上图是阿里云深圳VPC区数据同步过去24小时的情况。&lt;br /&gt; 注意事项 1:dts的延迟时间是5秒计算一次，api请求会取到最新的延迟时间，而控制台是每隔20秒才刷新一次； 注意事项 2:api在延迟时间取值为整数，即1.x显示为2，请知悉; 注意事项 3:此邮件是系统自动发出，如果有任何疑问请联系运维人员； &lt;/tr&gt;&lt;/br&gt; &lt;/table&gt; &lt;/body&gt; """ sub = "阿里云深圳VPC数据同步情况" if send_mail(mailto_list,mailcc_list,html,sub): logging.debug("Send mail succed!") else: logging.debug("Send mail failed") 上面四个脚本整个执行下来，效果如下，至此大功告成！ 参考资料https://github.com/aliyun/aliyun-oss-python-sdk/blob/master/examples/object_basic.pyhttps://hk.saowen.com/a/fe355cb5cc3ab17dbc84e9489621d2ab31da72b511092839832bc9e89d63bf71http://blog.csdn.net/baoli1008/article/details/47980779https://www.digglife.net/articles/html-mail-with-inline-images-python-perl.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个监控挂载盘的python脚本]]></title>
    <url>%2F2018%2F02%2F27%2F%E4%B8%80%E4%B8%AA%E7%9B%91%E6%8E%A7%E6%8C%82%E8%BD%BD%E7%9B%98%E7%9A%84python%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[前言公司产品线有一个公用的挂载盘，主要是用来方便各位开发人员去放置他们自己的一些工作材料，比如异常的日志或者tcpdump的抓包等等杂七杂八的东西，但是这个挂载盘由于使用人众多，容量自然要有监控，于是就有了写这个脚本的动机。 在这里我写了两个脚本，上面这个是用来监控磁盘容量，然后通过df -h的排序生成前十名占容量最大的文件夹，把这个文件夹的名字和对应的大小重定向到一个叫alarm.txt这个文件里，这个文件就是邮件正文。然后在确定他们的主人，统一加上公司邮箱后缀来得到他们主人的邮箱地址，最后对应他们各自的邮箱地址用下面那个脚本来发送文件夹容量过高的邮件。 监控挂载盘的脚本12345678910111213141516171819202122232425262728293031323334353637383940414243#!/usr/bin/env python# coding=utf-8import osimport AutoMailimport commands#设定变量判断是否挂载和挂载盘的容量mount = commands.getoutput("mount | grep ':.*nfs'|wc -l")size = commands.getoutput("df -h | grep share | awk '&#123;print $5&#125;' | cut -d '%' -f 1") ##建立发邮件的文本文件def Createalarm(): if os.path.exists('/root/chenscript/alarm.txt') == True: os.system("python /root/chenscript/weixin_sharealarm.py") print ("微信告警已经发送！") os.system("cd /root/chenscript; echo 'share盘容量大于80%，现在将调出容量排名前十位的文件夹名字及对应的容量，请各位处理一下不需要的文件！' &gt;/root/chenscript/alarm.txt") os.system("cd /挂载盘名称 ;du -s * --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹'|sort -nr |head &gt;&gt;/root/chenscript/alarm.txt") os.system("echo '\n' &gt;&gt; /root/chenscript/alarm.txt") if os.path.exists('/root/chenscript/alarm.txt') == False: os.system("cd /root/chenscript;touch alarm.txt")def Sendmail(): fp = open('/root/chenscript/alarm.txt', 'r') content = fp.read() AutoMail.send_mail('share挂载盘容量大于80%！收到邮件的各位请整理自己对应的文件夹！', content) #将邮件的文件刷新def Dellist(): os.system("cd /root/chenscript/;rm -f alarm.txt;touch alarm.txt")if mount == '1' and size &gt;= '80': print ("挂载盘存在！") print ("share盘容量大于80%...") Createlist() Sendmail() Dellist()elif mount == '1' and size &lt; '80': print ("挂载盘存在！") print ("share盘容量正常...")else: print ("挂载盘不存在，现在重新挂载...") os.system("mount -t nfs -o acl,rw,intr,soft,nolock,rsize=8192,wsize=8192 10.160.43.172:/share /share ") 发送告警邮件脚本1234567891011121314151617181920212223242526272829303132333435363738394041424344#!/usr/bin/env python#coding=utf-8#这个脚本的用途是用来发送邮件import smtplibfrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextfrom email.mime.application import MIMEApplicationmailto_list=[] #这里为空list，会从list.txt里一行一行的当做元素添加进来#生成list.txtif os.path.exists('/root/chenscript/list.txt') == True: os.system("cd /挂载盘名称;du -s * --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹'|sort -nr |head|awk \'&#123;print $2\"@dahuatech.com\"&#125;\' &gt;&gt;/root/chenscript/list.txt")if os.path.exists('/root/chenscript/list.txt') == False: os.system("cd /root/chenscript/;rm -f list.txt;echo '本人的邮箱地址'&gt;list.txt")with open('/root/chenscript/list.txt','r') as f: f=f.readlines()for i in f: i=i.strip('\n') mailto_list.append(i)mail_host="这里填写邮箱主机"mail_user="这里填写发送人的邮箱地址"mail_pass="发送人的邮箱密码"mail_postfix="dahuatech.com"mail_sender="与mail_host内容相同"def send_mail(sub, content): me=mail_sender msg = MIMEMultipart() msg['Subject'] = sub msg['From'] = me msg['To'] = ";".join(mailto_list) content1 = MIMEText(str(content), 'plain', 'utf-8') msg.attach(content1) try: s = smtplib.SMTP() s.connect(mail_host) s.login(mail_user,mail_pass) s.sendmail(me, mailto_list, msg.as_string()) print('发送成功！\n') s.close() except Exception as e: print(str(e))os.system("cd /root/chenscript/;rm -f list.txt;echo '我本人的邮件地址'&gt;list.txt") 执行的效果如下： 隐藏的知识点1）du -s是按照字节来统计，--exclude=&#39;yunwei&#39;是在排序的时候忽略掉yunwei这个文件夹，容后再用sort -nr|head是得到从大到小前10名，如果得到后10名就是sort -nr|tail；2）如果使用的是import commands，那么commands.getoutput得到的是字符串！3）用mount | grep &#39;:.*nfs&#39;来判断挂载盘是否存在是一个很简单的方式，如果挂了多个，就用ip in的方式来进一步判断；4）python要一行一行的读取文件，就readline；5）python按行读取文件，去掉换行符\n的方法： 12for line in file.readlines(): line=line.strip('\n') 6）import Automail的时候，就已经把Automail.py这个脚本固定住了，这时候mailto_list已经不能变化了，所以要把添加list.txt放到这个脚本里。 发了邮件，连吼带骂一顿，终于把share盘容量下降到了69这样一个美妙的数字…]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用matplotlib画图的一个脚本]]></title>
    <url>%2F2018%2F02%2F27%2F%E4%BD%BF%E7%94%A8matplotlib%E7%94%BB%E5%9B%BE%E7%9A%84%E4%B8%80%E4%B8%AA%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[准备工作之前在https://rorschachchan.github.io/2018/02/24/阿里云获取DTS服务延迟的脚本/ 里已经可以获取到阿里云DTS服务的延迟时长和同步速率。下一步就是把这些值以24小时为周期作一个图像，然后每天在固定时间发送到领导们的邮件里。 python作图的第三方工具叫matplotlib，安装步骤如下： 1234pip install matplotlib #画图模块pip install numpy #依赖的库pip install scipy #又一个依赖的库yum install -y Tkinter #如果是python3，那么就是yum install -y tkinter 脚本内容由于我是在centos 7里进行脚本操作，而linux服务器有没有安装图像，所以在执行import matplotlib.pyplot as plt的时候可能会爆错：RuntimeError: could not open display，这个时候需要在前面改成如下样式（注意先后顺序）： 123import matplotlib as mplmpl.use('Agg')import matplotlib.pyplot as plt 举一个简单的脚本例子如下，就是给予（x,y）然后连成曲线图的效果，脚本里数字的部分不加引号也是可以识别的，当然使用变量也可以。 12345678910111213141516171819202122232425262728293031323334353637383940414243#!/usr/bin/env python# -*- coding: utf-8 -*-import matplotlib as mplmpl.use('Agg') import matplotlib.pyplot as pltimport numpy as np import pylab as pl x=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]#横坐标的内容labels=['10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','1','2','3','4','5','6','7','8','9']a = '1'b = '2'c = '3'd = '4'#y1是延迟y1=['2','3','5','4','2','1','2','2','3','5','4','2','1','2','2','3','5','4','2','1','2','2','3','5']#y2是同步速率y2=[a,b,c,d,0.13,0.12,0.14,0.14,0.14,0.16,0.15,0.13,0.12,0.14,0.14,0.14,0.16,0.15,0.13,0.12,0.14,0.22,0.18,0.11]#输入对应的坐标，后面是颜色plot1,=pl.plot(x,y1,'r') #这里是有逗号的，用于参数解包plot2,=pl.plot(x,y2,'b') pl.xticks(x,labels)#图片的标题以及对应的字号大小pl.title('The DTS status of Shenzhen VPC',size=20)#X轴的标题和字号大小pl.xlabel('Time', size=14)#Y轴的标题，字号大小和长度pl.xlabel('Time', size=14)pl.ylim(0.0,5.0)#曲线对应注释pl.legend([plot1,plot2],('Delay','Sync rate'),'best',numpoints=1)#图片保存路径plt.savefig('/tmp/dts.png', format='png') 脚本执行效果之后，会在对应的路径里生成一个图片文件，然后把这个图片转移到windows，打开就看到效果了，如图： 这个图是全英文的，如果是中文的话，就会出现乱码，研究了半天也没搞明白，这一点让我很郁闷。 参考资料http://python.jobbole.com/81182/https://absentm.github.io/2017/03/18/Python-matplotlib-数据可视化/https://liam0205.me/2014/09/11/matplotlib-tutorial-zh-cn/https://morvanzhou.github.io/tutorials/data-manipulation/plt/1-1-why/https://www.lookfor404.com/%E8%BF%90%E8%A1%8Cggplot%E5%87%BA%E7%8E%B0%E9%97%AE%E9%A2%98no-display-name-and-no-display-environment-variable/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决https证书在赛门铁克认证失败的问题]]></title>
    <url>%2F2018%2F02%2F26%2F%E8%A7%A3%E5%86%B3https%E8%AF%81%E4%B9%A6%E5%9C%A8%E8%B5%9B%E9%97%A8%E9%93%81%E5%85%8B%E8%AE%A4%E8%AF%81%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题描述今天电子商城的市场接到一个故障，说更换了.lechange.com的https证书（原有的证书到期了，新买了一个依旧还是.lehcange.com域名证书）之后，订单在支付宝支付的时候提示支付失败。我把request id提供给支付宝的客服请他们查看一下后台，支付宝客服说我们电商的https证书没有认证成功。于是我就登陆https://cryptoreport.websecurity.symantec.com/checker/ 去检查一下电商的域名，果不其然，赛门铁克的反馈是错误的，如图： 但是登陆网站，在浏览器里却显示https证书是OK的，如图： 然后我用symantec的那个网站测试了一下电商平台开发环境的域名，发现也是OK的，如图： 这就郁闷了，到底哪里出问题了？ 问题排查首先跟研发确认，开发环境与线上环境在涉及到证书的代码是否一致，得到研发的确认之后。就检查服务器里的nginx，发现服务器nginx的配置文件里是没有涉及到ssl，无论是开发环境和线上环境都是通过阿里云slb配置的https证书。而且两者的证书指纹一模一样，如图： 既然都是用的一样的证书，为啥一个检验通过，另一个检验不通过呢？这个时候我想到线上环境与开发环境唯一的不同就是线上环境多了一个cdn，于是就登陆到cdn的控制页面，找到对应的https证书，发现cdn的https证书指纹也是跟上面的指纹一样，如图： 既然指纹一样，那证书也应该是一样的，场面又进入了一个僵局。 于是我就到一台服务器里使用curl -vv https://www.lechange.com，看到的结果如下： 提示未配置签发者根证书，我这时候想起来了，首先证书指纹一致不能说明证书是完全一致的，只能说明key文件是一样的！其次这个https证书是中级机构证书，那么中级机构颁发的证书链规则是这样的： 12345678-----BEGIN CERTIFICATE----------END CERTIFICATE----------BEGIN CERTIFICATE----------END CERTIFICATE----- 那么我怀疑就是https证书链那部分可能在cdn配置错误了，或许在slb配置错误了，甚至两个都配置错误了！ 于是干脆删除掉线上电商原有的https证书，重新导入cdn和slb的https证书，返回到symantec刷新，这次的检验结果就OK了。 补充虽然这个问题解决了，但是我还是不明白，为什么在网页端查看证书是绿色OK的呢？在sf.gg上提问之后，一个叫Avro的朋友是这么回答我的： 以chrome为例，他信任了[所在平台的信任证书列表][1]，而这些平台集成了一系列信任的根证书，如iOS 11 中可用的受信任根证书列表可以找到你的根证书“04 00 00 00 00 01 15 4B 5A C3 94 ”(序列号)，因此验证过程中没有问题，而对于其他的工具，如果未使用这些平台根证书信任列表依然需要完整的证书链（这个证书链在ssl握手过程中被下发）进行校验。 参考资料https://openclub.alipay.com/read.php?tid=3451&amp;fid=57&amp;page=1https://www.jianshu.com/p/84af353f43c5https://help.aliyun.com/knowledge_detail/39468.html?spm=a2c4g.11186631.2.2.w2qcWT]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>https证书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录Apache Storm的部署始末]]></title>
    <url>%2F2018%2F02%2F25%2F%E8%AE%B0%E5%BD%95Apache-Storm%E7%9A%84%E9%83%A8%E7%BD%B2%E5%A7%8B%E6%9C%AB%2F</url>
    <content type="text"><![CDATA[前言Storm是一个流式处理框架（你可以把它当成一种消息队列），开发人员开发出特定的项目，然后通过storm这个渠道下发各种任务，从而达到任务执行的效果。 Storm有两个比较重要的组件：nimbus和supervision，其中nimbus主要是承接任务和分配任务用，而每一个supervision可以有若干worker（视服务器硬件而定），而supervison的主要任务就是监控对应的worker，一旦worker死了，supervision就会把他们唤醒。 本次试验是用的是金山云服务器，storm的版本是1.0.2，配置是1个nimbus，三个supervision，每一个worker上只执行一个任务，总共三个任务。 准备工作安装storm之前需要在storm里新安装一套zookeeper，因为storm是需要一个zk集群的，nimbus和每一个supervisior是通过zk的心跳来传递存活的信息，于是我们就在每一个supervision里面安装一个zookeeper，并且启动zookeeper的server端，安装zookeeper的方法可以移步http://chenx1242.blog.51cto.com/10430133/1889715 。 上面这段话用图来说就是这样子： 启动zookeeper之后，就需要在nimbus和supervisior里安装storm，上面说过本次安装的storm是1.0.2版本，路径直接是/storm/apache-storm-1.0.2。 将storm安装完之后，需要在nimbus和supervisior里更改/etc/hosts文件，改成如下的格式： 1234567891011127.0.0.1 localhost nimbus的内网IP online-nimbus-001supervision1的内网IP supervision-001supervision2的内网IP supervision-002supervision3的内网IP supervision-003 zookeeper的内网IP zookeeper的名称 #注意，这里的zk是给模块拉取配置的zkstorm的zk1的内网IP storm的zk1 #这里的zk就是给storm集群用的zkstorm的zk2的内网IP storm的zk2 #如果storm的zk是standalone模式，这里就不要写了。storm的zk3的内网IP storm的zk3 #如果storm的zk是standalone模式，这里就不要写了。 保存完/etc/hosts之后，还有一个比较重要的步骤，就是在/etc/ld.so.conf.d/这个路径里面建立一个ffmped.conf这个文件，文件的内容如下： 12/storm/apache-storm-1.0.2/lib/storm/apache-storm-1.0.2/lib/3rd 注意，/storm/apache-storm-1.0.2是我的storm路径，在实际情况下需要根据自己的路径进行更改。 把这个ffmped.conf建立成功之后，我们可以测试一下，如果输入ldconfig的话，会出现如下的内容，就证明达到了我们的效果： storm本身的bin目录夹里也有很多命令可以直接使用，为了调用storm list方便，我们需要把bin/storm这个可执行文件作一个软连接，方法就是先cd /usr/local/bin/，然后ln -s /storm/apache-storm-1.0.2/bin/storm storm。这样的话，我们就可以直接使用storm list来查看任务列表了。 Storm的具体配置安装了storm，调整了命令行，同时也搞定了ffmpeg.conf，下面就是调整storm的配置文件了，nimbus和supervisior都要修改。 storm的配置文件叫storm.yaml，路径位于storm文件夹下的/conf/文件夹，我们需要在这个文件里面输入如下的内容： 下面对配置文件作一个简单的解释：1）storm.zookeeper.port:zk的默认端口2181；2）storm.cluster.mode:storm的集群运行模式，这里我们也是采用默认的distributed（分布式）；3）storm.local.dir:storm使用的本地文件的目录，这个目录必须存在而且storm进程可读写；4）supervisor.slots.ports：这个地方在nimbus里可以不用管，但是在supervisior里是需要改的，如果你只打开6700，那么就只放开了6700端口，即只有一个worker，如果你打开了6700、6701、6702三个端口，那么就意味这个supervisior将有三个worker在工作，由于这次试验里我们每一个supervisor只开启一个任务，所以在supervisior的storm.yaml里这个节点就只保留6700，其他的就全部注释掉；5）nimbus.task.launch.secs:task启动时的一个特殊超时设置.在启动后第一次心跳前会使用该值来临时替代nimbus.task.timeout.secs；6）worker.childopts:设定每个worker (JVM任务)的最小和最大内存； 更改完了storm.yaml之后，就要在nimbus里面安装zkclient。直接复制粘贴过来就好了。 如果你不喜欢storm自带的日志格式，想更改一下日志的内容，那么就要在/storm/apache-storm-1.0.2/log4j2文件夹里面修改worker.xml，不过在这里善意的提醒，最好在修改之前先备份原有的worker.xml。 连接具体任务这次的实验包用的是我所在的公司开发内部使用的包，先把这个包的内容复制到/storm/文件夹下，同时mkdir install和makir properties这两个文件夹，在install文件夹里有开发写的任务的jar包和启动程序，如下： 而在properties文件夹里，应该有这个任务的配置文件，如下： 由于我们已经事前在/etc/hosts里指定了zkclient需要访问的zk的ip地址了，那么如果zk项配置正确，zkclient这个时候是可以成功启动的。同时在install文件夹里./update_stormserver_config.sh也应该是反应正确的。 然后我们就可以启动storm了。 启动nimbus和supervision启动storm要先启动nimbus，在/storm/apache-storm-1.0.2/bin里面启动run_nimbus.sh，然后等一下会有一大片东西出现，再jps一下就能看到nimbus已经启动了，如图： 从上图我们可以看到，18141的进程就是zkclient，只不过在jps里它名字叫AppServerDaemon，而zkServer在jps里叫QuorumPeerMain。 如果 storm出现Did you specify a valid list of nimbus hosts for config nimbus.seeds?的错误提示，那么就是nimbus没有启动的缘故。 启动了nimbus之后，就可以在supervisor的机器里去效仿着启动supervisor，但是这里要注意，如果你开启了一个supervisior，那么按照我们上面的配置文件，就启动了一个6700端口的worker，这个时候在nimbus执行下派一个任务的命令，nimbus就会下派这个任务给这个worker。 下派命令的例子如下： 1storm jar storm-starter-0.9.2-incubating-jar-with-dependencies.jar com.lechange.recordshare.RecordShareTopology 1 这样就启动了一个叫videoshare的任务，这个任务只用1个worker。 如果在命令行里反馈这样的错误： 1Error: Could not find or load main class storm.starter.recordshare.RecordShareTopology 或者exception in thread main java.lang.NoClassDefFoundError这样的错误，那就要检查jar包和路径。 而如果你再打开一个supervisor，在nimbus端又下发了一个任务，那么这个任务就会给刚刚新启动的supervisor。这样，启动一个下发一个，就会对每一个worker具体干的任务情况有一个比较清晰的了解。 在nimbus上执行storm list，就可以获得上图的样子，可以看出，我在nimbus端下发了三个任务，就是topology_name这一栏，他们的状态也是active，而workers数量都是1，也就是说在那三台supervisor里都在工作。而跑到supervisor一看日志，也是对应有各自的任务日志。 至此整个storm和具体的模块工作的搭建就完成了。 补充如果你事前一口气把三个supervisor都打开了，即开启了3个worker，然后一口气在nimbus端，一口气输入了三个下发任务的命令，那么这三个命令会随机的到这三个worker里，没有任何顺序而言，你只能通过日志的关键词来判断具体的worker做哪些任务。 而如果你的worker数量少于nimbus下发任务的数量，会有什么反应呢？ 答案就是任务根本没有worker去干，在storm list里，多余的任务对应的num_workers的数字是0，而如果这个时候你新增一个supervisor到这个storm集群，那么这个任务就会吭哧吭哧开始工作了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>大数据分析</tag>
        <tag>storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DockerFile创建一个nginx容器的全过程]]></title>
    <url>%2F2018%2F02%2F25%2FDockerFile%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AAnginx%E5%AE%B9%E5%99%A8%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[创建容器首先，随便建立一个文件夹，比如先mkdir sample，然后我在这个sample文件夹里建立一个Dockerfile，内容如下： 12345678FROM ubuntu:14.04MAINTAINER Chris Chan "chenx1242@163.com"ENV REFRESHED_AT 2016-12-05RUN apt-get -y update &amp;&amp; apt-get install -y nginxRUN mkdir -p /var/www/html/websiteADD nginx/global.conf /etc/nginx/conf.d/ADD nginx/nginx.conf /etc/nginx/nginx.confEXPOSE 80 从这个Dockfile里面看出：我们使用了ubuntu的基础镜像，然后下载了nginx，同时建立一个/var/www/html/website文件夹，然后又拷贝了宿主机上的两个文件，一个是global.conf，另一个是nginx.conf，这两个文件需要我们自己写。于是我们就要在sample下再建立一个叫nginx的文件夹，里面写上这两个文件，其中global.conf的内容如下： 12345678server &#123; listen 0.0.0.0:80; server_name _; root /var/www/html/website; index index.html index.htm; access_log /var/log/nginx/default_access.log; error_log /var/log/nginx/default_error.log;&#125; 而nginx.conf的内容如下： 123456789101112131415161718user www-data;worker_processes 4;pid /run/nginx.pid;events &#123; &#125;http &#123; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; gzip on; gzip_disable "msie6"; include /etc/nginx/conf.d/*.conf;&#125; 全部搞定之后，我们就来build这个镜像，比如这个镜像名叫做chentest/nginx001，在sample文件夹里使用的命令语句就是：docker build -t=&#39;chentest/nginx001&#39; .。 一顿七七八八之后，显示OK，docker ps -a就会显示我们新建的镜像，如图： 有了镜像，再在sample文件夹里新增一个文件夹，比如就叫webiste，里面有一个文件叫index.html。而index.html的内容如下： 1this is a nginxtest page. 保存退出之后，返回到sample目录。 现在我们可以制作一个容器了，制作容器命令是docker run -d -p 8080:80 --name test02 -v $PWD/website:/var/www/html/website chentest/nginx001 nginx -g &quot;daemon off;&quot;,这句话里规定容器的8080端口映射到宿主机的80端口，同时引入了当前目录的website目录到容器的/var/www/html/website目录，nginx也默认在前台进程进行。执行之后，docker ps -a看一下： 看见port这一栏已经显示8080与80端口的相勾结成功，于是我们可以登录这台机器的80端口看一下。 而如果现在我更改一下上面的index.html，改成另外一句话。比如说改成“why so serious??”,保存文件之后，直接刷新网页，就会看到网页的内容已经发生了变化，如图： 可见引入-v这个命令在容器里，可以随时调试内容，而不是每次都要重新打包生成镜像。这一点再调试阶段为我们提供了很大的方便。 docker端口映射的问题docker run命令里指定端口的格式是-p 容器端口:宿主机端口。如果想要随机指定就是大写的P。如图： 这里就是随机分配了一个32775端口给宿主机，访问的时候也是要访问这个32775端口。 有时候port这里却不显示端口映射的情况，如图： 这个情况是因为这个容器的status是exited，docker会在容器主进程结束后自动终止容器运行，而nginx启动后就会在后台运行，docker以为nginx已经结束运行了，所以就会停止容器。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DockerFile创建一个redis容器的全过程]]></title>
    <url>%2F2018%2F02%2F25%2FDockerFile%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AAredis%E5%AE%B9%E5%99%A8%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[正文本次目标是用Centos 7的基础镜像做一个redis容器供开发人员在开发环境里蹂躏。 首先，创建一个叫redis-test的文件夹，在这个redis-test文件夹里建立一个Dockerfile，内容如下： 1234567FROM centos:latestMAINTAINER Chris Chan "chenx1242@163.com"ENV REFRESHED_AT 2017-02-16RUN yum -y update &amp;&amp; yum -y install epel-release &amp;&amp; yum -y install redis &amp;&amp; yum -y install net-toolsEXPOSE 6379ENTRYPOINT [ "/usr/bin/redis-server" ]CMD [] 这里我们简单说一下整个Dockerfile的内容： 首先选择了基础镜像是centos的最新版，即centos 7，然后填写作者信息； 在yum这一块要注意，如果没有安装epel-release的话，是无法正常安装redis的，这是centos与ubuntu不一样的地方。至于后面又补充安装了net-tools是因为centos 7里不自带ifconfig命令，所以需要安装一下net-tools，这样就有了ifconfig了； 随即我们又开放了6379端口； 然后就是entrypoint和cmd，这两个命令的区别很重要，具体区别请看：http://cloud.51cto.com/art/201411/457338.htm 这篇文章。 然后我们就可以依照这个Dockfile去建立一个镜像，因为目的是要在“centos环境下建立一个redis”，那么我们这个镜像的名字就叫作lccentos/redis，具体操作就是在redis-test文件夹下执行docker build -t lccentos/redis .。 然后根据这个镜像需要制作一个容器，容器的名字就叫redisforcentos，那么命令就是：docker run -d -p 6379 --name redisforcentos lccentos/redis。 然后我们docker ps -a看一下效果，如下： 可见宿主机的32774端口和容器的6379端口“融为一体”，这个时候，我们测试一下这个redisforcentos的容器是否已经正常启动了redis，如图： 而且对于Docker来说，可以多个docker对应宿主机的同一个端口，比如我这台机器搞了两个redis，两个容器都可以指向6379的端口，如图： Dockerfile的优化原则1）ADD和VOLUME应该放在Dockerfile底部，因为它们相对比yum安装那些变化的更勤；2）EXPOSE可以一口气对应多个端口，比如EXPOSE 80 2003 2004 7002的效果跟下面的效果一样； 1234EXPOSE 80 EXPOSE 2003 EXPOSE 2004 EXPOSE 7002 3）ADD的操作应该放在Dockerfile的最下面； 参考资料http://dockone.io/article/255?spm=5176.100239.blogcont40494.25.8RXqDX]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云获取DTS服务延迟值的脚本]]></title>
    <url>%2F2018%2F02%2F24%2F%E9%98%BF%E9%87%8C%E4%BA%91%E8%8E%B7%E5%8F%96DTS%E6%9C%8D%E5%8A%A1%E5%BB%B6%E8%BF%9F%E7%9A%84%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[正文春节“嗖”的一下就过完了，在年前领导交代另一个任务，想要每天统计一下在阿里云DTS（数据同步）服务的延迟情况，于是我就要使用阿里云的api去写一个脚本，每小时运行一次，然后将这24个数字输出出来给领导过目。 阿里云dts的sdk包在这里：https://help.aliyun.com/document_detail/57694.html?spm=a2c4g.11186623.6.675.W811bN ，直接点击Python下载即可，不过这个地址经我测试使用非国内IP 地址是打不开的，需要使用国内IP地址下载。 下载完毕之后，上传到linux服务器并解压，解压后的样子如图： 由于我们这次只是查看同步作业状态，所用的py就是DescribeSynchronizationJobStatusRequest.py，现在我们就可以写脚本，假设这个脚本叫getDTS.py,那么整个内容如下： 12345678910111213141516171819202122232425262728#!/usr/bin/env python#coding=utf-8#auther:ChrisChan@2018-2-24#这个脚本是用来获取DTS服务的延迟值from aliyunsdkcore import clientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionimport jsonimport sys #由于这个包不是通过pip install的方式安装,要调用其它路径的python脚本就要使用sys方法sys.path.append('sdk压缩包的绝对路径')import DescribeSynchronizationJobStatusRequest # 创建Client实例clt = client.AcsClient('阿里云AK','阿里云SK','所属地域')# 创建request并设置参数request = DescribeSynchronizationJobStatusRequest.DescribeSynchronizationJobStatusRequest()request.set_accept_format('json')# 写上对应的服务IDrequest.set_SynchronizationJobId("这里写上DTS的ID")response = clt.do_action_with_exception(request)print responsedelay = json.loads(response)print "===================================================="print "当前延迟是：" + str(delay["DataSynchronizationStatus"]["Delay"])print "当前同步速度是：" + str(delay["Performance"]["FLOW"]) 整个脚本执行的效果如下： dts的延迟时间是5秒计算一次，API请求会取到最新的延迟时间，控制台是每隔20秒才刷新一次。 补充getDTS.py这个脚本获取到的response是一个str字符串，这里我使用json.loads来将其转化成了dict模式。但是除了这个方法还有两个方法： 123456789101112&gt;&gt;&gt; user"&#123;'name' : 'jim', 'sex' : 'male', 'age': 18&#125;"&gt;&gt;&gt; b=eval(user)&gt;&gt;&gt; b&#123;'age': 18, 'name': 'jim', 'sex': 'male'&#125;&gt;&gt;&gt; print b['sex']male&gt;&gt;&gt; exec("c="+user)&gt;&gt;&gt; c&#123;'age': 18, 'name': 'jim', 'sex': 'male'&#125; &gt;&gt;&gt; print c['name']jim 但是要注意！上面这两个方法有一定的安全隐患，而且只能全是字符串可用，如果有的value是True、False、Null这样的字眼的话，eval是不支持的，所以没法正确转换，就会爆这样的错：NameError: name &#39;True&#39; is not defined。 参考资料https://help.aliyun.com/document_detail/49453.html?spm=a2c4g.11186623.6.667.sRyVqYhttps://segmentfault.com/q/1010000000174694https://www.crifan.com/resolved_in_python_using_eval_to_force_variable_to_convert_a_string_to_a_dictionary_when_the_error_nameerror_name_39null39_is_not_defined/https://segmentfault.com/q/1010000000345915]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Atlas的几种常见故障解决方法]]></title>
    <url>%2F2018%2F02%2F23%2FAtlas%E7%9A%84%E5%87%A0%E7%A7%8D%E5%B8%B8%E8%A7%81%E6%95%85%E9%9A%9C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[使用atlas却发现“读库闲置，框架还是去主库读写数据”配置完atlas之后，发现使用jdbc框架的话，读库和写库各司其职，但是使用mybatis框架之后，就发现框架的读写都去了主库，把读库放置一边，那么这种情况是因为有事务存在的话，atlas就会强制走主库，遇到这种情况就检查一下是否有事务的存在，比如@Transactional，如果要解决的话，就加上@Transactional(propagation=Propagation.NOT_SUPPORTED)即可。 自动读写分离挺好，但有时候我写完马上就想读，万一主从同步延迟怎么办?SQL语句前增加 /*master*/ 就可以将读请求强制发往主库。在mysql命令行测试该功能时，需要加-c选项，以防mysql客户端过滤掉注释信息。不过这不能从本质上解决问题，使用Atlas需要考虑到这点，提高主机的IO性能，加大memory可以缓解延迟症状，但依旧不能避免延迟的出现，尤其是读多写少的应用。 resource limit的问题atlas有自己的连接池，会吃掉很多CPU, php应用端改用短链接来连接atlas, 这时候atlas对php发送来的sql只负责验证和转发的操作，后端DB的连接由atlas自己管理,未使用的连接线程进行剔除操作(DB的wait_timeout和interactive_timeout设置为300s,超时亦退出)。 1234562014-04-12 20:56:29: (warning) (libevent) event_del: event has no event_base set.2014-04-12 20:56:29: (critical) last message repeated 5 times2014-04-12 20:56:29: (critical) network-conn-pool-lua.c.144: socket() failed: Too many open files (24)2014-04-12 20:56:29: (warning) (libevent) event_del: event has no event_base set.2014-04-12 20:56:30: (debug) chassis-unix-daemon.c:168: 12951 returned: 129512014-04-12 20:56:30: (critical) chassis-unix-daemon.c:196: [angel] PID=12951 died on signal=11 (it used 16 kBytes max) ... waiting 3min before restart 如果MySQL后端的连接数也满了可能会报以下错误: 1232014-11-13 12:21:07: (critical) network_mysqld_proto_password_scramble: assertion `20 == challenge_len' failed2014-11-13 12:21:07: (warning) (libevent) event_del: event has no event_base set.2014-11-13 12:21:07: (critical) 可以临时增加MySQL connection数量: 1echo -n “Max processes=SOFT_LIMIT:HARD_LIMIT” &gt; /proc/`pidof mysqld`/limits 出现Too many open files的错误，怎么办？关于Too many open files错误，可能由两种情况引起:一、php长连接连接到atlas后，每个线程占用一个FD,直到超出系统资源限制而出现too many错误;二、php应用端发送到atlas的sql过多，大量并发的情况下,linevent维护的队列过多，每个event吃一个FD，超出系统资源限制引起Too many open files错误; 避免Too many open files错误,增加用户的ulimit值加大FD的使用量,可增加系统ulimit资源到 ~/.bash_profile文件或/etc/security/limits.conf文件: 123456# cat .bash_profile # .bash_profile......export PATHulimit -n 16384]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>atlas</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何手动释放linux内存]]></title>
    <url>%2F2018%2F02%2F23%2F%E5%A6%82%E4%BD%95%E6%89%8B%E5%8A%A8%E9%87%8A%E6%94%BElinux%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[在生产过程中，一些java模块会比较残忍的吃系统内存，然后如果这个模块写的比较挫，产生的垃圾就会比较多，如果linux系统的内存释放也不会及时，然后恶性循环，最后就把进程卡死，但是服务器是不可以down机的，所以这个时候就需要我们运维出来，手动的释放内存。 首先，我们登陆一台服务器，free -m看一下目前的情况： 然后cat /proc/sys/vm/drop_caches，会看到里面的值是0，0是不释放的意思。 sync,将系统缓存区中的脏数据写入磁盘中，包括已修改的i-node、已延迟的块I/O和读写映射文件。 echo 3 &gt; /proc/sys/vm/drop_caches 为什么这里是3呢？这是因为echo 1的话代表“清理页面缓存”，echo 2的话代表“清理索引节点（inode）链接”，echo 3就是包括上面两者。 sysctl -p,这样不用重启服务器也可以生效。出现下面的一连串文字之后，再free -m看一下： 从112释放到2790，可见效果立竿见影。 上面整个过程的自动化脚本是这样的： 12345678910#!/bin/bash#Author:Chris Chan#E-mail:chen_shuo@dahuatech.comoldmemory=$(free -m|sed -n '2p'|awk '&#123;printf $4&#125;')echo "开始的空余内存值："$oldmemorysyncecho 3 &gt; /proc/sys/vm/drop_cachessysctl -pcorrectmemory=$(free -m|sed -n '2p'|awk '&#123;printf $4&#125;')echo "释放完后的空余内存值："$correctmemory]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回家过年]]></title>
    <url>%2F2018%2F02%2F21%2F%E5%9B%9E%E5%AE%B6%2F</url>
    <content type="text"><![CDATA[我承认我是一个很恋家的人，但是我在3年之前还不是这样。 我记得我在哈尔滨上大学的时候，虽然坐火车也就一个半小时的时间，但是是“能不回家就不回家”，哪怕自己一个人蹲在寝室也是自由舒服，后来上班，我也是有很长的时间自己独住，只有周末才回去一次。那时候我奶不止一次的批评我“都快成一个客人了”。 真的应了那句传烂了的话“只有失去的才是美好的”，现在我人在杭州，天天忙成狗。最欢喜的事情第一个是涨工资，第二个是发工资，第三个是放假，第四个就是放假回家。当初的我总是忽略家庭的温暖，在家里逗留的时间不长，现在却倍感珍惜回家的机会，唉，那几年真是简单的可笑。 这一次回家过年看到了许许多多亲人：生病的大姨夫的精神状态也好了许多，不过他这次回来又害了一次发烧；小外甥和他那婴儿肥的脸蛋，在《守望先锋》里越死越勇；我那几个弟弟们全都瘦了也更精神了，从我妈和女票看我的眼神里，我觉得我的体重是应该好好管控一下了：体型太腐败。 短短的六天时间，吃完三姨家吃四姨家，吃完老叔家吃小舅家，总之就是带着女票游走于各种亲戚家。中途还抽空跟龙南数据班的几个老同事一起吃了顿“一口猪”，主要也是带我女票看看东北菜，看上去我这几个老同事们都过得很不错，至少几杯酒下去均红光满面，依旧插科打屁、大呼小叫。这次过年唯一可惜的是，没有给四姨夫装上翻墙软件，害得他要继续挠墙忍耐。 我吃我妈的菜已经吃了30年，但是这次过年真正在家里吃饭仅仅只有一顿。我妈烧了虾，做了孜然羊肉，而且煮了酸菜馅饺子。这都是我爱吃的，杭州的确能吃到很多美味，但我妈的手艺却是独一份儿。我跟我爹依旧话不算多，但是关系却比之前好了许多倍。有可能是我现在比以前有了一点进步，让我爸看起来顺眼了一点，这一次回家没有跟我爸单独喝上酒，但是他有几顿喝的很开心。看到他俩这个年过得快乐满足，我这个做儿子的，心底涌起了最大的温暖。 离开家的时候，依旧是箱子沉沉，里面有爸妈装的许多东西，有给我的也有给我女票她妈的，每一个东西都是代表了他们的心思。其实家中长辈身体健康、心情愉悦，就是给我们这些在外的儿女最大的宽慰了。假期就这样结束了，我也马上要踏上回杭州的航班，希望家里所有长辈都平平安安，也希望我今年能够达到自己给自己定下的目标！]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>春节</tag>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中国梦，宪政梦]]></title>
    <url>%2F2018%2F02%2F13%2F%E4%B8%AD%E5%9B%BD%E6%A2%A6%EF%BC%8C%E5%AE%AA%E6%94%BF%E6%A2%A6%2F</url>
    <content type="text"><![CDATA[本文原作者：《南方周末》评论部编辑戴志勇 天地之间，时间绽放。 这是我们在2013年的第一次相见，愿你被梦想点亮。 2012年，你守护自己的生活，他们守护自己的工作。守护这份工作，就是在守护他们对生活的梦想。 2012年，庙堂之上发出的宪政强音嗡然回响：”宪法的生命在于实施，宪法的权威也在于实施。”我们期待宪法长出牙齿，宪政早日落地。惟如此，才能成就这个沧桑古国的艰难转型；惟如此，国家与人民，才能重新站立于坚实的大地之上。 今天，已是能够梦想的中国，今天，已是兑现梦想的时代。经历过宪政缺失的”文革”梦魇，我们花费三十多年的时间来逐渐回归常理与常情。从土地联产承包责任制到个体户、乡镇企业到”民企”，稍稍归还国人自主安排生活的权利，我们便创造了繁华城市，收获了满仓粮食。 我们重新体认什么是真，什么是假，是其是，非其非；我们重燃对公义的热爱，对自由的向往。面对暴虐强力，我们双手相握，一起走过艰难时刻，迎接生活转机。 今天，我们终于可以从厚厚的历史尘埃中挺起胸，从琐碎的日常生活中抬起头，重走先辈的宪政长征，重温先辈的伟大梦想。 一百七十多年前，我们开始从天朝上国的迷梦中醒来。先败于英，后败于日。百姓愈加民不聊生，耻感深深刺痛中国士人。保国！保种！由洋务而君宪，由立宪而革命。从器物到制度再至文化，激愤者不惜彻底打倒”孔家店”，决绝地将自己的文明连根拔起。 辛亥革命后，清帝退位，先辈们终于建立了亚洲第一个共和国。但是，一个自由、民主、富强的宪政中国并没有随之而来。 国家内外，战争连连；人群内外，残酷不断。 一度，人们远离仁，远离义，远离天道，远离对自由的坚守。 一度，人们认错为对，指鹿为马，万千生灵生机断绝。 美梦与山河，齐齐破碎。自由与宪政，双双消隐。 度尽人世劫波，深味人性幽暗，我们依然是能做梦的人，有颗能做梦的心。 今天，我们断断不只梦想物质丰盛，更希望性灵充盈；我们断断不只梦想国力能强盛，更希望国民有自尊。新民和新国，救亡与启蒙，谁也离不开谁，谁也不能压倒谁。而宪政便是这一切美梦的根基。 兑现宪政，坚守权利，人人才能心如日月流光溢彩；鳏寡孤独才能感受冬日暖意而非瑟瑟发抖；”城管”与小贩才能谈笑风生；房屋才能成为自己与家人的城堡； 兑现宪政，限权分权，公民们才能大声说出对公权力的批评；每个人才能依内心信仰自由生活；我们才能建成一个自由的强大国家。 兑现宪政大梦，每个人才能做好个人的美梦。而这需要我们就从手边做起，就从守护此时此刻的生活做起，而不要将重任留给子孙。 很多人一直深深懂得这一点，很多人早就努力践行这一点。 不是杰出者才做梦，是善于做梦者才杰出。 你的天赋权利就是可以梦想，并且兑现梦想！ 为你的梦想鼓掌，为这个国家的梦想加油，这就是很多新闻人的梦想，是他们不大不小的野心。他们忠于新闻，更忠于内心。愿你也有个玫瑰色的美梦；自由成就自己，完成天之所赋。 总会梦想人人都可以做一个有尊严的人，不论身居高位，还是街头卖艺； 总会梦想人人内心有爱，即使罪犯也未必穷凶极恶，总有恻隐之心自由闪动； 总会梦想阶层只是引人自由流动的动力，而不再是相互猜忌和仇视的天堑；总会梦想这五千年文明生生不息，为改善人类的现代处境，捧出一掬甘冽清泉…… 兑现这一千一万个梦想，才能抚平这一百多年的刻骨痛楚。 兜兜转转一百七十年，美梦成真何其难！一百七十年后，依然有人渴望良知萌新芽，重温天命之谓性；依然有人坚持要求权利一一落地，政治复归于正，公义自在流淌。 依然有人相信，不管多难，梦想终会落实为宪政良制，风行为敦敦美俗。 先辈们筚路蓝缕，践义成仁。如今，后人承继其志，燃灯前行。 兑现梦想，自然要借鉴前贤智慧，与古人的信仰、习俗和情感和解。儒释道法墨，百家皆是源泉；周汉唐宋明，代代皆有可取。 但这决不是要复古，古人不能给予今天所需的一切。只是不再轻易贬损先辈，平心静气地吸收转进，以让中华文明开新花，结新果。 兑现梦想，自然要吸取世界经验。所以要认真审视希腊民主，罗马法治，借鉴英美宪政，追赶现代科技文明。 但这也不是仅仅作一个西方文明的优等生，西人有西人演进的轨迹，同样未必能直接给予我们今天所需的一切。 我们要站在自己的大地上，与各国人民一起，生活出一种古今相融的新生活，文明出一种中西合璧的新文明。在古今中西的激荡中，要遵循人类共通的价值，也要不惮于做自己的新梦。 称美古人，赞扬邻居，不是因为他们足够完美，而是因为我们熟悉他们眼中洋溢的快乐，心底流淌的自由。 中国人本应就是自由人。中国梦本应就是宪政梦。 宪政之下，才能国家持续强盛，宪政之下，才有人民真正强大。兑现宪政梦想，才能更好地外争国权，维护国家的自由；才能更好地内争民权，维护人民的自由。而国家的自由最终必得落脚于人民的自由，必得落脚于人人可以我口说我心，人人可以用心做美梦。 生而为人，谁能不热爱自由？这自由，不仅是权利针对权力而言，也是宽恕针对报复而言，是般若针对无明而言，是仁爱针对暴虐而言，是有道针对无道而言。 大道之行，天下为公；万物自在，各正性命。这就是古人的梦想，先辈的梦想，也是今天很多人的梦想。 中国梦，自由梦，宪政梦。 万物速朽，但梦想永在。万物诞生，因梦想不灭。梦想就是生生之几，就是当你失败了一百次，那第一百零一次充实你内心的不死之希望。 依然有人倾听你的梦想，期待你敢于做梦。你从苦难中爬起，他们为你加油；你尝尽人世冷暖，他们为你加油；你收获美好生活，他们为你加油……他们别无所资，惟有对梦想的执着；他们别无所长，惟有对真相的追求。 一句真话能比整个世界还重，一个梦想能让生命迸射光芒！]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>中国政治</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于logrotate的额外补充]]></title>
    <url>%2F2018%2F02%2F12%2F%E5%85%B3%E4%BA%8Elogrotate%E7%9A%84%E9%A2%9D%E5%A4%96%E8%A1%A5%E5%85%85%2F</url>
    <content type="text"><![CDATA[https://rorschachchan.github.io/2018/02/12/日志文件管理者：Logrotate/ 里面已经简单介绍了logrotate命令，这里还有一些额外补充的东西： 1）查看logrotate对log文件的具体执行情况的语句是cat /var/lib/logrotate.status，效果如图： 2）使用-v或-d参数时，显示log does not need rotating，这是因为logrotate在对status未记录的文件进行转储时，会在status添加一条该文件的记录，并将操作时间设为当天。之后程序再次对此文件进行转储时发现这个文件今天已经操作过，就不再进行相关操作。要是想解决这个问题可以使用-s指定logrotate状态文件； 3）分割日志时报错：error: skipping &quot;/var/log/nginx/test.access.log&quot; because parent directory has insecure permissions (It&#39;s world writable or writable by group which is not &quot;root&quot;) Set &quot;su&quot; directive in config file to tell logrotate which user/group should be used for rotation.这是当前用户不是root，需要添加su root list这个语句到对应的logrotate配置文件里，比如： 1234567891011121314151617181920 /var/log/nginx/*.log &#123; su root list #第一句添加 daily missingok rotate 52 compress delaycompress notifempty #ifempty create 0640 www-data adm sharedscripts postrotate [ ! -f /var/run/nginx.pid ] || kill -USR1 `cat /var/run/nginx.pid` endscript &#125;4）如果觉得使用`logrotate`很麻烦，而当某个文件过大的时候，要实现把该文件压缩并且拆成若干个指定大小的文件，怎么办？ ```js tar -zcvf 新文件名.tar.gz 原文件名 | split -b 每个分格包大小 -d -a 1 - 新文件名.tar.gz 比如：tar -zcvf ABC.tar.gz ABC | split -b 4000M -d -a 1 - ABC.tar.gz。这个命令就是把ABC这个文件压缩成ABC.tar.gz，但是如果ABC大于4000M就会切块，切成ABC.tar.gz.0,ABC.tar.gz.1,ABC.tar.gz.2……这个样子。 123//使用split命令，-b 4000M 表示设置每个分割包的大小，单位还是可以k// -d 参数指定生成的分割包后缀为数字的形式//-a x来设定序列的长度(默认值是2)，这里设定序列的长度为1 如果要把这一堆已经切块的文件重新接压缩的命令：cat ABC.tar.gz.* | tar -zxv; 5）如果用kill -HUP来重启一个包含守护进程的进程，比如httpd，一条语句搞定： 1ps -ef | grep httpd | grep -v grep | awk '&#123; print $2; &#125;' | xargs -L 1 sudo kill -HUP 这里面首先用awk获取到httpd的pid进程号，然后把这个进程号传给了xargs，通过-L 1来一次提取一行pid值，然后分批进行kill -HUP; 6）想更多的了解守护进程，参看http://www.cnblogs.com/mickole/p/3188321.html；]]></content>
      <categories>
        <category>技术与工作</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>logrotate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志文件管理者：Logrotate]]></title>
    <url>%2F2018%2F02%2F12%2F%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E8%80%85%EF%BC%9ALogrotate%2F</url>
    <content type="text"><![CDATA[前言服务器在服务运行的时候，难免会生成大量日志，一般来说遇到日志过多的情况，就会写一个看门狗：监控磁盘容量的大小，如果磁盘剩余空间小于某个值，就去日志文件夹里把一个月或者几个月之前的废弃日志删除掉以达到释放磁盘空间的目的。 但是往往有的时候过期的日志很重要，或者即使是一周的时间内，也会生成容量非常可观的日志，那么就需要使用logrotate命令来管理这些日志，这个命令是linux自带的。 logrotate这个命令的用法请看：https://linux.cn/article-8227-1-rel.html和https://linux.cn/article-4126-1.html 。 实验开始首先，假设服务器里某个日志文件夹里的日志auc.log.10是这样的： 然后在logrotate的配置文件是这么写的： 12345678/mnt/hswx/auc/logs/auc.log.10 &#123; 这里是目标日志的绝对路径 daily 每天执行一次 minsize 200M 文件容量大于200M开始处理，如果到了时间但是没有大于200M，不会处理 compress 压缩 dateext 文件会以日期为后缀 create 777 root root 新建的那个日志文件属性是777 rotate 2 保留最多2个文件&#125; 然后执行logrotate -vf /etc/logrotate.conf，看到的效果是： 命令执行后，服务器create了新的auc.log.10，而且属性变成了777，同时把原有的部分压缩成gz的格式。 上面那个测试的对象是已经过期的日志，现在我们要压缩当前的日志，目的是在压缩了auc.log并且重命名之后，可以生成新的auc.log，同时这个新的auc.log会被写入。 现在我们尝试一下，把原来的配置文件改成这样： 123456/mnt/hswx/auc/logs/auc.log &#123; weekly minsize 200M compress rotate 2&#125; 但是执行之后，我们发现变成了这样： 原来的auc.log不见了，而出现的auc.log.1里面的内容是原来auc.log的内容，可见原有的auc.log已经被顶掉了。这是因为我们上面的配置文件里面没有加上dateext，所以默认会以.1、.2、.3为后缀。 问题是我们没有生成auc.log，那么这段时间的日志就会找不到auc.log而凭空消失。可见这个方法没有达到我们的目的，需要改进。 改进之后我们这个内部模块auc只有重新启动这个进程才会生成auc.log，既然要解决这样的问题，我们很自然的就想到kill -HUP这种平滑启动的方式，但是要注意！kill -HUP对deamon会进行重新读取配置启动，但是对于普通的进程只会把其杀死！而这个auc就是一个普通的java程序，没有配套的守护进程。所以只能使用一般的重启方式来达到生成auc.log这个目的。 首先我们把原来的配置文件改成这样： 1234567891011/mnt/hswx/auc/logs/auc.log &#123; weekly #每周执行 dateext #以日期作为后缀 minsize 200M #到达了200M自动执行，不然即使到了一周的时间也不执行 compress #压缩 rotate 2 #最多保留两个文件 sharedsripts postrotate #在执行完日志压缩之后就执行如下动作 /bin/bash /root/restart.sh #动作就是执行这个绝对路径的脚本 endscript #收工&#125; 而这个restart.sh的内容很简单: 1234#!/bin/bashcd /mnt &amp;&amp; ./stopAUC.sh #停止auc进程cd /mnt &amp;&amp; ./startAUC.sh #启动auc进程echo HAHAHAHA！！！ #表示已经OK了，让我们发出杠铃一般的笑声 现在我们重新跑一下logrotate，logrotate -vf /etc/logrotate.conf。看一下效果： 可以看到先把日志改名压缩，完事后也执行了restart.sh这个脚本，再日志里一看，auc.log也顺利生成了！ 参考资料http://www.pythondev.org/post/8.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>运维技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个暗藏杀机的脚本]]></title>
    <url>%2F2018%2F02%2F11%2F%E4%B8%80%E4%B8%AA%E6%9A%97%E8%97%8F%E6%9D%80%E6%9C%BA%E7%9A%84%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[脚本背景老总最近总是发现某台relay服务器的CPU值会突然彪很高，于是勒令几位工程师检查问题，但是工程师一时半会也想不到究竟是什么程序这么耗费CPU，于是就委托运维写一个脚本，具体要求是这样的：每隔一秒钟输出一下top命令的前十二行情况（其实就是配置总览和耗费cpu前五名程序情况），将这些情况保存到一个文件里，如果这个文件大于500MB，就把这个文件删除（为啥要删除？我也不知道），重新再生成一个文件用来保存top命令结果。 分析由于脚本无法自己跳出运行并检查自己的大小，所以这个任务需要两个脚本，一个是单纯的把top命令重定向到一个文件（recordTOP.sh），另一个脚本就是一个if判断大小（checksize.sh）。再加上crontab每一天一检查（其实完全没必要，500MB足够top这个命令跑5天的），应该可以满足开发人员的需求。 脚本内容获取top.txt的脚本recordTOP.sh如下： 12345678910#!/bin/bash#written by ChenShuo @2016-8-15#Desription:每一秒钟记录一次top命令里占用cpu前五程序while true do $(top -bn 1 | head -12 &gt;&gt; /root/top.txt) echo "------------------------------------------------" &gt;&gt; /root/top.txt sleep 1 done 判断top.txt大小的脚本checksize.sh如下： 12345678910#!/bin/bash#written by ChenShuo @2016-8-15#Desription:当recordTOP.sh文件大小超过500MB的时候将会重新覆盖size=$(ls -l | grep top.txt |cut -d " " -f 5)if [[ $size -ge 536870912 ]] then $(ps -ef|grep recordTOP.sh|grep -v grep|awk '&#123;print $2&#125;'|xargs kill -9) $(rm -rf /root/top.txt) bash /root/recordTOP.sh &amp; fi crontab这一步我就略掉不写了。 补充说明1）top不可以直接重定向，如果是top &gt; 123.txt，它将会不断的导入，因为top就是一个实时更新的命令，所以这里要用top -bn 1|head 12 &gt;&gt; /top.txt； 2）shell脚本里调用shell，不能采用$()的方法了，因为$()是一个返回值，而.sh是一个不断进行的脚本，所以要用bash +脚本名的方式； 3）recordTOP.sh这个脚本是可以同时存在多个的，但是如果不小心后台启动多个，用checksize脚本ps -ef语句就会报错，因为获得到的不是一个数字，而是多个数字，没法一波kill掉。同理，直接调用checksize也会报错，因为没有ps -ef的值； 4）因为是要先关闭原来的top重定向脚本，所以才用了保守的ps -ef，然后kill的方式，这里不可以使用pkill，因为pkill是干掉整个类型程序，比如pkill -9 java，就是干掉所有java的进程。而在linux里，千万不可以pkill -9 sh，可以想象一下，这个命令的结果就是会从ssh上跳出，同时无法登陆，因为整个sh都被你杀死了。那么真的出现了这个结果怎么办？答曰：重启，重启能救命。 整个执行效果如下，可见top.txt文件是在不断的扩大，由于是测试，我把文件大小调整为20000字节，即大于20000字节就覆盖原文件，当文件大于20000字节的时候，就会把原来的top.txt删除，同时生成一个新的top.txt。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>top</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http返回码是000...]]></title>
    <url>%2F2018%2F02%2F11%2Fhttp%E8%BF%94%E5%9B%9E%E7%A0%81%E6%98%AF000%2F</url>
    <content type="text"><![CDATA[正文今天开发童鞋在测试往一个网站发请求的时候，发现返回码是000，如图： 众所周知，常见的返回码是以下四种： 12342XX 成功；3XX 重定向；4XX 客户端错误；5XX 服务器端错误； 但是000是啥玩意？简单的说就是没有有效的http状态码，比如连接被拒绝，连接超时等。 使用curl -w &quot;%{http_code}\n&quot; -m 5 https://60.191.94.115:38303/cloudSignalling/events/deviceState ; echo &quot;Exit code: $?看一下详细的code，显示如图： 可以看到提示：curl: (60) Peer certificate cannot be authenticated with known CA certificates，翻译过来就是对方的证书不能用已知的CA证书验证。但是下面也说了可以用-k或者--insecure来跳过这一步。 于是我又使用curl -I -k https://60.191.94.115:38303/cloudSignalling/events/deviceState这个命令，效果如图： 里面这一下说的就很明白了，405，方法不正确，再搭配一下curl -k -w &quot;%{http_code}\n&quot; -m 5 https://60.191.94.115:38303/cloudSignalling/events/deviceState，看一下： 这么上下一结合，明白了GET是不准许的，准许POST。于是反馈给60.191.94.115告诉他们把前后台接口请求方式、参数传递方式都拿回去整改。 参考资料http://www.1987.name/365.htmlhttps://superuser.com/questions/501690/curl-http-code-of-000]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将redis加入到elk日志系统里]]></title>
    <url>%2F2018%2F02%2F09%2F%E5%B0%86redis%E5%8A%A0%E5%85%A5%E5%88%B0elk%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E9%87%8C%2F</url>
    <content type="text"><![CDATA[之前在https://rorschachchan.github.io/2018/01/16/记录日志系统ELKB-5-6-4的搭建过程/里面，我画的那个架构图里说了整个架构可以加入redis，但是在文章里我没有写到redis怎么加进去。为了让整个系统更好的分层，是非常建议引入Redis的，毕竟Redis服务器是logstash官方推荐的broker选择。Redis作为一个缓存，能够帮助我们在主节点上屏蔽掉多个从节点之间不同日志文件的差异，负责管理日志端（从节点）的人可以专注于向 Redis 里生产数据，而负责数据分析聚合端的人则可以专注于从Redis内消费数据。所以这一次实验要把redis加进去，同时也要部署一个nginx，让elk再去采集nginx的日志。 整个架构图图下： 部署redis安装redis的方法请去看http://blog.51cto.com/chenx1242/1793895，我这里使用的redis版本是4.0.6，在执行make test的时候可能会有如下的错误： 那就安装新一点的tcl吧，方法如下： 12345wget http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gztar xzvf tcl8.6.1-src.tar.gz -C /usr/local/cd /usr/local/tcl8.6.1/unix/./configuremake &amp;&amp; make install 然后重新去make test就会看到成功的字样，如图： 现在redis的漏洞比较多，大多数就是因为密码太简单导致的，所以把redis密码改一下，在redis.conf里，改成如下的样子： 123456789bind 内网IP地址 127.0.0.1 ###仅允许内网和本机访问protected-mode yes ###保护模式开启port 6379 ###端口默认为6379，按需修改daemonize yes ###守护模式开启pidfile /usr/local/redis/redis.pid ###指定pid文件路径和文件名logfile "/usr/local/redis/redis.log" ###指定日志文件路径和文件名dbfilename redis.rdb ###指定数据文件RDB文件名dir /usr/local/redis/ ###指定数据文件RDB文件的存放路径requirepass 『YOURPASSWORD』 ###设置访问密码，提升密码强度 保存之后启动redis即可。 如果redis是主从配置，若master配置了密码则slave也要配置相应的密码参数否则无法进行正常复制的。需要在slave的redis.conf里找到#masterauth mstpassword，去掉注释，也改成跟master一样的密码，重启一下即可。 nginx的安装这里就不写了，直接看http://www.runoob.com/linux/nginx-install-setup.html这个就行了。 安装x-packx-pack是elk官方提供的认证授权插件，安装方法很简单，分别找到下面三个文件，然后后面加上install x-pack即可： 123./elasticsearch-plugin install x-pack --batch ./logstash-plugin install x-pack ./kibana-plugin install x-pack 如果要查看已经安装的插件，那就是： 1234[root@chen-elk-001 bin]# ./elasticsearch-plugin listx-pack[root@chen-elk-001 bin]# ./kibana-plugin listx-pack@5.6.4 如果kibana-plugin要卸载x-pack，那就是：./kibana-plugin remove x-pack。 重启服务即可登录，默认的登录用户名: elastic，密码:changeme。 这里注意一下，./logstash-plugin install x-pack的时候可能是出现ruby源的错误，如图： 这是因为中国特色社会主义的网络限制访问https://rubygems.org，一般来说，可以把它更改成阿里的ruby源https://ruby.taobao.org/，不过如果你的服务器无法跨越长城的话，那么更改也是不好使的，所以在这一步，我选择离线安装x-pack。也就是先把https://artifacts.elastic.co/downloads/packs/x-pack/x-pack-5.6.4.zip这个文件下载到本地上传到服务器的root文件夹里，然后安装： 123[root@chen-logstash-001 bin]# ./logstash-plugin install file:///root/x-pack-5.6.4.zipInstalling file: /root/x-pack-5.6.4.zipInstall successful 配置filebeat由于这个nginx我们需要先让filebeat把nginx.log和error.log先推到redis存储，然后再由redis推到logstash。配置filebeat.yml的具体信息如下: 1234567891011[root@iZbp10hw6wezxmrvrcjyhlZ filebeat]# grep -iv '#' /etc/filebeat/filebeat.yml | grep -iv '^$'filebeat.prospectors:- input_type: log paths: - /usr/local/nginx/logs/*.log #这里是nginx的日志文件夹 output.redis: #以下这部分都是新加的 enabled: true hosts: ["127.0.0.1:6379"] key: logindexer_list #与redis配置文件里的key遥相呼应 password: 『YOURPASSWORD』 #跟上面的密码遥相呼应 配置完毕之后，启动filebeat，命令语句：/etc/init.d/filebeat start -c /etc/filebeat/filebeat.yml。 配置logstash由于这台logstash已经开启了一个logstash进程，那么再收集nginx的日志需要新开一个logstash进程，也需要新写一个conf文件，假设新的conf文件是nginx-logstash.conf，它的写法如下： 1234567891011121314151617181920212223input &#123; redis &#123; host =&gt; "10.168.173.181" type =&gt; "redis-input" data_type =&gt; "list" key =&gt; "logindexer_list" port =&gt; 6379 password =&gt; "ChenRedi$" &#125;&#125;# filter configration hereoutput &#123; elasticsearch &#123; hosts =&gt; [ "10.162.80.192:9200" ] user =&gt; elastic password =&gt; changeme index =&gt; "nginxlogstash-%&#123;+YYYY.MM.dd&#125;" #这个是新的索引 &#125;stdout &#123; codec =&gt; rubydebug &#125;&#125; 现在logstash不支持多个实例共享一个path.data，所以要在在启动不同实例的时候，命令行里增加--path.data PATH，为不同实例指定不同的路径。启动logstash之后，看到显示如下： 再到nginx的日志看一下，因为logstash里没有做日志的切割，所以是整个一个类似字符串的形式发送了过来： 果然有这样的日志，可见logstash与nginx的redis已经正确连接。在elasticsearch里，使用curl -u 账号密码 &#39;localhost:9200/_cat/indices?v&#39;查询索引的时候，就会看到那个nginxlogstash，如图： 参考资料https://doc.yonyoucloud.com/doc/logstash-best-practice-cn/input/redis.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>elk</tag>
        <tag>大数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql-Atlas从库始终没有建立连接怎么办]]></title>
    <url>%2F2018%2F02%2F09%2FMysql-Atlas%E4%BB%8E%E5%BA%93%E5%A7%8B%E7%BB%88%E6%B2%A1%E6%9C%89%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5%E6%80%8E%E4%B9%88%E5%8A%9E%2F</url>
    <content type="text"><![CDATA[最近发现阿里云线上环境有一台hls模块的数据库从库一直没有连接，而主库却一直连接不断。在阿里云控制后台看到连接情况如下图： 上图是主库的，下面那个是从库的，两者差距很大，可见这样的配置是错误的，因为读库根本没有使用，也就是说读库的那份钱是在浪费！ 来到对应的atlas服务器查看配置，看到atlas 的配置里规定管理接口的用户名和密码是默认的原始套餐，端口被改成了2346，如下面， 于是我们就在模块服务器（也就是图里的online-hls-001)上登录这个atlas服务器的管理端口，看一下效果： 发现mysql根本没有反应，可当我们telnet去atlas的2346端口的时候，发现端口是通的： 于是我们返回到atlas 的配置文件，把这台hls模块服务器的ip地址添加到clients-ips这个字段里。 然后再用hls服务器去测试一下atlas的管理端口，mysql -hatlas服务器ip地址 -uuser -ppwd，然后使用select * from backends;,发现里面的两个库一个连接成功，另一个是失败的： 两个库都可以ping通，state却有这样的差别。由此可见这台atlas根本没有连接到从库，导致从库的连接数始终为0。这个时候我们就要检查从库配置的账号密码是否正确，而且在阿里云控制后台给从库开启这个atlas的白名单，然后重新启动这个mysql-proxy进程，再登录atlas管理端口查看，发现从库由down转up了： 但是此时的atlas日志里却出现了很多forbidden的warning的提示： 这时候我们返回atlas的配置文件，把之前的修改过的client-ips这个字段注释掉，让所有合法ip都连接，然后重启atlas，这样这种forbidden ip的警告日志就会消失。 稍等一会，就会看到从库上也会出现连接数了，至此一切恢复到正常状态，故障排除！ 本次故障排除感谢https://highdb.com/?s=atlas这位大神的帮助！ 文末补充数据库访问使用了事务的话，从库也会建立连接，只是连接量要小于“非事务访问”，而不是一点连接都没有。 一般来说，在atlas配置文件里，主库写一个，而从库最好把主库和从库都写进去，如果希望从库承担读的任务多一点的话，可以把权重调高，比如我想从库与主库的读任务比是2：1，那么就可以这么写： 1234#Atlas后端连接的MySQL主库的IP和端口，可设置多项，用逗号分隔proxy-backend-addresses = 主库地址:3306#Atlas后端连接的MySQL从库的IP和端口，@后面的数字代表权重，用来作负载均衡，若省略则默认为1，可设置多项，用逗号分隔proxy-read-only-backend-addresses = 从库地址:3306@2,主库地址:3306@1]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>读写分离中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[脚本里添加crontab的方法]]></title>
    <url>%2F2018%2F02%2F08%2F%E8%84%9A%E6%9C%AC%E9%87%8C%E6%B7%BB%E5%8A%A0crontab%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一般来说，增加计划任务都是crontab -e，然后在里面添加内容。但是在一些脚本里，需要自动添加，那么这种情况怎么办？ 第一种方法重定向crontab到其他文件： 123crontab -l &gt; crontab.bakecho "*/1 * * * * ./yourscript &gt; /dev/null 2&gt;&amp;1" &gt;&gt; crontab.bakcrontab crontab.bak 如果想删除某个计划任务，就进去crontab -e删除就好，crontab.bak不用管，不用担心内容会自动变成crontab.bak的样子。 第二种方法如果你觉得使用crontab 文件这种方法心里没有底的话，就选择最妥善的方式，也就是下面这样： 1echo "*/1 * * * * ./yourscript &gt; /dev/null 2&gt;&amp;1" &gt;&gt; /var/spool/cron/root 当crontab突然失效时，可以尝试/etc/init.d/crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>crontab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在百花之中干掉一个杂草连接...]]></title>
    <url>%2F2018%2F02%2F08%2F%E5%9C%A8%E7%99%BE%E8%8A%B1%E4%B9%8B%E4%B8%AD%E5%B9%B2%E6%8E%89%E4%B8%80%E4%B8%AA%E6%9D%82%E8%8D%89%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[正文早上接到阿里云的服务器报警，说有一台服务器的流量超标，这个服务器的外网带宽是5M，但是登陆进去使用iftop -i eth1发现里面的流量已经几乎跑满，如图： 我这个服务器的名称叫online-mts-001，为啥会有一个mail25.u.tsender.com，这个是什么鬼？莫非是通过我的服务器去连接这个“邮箱”域名？于是我就ping了一下这个mail25.u.tsender.com，结果如图： 看到这个域名对应的ip地址是115.29.177.8，嗯，115.29.177.8，哎？这个ip地址好熟悉啊，卧槽，这特么不是这个online-mts-001的外网ip么？ 也就是说我这个机器在我不知道的情况下被人绑定了一个域名！但是我这个服务器不是网页服务器，上面那个tsender.com的域名打不开，我检查了服务器一番，发现这个机器没有被人入侵的痕迹，只能说是被人有意/无意（无意的可能性更大，比如看错了阿拉伯数字）绑定了域名。 被人绑定了域名就好比被人起了外号一样，一旦非本人操作就不太好往下摘了，查了很多资料都没有办法，毕竟主动权不在我这里了。 但是回头过来，我们的重心是要解决那个占据了3M带宽的连接，netstat看了一下，发现这个连接的具体信息如下： 仅仅是干掉连接的话，方法有很多，关闭网卡再重开或者关闭相应的服务都可以，但是现在的问题是这台服务器是生产环境的服务器，它主要是给用户提供视频拉流，通过抓包分析得知，这位183.228.128.188的用户合法通过外网连接到了这台视频服务器，而且拉取的是高清视频，所以才占据了这么大的带宽。不过我们还是决定先断开这位用户的连接同时不动其他用户的连接，这位183.228.128.188的用户在客户端虽然会发觉视频断开，但是有缓存和人为刷新的客观因素，实际的体验不会差太多，至少不会投诉400… 那么如何干掉一个established连接同时保证其他连接呢？请使用tcpkill。 tcpkill的下载比较有说法，下面是安装步骤： 1234567wget http://rpm.repo.onapp.com/ramdisk-hv/centos6/dsniff/libnids-1.24-1.el6.x86_64.rpmwget http://rpm.repo.onapp.com/ramdisk-hv/centos6/dsniff/libnet-1.1.5-1.el6.x86_64.rpmwget http://rpm.repo.onapp.com/ramdisk-hv/centos6/dsniff/dsniff-2.4-0.14.b1.el6.x86_64.rpmyum install libICE libSM libXmu -yrpm -ivh libnet-1.1.5-1.el6.x86_64.rpmrpm -ivh libnids-1.24-1.el6.x86_64.rpm rpm -ivh dsniff-2.4-0.14.b1.el6.x86_64.rpm 请按顺序操作，不然的话dsniff就会报错： 1234warning: dsniff-2.4-0.14.b1.el6.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 0608b895: NOKEYerror: Failed dependencies:libnet.so.1()(64bit) is needed by dsniff-2.4-0.14.b1.el6.x86_64libnids.so.1.24()(64bit) is needed by dsniff-2.4-0.14.b1.el6.x86_64 安装完毕之后，就会生成tcpkill命令，如图： 然后断开上面那个大带宽连接的命令是：./tcpkill -i eth0 src port 9132 and dst port 9595 and src host 115.29.177.8 dst host 183.228.128.188或者./tcpkill -s 115.29.177.8:9132 -d 183.228.128.188:9595。 但是要注意一下！tcpkill一定要运行在能接收到应答包的主机上在，最好运行在连接或半连接存在的一端主机上，因为tcpkill会发现这个连接里有数据传输进而感知并且干掉。而且tcpkill默认情况下是只能干掉established状态的连接，对于假死连接（连接在，但是数据不传输）或者半连接（由于tcp keeplive没打开而又没有数据向对端发送，导致一直无法感知次连接其实已经断开）是无法断开的。 如果遇到上述所说的假死连接和半连接就需要手动更改tcpkill的源码，更改原理在https://yq.aliyun.com/articles/59308。 如果使用的系统是ubuntu or debian，还可以使用cutter命令，apt-get install cutter下载即可。使用方法：http://www.cyberciti.biz/tips/cutting-the-tcpip-network-connection-with-cutter.html。 至于第一个问题，怎么把这台服务器上的域名撤除，我倒要好好想想了… 参考资料http://www.cyberciti.biz/howto/question/linux/kill-tcp-connection-using-linux-netstat.phphttp://www.gnutoolbox.com/tcpkill-command/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix里item取值超时怎么办？]]></title>
    <url>%2F2018%2F02%2F08%2FZabbix%E9%87%8Citem%E5%8F%96%E5%80%BC%E8%B6%85%E6%97%B6%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[正文开发同学新开发了一个模块，需要运维监控一下8683\8682\9002这三个端口，于是我就在zabbix里把这三个端口进行了监控，但是却无法返回值，如图： 可见其他的自定义监控项是好使的，偏偏三个监控端口的项都是not-supported。我就进去到item里看看，type of information和data type都是正常的，而且每三十秒一次更新，应该是没有什么问题的。 于是我就去zabbix的server使用zabbix-get去试试，到底是怎么回事儿，使用结果如图： 可见使用zabbix_get是可以取到值的，而且取值都正确，三个正常的端口反馈都是1，而不存在的端口（9002）的反馈是0。可是,我发现使用zabbix_get取值pid是结果秒出，而取值net.tcp.listen则是等了几乎5秒钟才获得结果。那么问题就出在这里了。 调整zabbix_agentd.conf里的Timeout值，把其设定为10，然后重启zabbix进程就OK了。 补充1）https://www.xiaomastack.com/2015/07/03/zabbix_net-tcp-listen/comment-page-1/#comment-319，很多时候端口监听会出错，于是就用自定义键值的方法，但是小马哥博客里的这个方法在centos里是无法启动，zabbix会报语法错误。由于公司的zabbix是2.2版本，等我有时间需要细化一下这个语法。 2）调整unsupport items检查时间的方法是：在Adiministration里选择General然后在右侧下拉菜单里选择Other，然后修改Refresh unsupported items (in sec)的值，这个值得意思是“每多少秒去重新检查一下那些not_supported的值”。 3)这种长时间获取key的行为，很容易导致zabbix unreachable poller processes more than 75 busy这个错误，所以尽可能的不要添加这样的监控，而换用其它的方式。导致zabbix unreachable poller processes more than 75 busy这个错误的另一个原因就是可能有某台zabbix-agent死机了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>运维监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十六年，九个队，一份爱]]></title>
    <url>%2F2018%2F02%2F07%2F%E5%8D%81%E5%85%AD%E5%B9%B4%EF%BC%8C%E4%B9%9D%E4%B8%AA%E9%98%9F%E4%BC%8D%EF%BC%8C%E4%B8%80%E4%BB%BD%E7%88%B1%2F</url>
    <content type="text"><![CDATA[原文地址：https://www.theplayerstribune.com/caron-butler-retiring/ 我妈第一次坐飞机的时候可真心把她吓得不行，我想她那时候肯定对Pat Riley有一些悄悄的不满。 那是2002年NBA选秀后的一天，我们乘Pat Riley派来的球队机飞翔在30000英尺的高空，从威斯康辛出发到佛罗里达的迈阿密热火队报到。我现在一闭上眼也能想起当时我妈妈Mattie坐在一个宽敞的椅子里，时而看看我时而看看窗外，前后张望的样子。她的脸上交织出坐飞机的恐惧，但又很自豪的复杂表情。 “这整个飞机只为我们几个服务的么?”她简直难以置信，要知道整个飞机上的乘客只有我、我的家人和两个热火队的工作代表。 我其实也是觉得如此的不可思议，但是我要管理好自己的神态，让自己显得比较酷。我坐在的位置上，平复自己的心情，保持正常的呼吸。球队代表给我展示了属于Alonzo Mourning和LaPhonso Ellis的专位，这看上去太梦幻了。 我对我母亲说“这一切太梦幻了”。 我一直在告诉我自己，现在我已经是热火队的一份子了。不是我吹牛，我也曾经在康大的时候也坐过飞机去打比赛，但是从来没做过头等舱，这在那个时刻我就坐在这架专机比头等舱还要牛逼的地方。那是Pat Riley级别的仓位。我一直让自己尝试冷静，“Caron，冷静，你很棒，你是个爷们，你要表现的就像以前那样从容。” 当我回忆起来当时的情景，觉得实在太滑稽了。我一直试图去安抚我那位紧张的老妈，而其实我内心的紧张不比她少多少。 这就是16年前我去迈阿密热火队报到的情景，从此开始了我的NBA生涯。如果那时候你跟我说我要在十多年的职业生涯里为9个队伍打球，我想我的表情会跟当时飞机上我的老妈一样。 但是事情就这么发生了，顺其自然，这16年真是一段棒极了的旅行。而今天，我宣布正式从NBA退役。 你知道，我其实很想写一封信给年轻时候的自己，不过我想12岁的我应该压根不会理会这封穿越时空的信。如果他发现信封里没有钞票，可能就会直接把它扔进垃圾桶里。然后会嘲笑我现在的光头并且补上一刀“哥们，你真老”。 但我现在就想告诉你那些让我NBA梦成真的人和故事。而这一切的一切都要从当时热火队总裁Pat Riley开始。 我出生在威斯康星州的拉辛，在18岁之前我没有踏出过那里半步，不过我有听说过芝加哥，也见过有人在迈阿密的海滩上放风筝。除了康涅狄格州那两年，拉辛就是我的全部。大城市？我只有在电影和电视里看到他们的样子。 然后就是参加NBA选秀，不久我就接到Pat Riley总裁的电话，然后我成了迈阿密的一份子，那一切的一切彷佛是发生在我身体之外的。我觉得我可牛逼了，你知道么？我那时候简直是全世界最幸福的人，我准备把人生最好的青春时光投身于职业篮球，我要让家族骄傲，要让整个拉辛骄傲。 但我第一天踏进热火队训练馆的时候迎接我的不是派对，生活也不想在海边抽雪茄那么潇洒，迎接我的是“你的更衣间在这里，你迟到了，你应该早来一个小时的，明天开始训练，对了，你叫啥来着？” 这就是我到训练馆听到的第一句话，这就是热火给我的第一感觉。它让我停止了“从专机到专车，全家在迈阿密的豪华旅行，每个人都以我为豪”的感觉，开始了真刀真枪的训练—-我看到Pat Riley就站在训练场场边，他手上带着总冠军戒指，他很正经的跟你说，马上去好好训练或者从训练馆出去。 迈阿密的纸醉金迷让很多年轻人迷失，不过那种夜生活对我没有什么侵蚀力。我14岁的时候就有了我第一个儿子，我年少的时候可没少蹲过号子，记得我16岁的时候，警察曾经在我学校的储物柜里搜出来了毒品和手枪，我也被拘留了一段时间。我出自黑人街头，小时候经历了很多哥们朋友死掉。所以我没有期待过什么幸福温暖的日子，那时候，篮球是我唯一守护的东西。我尽力的不让那些声色犬马去分散我的注意力。 不过那时候我毕竟还是一个小孩，虽然我心态还算端正，但是我却不知道如何百分百的把精力都投入到训练里去。 最开始的几个月对于我整个职业生涯来说是非常重要的，热火队从一开始培养我的比赛观和胜负观，你把它想像成是一个称之为愿望也好，意志力也好，反正就是一个坚定的信念，我想正是这个信念让我能在NBA待这么久。我们为热火队打球，为Pat Riley总裁和Stan Van教练卖命。他俩教会了我如何正确的身体训练，正确的战术训练，叮嘱我们正确的去准备比赛，告诫我们细节决定成败。而这些都是你每晚在TNT直播中看那些NBA球员时所看不见的。 幸运的是，我很早就领悟到“天赋并没有你想象的那么重要”这个道理，当然，有天赋肯定很赞，但是如果你在比赛里倾尽所有、全力以赴，哪怕你的对手比你能跳能跑，但是你也有很大的几率赢球。钻研，不断地打磨技术，这才是赢球的不二法则。如果有人说“在NBA这么高水平的比赛里，基本功并不是重要”，这话简直就是痴人说梦。 Pat Riley教练会以各种不同的方式教我事情，我永远不会忘记他会在我的更衣柜上留下字条，我会在训练前看到这些字条，上面有些写的是我技术上缺陷和需要进步的地方，有些写的是励志的话语。那虽然只是简单的一两句话的便条，但是每一句话都对我有着绝大的影响，这就是我跟我篮球教父之前所建的秘密联系通道—用我们自己的语言去彼此沟通，正是这每一张字条让我成为了一个更好的篮球选手。多年之后，我转会去了雷霆队。我开始效仿当年Pat Riley给我留字条那样的给Kevin Durant留字条，KD是我的小兄弟。我很惊讶和感激在他的MVP的获奖演讲里他特别提到了这个事儿。但是我看来，我只是做了我的篮球恩师Pat Riley做的事情。 第二年，当我得知被交易去湖人队的时候，我很受伤，我以为Pat Riley跟我在篮球层面的之间是有特殊关系的。我的意思是说，如果我当时在Pat Riley的位置上也会把自己拿去交易Shaq的。如果你看着镜子中自己，然后说你比Shaq对这个队伍更有价值，那我无话可说，因为我实在不想打击你的自尊心。 不过那种失落并没有持续很久啦，这就是在联盟里生存的学费。就像我前面说的，我在拉辛住了十多年，我也希望终老迈阿密。我还记得跟D-Wade、Brian Grant、Eddie Jones、Alonzo这些家伙一起打球的日子，那是一段令人难以置信的学习经历，我会永远记得和那些家伙一起玩的开心时光。但是这就是生意，不久后我就动身出发去洛杉矶报到，身边的人从Dwyane Wade变成了Kobe Bryant，Dwyane Wade是我的铁哥们，但是这个世界也没几个人会拒绝跟Kobe联手。当我到了洛杉矶也就大约一周的时间吧，当初到迈阿密的紧张感觉被我忘个干净。 我仅仅在湖人效力了一个球季就被交易去了华盛顿奇才，有趣的是，那个交易对我来说没什么伤害。我认为那是一个很好的决定，当时的奇才队有很多年轻的充满天赋的选手，我很高兴有机会成为他们的一员。 华盛顿的六年是我一生中最棒的时光，在奇才队我两次入选全明星赛。我和Antawn Jamison、Brendan Haywood、以及当时还没有称呼自己是“Hibachi”的Gilbert Arenas在东部打出了一片天,我永远记得华盛顿人民是多么的热爱那支奇才队。纵然迈阿密和洛杉矶都是超级大城市，但是华盛顿却是我职业生涯效力时间最长的地方，那是我第二个篮球之家。 交易帮助我学习到了篮球生意的真相，我不论到哪个球队，都试图在训练里做一个榜样，就用当初在迈阿密学到的那套。我在健身房里专注训练，总是要求自己做的更好，总是要求自己记住细节。在每一支队伍里我都与队友们打成一片，我的意思是，换做是你整天跟这帮队友们泡在一起，如果你不是太拘谨的话，会很容易融入这个集体的。 不过我毕竟辗转了九个城市，这漂泊的生活对我的家庭来说是很困难的。要知道，我那时仅仅在菲尼克斯就待了一个月左右的时间，我的妻子Andrea又不得不收拾行李搬家去下一站，所以我的孩子们总是在不停的转学转学。我妈–她一直以我为荣，即使我不是比赛中的MVP，但是只要我命中投篮但是没有拿下比赛最佳球员她都会在场边不爽（谢谢你，老妈）。但我也深知，为了我的篮球生涯，其实我的家庭牺牲了很多。 我现在感谢上苍，我依旧活着，这简直是一个奇迹。我现在想谈谈生与死，上周，我回拉辛去参加一个葬礼，那是一个26岁的小伙子，从他的车上逃离的时候被警察连开数枪。我本人不认识他，但是我理解那种感觉。因为我和那些在拉辛长大的朋友，我们都知道死亡随时都降临的恐惧感。我深深地理解被困在那里是一种什么滋味，我很幸运我走出来了。我知道那些被杀或者误入歧途的人没有离开那座城市。我参加过很多个葬礼，那很难受。不过很奇怪，在生活中你会像我一样已经达到了一定的高度，当周围人告诉你你已经挺过来了，你也会想“我真的做到了”，就是这样，但是并不是那么简单。我想我还是回回到家乡来看看的，以后也常回来。 对于现在的我来说那些拉辛的孩子就跟曾经的我一样，我也出生在这里，我也曾经是拉辛的孩子，我也做过各式各样的蠢事。但是我从中交了学费，要知道从教训里学习的确不是一个容易的事儿，我花的时间比我母亲期望的时间要长，但是我最终还收获了经验。一旦我有一个目标，就要付出全部，我不想让那些相信我的人失望。我能拥有如此多的东西，我已经很知足了。 文章的最后我想说几个人，这可能会像是一连串名单，毕竟我在联盟里摸爬滚打了这么多年，肯定有很多人要去感谢，如果我忘记了提到某人，那请准许我提前道歉。 在我开始第一场NBA比赛之前，我的妻子就对我说无论我去哪里她都会跟着，这么些年，她一直信守当初的承诺。这辈子讨到她做老婆真是我的福气，无论是现在还是将来她都会是我生命里最棒的那部分。 感谢BJ Evans、Rob Wilson、Tim Donovan、Andy Elisberg、Jay Sabol、Marjie Kates、Shivani Desai、Tim Grover 和整个Arison家族在我职业生涯初期给我的帮助。 我要感谢Buss 家族、Mitch Kupchak、Magic Johnson、Alison Bogli和Eugenia Chow在洛杉矶给我的支持。 感谢Ernie Grunfeld、Milt Newton、Tommy Amaker、Sashia Jones、Candace、Susan O’Malley在华盛顿给我的帮助。 感谢老板Mark Cuban和主教练Rick Carlisle在达拉斯给我的帮助。 还有我在快船队的队友们：Blake Griffin、DeAndre Jordan、CP3–正是你们让我从重伤中走出来，重获新生。 Matt Barnes、Lamar Odom、Chauncey Billups还有我的偶像Grant Hill，我不会忘记跟你们一起的那段日子。 我一直都梦想能穿着雄鹿队的队服打球，感谢John Hammond和Senator Kohl，你们圆了我的梦，说实话在家乡打球的感觉真好！谢谢你们。 在雷霆队，我要感谢总经理Sam Presti、KD和Russell Westbrook。 在活塞队，我要感谢Tom Gores，而且在底特律能跟Stan Van重聚，并且与我的哥们Andre Drummond、Reggie Jackson和Caldwell-Pope一起打球。 Vlade Divac，是你在2016年给那个躺在沙发里以为生涯到此结束了的我打了电话，让我再去国王队跟Rajon Rondo和DeMarcus Cousins打了一年球。 还有一个需要特别说的，那就是刚刚去世的我永远的哥们Rasual Butler，我俩同一年进入联盟。像我一样，Rasual Butler也是一个辗转多队的浪人，但他身上有我敬佩的一切特征—勤奋、专业、积极、体育精神。他是一个人民交口称赞的好队友。哥们，NBA的家人们会想你的。 我的粉丝们，你永远不会知道你们曾经带给我的快乐。谢谢你们的支持!我希望每当你想到Caron Butler这个名字的时候，你会记得我曾经是多么的热爱和尊重比赛，我也希望你们会记住我付出所有时的那个形象。我知道这是一个陈词滥调，但那个形象对我来说要比比赛还要重要–这让我可以去面对一个严峻的未来。 我现在仍然会深深地回想起2002年那次飞往迈阿密的情景，当时我和我的家人在热火队的飞机上—不是因为昂贵或奢侈，也不是因为我第一次去海边。而是因为那是我一生中第一次真的感觉要去某个地方。 在NBA打球是我的梦想，我和所有这些伟大的教练和队友们一起度过了这16年，那是一段比我想象的要好的时光。我虽然身体已经不适合打NBA的比赛，但是篮球依旧在我的生活里，我会以另外的一种形式继续跟它在一起。 我只想让你们都知道我拥有我自己的生命，但正是有了你们的帮助，这个生命才活的如此多姿多彩。]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>NBA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录Uwsgi与Django成功勾搭的始末]]></title>
    <url>%2F2018%2F02%2F07%2F%E8%AE%B0%E5%BD%95Uwsgi%E4%B8%8EDjango%E6%88%90%E5%8A%9F%E5%8B%BE%E6%90%AD%E7%9A%84%E5%A7%8B%E6%9C%AB%2F</url>
    <content type="text"><![CDATA[环境说明Uwsgi版本：2.0.14(yum install安装）django版本：1.10.6（pip install安装）python版本：2.7.5(阿里云 centos 7自带）nginx版本：1.10.2（yum install安装） 正文在https://rorschachchan.github.io/2018/02/02/Uwsgi的安装和简单使用/里面，我们已经实现了网页打开出现”good bye,logan”的效果，可见Web Client &lt;===&gt; uWSGI &lt;===&gt; Python是通畅的，现在我们要调整看看django与uwsgi是否是通畅的。 首先，我们在/django这个目录下，django-admin.py startproject logan，建立了一个叫logan的project，然后在/django/logan/logan里会有一个自动生成的wsgi.py，打开一看，里面的内容如下： 12345678910"""WSGI config for logan project.It exposes the WSGI callable as a module-level variable named ``application``.For more information on this file, seehttps://docs.djangoproject.com/en/1.10/howto/deployment/wsgi/"""import osfrom django.core.wsgi import get_wsgi_applicationos.environ.setdefault("DJANGO_SETTINGS_MODULE", "logan.settings")application = get_wsgi_application() 我们原来的目标就是测试django跟uwsgi的链接是否正常，那么返回到/django/logan，使用python manage.py runserver 0.0.0.0:8000启动django，然后打开浏览器，在地址栏里输入外网ip:8000，看到了如下的界面： 可见django已经启动成功，但是前面说过了，这种方法只能测试环境里小规模的玩玩，完全不推荐拿去生产化境里。所以现在我们用uwsgi在8000来启动一下django。 首先，先停止了原来我们启动的django。 然后，使用命令uwsgi --http :8000 --wsgi-file logan.py,反馈错误信息如下： 出现这个错误，那就yum install uwsgi-plugin-python，同时使用uwsgi --plugin python --http-socket :8001 --wsgi-file /django/logan/logan/wsgi.py，这样却又出了一个新错误： 提示说：ImportError: No module named logan.settings。可是当我使用python客户端单独测试的时候，这个语句是可以使用的，如图： 很多人都卡在了这种情况，这个时候我们需要换一个命令：uwsgi --plugin python --http-socket :8001 --chdir /django/logan/ --wsgi-file /django/logan/logan/wsgi.py。然后我们在浏览器地址栏里输入外网地址：8001就可以看到如下网页： 可见，我们已经通过uwsgi启动了原本已经关闭了的django，这样就达到了Web Client &lt;===&gt; uWSGI &lt;===&gt; Django的目的。 如果过程中出现了端口被占用的情况，比如8002端口已经被使用了： 12probably another instance of uWSGI is running on the same address (:8002).bind(): Address already in use [core/socket.c line 764] 那么就可以使用lsof -i:8002，然后把对应的进程干掉就好了。 最后附赠python脚本一个，这个脚本可以显示python的path，内容如下： 12345import osprint '===== sys.path / PYTHONPATH ====='for k in sorted(os.environ.keys()): v = os.environ[k] print ('%-30s %s' % (k,v[:70])) 参考资料http://www.python88.com/topic/101/http://www.nowamagic.net/academy/detail/1330334]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>uwsgi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins与钉钉机器人实现手机端获取当前服务日志]]></title>
    <url>%2F2018%2F02%2F06%2FJenkins%E4%B8%8E%E9%92%89%E9%92%89%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%90%AD%E9%85%8D%E6%89%8B%E6%9C%BA%E7%AB%AF%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E6%9C%8D%E5%8A%A1%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[马上要过年了，各位运维们除了因为买不到回家的火车票而嚎嚎大哭之外也开始扩容服务器和提前调整监控值，目的就是为了过一个消停的春节。可是这毕竟十天左右不在公司，要是模块真出了什么意外肯定没法第一找到日志分析问题，毕竟这几天都在串门拜年和醉生梦死中度过，走到哪都要再背一个笔记本实在太不方便了。 那么这个时候，我就琢磨使用手机端来启动服务器里脚本，让这个脚本可以去获取当前的日志，然后再把结果返回到手机端。这样就不用到哪里都带那个一看就很扫兴的公司笔记本电脑了。 使用手机端启动服务器里脚本？我又不会开发android和ios，那么肯定就要使用第三方工具，我条件反射的想到了jenkins，因为jenkins是用手机可以登录的，那么在手机端得到结果用什么呢？在微信公众号和钉钉机器人里，我选择了钉钉机器人。 创造钉钉机器人我的钉钉版本是4.2.6.37，首先在左上角头像的三角菜单有一个机器人管理，如图： 然后选择自定义机器人，给它起个名又换一个图标之后，添加到一个群聊里，如图： 添加的时候，这个机器人会生成一个webhook，它的结构应该是：https://oapi.dingtalk.com/robot/send?access_token=XXX，后面的XXX是标识符，不同的标识符代表不同的机器人，这个标识符如果丢了，可以在机器人头像点击一下然后选择机器人设置重新看到。 编写机器人脚本机器人的官方说明网址就是https://open-doc.dingtalk.com/docs/doc.htm?spm=a219a.7629140.0.0.zZIvnt&amp;treeId=257&amp;articleId=105735&amp;docType=1，这里面已经把使用方法写的够清楚了。我这里的这个python脚本是用json的格式，如下： 1234567891011121314151617181920212223242526272829303132#!/bin/python#coding: utf-8import json,urllib2#这里是机器人对应的Webhook地址url = "https://oapi.dingtalk.com/robot/send?access_token=这里输入你机器人的标识符#这里是头，原样复制就好header = &#123; "Content-Type": "application/json", "charset": "utf-8" &#125;#这里是传送的消息data = &#123; "msgtype": "text", "text": &#123; "content": "这里是消息正文！" &#125;, "at": &#123; "atMobiles": [ "A的手机号", "B的手机号" ]， "isAtAll":False #这里True代表要发给所有人，False的话，要代表消息只发给A和B这两个人 &#125; &#125;sendData = json.dumps(data)request = urllib2.Request(url,data = sendData,headers = header)urlopen = urllib2.urlopen(request)print urlopen.read() 直接执行这个脚本，就会看到我刚新建的钉钉机器人在群聊里说话了。 机器人搭配nginx上面那个脚本已经可以初步实现我们的目的，但是有一个缺点，就是正文内容不能过长。但是我想多打印一点日志，至少50行，怎么办？我想了想，可以把日志放进nginx的一个网页里，然后用钉钉机器人反馈这个网页地址啊，这样内容想写多少就可以写多少了。 假设我现在获取到的日志的文件写进一个叫chairmanmao.html里，在浏览器打开看是这样的： 那么上面那个机器人的python脚本就要改成这样： 1234567891011121314151617181920212223242526272829303132#!/bin/python#coding: utf-8import json,urllib2,commandscommands.getstatusoutput('echo -e "THIS IS TEST MESSAGE！ \n" &gt; /路径/chairmantail.html') #这里可以给网页加一个标题commands.getstatusoutput('cat /路径/chairmanmao.txt &gt;&gt; /路径/chairmanmao.html') #这里就是把诗词写进html文件里#这里是机器人的webhook地址url = "https://oapi.dingtalk.com/robot/send?access_token=这里输入你机器人的标识符"header = &#123; "Content-Type": "application/json", "charset": "utf-8" &#125;data = &#123; "msgtype": "link", "link": &#123; "text": "点击网址就可获取到本次日志查询的结果", "title": "日志查询结果已经生成！", "picUrl": "http://p1x3hd2at.bkt.clouddn.com/nanshen.jpg", #这里可以加一个缩略图片 "messageUrl": "http://服务器外网IP地址/chairmanmao.html" &#125;, "at": &#123; "isAtAll":True # at为非必须 &#125; &#125;sendData = json.dumps(data)request = urllib2.Request(url,data = sendData,headers = header)urlopen = urllib2.urlopen(request)print urlopen.read() 执行这个脚本可以看到机器人发送的信息如下： 然后打开这个网址，就看到完整的网页信息： 到时候把毛主席诗词换成实际的日志文件就好了，不用一口气打印所有的日志出来，tail -n 50 日志文件名，50行足够用了。 配置Jenkins脚本写完了，机器人也写完了，这个时候就要添加“启动端”。安装Jenkins的步骤我这里就不写了，直接可以去看https://rorschachchan.github.io/2018/02/05/Jenkins安装与创建简单任务/。现在去登录Jenkins的网页，去添加一个新的Job，比如我这个Job就叫“获取模块日志”，如图： 如果是要在Jenkins上去读取其他服务器的日志，就可以在构建project的时候选择参数化构建过程，然后配置参数ip，到时候把这些ip传递给目标脚本。如果觉得这样hold不住，可以不用jenkins的这个功能，把ip写到脚本里去，一了百了： 在构建那一步，选择Execute Shell，然后里面写上具体的shell命令，如果在上面使用了参数，那么参数就可以在这里使用，我的脚本里是没有ip这个参数的，在图里写$ip就是做一个例子讲解一下用法而已： 在构建后操作这一步可以选择E-mail Notification，这样如果失败了会发送邮件通知。如果用不着就什么都不用选。然后就是保存好这个project，点击左侧菜单栏的立即构建，就会看到下面Build History会多一个#1出来，同时钉钉机器人也在群里发消息，这个#1就是构建的记录，这个纪录多了的话，新纪录会覆盖掉老的记录。 点击这个#1，选择控制台输出，就能看到具体的操作结果了，跟在shell界面里执行的效果差不多的。可见操作成功，目的已经达到了！ 以后需要调用脚本，就在手机端浏览器里登陆jenkins，然后构建一下这个project，同时就可以看到钉钉里机器人有反馈了。 参考资料https://xu3352.github.io/linux/2017/05/01/jenkins-restart-remote-server-tomcathttps://github.com/typ431127/zabbix_dingding]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>钉钉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次官网打不开的经历]]></title>
    <url>%2F2018%2F02%2F06%2F%E4%B8%80%E6%AC%A1%E5%AE%98%E7%BD%91%E6%89%93%E4%B8%8D%E5%BC%80%E7%9A%84%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[今天有人反映官网在登陆的时候，chrome浏览器不能正常打开页面，反而会出现一个下载框。我使用IE浏览器尝试登录官网，页面也不是正常的页面，而是下面的内容： 由于官网的域名跳转是在阿里云的域名解析的地方配置的，于是就登陆到阿里云的域名解析地方，查看了一下发现，这里的配置是www.lechange.com会302跳转到home.lechange.com，而ping一下home.lechange.com得到的ip地址是一个负载均衡的地址，然后在阿里云的控制台查询这个负载均衡的情况，发现这个负载均衡后面挂载的是两台服务器A和B。 于是我在浏览器里面直接输入负载均衡的ip地址，发现还是像上面那样错误的php界面，而浏览器地址栏使用两个服务器的外网ip却是正常可以打开的。这个时候初步怀疑是SLB的问题，而我当时就觉得就凭上面这一点就去跟阿里撕逼不太妥当，但是事实告诉我们事情不是那么简单的。 我检查一下slb的端口配置情况，分别是http 80转8080和https 443转80，可见这个网站有两个协议，一个是http的而一个是https的，我们刚才虽然在浏览器里直接使用A和B的外网ip访问是可以正常打开页面，只能说明http协议是OK的，我们还要测试一下https协议访问的效果。 我就在浏览器地址栏里进一步尝试，发现使用A外网ip：8080访问是OK的，而使用B外网ip：8080访问就是PHP的文字界面。于是基本问题定位到B服务器里有文件的配置错误。 登陆到B服务器里，在nginx的conf文件夹里发现一个多余的文件，打开内容如下： 12345678910111213141516server &#123; listen 8080; server_name www.lechange.com (file://www.lechange.com/) www.lechangebuy.com (file://www.lechangebuy.com/); index index.html index.htm index.php; root /data/www/ecstore; add_header pos 'web2'; # location / &#123; # rewrite ^/(.*)$ https://www.lechangebuy.com/$1; # &#125; location /public &#123; root /data/www/ecstore; &#125; access_log /data/logs/nginx/access.log; #access_log off; &#125; 而原来nginx是有正常的conf文件，现在又多余了一个这个文件，可见是因为没有无法正常解析.php的文件，两个文件都在占用8080端口时出现了冲突，所以就导致这样php download界面的情况。删除这个多余的文件后，重启nginx，清除浏览器缓存，再重新尝试就正常打开页面了。 为什么会多一个这样的文件，后来把各位运维人员严刑拷打一顿才知道，原来有一次某运维小弟在B服务器里面做跳转的测试，测试完毕之后忘记了把这个多余的文件删除，原本这一切是没有问题的，但是可能服务器nginx经历了重启，于是就加载了这两个conf文件，就把这个隐藏的问题暴露了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[往github里上传代码]]></title>
    <url>%2F2018%2F02%2F05%2F%E5%BE%80github%E9%87%8C%E4%B8%8A%E4%BC%A0%E4%B8%80%E4%B8%AA%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[说来惭愧，使用hexo博客这么久了，但是真正使用github保存代码却是第一次。因为要打算自己搞一个jenkins试试自动化部署，所以就打算把我那些不堪入目的代码放在github上，然后用jenkins去执行。今天这篇文章就是来记录如何把本地的代码文件上传到github上的过程，本次过程是在windows下操作的。 建立远端仓库首先登录github的界面，然后建立一个新的仓库（repository），如图： 在建立仓库的时候，要注意最好选择一下Initialize this repository with a README这个选项，这样可以省去一些麻烦，如图： 在这里就用我刚建立的仓库—chentest。 建立本地仓库首先我们先去http://windows.github.com/上下载git工具，在安装的时候你还可以顺便登陆，如果没有github账号的话这一步可以跳过的。 安装完毕你的鼠标右键应该多了一个功能Git Bash Here，此时，可以在电脑找一个文件夹，这个文件夹不推荐安装在C盘，假设我就在E盘根目录下叫chentest的文件夹，这个文件夹名称应该与我们刚刚建立的github仓库名称相同。不然的话，可能在git pull的时候爆fatal: refusing to merge unrelated histories这个错误。 在这个chentest的空文件夹空白处，右键鼠标，然后选择Git Bash Here，就会出现一个类似dos的命令行窗口，此时需要输入git init，这个时候发现chentest文件夹里多一个隐藏文件叫.git，这就代表本地仓库已经创建成功了。 配置公私钥然后就是建立一个SSH key，以后你上传任何东西到远端仓库的时候都要输入这个key，那么在命令窗口输入ssh-keygen -t rsa -C &quot;你的GitHub注册邮箱&quot;，此时会让你输入一个文件路径，这个路径就是存放SSH key公钥和私钥的地方，由于我这个电脑已经在默认的/c/user/33664/.git/id_rsa已经存放了hexo博客的上传密钥了，于是我就手动把路径改成了/c/user/33664/.git/id_rsa-github，如图： 这里注意！如果你也之前有一个git id_rsa密钥的话，我个人强烈推荐这个密钥跟之前的id_rsa密钥是一样的。 在浏览器里返回到github的settings主页，在SSH and GPG keys里点击New SSH key，然后就把刚刚生成密钥的pub版输入进去，这个公钥是可以告诉别人的，但是私钥要保密好。如图： 再命令行里输入ssh -T git@github.com，这时候会让你输入一下/c/user/33664/.git/id_rsa的密钥，由于我刚刚把id_rsa-github密钥和id_rsa密钥内容是一样的，所以就输入正确了。如图： 进一步配置此时，再在命令行里输入如下的语句： 12345git config --global user.name "your name"git config --global user.email "your_email@youremail.com"git remote add origin git@github.com:用户名/Git仓库名称.git #我这个例子里就是chentest.gitgit config branch.master.remote origin git config branch.master.merge refs/heads/master 一个项目可以同时拥有好几个远端仓库为了能够区分，通常会起不同的名字。通常主远端仓库被称为origin。 加完之后进入.git，打开config，这里会多出一个remote “origin”内容，这就是刚才添加的远程地址，也可以直接修改config来配置远程地址。如图： 下载与上传由于这次是我们第一次上传，那么按照惯例，我们需要先下载一下，使用git pull origin master --allow-unrelated-histories，然后输入id_rsa密钥，看见chentest就多了那个README.md文件了。把这个README.md文件改成这样： 12# chentest这是一个做测试的仓库，做好了之后，就先尝试把代码传上去，然后结合Jenkins来搞！ 同时也写一个新的代码，比如这个文件就叫test1.md，里面内容是： 1234#/bin/bashecho "hello,chrisChan!"echo "this is your first git"ifconfig 这个shell脚本内容就是输出两个废话，然后打印ip地址。保存test1.md，然后在命令行里输入如下的内容： 123git add README.mdgit commit -m "提交注释" #这个注释内容是会在网站上体现出来的git push origin master git push命令会将本地仓库推送到远程服务器，而之前说过的git pull命令则相反。同样的输入id_rsa密钥，然后就会看到文件成功上传了！如图： 来到github网站里一看，果然刚刚写的那个test1.md出现了，如图： 结语通过刚才的操作，我想各位应该对github操作有一点初步的了解。其实Git命令行是一个版本控制工具，Github是一个用Git做版本控制的项目托管平台。形象解释的话Git相当于是弓，GitHub是靶，你的代码是箭，弓把箭射到靶上。 参考资料https://www.jianshu.com/p/0fce531dba31http://blog.csdn.net/zhangmingbao2016/article/details/73478899http://www.cnblogs.com/findingsea/archive/2012/08/27/2654549.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins与Github组合成持续集合环境]]></title>
    <url>%2F2018%2F02%2F05%2FJenkins%E4%B8%8EGithub%E7%BB%84%E5%90%88%E6%88%90%E6%8C%81%E7%BB%AD%E9%9B%86%E5%90%88%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[生成Token码首先登录github，在首页选择settings，如图： 然后点击最下面的Developer settings，点击Personal access tokens，最后点击Generate new token，如图： 输入名称和权限，权限选择repo和admin:repo_hook这俩，如图： 然后就会生成一个token密码，这个token密码请妥善保存，丢失或者删除就GG了。 将Token码配置到Jenkins浏览器返回到Jenkins界面，在首页里点击系统管理，然后选择系统配置，在系统配置里面添加一个GitHub Servers，在Add Credentials这一步的时候，要把kind改成Secret text，如图： 这里Secret的地方就是填写刚刚生成的Token码。 保存之后，点击一下test connection，如果出现Credentials verified for user xxx, rate limit: xxx的字样就是成功了，如图： 设置webhooks在github里找一个源码库，选择settings，然后点击小菜单栏里的Webhooks，再点击右边的Add Webhook即可，如图：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins的安装与创建简单任务]]></title>
    <url>%2F2018%2F02%2F05%2FJenkins%E5%AE%89%E8%A3%85%E4%B8%8E%E5%88%9B%E5%BB%BA%E7%AE%80%E5%8D%95%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[安装与启动环境：CentOS 7.0 + java 1.8 安装方式： 12345yum install yum-fastestmirror -y #安装自动选择最快源的插件#添加Jenkins源:sudo wget -O /etc/yum.repos.d/jenkins.repo http://jenkins-ci.org/redhat/jenkins.reposudo rpm --import http://pkg.jenkins-ci.org/redhat/jenkins-ci.org.keyyum install jenkins #安装jenkins 启动方式：sudo service jenkins start，如果没有java是无法启动的。 Jenkins默认端口是8080，如果要更改端口，需要先vim /etc/sysconfig/jenkins，然后修改JENKINS_PORT=&quot;8080&quot;为自己想要的端口号即可。 访问方式：浏览器输入http://your server ip:8080/，然后会看到这样的一个界面，打开这个文件，输入里面的key就可以访问jenkins了。 然后就是让你安装插件，如果是新手的话，可以安装系统推荐的插件，如果插件安装失败不要怕，可以日后手动补上。 插件安装完毕之后，就是自己创建一个管理员账号和密码，输入之后，点击右下角保存并完成。 然后就可以看到Jenkins初始化的首页。 创建任务假设现在要创建一个Job(任务)，这个任务就是输出当前服务器的外网IP地址，那么就点击首页里的新建任务，然后输入任务名，补充一句，生产环境里的Job名最好不用中文，不做死就不会死，然后选择构建一个自由风格的软件项目，如图： 在源码管理的地方，我们暂时选择None，待日后把jenkins与github相关联之后，就可以通过github来配置源码了。在构建触发器的地方，我们选择Poll SCM，这里说一下这几个触发器选项的意思： 1234Build after other projects are built： Build periodically ： 周期进行项目构建（它不关心源码是否发生变化），可以配置如下：0 2 * * *（每天2:00 必须build一次源码）Build when a change is pushed to GitHub： 只要github上有提交了，jenkins没有自动检测到并构建，这设置之后在github中也需要设置才能生效Poll SCM：定时检查源码变更（根据SCM软件的版本号），如果有更新就checkout最新code下来，然后执行构建动作。可以配置如下：*/10 * * * * （每5分钟检查一次源码变化） 构建步骤这里有很多的选项，我们选择Execute Shell，里面可以写shell命令也可以写shell脚本，这里我就写入一个很简单的ifconfig命令去查看一下IP地址，如图： 构建后操作这里也有很多的选项，这里我选择E-mail Notification，然后输入自己的邮箱地址，这样如果构建失败了，就可以发邮件提醒。如图： 配置完毕之后，点击左下角保存即可。 查看任务效果返回到Jenkins的首页，我们看到多了那个刚才新建的任务，然后点击任务名旁边的小三角，选择立即构建，如图： 然后就会看到构建的历史，点击任意历史记录的控制台输出，就会看到效果，的确是操作了ifconfig命令的效果：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper集群的搭建与配置]]></title>
    <url>%2F2018%2F02%2F05%2FZookeeper%E9%9B%86%E7%BE%A4%E7%9A%84%E6%90%AD%E5%BB%BA%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Zookeeper的下载地址：https://github.com/apache/zookeeper/archive/master.zipzkclient的下载地址：https://github.com/sgroschupf/zkclient 至于zookeeper的作用和原理我这里就不多赘述了，大家有兴趣可以去查查，这里主要就是动手操作。 搭建集群首先先看一下本次zk实验服务器的名称和IP情况，这里我们选择了三台服务器作zkserver，因为三台是标配，一台的话就只有leader没有follower，不是很稳定的结构，当然啦如果你的公司土豪的话是可以玩三十台： 123dvl-mrszk-001 10.117.0.125dvl-mrszk-002 10.117.1.158dvl-mrszk-003 10.168.152.227 对这三台服务器都要进行如下的步骤: 1)先把zookeeper.zip传到linux里，然后解压到/usr文件夹下； 2)进入/usr/zookeeper/conf文件夹，vim zoo.cfg，在最下面补充上面的三个zkserver，见图： 3)再来到/usr/zookeeper/data文件夹，如果里面有文件就清空所有文件，如果是1号zkserver就echo 1 &gt; myid，如果当前机器是2号zkserver就echo 2 &gt; myid，依次类推，这里一定要注意，不可以都写一样。 4)vim /etc/hosts，还要把这三台机器的ip地址和名字都写进去，如下： 12345127.0.0.1 localhost::1 localhost localhost.localdomain localhost6 localhost6.localdomain610.117.0.125 dvl-mrszk-00110.117.1.158 dvl-mrszk-00210.168.152.227 dvl-mrszk-003 5)再来/usr/zookeeper/bin文件夹，./zkServer.sh start启动zk，然后再./zkServer.sh status查看进程情况，如图看见第一台和第三台zkserver的身份是follower，第二台是leader： 至此整个zk集群就搭建并且启动完成了。 注意：zookeeper集群时，zookeeper要求半数以上的机器可用，zookeeper才能提供服务。 如果这里有启动失败的情况，比如Error contacting service. It is probably not running.这样的字样，那么有这么几种可能： 1）data文件夹下的myid有数字重复或者是数字漏写的情况； 2）zoo.cfg里的指定日志文件夹没有手动创建； 3）/etc/hosts下的名字与zoo.cfg里的server字段不相符，注意一下，/etc/hosts里的127.0.0.1的名字不要与本ip后面的名字一模一样，不然zk也无法识别！ 4）/etc/hosts名字使用了中文，java系对中文是很不友好的。 配置文件详解1.tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。2.dataDir：顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。3.clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。4.initLimit：这个配置项是用来配置 Zookeeper 接受 客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 52000=10秒。5.syncLimit：这个配置项标识 Leader 与 Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是22000=4秒。6.server.A=B：C：D：其中 A 是一个数字，表示这个是第几号服务器；B 是这个服务器的 ip 地址；C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号。 验证成果Zookeeper的配置工具叫Zooinspector，下载地址是：https://issues.apache.org/jira/secure/attachment/12436620/ZooInspector.zip，下载完直接解压缩就可以在windows里使用。 我们实验的这三台服务器只有内网，但是如果要连接zooinspector，还是需要通过外网权限连接的，这里可以配一个iptables转发规则，配iptables的步骤在这里：http://chenx1242.blog.51cto.com/10430133/1875950 ，照葫芦画瓢即可，但是要注意，zk的端口是2181。 当然，如果不想费事的话，就直接给zkserver配一个外网IP，直接连接。 成功连接到zooinspector，就会看到这样的内容，这里的lcconfig是手动添加的，右击鼠标，选择add node，然后直接写上lcconfig就行，这个名字是根据实际需要填写的： 上面我们已经配置了zkserver集群而且还启动zkserver进程，现在还需要zkclient，zkclient就是请求发起的一方，然后我们可以在各个的模块服务器上部署zkclient服务，通过启动zkclient服务，来让这些模块统一从zooinspector里取值，这样就达到了批量配置，同时保证一致性的效果。 zk的模板文件是_tpl.properties为结尾的文件，我这里模块的名字叫mrs，那么在实验里这个模板文件就是mrs_tpl.properties，这个mrs_tpl.properties里有这样的一个字段，如图： 而我们在zooinspector里对应就这么填写： 保存zooinspector，然后从windows返回到linux，启动zkclient服务和对应的模块进程，如果配置都正常的话，那么程序就会正常启动，ps -ef|grep java就会看到一个叫lczk.AppServerDaemon的进程。这个时候在去看一下mrs的配置文件： 可以看到areaAk取得值就是zk里面data_center里面access_key里面的ak的值，其他的几个值也是同理。可见整个zk已经配置成功，模块都进行了统一配置，而且这些配置既然能被一个接受，同时也会被其他相同的模块服务器所接受。这样就达到了批量配置的效果。 拓展阅读http://ibruce.info/2014/10/23/zookeeper/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Uwsgi的安装和简单使用]]></title>
    <url>%2F2018%2F02%2F02%2FUwsgi%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[正文运维平台的搭建已经提上日程，而我选用了大家比较常用的Uwsgi+nginx+django的架构，这里先记录一下安装Uwsgi的过程。 这里解释一下Uwsgi+nginx+django，我们整个流程如下图： 这里我们可以看出，web server是无法与我们的app（django等等）进行直接对话，他需要通过uwsgi这个桥梁，这个桥梁很重要，虽然我们使用django的runserver功能也会打开一个页面，但是这个页面是很脆弱的，小规模使用还好，要是放在网络上供很多人点击的话，根本就是脆不经风。 uwsgi是啥，请查看文末的参考资料，写的已经非常好了。我这里就简单说下： uwsgi 实际上也是一个http服务器，只不过它只面向python网络应用程序。虽然uwsgi也是http服务器，但是却不能直接使用它部署python web应用程序，否则会出错。 在本文中，uwsgi所扮演的的角色是后端http服务器，nginx扮演的角色是前端http服务器，hello.py是客户端应用程序。用户从网页浏览器中发出请求，nginx服务器收到请求后，会通过它的uwsgi模块将用户的请求转发给uwsgi服务器，uwsgi服务器处理完毕后将结果返回给 nginx，浏览器将最终的结果展现给用户。 Uwsgi的安装比较简单，推荐使用yum install Uwsgi直接下载使用，而不推荐用pip install uwsgi，因为pip安装的话，虽然也能成功（如下图红框），是没有uwsgi.ini文件的，其实没有这个uwsgi.ini是无足轻重的，因为这个文件可以自己写，但是对于生手来说，没有这个文件可能会心里发毛，就无法按照攻略继续下去，所以我更推荐用yum安装，如图： 为了纪念我们的金刚狼同志，我们就写一个叫logan.py，里面的内容是这样的： 123def application(env, start_response): start_response('200 OK', [('Content-Type','text/html')]) return "good bye,Logan..." 然后我们就可以启动这个uwsgi看看效果，使用uwsgi --http :8001 --wsgi-file logan.py，把端口设定为8001，同时指定协议是http，然后加载的文件就是logan.py，启动之后，如图： 遇到这种情况，你就yum install uwsgi-plugin-python，然后把命令做一点点修改，改成：uwsgi --plugin python --http-socket :8001 --wsgi-file logan.py。 屏幕会出现一大堆文字，然后提示，uwsgi已经启动成功了。在浏览器输入服务器外网地址:8001看一下效果，如图： 我们在root目录下再写一个测试的文件，这次我们写一个比较老实的python脚本来测试，这个脚本就叫test.py，里面的内容如下： 12345678910#!/usr/bin/python#coding=utf-8import osimport sysdef application(environ, start_response): status = '200' output = 'this is a test for uwsgi,HOHO~' response_headers = [('Content-type', 'text/plain'),('Content-Length', str(len(output)))] start_response(status, response_headers) return output 还是用刚才的方法，依旧可以打开网页，其实上面这个简单的uWSGI程序更好理解整个套路，只需要实现一个名为application的函数就可以了，该函数有两个参数，environ为包含有http请求的环境变量，start_response为一个函数，用来设置http头。在这个函数里，我们只需要调用一次start_response函数，设置一下HTTP返回头，再return一个HTTP body即可。 至此，整个uwsgi就安装成功了。 参考资料http://xiaorui.cc/2017/02/16/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3uwsgi%E5%92%8Cgunicorn%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B8%8A/http://uwsgi-docs.readthedocs.io/en/latest/tutorials/Django_and_nginx.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
        <tag>uwsgi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从excel的大单元格里快速提取内容]]></title>
    <url>%2F2018%2F02%2F01%2F%E4%BB%8Eexcel%E7%9A%84%E5%A4%A7%E5%8D%95%E5%85%83%E6%A0%BC%E9%87%8C%E5%BF%AB%E9%80%9F%E6%8F%90%E5%8F%96%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[我公司的服务器信息会保存在一份高加密的excel里，由于历史遗留问题，里面的格式节选一部分出来是这样的： 注意看，ip地址不分内网外网是放在一个大的单元格里，中间是用空格隔开的，造成了这样的视觉效果。 现在公司需要把所有的服务器重新更换到新的zookeeper，那么使用ansible在批量处理的时候，就需要提取这些服务器的内网ip地址录入到/etc/hosts文件里，但是由于服务器实在太多不可能一个一个手动从excel的单元格挑选出“内网IP地址”复制粘贴，那么就需要进行一下批量挑选内网IP地址的操作。 首先我们先把整个IP的单元列里的”（公）””（内）”的字样去掉，然后把整列全部拷贝，粘贴到notepad里，看到它们变成了这样的样子： 在notepad里，双引号之间的内容会被认为同一行，所以这里我们需要使用“替换”功能把所有的双引号去掉，让它变成下面这样： 这样就可以把上面的内容复制到一个新的excel去，发现每一个内容对应了一行，即一个小单元格： 然后我们把第一行染成黄色，第二行染成绿色，当然颜色你可以选择自己的口味，然后使用excel的“格式刷”功能，一拉到底，让他们变成条纹状： 然后在excel里找到“筛选”功能，先选择住这一条纹块，然后选择“按颜色筛选“，由于我们需要内网IP，那么我们就留下绿色内容即可，如图： 得到效果如下： 这样就可以把整个内容拷贝进ansible的hosts文件里，然后搭配ansible批处理这些内网IP，双管齐下，大大的提升了提取数据的效率。 如果遇到偶尔三行（即中间有空格行）的情况，那么就在notepad那一步的时候，把空格行干掉，不如下图的情况里，第五行和第八行是空格行，可能是当初记录人员复制的时候自带了空格： 如果是空格很多的情况，那么就需要批处理一次性的把所有空格都干掉。干掉的方法，还是使用notepad的“替换功能”，选择“正则表达式”，然后把\n[\s|]*\r替换成空值就可以了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>excel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[再见，魔兽世界]]></title>
    <url>%2F2018%2F02%2F01%2F%E5%86%8D%E8%A7%81%EF%BC%8C%E9%AD%94%E5%85%BD%E4%B8%96%E7%95%8C%2F</url>
    <content type="text"><![CDATA[var ap = new APlayer({ element: document.getElementById("aplayer0"), narrow: false, autoplay: false, showlrc: 0, music: { title: "暴风城主题音乐", author: "World of Warcaft", url: "http://p1x3hd2at.bkt.clouddn.com/stormwind.mp3", pic: "http://p1x3hd2at.bkt.clouddn.com/wow.jpg", } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 这张月卡马上就要用完了，我想我的《魔兽世界》生涯也要到头了。 地球时代我是从大学的时候就开始接触《魔兽世界》，当时是在同寝的xur同学的推荐下，注册账号买了CDKey，然后跟着他在六区黑翼之巢创建了角色，那是一个留着武士头和山羊胡的暗夜精灵德鲁伊，起了个带有劲舞团性质的ID叫“删除过去”。记得德鲁伊刚出生是人形态，泰达希尔里背着一个木棒棒，靠着“愤怒”这个技能打人。于是乎，我就搓出了一个又一个原谅色的冲击波，波遍了泰达希尔的每一个角落，波倒了一个又一个萨特和野熊。当时我作为一个萌新，什么都不懂，后来在一个另外的德鲁伊的帮助下，开始做任务升级，顺便粗略的了解了魔兽最基本的操作。这个德鲁伊是我在游戏里认识的第一个朋友，是一个萌妹子，ID叫什么我忘了，不过后来她游戏上的很少了，依稀记得后来某一个半夜我在西瘟疫之地变成小豹子一个一个挠亡灵的时候，她上过一次线，等级好像是20~30级的样子，我俩说了一会话，具体说的是什么我已经记不清了，那就是我俩最后一次说话。 从泰达希尔港出来，我就开始了艾泽拉斯的冒险之路：去月光林地学变熊变豹子，拖尸到血色修道院，打过那么一两次诺莫瑞根，在荆棘谷的森林里穿梭，长期蹲在塔纳利斯刷“XD求组祖尔法拉克”。 当时寝室里没有电脑装wow，总去学府三和学府四那两条街的网吧玩，就这样我成了被盗号的重灾户。记得最过分的那次上号发现角色干脆消失了，还有一回上号发现，角色被扒的就剩下一个裤衩、一个披风和一个狼头样子的皮甲头，还别说，这造型跑出去比较拉风。后来九城推出了密保卡，就是充值卡后面的8x8的数字卡，虽然有一小段时间遏制了盗号，不过缺点就是要随身带着密保卡。在网吧开机坐下了发现没带密保卡，又跑回寝室取卡的事情，我当初可没少干。 这个德鲁伊就这样摸爬滚打到了六十级满级的时候，开始刷三大本（前后斯坦索姆，通灵学院，黑石塔上层），那时候的黑下是一个冷门本，黑石深渊更不要说了，打一次就花费了几乎一下午的时光。那段反复的刷斯坦索姆和通灵学院的日子给银色十字军捐过不少亡灵印记。后来加入了工会跟工会开始打熔火之心，记得公会团长叫火枪队长，一个男人类战士，其他的一团的队员我现在还能记住名字的有：京乐春水（德鲁伊）、Hater（女人类牧师），魂之血杀（暗夜大元帅战士）。那时候的MC已经没有DOT限制了，但是还要做水元素任务，带着圣水去灭火。接触的第一个G团是祖尔格拉布，当时德鲁伊是一个稀缺职业，我就开始去打工兼消费挣俩小钱，用那点G去买拍爪子的材料。在祖格G团认识了同大学的一个哥们，叫阿尔萨斯之心，是一个女人类圣骑士，他那个时候就有祖格龙了，但是没玩太久，60级没完事就把号给卖了…MC通了后，公会团开始打黑翼之巢，我记得当时的BWL老1还有BUG，远程和治疗可以跳在窗户上。到了老2就卡的死去活来，好不容易过了老2，接下来的三个就一片通途。然后又花了一个晚上打掉了克洛玛古斯。我那时候奈法利安和克洛玛古斯打得不多，仅有的几次击杀也没有掉落怒风胸和怒风肩，这成了我60级的一个怨念。 在打BWL的时候，安其拉版本已经开始了。G团也开始做安其拉废墟的生意，我也在其中一次无疤者奥斯利安的身上得到了废墟法杖，换掉了之前埃克索图斯的挖掘锤，为了这个废墟法杖我还卖了一张卡，那时候一张卡是300G，那次好像是我唯一的一次卖卡。说到卖卡我想起来，我人生的第一只千金虎是一个暗夜盗贼赞助的，ID好像叫小什么哥，当时的G真的很值钱，非常非常感谢他。 我在地球时代RAID的最高纪录就是安其拉神殿到公主、NAXX打了蜘蛛区前二、DK区到了老1、憎恶区的帕奇维克好像是没过，反正就是一个很一般的进度啦。然后公会团就有了一些动荡，我个人总觉得德鲁伊打人不爽，还是拿起大刀砍人过瘾，于是就开始了玩战士小号的生涯，ID叫燕小鱼。战士满级后不久就开了“远征前夕”，也就是那个全民刷战场换大元帅的时代。我那时候也在YY里加入了联盟军校，开始了没日没夜刷大奥的日子，先换了猪头锤，又换了雷矛羊，最后拿着一堆牌子去换一身漂亮的大元帅，直到现在我的YY名称依旧是以“联盟军校”开头。 我玩战士的时候还认识了一个男矮人牧师，叫赤红丹朱，这个哥们手法很骚，以前是玩部落的，记得有一次我俩要去荒芜之地，在莫高雷的高原上，他说这里曾经是他玩部落开始的地方，然后看着脚下这片大草原心潮澎湃，我俩一起战斗过不少副本，从斯坦索姆到祖尔格拉布，他没有坚持到70级就不玩了，账号也给我了…我后来去他的新浪博客看过，背景音乐是王若琳的《有你的快乐》，后来的某一天，发现他的新浪博客内容就被全删光了。 燃烧的远征记得那是7月份，大二刚开学没多久，我就穿过黑暗之门开始了燃烧的远征。那时候我先升的是战士，在地狱火堡垒里面拿大砍刀砍来砍去。七十级的raid就是先从卡拉赞开始，当时我的小战士就当主t，当时跟的团团长ID是叫小豆宝宝，一个侏儒术士。那时候卡拉赞的bug很多，埃兰可以卡门，马克扎尔王子也可以卡地点。我个人对于卡拉赞比较有印象的是虚空龙，那是这个十人小团队一个比较有成就感的boss。 往后就是打格鲁尔，那个时候我记得隔壁寝室的老朱已经开始练他的女暗夜盗贼了，那个时候我俩开始比较频繁的厮混在一起，肩并肩的不上课跑去网吧打魔兽，我印象最深的一次就是他当时为了刷一个午夜护腿在沙塔斯找了一个猎人，但是这个猎人不是很靠谱，在奴里围栏一个人忙乎从早上八点到晚上八点，结果还没出，给老朱气得牙痒痒。 TBC的时候，就有了日常任务的概念，每天早上要做奥格瑞拉和虚空龙任务，后来又有了奎岛日常，日复一日的刷声望。玛瑟里顿这个副本公会团当时没有正经打，直接就开始打风暴要塞，当时打掉了凤凰和奥术师和机器人。而毒蛇神殿我跟公会打得不多，记得有打过瞎子外加鱼斯拉。这个时候，邪神禁地祖阿曼上线了，开始了有事没事冲箱子的新征程。我印象里整个70级就是一个很多bug的版本，祖阿曼体现的尤为明显，里面BUG有术士副本拉人以及祖尔金跳柱子。但是即使这样我也只冲成功过一次四箱，那一次是t6级别队伍带队，完全没用bug。除了那一次剩下的基本就是两箱，三箱屈指可数。 然后我现实的一个的哥们由于学业的问题不能继续跟团队RAID无奈只能把账号暂给我打理，于是我改玩了他的暗夜女精灵牧师，ID叫外面下雨了（后面简称下雨）。我开始跟《荣耀》公会活动，会长就是鼎鼎有名的震撼。荣耀公会最早是桑德兰服务器的，后来由于想当联通区的第一工会，就集体转服到泰拉尔。当时我也是第一次接触牧师，完全是抱大腿的姿势跟他们一团打掉阿克和伊利丹。他们打阿克因为要录视频所以是不用bug的，真真的要考验跑火的功力。第一次打伊利丹我印象很深，当时寝室里有电脑了，由于很多人当时进度很慢，所以打伊利丹的时候，全楼道的wower都来看，然后啧啧惊叹。 跟着震撼一边打进度团也一边打公会的G团，记得当时t5一套是五万金，t6一套是十五万金。再加上卖武器饰品，一趟下来也分到不少，而且还能直接跟老板换卡，据说公会当时用的付费ts语音也是用老板的钱买的。 那时候打进度团主要就是开荒太阳井，我用那个牧师号拿了全服第一个t6鞋，首down双子的战报也上了nga，地址在：http://nga.178.com/read.php?tid=1644774 ，视频也被传上了优酷，但是现在那个视频找不到了，不过记得BGM还是很好听的。当时进度团活动时间是晚上七点到早上五点，真的很累人，最后击杀基尔加丹我并没有参与。但是震撼的指挥和语音口头禅给我留下了很深的记忆，他的确是一个很赞的指挥。 燃烧的远征也是我寝室山哥沉迷魔兽并且活跃的日子，当时山哥投奔了部落玩德鲁伊。我记得他们团第一次过血沸很惊险，当时血沸还有大约5%的血，T都躺光了，就在BOSS准备大肆屠杀的时候，结果血沸那时候点名，好巧不巧的点名了一个盗贼，那贼开着闪避上去顶掉了最后5%的血。其实FD就是这样，需要实力的同时也需要那么一点运气。 巫妖王之怒当时由于大陆魔兽推迟开巫妖王，那时候我跟老朱、涛哥、永森、老刘、阿俊、小勇几个寝室的哥们还有那个下雨一起转战去了台服，改玩部落。当时我是防骑，老朱改玩牧师，涛哥是法师，老刘是盗贼兼指挥，小勇是术士、阿俊是德鲁伊、永森是萨满，下雨依旧是牧师，不过老朱主要玩的是神牧，下雨主要是暗牧，必要的时候会切奶。 老朱的魔兽之路开始于60级，当时他第一个职业是法师，最开始的时候他跟xur打赌会尽快的把等级练到骑小马的等级，话说老朱练号的速度是很快的，他也是我们几个人里玩职业好象最多的。从法师到萨满，然后还有盗贼，但是直到这次玩上了牧师，他终于找到了灵魂的归属，发现原来牧师才是他的本命。 除了老朱我多说说老刘，老刘原名刘义超，是我们年级的一个牛人，很瘦，戴个眼镜，走路有点发飘。用他话说从小身体就不好，所以不是很喜欢运动，除了打魔兽打dota就是看漫画再不然就是用psp打麻将，老刘的经典语录就是“对于我来说，每一把DOTA都是一把新的DOTA”。老刘是一个很聪明的人，打游戏思路很清晰，很少反重复的错误。他为了游戏也肯砸钱，那时候都是老刘给我们搞代理。老刘巅峰的时候在第七天堂打主力牧师，我也亲眼见过他那时候打便当二十五人英雄十字军，后来由于要带我们几个就放弃了第七天堂，转来跟我们一起组团队。当时我们几个人一边小团队打十人icc，一边也跟个工会活动。 不过后来老刘觉得公会团打得不爽，揭竿而起，自立门户开起了25人H ICC金团。每周四，都会看到一个叫德意忘形的德鲁伊在达拉然喊人刷屏，喊满了就向冰冠堡垒浩浩荡荡的出发，由老刘带队指挥，当然我们也会偷偷摸摸的黑下几件装备和一点金。老刘指挥虽然不如震撼激情，但是思路很有条理，基本上战斗力不算很差的团一个下午就打掉2到3个区。当时我已经大四下半学期了，由于有驾校考试，所以当时老刘的金团我参与了也就一半，不过在金团里我得到了大盾冰冠冰川之墙，当时好像是花了4万金。最可惜的一次就是他们有一次开出了英雄的异物逐除，卖了17万金，按当时的物价换算是二千多块人民币!那次的金团真是赚翻了。 我们十人团的进度是“十人十字军试炼最高差两次就大十字军”、“ICC普通全通”、“h我记得没过冰龙”，因为不久就要毕业了，就没有很全力的去开荒。毕业后从此我们几个战友就四散天涯：老刘回齐齐哈尔，永森和阿俊回佳木斯，涛哥留在哈尔滨，我、小勇和老朱回大庆上班，而下雨就一直在国外，直到现在也没有回来。 现在除了涛哥和老朱，我还有联系之外，其他人我已经联系不上了，也不知道他们过得好不好。 魔兽的八十级之前的版本可以说陪伴了我在大学的大多数时光，那也是我魔兽生涯唯一玩部落的时光。 大地的裂变到了八十五级我又回归国服了，重返联盟命。由于大学里各位同学都开始了新的生活，我也开始直到现在的魔兽独行侠之路，独自练级独自打战场。 也从此之后，我就再也没有正经的跟过公会团，要么是打随机本看看剧情，要么就是打金团。其实我对八十五级的印象不多了。不过要说一下，八十五刚开始的5h真的很难，经常小怪的治疗一个打断不到就满血了，记得那时候打一个影牙城堡就累的死去活来。硬要说大裂变里印象比较深的，也就是打托尔巴拉德和打巨龙之魂，比如很多战士一起开剑刃风暴一起命令怒吼，场面非常壮观。那个时候我也把战士的种族转成了狼人，也背上了触手剑爬在地上跑来跑去。最后没事干，就趁此机会又练起来一个牧师和一个女人类圣骑士，开始了我的圣光追寻之旅。 熊猫人之谜到了九十级，朋友也多了起来。主要是跟单位里的磊哥、建哥、亮哥和迪哥一起在奥拉基尔服务器玩。磊哥原先是亡灵贼，后来投奔了联盟转了女人类，但是一直都纠结女人类的动作不如男亡灵飘逸。磊哥自封外号“阿拉希小王子”，长期在农场神出鬼没，也善于在战歌抗旗。迪哥是男德莱尼萨满，满地插柱子，他是一个个性男人，死活不去网吧，坚持就在家里玩。不过迪哥玩魔兽的时间并不长，也就几个月的时间他就投奔去三国杀和单机游戏了。健哥是一个猎人，单刷无敌，他那时候是我们几个里最有G的，输出也最为残暴，不过后来他由于工作原因也忍痛割爱了。亮哥是血DK，号称“通信公司第一DK”，不过我们四个很少玩在一起，毕竟上线时间其实是错开的。 熊猫人的本我印象比较深的就是“攻打奥格瑞玛”，至于之前的恐惧之心、永春台神马的我压根就没参与过。当时我的小牧师也算练的不错了，主要得益于我下班没事经常混迹在NGA看帖子，再加上那个版本对戒律牧也特别的友好，偶尔在金团也能拿到治疗第一的补助。而磊哥一直想要箱子BOSS的马刀，最后他也算圆梦了。至于建哥一直眼馋的火鹰，好像一直都是没有达成。 这里我要感谢磊哥，当时我俩在祖尔格拉布翻新之前去刷过祖格虎，结果出虎的时候，磊哥高风亮节让给我了，满足了我开上“红色法拉利”的梦想。 德拉诺之王一百级给我的游戏感觉就是高开低走，尤其是要塞，从最开始新鲜成了后期的累赘。虽然它给了我很多战火装备，但是也让我越来越少出去。整个德拉诺之王我最喜欢的副本就是黑石铸造厂，很有六十级副本的味道，容错率很低。那个时候也认识了以骄傲纹身为首的几个朋友，也打了金团攒了不少钱，这些钱后来也都被我换成了点卡。 至于地狱火堡垒这个副本我印象不多，翻来覆去就打了两三遍h，还都是跟G团，最后过了h的阿克蒙德，m难度我压根没尝试，后来由于公司里各个朋友们由于现实各种情况AFK，我也开始改玩单机游戏，上号就是刷刷阿什兰和四本刷金，消磨时间休闲娱乐。 军团再临到了一百一十级，几乎整个一百级都没玩的老朱重返魔兽，一口气练了牧师、死骑和恶魔猎手三个职业，我俩也配合打了几个高层大秘境，没有老朱的日子就是我自己慢慢肝神器，每周争取打一次低保，再混一次世界BOSS。也就是这张点卡玩完，我觉得魔兽已经对于我来说没有什么留恋的了，该体验的我差不多都体验过了，没体验到了我也不在乎了。我把牧师停在暴风大教堂，把战士停在暴风要塞，把圣骑士停在激流堡，下线。 至此，我整个魔兽的生涯就算总结完了。 PVP有关地球时代的野德不算很强，除了战歌抗旗好像就是补刀了。那时候我看过一个叫dazeroth的暗夜德鲁伊Unstoppable系列视频，觉得很吊，他的视频不算很多，但是打得很棒，然后再看德鲁伊就是一个中国风很浓的暗夜德鲁伊视频，但是我忘了他的名字了。改玩了战士之后，就看Swifty的视频和苹果牛的视频，看直播就看太极龙。牧师的话，看Hydra是最多的。 我个人认为PVP是魔兽的一个重要的玩法，不过这种玩法随着玩家属性暴涨而变得不再公平（不过有几个乱斗还是挺好玩的）。我竞技场打得不算多，从70年代组织55战队去每周去混10场到现在，加起来不超过200场的JJC实战经验。不过战场混得经验丰富，打一些战场也有自己的心得，比如征服之岛要上来抢车间，大奥如果速推不成功就要抢冰雪墓地耐心打平推，打战歌中场压制住了等于赢了8成，风暴之眼先抢墓地再抢骑，控制了地盘后第一时间去墓地堵人等等等等。但是战场毕竟各位玩家PK水平参差不齐，打战场其实更多就是一个图个乐。 至于搏击俱乐部，我没玩太多，不过金牌挑战我还是很喜欢的。 结束语魔兽世界陪伴了我12年的时光，现在回首来看，我个人最喜欢的是WLK，因为那个版本装备比较好看，其次相对来说各个职业的能力都比较平均，最重要的就是身边有一堆战友并肩作战；其次就是TBC，他在一定程度上弥补了很多60级的缺陷，而且极大地提升了惩戒骑、野德、元素萨等混合职业的存在感，不过TBC的BUG实在太多（我重复几次了？），光一个阿克我就见识过不下4种BUG打法，这一点是TBC的败笔；再其次就是90级和地球时代；大灾变和军团再临他们俩并列再后面一点。 我爱魔兽，他是我的另一个世界，因为我觉得在现实世界里能做的事情，在魔兽世界能做的更多。不可否认，我曾经在魔兽世界上投入了大量的时间，这耽误了我很多现实中的事儿，不过我还是认可它给我带来了不少的快乐。我还记得在06年的路边书摊会买魔兽世界带副本地图和掉落的攻略的那个宅男；我也记得当初那个小德鲁伊在灰谷，一边看着新浪魔兽任务详解，一边在地图上费劲的查找线索；我也记得当初圣骑士到了查索拉盆地的时候，被那种仙剑风的音乐陶醉；我也记得在阿什兰和奥特兰克山谷，战士那一身部落血的豪爽。但是一切缘分都有到头的时候（或许我将来会有机会到网易的魔兽世界部门上班，不过这个暂且不提），虽然我不能亲眼看见联盟一统艾泽拉斯，但是我还是要说，谢谢暴雪做的这款精良的游戏，感谢你陪我走过的这12年，谢谢跟我并肩作战过的战友，没有你们，我也无法享受这段丰富而美好的时光。 最后，我要用《军团再临》里面伊利丹的那个口信内容作为我整个魔兽世界生涯的结尾： 我留下的水晶里其实有三条口信 最后一条是给你的，勇士 你证明了你对艾泽拉斯的忠诚 你的奉献和牺牲都足以与我媲美 但你还得付出许多，更多! 此刻敌人正在集结，阴云正在汇聚 从今天起，守护我们的世界和亲人的重任 就交给你了 再见了，那些一路陪伴我的NPC们，我要离开你们了，去开始新的征程。]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>魔兽世界</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈raid0,raid1,raid10,raid01等等硬盘阵列搭配]]></title>
    <url>%2F2018%2F01%2F31%2F%E7%AE%80%E6%9E%90raid0-raid1-raid10-raid01%E7%AD%89%E7%AD%89%E7%A1%AC%E7%9B%98%E6%90%AD%E9%85%8D%2F</url>
    <content type="text"><![CDATA[RAID 0RAID 0可用于两个或更多硬盘或SSD。目标是提高读的性能。 数据以特定大小（通常为64KB）的块写入，并在可用驱动器中平均分配。下图显示了带有三个硬盘的RAID 0阵列的示意图。RAID控制器将第一个数据块写入硬盘1，第二个数据块写入硬盘2，第三个数据块写入硬盘3，第四个数据块再次写入硬盘1,以此类推，RAID 0中的三个1TB硬盘提供3TB的存储空间。 由于数据分布均匀，所以在访问的时候会从硬盘1~硬盘3提取数据，然后拼接在一起就是一个完整的数据。理论上从3个硬盘的RAID 0阵列读取数据比从一个硬盘读取要快3倍，换言之，使用RAID 0读数据的能力跟磁盘数量成正比。 RAID 0也有缺点：如果其中一个磁盘出现故障，从其他磁盘上的数据拼起来就不再是一个完整的数据了。另外，磁盘越多，则发生磁盘故障的可能性也越高。所以如果磁盘阵列里包含着对您来说很重要的数据，则最好创建频繁的备份。 RAID 1RAID 1用于创建数据的自动副本。RAID 1会将同一份数据写入两个单独的磁盘，如果A盘出现故障，仍然可以在B磁盘上读取所有数据，当然这是比较壕的，毕竟做一件事用了两块盘。这里要注意！镜像和备份可不是一样！！！如果你不小心从一个磁盘A上删除了一个文件，或者某个文件被病毒侵蚀了，那它再另一个磁盘B上也是一样的待遇。只有真正的备份才能使所有文件保持其保存状态。因此，如果想不让宝贵数据陷入灾难，创建频繁的备份是必须的。 RAID 1中的读性能通常与单独的硬盘差不多—-从A和B里一起读数据，谁出数据快就采用谁的，写的话就是要同时写到两个盘里去。因此，使用RAID 1来获得额外更多的读写性能是不太可能的。以下是RAID 1的工作原理图，如果HDD1坏了，那么HDD2直接上任，若HDD1里的东西被删除了，那么HDD2也会被删除，即使它上任了也是坏的。 RAID 10和RAID 01所谓RAID 10,其实就是磁盘阵列先RAID 1,后RAID 0,同理，RAID 01也是先RAID 0,后RAID 1。无论是1+0还是0+1，都至少需要4个硬盘。 这里先看一下RAID 10和RAID 01的效果图： 就像图里说的“在六个硬盘列里，RAID 10比RAID 01更安全”。的确，RAID 10也凭借很棒的容错能力和恢复能力当选了大多数的RAID配置，为什么不要RAID 01呢？那就是如果在RAID 0那一步磁盘就坏了，那RAID 1那步就没有意义了，因为生成的镜像全是坏镜像。 RAID 3RAID 3是这样的：若有n块盘，其中拿出1块盘作为校验盘，剩余n-1块盘相当于作RAID 0同时读写，当n-1那里的其中一块盘坏掉时，可以通过校验码还原出坏掉盘的原始数据。这个校验方式比较特别，事奇偶检验，1 XOR 0 XOR 1=0，0 XOR 1 XOR 0=1，最后的数据是校验数据，当中间缺了一个数据时，可以通过其他盘的数据和校验数据推算出来。但是这存在了问题，由于n-1块盘做了RAID 0，每一次读写都要牵动所有盘来服务，而且万一校验盘坏掉就完蛋了。 RAID 5 and 6上面说了RAID 10是一个很棒的方案，但是它的实现至少需要4个硬盘，这一点太伤钱了，于是就出现了RAID 5。与RAID 0一样，数据被分成块并执行写入处理，同时把RAID 3的“校验盘”也分成块分散到所有的盘里。同时，产生并写入称为“奇偶校验”的冗余代码。因此，即使其中的一个硬盘出现故障，也可以根据剩余的数据和奇偶校验来计算出丢失的数据，然后生成完整的状态数据。由于无论需要配置多少个硬盘，保存校验只使用一台设备的容量，容量效率随着待配置硬盘数量的增加而提高。RAID 5模式下硬盘读取数据的速度很快，因为它是从多个驱动器同时处理的。预计速度将与要配置的驱动器的数量成比例地增加。但是，数据的写入/更新涉及奇偶校验的创建/更新，所以写入性能不高。 RAID 5已经提供了一定程度的可靠性,然而也牺牲了一定的读取速度。RAID 5的局限性还表现在RAID 5仅能在一块硬盘发生故障的情况下修复数据,如果2块硬盘同时发生故障,RAID 5则无能为力。于是RAID 6应需诞生了，RAID 6同RAID 5最大的区别就是在RAID 5的基础上除了具有P校验位以外,还加入了第2个校验位Q位。当一块磁盘出现数据错误或者丢失的时候,恢复方法同RAID 5,无须使用Q校验位。当两块磁盘上的数据出现错误或者丢失的时候,恢复方法为:利用上边给出的P,Q的生成公式,联立方程组,无论受损的数据是否包括P或者Q,总是能够解出损失的两位的数据。 RAID 50 and 60在硬盘数量较少的情况下，RAID 5是极好的选择，如7-8块硬盘组成的RAID。但是，当硬盘的数量更多的时候，如10块、20块甚至100块，那么RAID 5就无法胜任了。RAID 50是在RAID 5的基础上，将多个RAID 5组以RAID 0的形式组成在一起。可以这么认为，一个RAID 5组在这里就是一个“大硬盘”，再把这些“大硬盘”以RAID 0的形式组成在一起。而RAID 60的组成就是在RAID 6组的上面组成一个RAID 0。理论上说在写入性能方面，RAID 50相比RAID 5要好太多，而RAID 50相比性能冠军RAID 10要差一点，考虑到RAID 5在一些负载面前的平庸性能，RAID 50是个不错的中间选择。和RAID 5和RAID 10一样，RAID 50也提供极好的读性能，同时RAID 50即使使用最低配置，也需要六个硬盘，所以安装成本很高。 如果担心一个RAID组里面同时有2块硬盘发生故障，导致数据丢失，那么可以选择使用RAID 60。RAID 60提供更高的安全性，相应的其可用容量会比RAID 50少点，RAID 60即使使用最少的配置，也需要8个硬盘，所以安装成本相当高。 结语以上几个磁盘阵列，从读的能力来说：RAID 5 ≈ RAID 6 ≈ RAID 60 &gt; RAID 0 ≈ RAID 10 &gt; RAID 3 ≈ RAID 1从写的能力来说:RAID 10 &gt; RAID 50 &gt; RAID 1 &gt; RAID 3 &gt; RAID 5 ≈ RAID 6 ≈ RAID 60如果将来有一天你对这篇文章记得不是很清晰了，那么但愿你可以记住下面这张图，这几幅图虽然对于RAID 上不是完全的准确，但是已经很大的表达清楚了各种RAID的特点了。 参考资料https://us.hardware.info/reviews/4123/raid-0-raid-1-raid-10-and-raid-5-how-do-they-actually-workhttp://support.huawei.com/enterprise/zh/knowledge/KB1000149118/https://zh.wikipedia.org/wiki/RAIDhttp://www.hpc.co.jp/raid_kaisetsu.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>raid</tag>
        <tag>磁盘阵列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible-playbook如何获取ip]]></title>
    <url>%2F2018%2F01%2F31%2FAnsible-playbook%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96ip%2F</url>
    <content type="text"><![CDATA[公司的模块都新加了加密算法，现在就是需要把约100台机器的/etc/hosts文件里的zookeeper server的ip调整成新的ip 地址，目前在ansible控制机上已经写好了带有新的zookeeper server的ip的/etc/hosts文件，然后计划是把这个新文件下发到大约100台具体模块的服务器里，然后这100台机器的文件中把他们各自的ip和hostname添加到这个新的/etc/hosts文件上。 于是就写了一个ansible-playbook: 123456789101112---- hosts: all tasks: - name: 将原有的hosts文件备份 shell: mv /etc/hosts /etc/hosts_bak - name: 将ansible端的hosts复制到各自机器上 copy: src=/root/hosts dest=/etc/ owner=root group=root mode=0544 - name: 在新的hosts文件后面追加各自机器内网ip和hostname lineinfile: dest=/etc/hosts line="`ansible_all_ipv4_addresses` `ansible_hostname`" 但是写完之后执行出来，却是这样的效果： 而我想要的是这样的效果： 遇到这种情况怎么办？ 后来调整了一下，变量用IP: ““，而不是ansible_all_ipv4_addresses。 修改了之后的playbook 如下： 1234567891011121314---- hosts: all vars: IP: "&#123;&#123; ansible_eth0['ipv4']['address'] &#125;&#125;" tasks: - name: 将原有的hosts文件备份 shell: mv /etc/hosts /etc/hosts_bak - name: 将ansible端的hosts复制到各自机器上 copy: src=/root/hosts dest=/etc/ owner=root group=root mode=0644 - name: 在新的hosts文件后面追加各自机器内网ip和hostname lineinfile: dest=/etc/hosts line="`IP` `ansible_hostname`" 这样就达到目的了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql查看实时语句和慢sql]]></title>
    <url>%2F2018%2F01%2F30%2Fmysql%E6%9F%A5%E7%9C%8B%E5%AE%9E%E6%97%B6%E8%AF%AD%E5%8F%A5%E5%92%8C%E6%85%A2sql%2F</url>
    <content type="text"><![CDATA[查看实时语句Mysql除了手动执行的语句，还有很多在后台由其他模块执行的语句，按理来说，那些由其他模块执行的语句是不能实时查看的，因为这个资源消耗特别的大，但是当我们实在需要查看实时sql语句的时候也不是做不到，需要手动开启一个日志开关general_log。 首先登陆mysql，然后执行show variables like &quot;general_log%&quot;;，看一下反馈的结果，如下： 12345678mysql&gt; show variables like "general_log%";+------------------+-------+| Variable_name | Value |+------------------+-------+| general_log | OFF || general_log_file | |+------------------+-------+2 rows in set (0.04 sec) 发现这个Value是off，那么就说明实时记录general_log没有开启，如果我们要开启它很简单，如下： 123mysql&gt; set global log_output = file;mysql&gt; set global general_log = 'ON';mysql&gt; set global general_log_file = '/tmp/mysql/general_log.log'; 可见我们不仅打开了general_log的开关，而且设置日志输出方式为文件（如果设置log_output=table的话，则日志结果会记录到名为gengera_log的表中，这表的默认引擎都是CSV）。同时规定它的保存位置是/tmp/mysql/general_log.log。 但是这个是临时方法，如果mysql重启了那么就会失效，如果想要永久有效的话，就要编辑my.cnf，添加下面两句话： 12general_log = 1general_log_file = /tmp/mysql/general_sql.log 这里要注意！开启general_log会影响性能，谨慎使用!正式系统用完要关闭!!!关闭的语句SET GLOBAL general_log = &#39;OFF&#39;;。 查看慢sql慢sql的意思就是那些执行很慢的sql，这些sql拖慢进程的执行效率而且有很大的优化空间。默认的来说，执行时间超过1秒就算慢sql了，在mysql里输入show variables like &#39;long%&#39;，就会看到如下的内容： 1234567mysql&gt; show variables like 'long%';+-----------------+----------+| Variable_name | Value |+-----------------+----------+| long_query_time | 1.000000 |+-----------------+----------+1 row in set (0.00 sec) 这个long_query_time是可以更改的，这里是1，那就是代表查询时间大于(不是大于等于)1秒的都是记录到日志，最大值是10。如果写的是0，那么就是输出所有的语句。 这里多说一句，使用命令set global long_query_time=4修改慢查询阈值为4秒后，需要重新连接或新开一个会话才能看到修改值。你用show variables like &#39;long_query_time&#39;查看是当前会话的变量值，你也可以不用重新连接会话，而是用show global variables like &#39;long_query_time&#39;;。 那么记录这些慢日志的地方在哪呢？使用show variables like &#39;%slow_query_log%&#39;;看看： 12345678mysql&gt; show variables like '%slow_query_log%';+---------------------+-----------------------------------------------+| Variable_name | Value |+---------------------+-----------------------------------------------+| slow_query_log | OFF || slow_query_log_file | /tmp/mysql/DB-Server-slow.log |+---------------------+-----------------------------------------------+2 rows in set (0.00 sec) 这里说明慢日志的地址是/tmp/mysql/DB-Server-slow.log，但是慢日志记录的功能没有启动。如果要启动，语句是：set global slow_query_log=1;，跟上面开启实时日志general_log一样，这个方法仅仅是一个临时方法，重启了mysql就会失效，如果要长期生效，还是在my.cnf文件里添加如下两句话： 12slow_query_log =1slow_query_log_file=/tmp/mysql/DB-Server-slow.log 慢日志还有一个系统变量叫log-queries-not-using-indexes，它的意思是未使用索引的查询也被记录到慢查询日志中，哪怕他可能执行的非常快（可选项）。如果调优的话，建议开启这个选项。另外，开启了这个参数，其实使用full index scan的sql也会被记录到慢查询日志。如下： 12345678910mysql&gt; show variables like 'log_queries_not_using_indexes';+-------------------------------+-------+| Variable_name | Value |+-------------------------------+-------+| log_queries_not_using_indexes | OFF |+-------------------------------+-------+1 row in set (0.00 sec)mysql&gt; set global log_queries_not_using_indexes=1;Query OK, 0 rows affected (0.00 sec) 如果你想自己试试慢sql是否被记录，那么可以使用select sleep(5);这样的语句，执行效果如下： 123456789101112131415mysql&gt; select sleep(5) ;+----------+| sleep(5) |+----------+| 0 |+----------+1 row in set (5.00 sec)mysql&gt; select * from mysql.slow_log;+---------------------+---------------------------+------------+-----------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+| start_time | user_host | query_time | lock_time | rows_sent | rows_examined | db | last_insert_id | insert_id | server_id | sql_text | thread_id |+---------------------+---------------------------+------------+-----------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+| 2018-01-30 21:45:23 | root[root] @ localhost [] | 00:00:05 | 00:00:00 | 1 | 0 | | 0 | 0 | 1 | select sleep(5) | 2 |+---------------------+---------------------------+------------+-----------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+1 rows in set (0.00 sec) 参考资料http://www.cnblogs.com/kerrycode/p/5593204.htmlhttps://www.cnblogs.com/qmfsun/p/4844472.htmlhttp://www.cnblogs.com/jasondan/p/3491258.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Goaccess---良心nginx日志分析工具]]></title>
    <url>%2F2018%2F01%2F30%2FGoaccess-%E8%89%AF%E5%BF%83nginx%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[Goaccess是一个非常良心的开源软件，它的良心之处体现在如下方面： 安装简单； 操作容易； 界面酷炫； 安装安装Goaccess十分的简单，在centos里直接yum install goaccess，如果yum源里没有goaccess，可以先安装epel。安装epel的方法如下： 123wget http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpmwget http://rpms.famillecollet.com/enterprise/remi-release-6.rpmrpm -Uvh remi-release-6*.rpm epel-release-6*.rpm 配置和使用安装完goaccess之后，我们需要在/etc/goaccess.conf里添加如下几句话： 123time-format %Tdate-format %d/%b/%Ylog-format %h %^[%d:%t %^] “%r” %s %b “%R” “%u” 保存退出之后，我们就可以通过goaccess来分析nginx日志了，语句格式也很简单：goaccess -f nginx日志的绝对路径。比如我的nginx日志是access-chen.log，查看一下里面的内容： 虽然有规律，但是看上去很乱，需要在分析日志之前喝两瓶静心口服液。 然后我就goaccess -f access-chen.log，就会看到如下的界面： 这一下，整个日志看起来更加友好，更加直白，更加高大上。足以吸引周围人的羡慕目光。 但是这里面还是有一个注意点：goaccess默认支持的日志格式是nginx默认的日志格式，也就是nginx.conf里的如下格式： 如果你的日志格式是有过更改的，而且还不想改回来，那么就需要去/etc/goaccess.conf里对应的log-format进行更改。 这还没有完，goaccess还可以生成html，这里goaccess -f access-chen.log -a &gt; /nginx安装路径/html/chen.html。然后在浏览器里登陆到这个服务器的chen.html，就会看到整个日志情况的网页排版，如图： 这样的话，我们可以每一天都发一份当天的日志html去运维人员的信箱里，这样更加方便我们分析日志。 缺点虽然前面说了那么多goaccess的优点，但是缺点也是有的，比如goaccess的粒度太粗，只能按天分割，如果要按小时分割，需要先grep出来，这个做法比较挫我懂… 还有一个缺点，就是访问人的来源只能定位到国家，无法具体定位到省市县村屯… 参考资料http://blog.maxhemby.se/determine-the-apache-traffic-load/#respond]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>日志统计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[处理掉积压过多的activemq持久化消息]]></title>
    <url>%2F2018%2F01%2F29%2F%E5%A4%84%E7%90%86%E6%8E%89%E7%A7%AF%E5%8E%8B%E8%BF%87%E5%A4%9A%E7%9A%84activemq%E6%8C%81%E4%B9%85%E5%8C%96%E6%B6%88%E6%81%AF%2F</url>
    <content type="text"><![CDATA[问题描述在项目使用activemq 5.14时，客户端发送消息而没有得到回复（在不考虑消费者是什么问题的情况下），导致持久化消息不断积压而得不到释放，最后造成队列堵塞而嗝屁。 一般来说遇到这样的情况，可以在配置文件中配置消息的过期时间和死信处理来防止消息的积压，配置如下： 1234&lt;plugins&gt; &lt;!-- 86,400,000ms = 1 day --&gt; &lt;timeStampingBrokerPlugin ttlCeiling="10000" zeroExpirationOverride="10000"/&gt; &lt;/plugins&gt; 配置消息过期时间使用timeStampingBrokerPlugin插件,ttlCeiling：表示过期时间上限（模块程序写的过期时间不能超过此时间，超过则以此时间为准），zeroExpirationOverride：表示过期时间（给未分配过期时间的消息分配过期时间），一般来说这两个值是一样的。执行之后，message过期则客户端不能接收，那些已经过期的message将会保存在data/kahadb目录下。 但是最近发现了一个问题，就是data/kahadb这个目录最近越来越大，越积越多。但是这个topic和quere又依旧是“持续订阅”的，它的消费者还在。遇到这样的情况，如何在activemq里配置呢？ 解决办法 配置message过期自动丢弃策略 12345678910111213 &lt;borker&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;policyEntry topic="&gt;" expireMessagesPeriod="60000"&gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy processExpired="false" /&gt; &lt;/deadLetterStrategy&gt; &lt;/policyEntry&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt;&lt;/borker&gt; 标签processExpired=&quot;false&quot;表示不保存过期消息到死信队列，处理手段为删除，为true则是保留。标签expireMessagesPeriod=&quot;60000&quot;属性表示每隔60秒钟检查message是否过期。topic=&quot;&gt;&quot;表示该策略对所有topic都生效。而topic=&quot;active.&gt;&quot;就表示该策略对以active.开头的所有topic生效，注意有个点号.。 message过期时间设置上面那步搞定了之后，再修改timeStampingBrokerPlugin标签里ttlCeiling=&quot;360000&quot; zeroExpirationOverride=&quot;360000&quot;表示过期时间为360000ms（1小时）。 123456&lt;borker&gt; &lt;plugins&gt; &lt;!-- 86,400,000ms = 1 day --&gt; &lt;timeStampingBrokerPlugin ttlCeiling="360000" zeroExpirationOverride="360000" /&gt; &lt;/plugins&gt;&lt;/borker&gt; 解决“空队列”的方法如果不是那种“持续订阅”的topic，那就简单了，配置如下： 123456789&lt;broker xmlns="http://activemq.apache.org/schema/core" schedulePeriodForDestinationPurge="10000"&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;policyEntry queue="&gt;" gcInactiveDestinations="true" inactiveTimoutBeforeGC="30000"/&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt; &lt;/broker&gt; schedulePeriodForDestinationPurge执行清理任务的周期，gcInactiveDestinations=&quot;true&quot;表示启用清理功能，inactiveTimoutBeforeGC=&quot;30000&quot;这个是Topic或Queue超时时间,在规定的时间内，无有效订阅，没有入队记录，超时后就会被清理。 参考资料http://activemq.apache.org/timestampplugin.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
        <tag>消息队列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python里调用redis的方法]]></title>
    <url>%2F2018%2F01%2F29%2FPython%E9%87%8C%E8%B0%83%E7%94%A8redis%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[正文Python 2.7里不是自带redis模块的，那么在调用redis的时候自然也会报错，比如： 遇到这种情况怎么办？ 第一种方法： 1pip install redis 第二种方法： 1easy_install redis 第三种方法：去登录https://github.com/andymccurdy/redis-py，下载包上传到linux里之后，python setup.py install。 flask模块的安装也是同理。 注意！这里只有Redis，如果使用StrictRedis会报错：AttributeError: &#39;Redis&#39; object has no attribute &#39;StrictRedis&#39;。这个是版本的问题。见https://github.com/andymccurdy/redis-py/issues/188 参考资料http://debugo.com/python-redis/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ssh连接port 22: Connection refused]]></title>
    <url>%2F2018%2F01%2F29%2FSsh%E8%BF%9E%E6%8E%A5port-22-Connection-refused%2F</url>
    <content type="text"><![CDATA[金山云有一个服务器需要连接到数据库但是总是失败，检查之后发现它的VPC配错了，更改VPC之后，这台服务器也会更换一个新的内网IP地址，但是问题来了，更换了内网IP之后，从跳板机连接，提示port 22: Connection refused。 ssh -v 新的ip地址发现根本没有到Connection established。直接就提示port 22: Connection refused。这基本可以断定不是跳板机的问题了，那么就需要在远程机器里看配置。 但是远程机器是无法连接的啊，怎么办？从金山控制台“连接实例”。 然后键盘随便按一下，就会看到linux界面，输入账号名和密码，这里密码不支持复制粘贴，需要手动输入。然后就会看到如下界面。 这样，我们就可以登陆这台机器了，然后vim /etc/ssh/sshd_config，看到最上面有这样的内容。 这个listenaddress后面就是跳板机ssh的地址，但是这个地址还是老的，而不是更改过后的内网ip地址，所以ssh的连接自然就是refuse。所以我们只需要手动更改成新的内网ip地址就好了。 更改完之后，重启一下服务器或者/etc/init.d/sshd restart就可以从跳板机上正常连接了。 如果在/etc/init.d/sshd restart的时候爆出“address family must be specified before ListenAddress”的错误，那么就把AddressFamily移到ListenAddress上面就可以了，如图：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SFTP不能连接服务器怎么办？]]></title>
    <url>%2F2018%2F01%2F27%2FSFTP%E4%B8%8D%E8%83%BD%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[今天在跳板机上传送文件，发现使用SFTP连接的时候，出现了这样的一个拒绝情况： 登陆到这个跳板机里，使用tail /var/log/secure，看到了拒绝的具体信息，如下： 这个时候，我就需要locate sftp-server，用locate定位一下sftp文件，但是发现服务器竟然回答我-bash: locate: command not found。 于是就yum -y install mlocate，安装mlocate之后执行updatedb，需要等待一小会，然后再次执行locate sftp-server，就可以得到sftp-server的文件路径了，如下图： 打开sshd的配置文件，vi /etc/ssh/sshd_config，把Subsystem这一行前面的#去掉： 然后重启启动ssh服务，语句是/etc/init.d/sshd reload，重新连接一下，发现就恢复正常了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>sftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible部署模块的时候出现中文乱码的问题]]></title>
    <url>%2F2018%2F01%2F27%2FAnsible%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%9D%97%E7%9A%84%E6%97%B6%E5%80%99%E5%87%BA%E7%8E%B0%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[今天在部署服务的时候遇到了一个很罕见的现象，线上有15台服务器是手机推送消息的服务，新来的小运维使用ansible批量跑部署脚本的时候，发现手机端接收到来的消息全是乱码，然后登陆到服务器，查看日志发现，日志里面就是乱码，如图： 由于这个问题用户是有感知的，所以属于“事故”级别了，于是小boss大怒，叫运维赶快回滚，然后让开发赶紧重新检查代码，然后开骂测试都是吃屎的么这么大的一个问题都看不出来真是一群猪伤不起啊。 开发看了半天自己的代码，发现没有任何问题，战战兢兢跑来跟新来的小运维窃窃私语，结果我发现这个模块用手动单独部署，日志却是正常的，中文显示十分OK。 这一下开发就腰杆硬了，说这不是我的锅啊我是无辜的啊老子天天辛苦加班没有功劳也有苦劳没有苦劳也有疲劳老子的代码经得住考验这一切就是部署的问题。 于是我就查看了一下ansible的配置文件，vim /etc/ansible/ansible.cfg，发现了问题所在： 这里最后三行需要改成下面的样子，这样就解决了乱码问题。 1234#module_lang = C#module_set_locale = Falsemodule_lang = zh_CN.UTF-8module_set_locale = True]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>自动化部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 6.x安装php 5.6和redis扩展的全过程]]></title>
    <url>%2F2018%2F01%2F26%2FCentOS-6-x%E5%AE%89%E8%A3%85php-5-6%E5%92%8Credis%E6%89%A9%E5%B1%95%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[安装PHP 5.6123456789101112yum clean allyum update 整体升级一下yum包yum install -y epel-releaseyum list installed | grep php 检查时候安装过PHPrpm -Uvh http://mirror.webtatic.com/yum/el6/latest.rpm yum -y install php56w.x86_64yum -y --enablerepo=webtatic install php56w-develyum -y install php56w-xml.x86_64 php56w-gd.x86_64 php56w-ldap.x86_64 php56w-mbstring.x86_64 php56w-mcrypt.x86_64 php56w-mysql.x86_64 php56w-pdo.x86_64 php56w-opcache.x86_64yum -y install php56w-fpmchkconfig php-fpm on 开机自启动/etc/init.d/php-fpm start 启动进程php -v 查看是否安装成功 注1：如果想更换到php5.5或5.4版本, 直接把上面的56w换成55w或者54w就可以了；注2：php-opcache和php-xcache会有效的提高php执行速度； 装php的扩展其实不是很麻烦，主要的步骤如下：1）在扩展模块的客户端文件夹里面使用phpize，这样会生成一个configure文件；2）执行configure文件，后面要加上php的路径；3）将“模块.so”文件名添加到php.ini文件里，重启php-fpm进程；4）通过so文件去调用扩展模块的客户端，实现连接对应的模块； 安装redis扩展123456redis-cli -v 检查是否安装了redisredis-server -vwget http://pecl.php.net/get/redis-2.2.8.tgz tar -zxvf redis-2.2.8.tgzcd redis-2.2.8 phpize 一个专门挂接php扩展的工具，该命令一定要使用在php的模块文件夹主目录下，这里报错Cannot find config.m4。因为phpize要根据模块生成模块的配置文件放在模块文件夹下面 12345./configure --with-php-config=/usr/bin/php-configmake &amp;&amp; make installmake testvim /etc/php.ini 在php.ini里添加一句“extension="redis.so"”service php-fpm restart]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>centos</tag>
        <tag>php</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个连接两个文件的python脚本]]></title>
    <url>%2F2018%2F01%2F26%2F%E4%B8%80%E4%B8%AA%E8%BF%9E%E6%8E%A5%E4%B8%A4%E4%B8%AA%E6%96%87%E4%BB%B6%E7%9A%84python%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[背景交代公司在阿里云上有一个模块叫mrs，一共120台，它是跟云录像有关的，这个服务一直都是云服务器里没有公网但是购买了公网SLB，然后20个为一组配置到一个SLB里，这个SLB是按流量收费的。但是最近到了年末，各种账目审核，领导发现这个SLB的费用太惊人了，这么搞不够挣的。但是实在没办法，因为云录像嘛，肯定流量很大，如图： 纵然流量大，但是开源节流也是必须的，于是领导就责令开发赶快想出一个办法，减少SLB的费用。于是开发们拉上运维就吭哧吭哧的开始算经济账，最后确定每一个云服务器买7M带宽，然后流量全部走公网，把SLB的架构舍弃掉。 但是开发在这个模块V2.0里有一个变化，就是Zookeeper需要读取到每一台设备的外网IP，同时这个外网IP必须跟机器是一一对应的，这样模块才能正常工作。 原来的zookeeper在servermap是长这样的： 1234["内网IP"] = &#123;app = "mrs", weight = 100&#125;,["内网IP"] = &#123;app = "mrs", weight = 100&#125;,["内网IP"] = &#123;app = "mrs", weight = 100&#125;,剩下略 而现在开发要求改成这样： 1234["内网IP"] = &#123;app = "mrs",mrsReportIp = "对应的外网IP",weight = 100&#125;,["内网IP"] = &#123;app = "mrs",mrsReportIp = "对应的外网IP",weight = 100&#125;,["内网IP"] = &#123;app = "mrs",mrsReportIp = "对应的外网IP",weight = 100&#125;,剩下略 那么这就要把两个文件合并起来了，而且是在合并后做到一对一，不能把IP搭配串了。 准备工作首先，阿里云的网页控制台是无法做到“包年包月的服务器批量永久升级基础带宽”的，只能通过API实现。那么开启了外网IP之后，服务器就会有一个对应的外网IP地址，然后在控制台里，点击“导出资源列表”，只选择服务器名称、内网IP和外网IP。 然后在生成的excel表格里，剪除掉不需要的服务器以及服务器名称，然后保证“内网IP”在前，“外网IP”在后的样式，而且不要服务器名只保留IP,然后把这个文件复制到linux里，起个名，比如叫IP.txt,如图： 12345[root@paas-online-crs-001 tmp]# cat IP.txt10.161.236.231 3.3.3.310.161.235.150 2.2.2.210.51.10.182 4.4.4.410.117.219.72 1.1.1.1 再把已经使用的zookeeper复制一下，放到一个叫mingdan.txt的文件里，如图： 12345[root@paas-online-crs-001 tmp]# cat mingdan.txt["10.117.219.72"] = &#123;app = "mrs", weight = 100&#125;,["10.161.235.150"] = &#123;app = "mrs", weight = 100&#125;,["10.161.236.231"] = &#123;app = "mrs", weight = 100&#125;,["10.51.10.182"] = &#123;app = "mrs", weight = 100&#125;, 脚本思路我最开始打算用awk的NR、FNR去写，但是发现由于我这个文本的结构太过复杂。awk对付这样的力不从心，稍不好就把人搞得无法自拔，于是就考虑使用python的字典。 各位都知道，字典里key是不能重复的，而我又不想把这个脚本搞得太复杂，就想在mingdan.txt里的每一行加上序号，用这个序号去当key，而后面的内网IP就作为value，这样保证一一对应。加序号的方法很多，你可以在vim状态下:set number，然后手动复制粘贴。不过我是用的是如下两个命令： 12sed -i 's/^[ \t]*//g' mingdan.txt #这一步是添加每一行序号sed -i 's/\t/ /g' mingdan.txt #添加序号之后，会生成一个ta 然后mingdan.txt就成了这样： 12345[root@paas-online-crs-001 tmp]# cat mingdan.txt 1 ["10.117.219.72"] = &#123;app = "mrs", weight = 100&#125;,2 ["10.161.235.150"] = &#123;app = "mrs", weight = 100&#125;,3 ["10.161.236.231"] = &#123;app = "mrs", weight = 100&#125;,4 ["10.51.10.182"] = &#123;app = "mrs", weight = 100&#125;, 万事俱备，现在就要把IP.txt和mingdan.txt按照相同的内网IP整合成一个文件！ 脚本正文这个脚本是不怕mingdan.txt和IP.txt的IP顺序的。 1234567891011121314151617181920212223#!/usr/bin/env python#coding=utf-8import refd = &#123;&#125; #先设置一个新的空字典叫fd#以下都是最后拼字符串用的aaa = '["'bbb = '"] = &#123;app = "mrs",mrsReportIp = "'ccc = '",weight = 100&#125;,' #首先先判断mingdan.txt里是否存在for l in open('mingdan.txt', 'r'): ar = re.split(r'[ ""]',l) #做分割，把内网IP切出来 print "ip is :" + ar[2] #确认是否分割出来的是内网IP地址 fd[ar[0]] = ar[2] #把这个内网IP地址当作value，前面的序号就是key with open('out.txt', 'w') as fw: for l in open('IP.txt', 'r'): ar = l.split() if ar[0] in fd.values(): #如果IP.txt里面的内网IP与字典fd里的value相符合 fw.write(aaa + ar[0] + bbb + ar[1] + ccc) #拼成一个完整的字符串 fw.write('\n') #保存文件print('文件整合完毕，请查看out.txt的结果！') 执行结果123456[root@paas-online-crs-001 tmp]# cat out.txt ["10.117.219.72"] = &#123;app = "mrs",mrsReportIp = "1.1.1.1",weight = 100&#125;,["10.161.235.150"] = &#123;app = "mrs",mrsReportIp = "2.2.2.2",weight = 100&#125;,["10.161.236.231"] = &#123;app = "mrs",mrsReportIp = "3.3.3.3",weight = 100&#125;,["10.51.10.182"] = &#123;app = "mrs",mrsReportIp = "4.4.4.4",weight = 100&#125;,[root@paas-online-crs-001 tmp]#]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix-proxy的搭建和配置全过程]]></title>
    <url>%2F2018%2F01%2F26%2FZabbix-proxy%E7%9A%84%E6%90%AD%E5%BB%BA%E5%92%8C%E9%85%8D%E7%BD%AE%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Zabbix-proxy的用途和构建图Zabbix-server是建立在金山云的，现在需要监控阿里云的redis，但是阿里云跟金山云之间通信是无法走内网的，如果直接让zabbix-server与redis直接联系，一旦公网的信息被截获的话，整个金山区的zabbix可能都会遭殃，那么既然有这种“远程监控+当监控的位置通信不便”的需求，就搭建一个zabbix-proxy来解决问题。 Zabbix-proxy是一个监控代理服务器，它收集监控到的数据，先存放在缓冲区，保存的时间可以通过配置文件设定，然后再传送到zabbix-server，这样也大大减缓了zabbix-server的压力，注意！监控代理需要一个单独的数据库，因为它的数据库表名与zabbix-server的数据库表名是一样的，如果不单独分开，后果就是数据错乱。 有人看到这里可能问了，说来说去你的zabbix-proxy跟阿里的redis依旧是走公网的啊！虽然这样也是走公网，我现在只需要配置一个防火墙规则来让他俩保证通信即可，通过防火墙来提升安全系数。架构如图： 安装Mysql 5.5Zabbix-proxy机器情况：金山云centos 6.5，安装zabbix版本：3.0.8 1234567891011[root@js-online-cjhmq-002 opt]yum list installed | grep mysql #列出已经安装过的mysql情况[root@js-online-cjhmq-002 opt]yum -y remove mysql-libs.x86_64 #把之前的mysql连根拔起[root@js-online-cjhmq-002 opt]# rpm -ivh http://repo.mysql.com/yum/mysql-5.5-community/el/6/x86_64/mysql-community-release-el6-5.noarch.rpmRetrieving http://repo.mysql.com/yum/mysql-5.5-community/el/6/x86_64/mysql-community-release-el6-5.noarch.rpmPreparing... ########################################### [100%] 1:mysql-community-release########################################### [100%][root@js-online-cjhmq-002 opt]groupadd zabbix #新建用户组zabbix[root@js-online-cjhmq-002 opt]useradd -g zabbix -u 808 -m zabbix#-g：指定用户所属的群组；#-u：指定用户id。#-m：自动建立用户的登入目录； 现在要修改一下/etc/yum.repos.d/mysql-community.repo这个文件，将5.5的enabled改为1,5.6的enabled改为0： 123456789101112131415# Enable to use MySQL 5.5[mysql55-community]name=MySQL 5.5 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.5-community/el/6/$basearch/enabled=1 #这里改成1gpgcheck=1 gpgkey=file:/etc/pki/rpm-gpg/RPM-GPG-KEY-mysql# Enable to use MySQL 5.6[mysql56-community]name=MySQL 5.6 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.6-community/el/6/$basearch/enabled=0 #这里改成0gpgcheck=1gpgkey=file:/etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 然后执行yum install mysql-community-client mysql-community-devel mysql-community-server php-mysql， 安装服务端和客户端，安装完毕之后可以mysql -h127.0.0.1看一下。 安装完毕之后，修改一下/etc/my.cnf，如图： 12innodb_buffer_pool_size = 512M #这个根据服务器性能填写，这个机器是2核2G的，所以我拿出半个G给mysqlinnodb_file_per_table=1 #这个是新增的字段，设置InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据目录 mysql安装完毕之后，我们还要导表进去，如图： 123456service mysqld startmysqladmin -uroot password '123456'mysql -uroot -p123456 -e 'create database zabbix_proxy character set utf8;'mysql -uroot -p123456 -e "grant all privileges on zabbix_proxy.* to zabbix@localhost identified by 'zabbix';"mysql -uroot -p123456 -e "flush privileges;"mysql -uzabbix -pzabbix zabbix_proxy &lt;/解压路径/zabbix-3.0.8/database/mysql/schema.sql 至此，mysql部分已经全部搞定。 安装Zabbix-proxy先去https://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/3.0.8/下载zabbix-3.0.8.tar.gz，上传到proxy服务器里。 12tar -zxvf zabbix-3.0.8.tar.gz./configure --prefix=/usr/local/zabbix-3.0.8 --sysconfdir=/etc/zabbix --enable-proxy --enable-agent --enable-ipv6 --with-mysql=/usr/bin/mysql_config --with-net-snmp --with-libcurl --with-openipmi --with-unixodbc --with-ldap --with-ssh2 --enable-java 如果出现了configure: error: Invalid LDAP directory - unable to find ldap.h，解决方法就是： 1yum -y install openldap* Zabbix-proxy的配置打开/etc/zabbix/zabbix_proxy.conf，需要修改几个地方： 123456789101112ProxyMode=0 #0是主动模式，1是被动模式Server=A.B.C.D #这里填写zabbix-server的内网IPHostname=J.Q.K.A #这里要与/etc/hosts下的名字一模一样LogFile=/tmp/zabbix_proxy.logDBHost=localhostDBName=zabbix_proxyDBUser=zabbixDBPassword=zabbixConfigFrequency=120 #主动去server端去拉去配置更新的频率120秒一次DataSenderFrequency=60 #发送采集的监控数据到服务器端，默认是1秒，我们一分钟发送一次#ProxyLocalBuffer=0 #ProxyLocalBuffer表示数据传递给server之后还要在proxy里保存多久（单位为小时）。如果注释就是代表不删除。#ProxyOfflineBuffer=1 #ProxyOfflineBuffer表示数据没有传递给server的话还要在proxy里保存多久（单位为小时）。如果注释就是代表不删除。 然后就是启动proxy: 1# /usr/local/zabbix_proxy/sbin/zabbix_proxy 用netstat查看一下端口和进程是否都OK： Zabbix-server端的配置登入zabbix-server的网页，如图添加proxy： 点击“create proxy”之后，就对应填写资料吧： 这里对上面的几个选项多说几句： 12345678Connections to proxy：服务器如何连接到被动代理：无加密（默认），使用PSK（预共享密钥）或证书。Connections from proxy：从活动代理中选择允许的连接类型。 可以同时选择几种连接类型（用于测试和切换到其他连接类型）。 默认为“无加密”。#点击Certificate之后又两个参数：Issuer：允许颁发证书。 证书首先通过CA（认证机构）验证。 如果CA有效，则由CA签名，则可以使用Issuer字段来进一步限制允许的CA。 该字段是可选的，如果您的Zabbix安装使用多个CA的证书，则使用该字段。Subject：允许的证书。 证书首先通过CA验证。 如果它有效，由CA签名，则主题字段可用于仅允许Subject字符串的一个值。 如果此字段为空，则接受由配置的CA签名的任何有效证书。 #点击PSK之后又两个参数：PSK identity：预共享密钥身份字符串。PSK ： 预共享密钥（hex-string）。 如果Zabbix使用mbed TLS（PolarSSL）库，Zabbix将使用GnuTLS或OpenSSL库，64位十六进制（32字节PSK），最大长度为512位十六进制数（256字节PSK）。 示例：1f87b595725ac58dd977beef14b97461a7c1045b9a1c963065002c5473194952 保存之后，就在zabbix-server用zabbix-get去ping一下proxy，看看返回值是否是1，如果是zabbix_get [18290]: Check access restrictions in Zabbix agent configuration，就检查一下刚才的hostname等值是否正确。 被监控机器的配置在被监控的阿里云redis里安装zabbix-agent，在agentd.conf里把hostname写成自己在/etc/hosts里的hostname，Server地址和ServerActive的地址都要写成proxy的外网IP地址。保存之后启动agent进程，这个时候在proxy端是可以通过zabbix_get得到这台被监控机器的值，如图： 在Zabbix-Server的WEB界面里，为阿里云的redis新建一个host，Agent interface那里填写被监控的机器IP，端口是10050，Monitored by proxy的地方要写成刚刚添加的proxy。如图： 上面已经提到过，用proxy模式并且zabbix的客户端也是主动模式提交数据，这样能大大提高采集效率，降低zabbix服务器端和proxy端的压力。现在我们希望添加的还是使用zabbix_agent的方式，新加到zabbix_proxy里面的主机使用zabbix_agent（active）的方式。注意在模板的克隆要选择full clone，不要选“clone”，那样的话就仅仅是把iterm的名字克隆过去而已，如图： 然后在items选择具体的类型，根据需要，想改那个改哪个，如图，注意！我图里写的是Zabbix agent，但是type这里选择Zabbix agent (active)。 改完之后，保存一下，就会看到type都是zabbix agent（active）了。 最后在host里把这个机器添加到proxy的模板里，如图： 在Administration的Proxies也看到效果了，如果server与proxy没有正确连接的话，last seen的地方会是--，如果连接的话就会显示具体时间，如图: 返回到hosts里，查看那个被监控的redis机器也成功被监控到了，ZBX已经变绿。如图： 因为我们线上环境基本都是用的zabbix_proxy方式是active方式，然后客户端也是active方式，既然都是active方式，那么zabbix_agent的Hostname就很重要，打个比方如果再zabbix_server端把一个主机的Hostname改了，然后客户端那边也改了，服务端和客户端的Hostname是统一的，但是proxy那里还记录的是旧Hostname，然后就会在proxy日志里面看到下面一条： 1cannot send list of active checks to "proxy内网IP地址": host [virt_proxy内网IP地址] not found proxy主动模式下，ConfigFrequency默认的是3600秒一小时，显然有点大了，可以适当的调低一下，如10分钟或者几分钟什么的。然后出现问题多看看zabbix服务端和proxy的日志，对症下药。 参考资料http://www.51niux.com/?id=156http://www.cnblogs.com/wangxiaoqiangs/p/5336630.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>监控技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云服务器更改时区为utc]]></title>
    <url>%2F2018%2F01%2F25%2F%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9B%B4%E6%94%B9%E6%97%B6%E5%8C%BA%E4%B8%BAutc%2F</url>
    <content type="text"><![CDATA[开发提出需求说，某个模块是给洋人使用，于是把服务器里的时间改成UTC时间。我登陆到服务器里使用date查看了一下，发现目前使用的是东八区时间，如图： 首先先开启UTC，方法就是在/etc/sysconfig/clock的文件里修改这样一处：UTC=true。这样即使机器重启，UTC时间依旧会“BIOS ▶ UTC时区转换 ▶ 系统时间”的顺序正常使用。 在Centos 6.5里，各时区的时间是在一个叫/usr/share/zoneinfo/的文件夹下，在里面我们发现了我们的目标—-UTC，如图： 然后就是修改，方法如下： 12mv /etc/localtime /etc/localtime-bakln -s /usr/share/zoneinfo/UTC /etc/localtime 先把老的时间文件备份，然后把UTC文件做一个软连接过来即可。我们所熟悉的date命令就是/etc/localtime的输出结果。 现在去date一下，看看结果，果然改成了UTC： 这个时候，如果你服务器里装的是nginx的话，就会发现nginx日志里的时间也会变成UTC而不会再是CST了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云购买、启动、停止ecs等等操作的python脚本]]></title>
    <url>%2F2018%2F01%2F24%2F%E9%98%BF%E9%87%8C%E4%BA%91%E8%B4%AD%E4%B9%B0%E3%80%81%E5%90%AF%E5%8A%A8%E3%80%81%E5%81%9C%E6%AD%A2ecs%E7%9A%84python%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[以下所有脚本都是在python 2.7的环境亲自测试的。阿里云的ak/sk是没有地域概念的，在任何地域都可以使用。 购买服务器以在新加坡购买服务器为例子： 12345678910111213141516171819202122232425262728#!/usr/bin/env python#coding=utf-8#注意！服务器创建完毕之后，状态是关机的。from aliyunsdkcore import clientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionfrom aliyunsdkecs.request.v20140526 import CreateInstanceRequest# 创建 Client 实例clt = client.AcsClient('阿里云ak','阿里云sk','新加坡的地域') #各地域的缩写请看：https://help.aliyun.com/document_detail/40654.html?spm=5176.doc25499.2.14.yh6n8c# 创建 request，并设置参数request = CreateInstanceRequest.CreateInstanceRequest()# 设置ECS细节request.set_ImageId("centos_7_04_64_20G_alibase_201701015.vhd") #这里是镜像request.set_InstanceName("xjp-test-001") #这里写名称request.set_SecurityGroupId("sg-23t6c6mjw") #这里是安全组request.set_Password("W2.bi7FX1dyb)T3Wh^,[") #这里是密码，推荐使用https传输，安全request.set_InstanceChargeType("PrePaid") #确定是包年包月request.set_Period("2") #先买两个月的request.set_SystemDiskCategory("cloud_efficiency") #注意，如果是海外的机器的话，要额外说明，海外的机器只有高速云盘和SSD盘# 设置实例规格request.set_InstanceType("ecs.s2.large")# 发起 API 请求并打印返回response = clt.do_action_with_exception(request)print response 服务器停机1234567891011121314#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import StopInstanceRequestlist1 = ['要停机的ecs id1','要停机的ecs id2','要停机的ecs id3'...]clt = client.AcsClient('阿里云ak','阿里云sk','地域名')for i in list1: shutdown = StopInstanceRequest.StopInstanceRequest() shutdown.set_InstanceId(i) action = clt.do_action_with_exception(shutdown) print "现在停机:" + i print action 服务器启动1234567891011121314#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import StartInstanceRequestlist = ['要停机的ecs id1','要停机的ecs id2','要停机的ecs id3'...]clt = client.AcsClient('阿里云ak','阿里云sk','地域名')for i in list: start = StartInstanceRequest.StartInstanceRequest() start.set_InstanceId(i) action = clt.do_action_with_exception(start) print "现在启动:" + i print action 查询阿里云镜像123456789101112131415#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import DescribeImagesRequestimport aliyunsdkcore.requestclt = client.AcsClient('阿里云ak','阿里云sk','地域名')request = DescribeImagesRequest.DescribeImagesRequest()request.set_accept_format('json')# 发起请求response = clt.do_action_with_exception(request)print response 查询服务器规格123456789101112131415#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import DescribeInstanceTypesRequestimport aliyunsdkcore.requestclt = client.AcsClient('阿里云ak','阿里云sk','地域名')request = DescribeInstanceTypesRequest.DescribeInstanceTypesRequest()request.set_accept_format('json')# 发起请求response = clt.do_action_with_exception(request)print response 参考资料https://help.aliyun.com/document_detail/25499.html?spm=5176.doc25501.6.857.wR0MHP]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>阿里云api</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Crontab里解决脚本时间重叠的问题]]></title>
    <url>%2F2018%2F01%2F24%2FCrontab%E9%87%8C%E8%A7%A3%E5%86%B3%E8%84%9A%E6%9C%AC%E6%97%B6%E9%97%B4%E9%87%8D%E5%8F%A0%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[正文Linux里的Crontab是一个好东西，但是它的默认最小执行频率是1分钟，但是我们在实际生产环境里有的时候遇到的脚本执行时间是大于1分钟的，这样就会出现一个很尴尬的情况，就是在1分钟过后，系统进程会出现多个脚本，neck and neck式的在后台运行，比如这样： 从上面的图可以看到，10点36分log499.sh没有执行完毕，10点37又开始了执行了一个新的log499.sh脚本。这种脚本冲突肯定不是我们所希望的，那么如何才能保证后台只是在一段时间里只执行一个脚本呢？ 这个时候我们就要使用文件锁，flock，这种方法要比判断pid高大上的多。 首先假设我们的脚本名字叫abc.sh，这个脚本文件的执行时间是要大于1分钟的，同时我们再设定一个锁文件，位置就叫/tmp/abc.lock,这个文件可以是空的，然后crontab -e，添加一句命令如下： 1* * * * * flock -xn /tmp/abc.lock -c 'sh /路径/abc.sh &gt;&gt; /记录日志的路径 2&gt;&amp;1' 这个时候静候crontab启动abc.sh，通过ps -ef|grep abc，发现在后台始终只有一个abc进程。 但是有的时候会有这样的一个问题，就是abc执行一次之后，在下一次该执行的时候却没有执行，好像crontab失效了一样，对于这样的情况，就需要添加下面的语句到abc.sh末尾： 123rm -rf /tmp/abc.lock #删除掉原有的锁文件sleep n #睡n秒touch /tmp/abc.lock #再新建一个锁文件 这样不断地更新lock锁文件，就会保证crontab每次都会按期执行。 这里要注意一下，里面我加了一句sleep n，这里的n是为了跨分钟的存在，这是为了防止没有走到下一个分钟又会生成一个新的lock锁文件，这样还是会出现重复启动脚本的情况。 这里就涉及到flock的一个原理：在每一次执行任务的时候都会先去尝试取到锁文件，如果取到了锁文件，那么就会下一步，反之就会放弃执行。A任务在运行的时候已经占据了lock文件，那么B任务来了，发现没有lock了，就不会执行任务。 这里我们使用了flock的三个参数： 123-x, --exclusive: 获得一个独占锁-n, --nonblock: 如果没有立即获得锁，直接失败而不是等待-c, --command: 在shell中运行一个单独的命令 当然，flock还是有很多丰富的参数可以供各位使用，大家就各自去google一下吧。 参考资料http://blog.csdn.net/fdipzone/article/details/38284009http://chuansong.me/n/285635151949https://segmentfault.com/q/1010000008039907]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>crontab</tag>
        <tag>运维技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum提示Error: rpmdb open failed]]></title>
    <url>%2F2018%2F01%2F24%2Fyum%E6%8F%90%E7%A4%BAError-rpmdb-open-failed%2F</url>
    <content type="text"><![CDATA[今天在一台机器里，使用yum安装的时候，出现了如下的故障： 这种情况就是RPM数据库被破坏了，这个时候就需要我们重建数据库，于是就输入如下的命令： 1234cd / var / lib / rpm /for i in ` ls | grep 'db.' ` ; do mv $i $i .bak ; donerpm -- rebuilddbyum clean all 重新cleanup就正常了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[由一个实例浅析sed用法]]></title>
    <url>%2F2018%2F01%2F23%2F%E7%94%B1%E4%B8%80%E4%B8%AA%E5%AE%9E%E4%BE%8B%E6%B5%85%E6%9E%90sed%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[首先，假设我们有一个文件，叫123.txt，cat一下看到里面的内容是这样的： 12345678[root@func-lms-001 ~]# cat 123.txt jamescurry durantwadeyaoming messi[root@func-lms-001 ~]# 如果我们想在james前面加上lebron，那么采用的sed语句就是：sed -i &#39;/^james/s/^/lebron /&#39; 123.txt，如果要在curry后面加上champion，那么采用的语句就是：sed -i &#39;/^curry/s/$/ champion!/&#39; 123.txt。 使用完上面两句话之后，再#cat一下，看下效果： 12345678[root@func-lms-001 ~]# cat 123.txt lebron jamescurry champion! durantwadeyaoming messi[root@func-lms-001 ~]# 现在我们要把durant前面加上FMVP这几个字母，按照上面的语句找葫芦画瓢的话，应该是：sed -i &#39;/^durant/s/^/FMVP /&#39; 123.txt。但是很抱歉，这个语句是错误的！因为^是匹配开头durant的意思，而我们再看一下durant那一行的开头是空格。 那么就要用liunx的正则来匹配空格，于是这句话就变成了：sed -i &#39;/^\s\+durant/s/^/FMVP/&#39; 123.txt，^\s\+这个就是正则里匹配空格的意思 。 cat一下： 12345678[root@func-lms-001 ~]# cat 123.txt lebron jamescurry champion!FMVP durantwadeyaoming messi[root@func-lms-001 ~]# 那么现在要在messi后面加上”GOAL !!!”，就很简单了。语句是：sed -i &#39;/^\s\+messi/s/$/ GOAL !!!/&#39; 123.txt。 以上我们把有/无空格情况下的首尾添加字符都练习了一遍，下面我们要看看如果要在中间添加怎么办？ 比如说，有一天苦逼的运维接到开发PL的邮件，说”由于安全基线要求，现在需要监听内网端口“，具体的需求就是把所有含tomcat的模块里的server.xml的文件里添加上内网IP。 原有的server.xml的节选如下： 12345678910&lt;Service name="LMS"&gt; &lt;Connector port="8080" connectionTimeout="20000" protocol="org.apache.coyote.http11.Http11NioProtocol" redirectPort="8443" enableLookups="false" disableUploadTimeout="true" maxThreads="500" minSpareThreads="20" acceptCount="100"/&gt; &lt;Connector port="8088" connectionTimeout="20000" protocol="org.apache.coyote.http11.Http11NioProtocol" redirectPort="8443" enableLookups="false" disableUploadTimeout="true" maxThreads="500" minSpareThreads="20" acceptCount="100"/&gt; &lt;Connector port="8099" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine defaultHost="localhost" name="Catalina"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase" /&gt; &lt;/Realm&gt; 现在要把&lt;Connector port=&quot;8099&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;这一句里面加上内网IP:1.2.3.4，改成这样： 12345678910&lt;Service name="LMS"&gt; &lt;Connector port="8080" connectionTimeout="20000" protocol="org.apache.coyote.http11.Http11NioProtocol" redirectPort="8443" enableLookups="false" disableUploadTimeout="true" maxThreads="500" minSpareThreads="20" acceptCount="100"/&gt; &lt;Connector port="8088" connectionTimeout="20000" protocol="org.apache.coyote.http11.Http11NioProtocol" redirectPort="8443" enableLookups="false" disableUploadTimeout="true" maxThreads="500" minSpareThreads="20" acceptCount="100"/&gt; &lt;Connector port="8099" address="1.2.3.4" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine defaultHost="localhost" name="Catalina"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase" /&gt; &lt;/Realm&gt; 请问怎么做？ 答案1： 1sed -i '/&lt;Connector port="8099"/s/port="8099"/port="8099" address="1.2.3.4"/g' server.xml 答案2： 1sed -i 's@Connector port="8099"@&amp; address="1.2.3.4"@' server.xml]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix添加网卡内外流量监控]]></title>
    <url>%2F2018%2F01%2F23%2FZabbix%E6%B7%BB%E5%8A%A0%E7%BD%91%E5%8D%A1%E5%86%85%E5%A4%96%E6%B5%81%E9%87%8F%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[现在笔者想对host名单里面的zabbix_server进行网卡的内外流量情况的一个监控，首先登录zabbix之后，configuration—hosts，出现如下的菜单： 现在可以看到这个zabbix_server后面link了很多个模板，正是因为link了很多的模板，所以导致它的items非常多，42个。现在是要在zabbix_server里添加两个新的监控项，这一步跟模板其实没有什么关系，只需要在items里直接添加items即可。 我们先添加网卡外流量的items，整个配置如图所示： 里面具体的数值可以自己更换，比如Applications什么的，key\units\Use custom multiplier这些是固定的，全部写完之后就可以save。 找葫芦画瓢，我们可以再添加一个网卡的内流量监控，也是一样的套路，如图所示： 有了items，就要有trigger，有了items里的key，那么trigger也很简单，这里的expression多时候各位都是从网上ctrl+c下来，却不能ctrl+v，因为会红字报错—-Incorrect item key &quot;net.if.in[eth0,bytes]&quot; provided for trigger expression on &quot;服务器名称&quot;，于是就有很多不明真相的吃瓜群众就走“add”路线，然后发现要走add路线还要先把服务器添加到对应的模板上去。其实大可不必，这个expression是可以自己写的，但是一定要确定trigger跟items是配对的。以外网流量所示： 在这里我添加成了1K，这样是为了方便监控，具体数值因情况而异，而且重要性我选择了无。 最后就是要形成图表来糊弄领导，让领导感受一下什么叫做高大上，在graph的界面里选择create graph，然后就如图所示的填写： 一个是红色线，一个是绿色线，双龙戏珠，save。 最后来到Monitoring—Graphs里，找到正确的host,group和graph，就会看到激动人心的图表了： 这里要注意几点，有时候zabbix反应较慢，可能写好的key会出现not support的情况，这个时候可以先登录zabbix_server去zabbix_get一下，zabbix_get的方法之前有讲过，请见http://chenx1242.blog.51cto.com/10430133/1738820 ，如果zabbix_get是成功返回值的，先检查对应的单位（结果是浮点值，但是units设定是一个整数值肯定会not support）,如果单位检查正确，就修改zabbix重新check的时间，实在不行就重新建立一个items。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>服务器监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Nessus进行漏洞扫描的过程]]></title>
    <url>%2F2018%2F01%2F23%2F%E4%BD%BF%E7%94%A8Nessus%E8%BF%9B%E8%A1%8C%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[对于一个服务器运维工作者，掌握和运用一门漏洞扫描的工具也是行走江湖的必备项，Nessus就是漏洞扫描的强力武器。Nessus为一款当下比较流行的系统弱点扫描与分析软件，他的优点是操作简单（配置几乎全web化），而且页面精美、扫描项广泛；缺点就是目前不支持中文… 下载与安装要安装Nessus，需要登陆https://www.tenable.com/products/nessus/select-your-operating-system,选择对应的系统，我这个服务器是centos 7，那么就选择下图里红色的那个rpm包： 点击之后，出来一个同意条款，同意之后就开始自动下载。但是要安装nessus仅仅有程序是不够的，还需要一个对应的验证码，在上面那个界面里，下拉一点有一个get an activation code的check，点击之后跳转到https://www.tenable.com/products/nessus/nessus-plugins/obtain-an-activation-code，里选择家用free版，点击下面的register now： 注册是很简单的，填写名称和电邮就可以了。不久后就会在电子邮件里面获得一个校验码。 把下载的那个Nessus-6.11.1-es7.x86_64.rpm包上传到centos之后，rpm -ivh Nessus-6.11.1-es7.x86_64.rpm进行安装，安装完成之后，service nessusd start启动进程，启动完毕之后，使用netstat -lnpt|grep 8834，来检查一下8834端口是否被监听，如图： 端口监听OK，那么在浏览器里输入https://服务器外网IP地址:8834打开控制web界面，如果有提示当前连接不安全，无视掉就可以。nessus的欢迎界面如下： 注册一个账号之后，在这个界面里面选择home那一条，输入邮箱里面获得的那个注册码： 整个的配置就完事了，继而就是nessus自动安装的过程，大约需要几分钟： 整个安装完毕之后，就会看到nessus的主界面，简单明了的风格： 至此整个nessus的安装过程结束。 配置扫描策略以及启动扫描任务nessus扫描漏洞的流程很简单：需要先”制定策略”，然后在这个策略的基础上建立”扫描任务”，然后执行任务。首先，我们先建立一个policy，如图： 点击New Policy之后，就会出现很多种扫描策略，这里我们选择Advanced Scan(高级扫描)： 我给这个测试的扫描策略，起名叫”chenchenchen”，如图： 对于上面这个图，Permissions是权限管理，是否可以准许其他的nessus用户来使用你这个策略；Discovery里面有主机发现、端口扫描和服务发现等功能；assessment里面有对于暴力攻击的一些设定；Report里面是报告的一些设定；Advanced里面是一些超时、每秒扫描多少项等基础设定，一般来说这里默认就好。我们主要来看看那个plugins。 Plugins里面就是具体的策略，里面有父策略，具体的父策略下面还有子策略，把这些策略制定得体的话，使用者可以更加有针对性的进行扫描。比如我这个策略是针对于centos系统的扫描策略，那么一些冗余的项目大可以完全不要，举个例子： 在上面这个图里面，我不需要amazon linux local security checks这个“亚马逊linux本地安全检查”父策略，那就把它disabled掉，而对于centos local security checks这个父策略呢，我又不需要那几个关于bind的子策略，那我就单独把那些子策略disabled掉，这样等等操作，就搭配成为了一个用时不长但是又包含了所有制定的检查项的策略，然后点击save保存。 保存完后，我们就发现policy里多了一条chenchenchen的记录： 既然策略有了，现在我们就来制定一个任务。在主界面里选择My Scans,点击New Scans,这个时候还是有很多个图标，但是我们选择后面的User defined，如图： 这里我们就看到了我们已经制定好的那个chenchenchen策略，点击这个chenchenchen之后，就要给这个依赖chenchenchen策略的任务起名字以及需要扫描的网络段，由于我这个测试机的内网ip段是10.132.27.0，于是我就写了“10.132.27.0/24”，任务名字叫chentest： 启动扫描任务点击save保存之后，就会看到My Scans里多了这个chentest的任务，点击三角播放箭头，那么这个任务就开始执行了！如图： 从该界面可以看到扫描任务的状态为Running（正在运行），表示chentest扫描任务添加成功。如果想要停止扫描，可以单击方块（停止一下）按钮。如果暂停扫描任务，单击暂停按钮。 扫描完毕之后，我们就会看到一个结果反馈，如图： 具体的颜色代表，在旁边有描述，例子里这些蓝色的info代表没有重大漏洞，点击一下蓝色，还会出现更加详细的信息，包括IP地址、操作系统类型、扫描的起始时间和结束时间： 同时，nessus还支持pdf、web、csv等多种方式汇报扫描结果，至此，整个nessus漏洞扫描的全过程就结束了。 Nessus配置smtpNessus漏洞扫描是提供邮件服务，可以将扫描的结果发送给指定的邮箱。配置它的方法很简单，先登陆Nessus的界面，点击左上角的settings，然后选择左侧菜单栏里的Smtp server，如图： 再就是填写对应的项目，我这里发送邮件的地址是：chenx3314@sina.com，接受的地址是124208739@qq.com，由于发送邮件使用的是新浪的邮箱，那么host就填写新浪的smtp服务器，即smtp.sina.com，如果是要SSL加密的话，端口写465，同时在Encryption那里选择Force SSL，在Auth Method那里选择login的鉴权方式，然后输入chenx3314@sina.com的账号密码，如图： 点击Send Test Email，然后输入接收的邮箱，如果是多个邮箱那么就用英文逗号隔开。看到成功的提示就是OK了： 然后就可以到邮箱里面看到那个测试的邮件内容：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>nessus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql清除磁盘碎片]]></title>
    <url>%2F2018%2F01%2F23%2Fmysql%E6%B8%85%E9%99%A4%E7%A3%81%E7%9B%98%E7%A2%8E%E7%89%87%2F</url>
    <content type="text"><![CDATA[任务背景接到金山云报警短信，说某数据库的容量已经达到了90%的水位线，于是登陆控制台查看详细情况。 在控制台首先发现，每一天的磁盘容量的确有所波动，那么就证明开发人员写的“资源回收”模块是在正常运行的，如图： 那么就说明没有什么数据是可以删的，既然删不掉多余的数据又不想多掏钱扩磁盘容量，只能从“磁盘碎片”下手了。而InnoDB引擎清理磁盘碎片的命令就是OPTIMIZE。 具体操作首先我先查询一下所有的“磁盘碎片情况”，使用语句如下： 1select CONCAT(TABLE_SCHEMA,'.',TABLE_NAME) as 数据表名,concat(truncate(sum(DATA_LENGTH+DATA_FREE+INDEX_LENGTH)/1024/1024,2),' MB') as total_size, concat(truncate(sum(DATA_LENGTH)/1024/1024,2),' MB') as data_size,concat(truncate(sum(DATA_FREE)/1024/1024,2),' MB') as data_free, concat(truncate(sum(INDEX_LENGTH)/1024/1024,2),'MB') as index_size from information_schema.tables group by TABLE_NAME order by data_length desc; 或者使用select table_schema, table_name, data_free, engine from information_schema.tables where table_schema not in (&#39;information_schema&#39;, &#39;mysql&#39;) and data_free &gt; 0;也可以，这个是查询data_free大于0的所有表。 然后看到我这个叫history_device_flow_day的表里情况如下： 表里的data_free就是磁盘碎片的量，比如我现在要干掉history_device_flow_day里所有的磁盘碎片，是975MB，于是先查询一下这个history_device_flow_day的存储引擎，使用语句如下： 1show table status from jsonlinefssrds where name='history_device_flow_day'; 上面语句里的jsonlinefssrds是对应的数据库，看到的效果如下： 存储引擎是InnoDB，那么就可以启动清除碎片的语句了：OPTIMIZE TABLE 数据表表名;，因为OPTIMIZE TABLE只对MyISAM、BDB和InnoDB表起作用。 再执行了OPTIMIZE TABLE history_device_flow_day;之后，大约9分钟，就会看到“OK”的字样： 估计有的朋友会问，那上面不是明明写了“Table does not support optimize, doing recreate + analyze instead”吗？这个其实无妨，实际上磁盘碎片已经被清除掉了。我们可以再用一次查询磁盘碎片的命令看一下，如图： 的确释放了900多M。 或者使用ALTER TABLE 表名 ENGINE = Innodb;（只是InnoDB的表可以这么做，而且据说这么做更友好）来达到清理磁盘碎片的目的，这个命令表面上看什么也不做,实际上是重新整理碎片了。当执行优化操作时,实际执行的是一个空的ALTER命令,但是这个命令也会起到优化的作用,它会重建整个表,删掉未使用的空白空间。 补充为什么会产生磁盘碎片？那是因为某一个表如果经常插入数据和删除数据，必然会产生很多未使用的空白空间，这些空白空间就是不连续的碎片，这样久而久之，这个表就会占用很大空间，但实际上表里面的记录数却很少，这样不但会浪费空间，并且查询速度也更慢。 注意！OPTIMIZE操作会暂时锁住表,而且数据量越大,耗费的时间也越长,它毕竟不是简单查询操作。所以把OPTIMIZE命令放在程序中是不妥当的,不管设置的命中率多低,当访问量增大的时候,整体命中率也会上升,这样肯定会对程序的运行效率造成很大影响。比较好的方式就是做个shell,定期检查mysql中 information_schema.TABLES字段,查看DATA_FREE字段,大于0的话,就表示有碎片，然后启动脚本。 参考资料http://pengbotao.cn/mysql-suipian-youhua.htmlhttp://irfen.me/mysql-data-fragmentation-appear-and-optimization/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一道传说中是百度面试的shell试题]]></title>
    <url>%2F2018%2F01%2F23%2F%E4%B8%80%E9%81%93%E4%BC%A0%E8%AF%B4%E4%B8%AD%E6%98%AF%E7%99%BE%E5%BA%A6%E9%9D%A2%E8%AF%95%E7%9A%84shell%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[【问题】写脚本实现，可以用shell、perl等。把文件b中有的，但是文件a中没有的所有行，保存为文件c，并统计c的行数。翻译成人话就是，假设有一个文件a是:abcd 文件b是:1234ab 现在要求输出“b有a没有”的行，即1 2 3 4，然后wc -l一下。 【思路】两个文件比较，第一想法就是diff，但是diff无论是-c还是-y会牵扯进大量的&gt; &lt; + -不说，而且diff命令是直白对比，即使字母相同但所在行不同，也会被diff记录。如果再用for in语句然后一项一项对比也不会很清晰的解决这个问题，所以要换个方法。 第二个方法就是comm命令，但是这个命令有一个前提，就是要sort排序，comm比diff高明之处在于它只比较内容而不在意是否同一行，但是要注意对比文件的先后。comm -12 a b是找”a和b都有”的项，comm -23 a b就是找”a有而b没有”。 【解答】perl我不会，我就用shell写： 123456#!/bin/bash#written by ChrisChan @ 2016-4-21sort a.txt&gt;a1.txt #排序，不然会有提示sort b.txt&gt;b1.txtcomm -23 b1.txt a1.txt &gt;c.txt #由于是要找b有a没有的,就要b写在前，a写在后echo $(cat c.txt|wc -l) 其实还有一个更简单的，只用一句话: 1grep -v -x b.txt -f a.txt|wc -l 很多书上不写grep -x -f的意思，这里补一下：-f:指定范本文件，其内容含有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每列一个范本样式。-x:只显示全列符合的列。 从一个题就能轻松看出shell的能力级别，用diff死纠缠就是初级，用comm就是中级，而grep就是高级。的确是一个好题。 【补充】如果考python，求这种类似“你有我没有”的东西，用set里面的差集算法。 12345678910&gt;&gt;&gt;A=&#123;1，2，3，4&#125;&gt;&gt;&gt;B=&#123;3，4，5，6&#125;&gt;&gt;&gt;print(A-B)set([1,2]) #A有B没有&gt;&gt;&gt;print(A ^ B)set([1,2,5,6]) #差集的补集&gt;&gt;&gt; A&amp;B&#123;3, 4&#125; #交集&gt;&gt;&gt; A|B&#123;1, 2, 3, 4, 5, 6&#125; #全集]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>面试经验</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Zabbix在web界面中文显示的问题]]></title>
    <url>%2F2018%2F01%2F22%2F%E8%A7%A3%E5%86%B3Zabbix%E5%9C%A8web%E7%95%8C%E9%9D%A2%E4%B8%AD%E6%96%87%E6%98%BE%E7%A4%BA%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[注意！这个是解决web界面中文显示乱码的问题，不是zabbix web界面全中文汉化的问题。 2.2版本的处理方法zabbix里给host或者item等项目起中文名字的时候，可能在graph上无法正确显示中文字符，如图： 那么遇到这样的情况其实很简单，就是zabbix的web界面没有安装中文字库的问题，那就对症下药，下载中文字库。 中文字库的下载地址在这里：http://linux.linuxidc.com/2012%E5%B9%B4%E8%B5%84%E6%96%99/11%E6%9C%88/22%E6%97%A5/Zabbix%E4%B8%AD%E6%96%87%E4%B8%8D%E8%83%BD%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98/ ，下载“LinuxIDC.com下载-kaiti.tar.gz”。 后把这个文件改一下名，可能很多linux不识别那个中文字“下载”,mv LinuxIDC.com下载-kaiti.tar.gz kaiti.tar.gz，tar -zxvf kaiti.tar.gz 然后就会发现当前路径里生成了一个叫kaiti.ttf，这个就是我们所需要的中文“楷体”字体文件。 来到zabbix的web字体路径，在我的机器里，这个负责字体的文件夹叫/usr/local/nginx/html/zabbix/fonts/。虽然各位安装zabbix的路径各有差别，但是这个文件夹一般都是在nginx or apache的html下，所以很好找的。 在这个fonts文件夹里默认已经有一个叫DejaVuSans.ttf的文件了，于是就把这个kaiti.tff也放到这个文件夹下。 光有字体文件没有用，还需要在配置文件里使用这个字体文件，于是就vim一下同样在nginx or apache/html/zabbix/include的defines.inc.php。把里面所有的DejaVuSans替换成kaiti，.tff这个后缀是不用加的。然后保存退出，重新刷一下界面就看到效果了。 vim的替换语句 :%s/DejaVuSans/kaiti/g 3.x版本的处理方法现在zabbix已经升级到3.x了，上述的方法已经失效了，这里记录一下新的中文配置方法。 首先从windows里，拷贝一个中文字体的文件到zabbix的服务器的/usr/share/zabbix/fonts文件夹里，比如我先择了“楷体”，这个文件叫simkai.ttf，chmod +x simkai.ttf 给予可执行权限。 然后vim /usr/share/zabbix/include/defines.inc.php，修改两处地方，分别是第四十五行，把原来的改成simkai，如图： 还有一处就是第九十三行，也是改成SIMKAI： 保存文件之后，刷新一下zabbix界面即可。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>运维与监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防盗链的等等相关]]></title>
    <url>%2F2018%2F01%2F22%2F%E9%98%B2%E7%9B%97%E9%93%BE%E7%9A%84%E7%AD%89%E7%AD%89%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[为什么网站们都要限制流量？无论是网站服务器亦或是游戏服务器还是邮件服务器，说穿了也是一台电脑，也有CPU和内存。只不过服务器的CPU功能比个人电脑的CPU功能强大，比如个人电脑的CPU一秒钟能算1亿个数，那么服务器的CPU一秒钟就能算十亿个数。毕竟个人电脑只针对个人，但是服务器是要“接客”的，有了强大的硬件做后盾，网页/游戏/邮箱才不会那么轻易的Down掉。 但是CPU不是人类大脑，人脑是越用越聪明，CPU是越用越磨损，毕竟始终在连电的环境下。于是乎，没有必要的运算能省就省，一个人省一次，十万个人就省十万次，一千万个人就省一千万次，这样达到积少成多的目的。 CPU计算的是各种数据，而这些数据也叫作流量。有用的流量、有价值的流量通过CPU计算无可厚非，但是出现了没有用的流量或者是别人盗用我们的资源，那么这种情况能避免都要避免。什么叫盗用我们的资源，比如自己网站（网站A）上的图片或者视频，被其他人直接复制网站然后粘贴到他们的主页（网站B）上，其他用户登录了B网站，然后点击了那个图片和视频，由于是网址重链接，里外里提供数据的还是我们的服务器。也就是说B网站就是一个中介，而真正提供服务的是网站A，但是广告费和点击率都要网站B赚走了，这事儿实在是叔可忍婶不可忍。 什么是盗链？如何发现被盗链？什么叫盗链，上面已经说的差不多了，如果上面的文字没有看懂的话，举个例子，如果您看到了这两个图片，证明这个网站就是在盗链。 这两个就是一个盗取的是QQ空间的图片，另一个就是百度的图片。用其他网站的图片这事儿本身是无所谓的，只要不涉及版权问题，都希望自己的作品能广泛传播，但是请不要直接通过网址重定向，厚道一点的行为应该是：“图片另存为”，然后到目标网站上去重新上传一下。 这里再多说一点网站的基础知识。 PV值：PV=page view，网站是有少则一个网页多则N多网页组成的一个整体，PV值就是统计用户访问网站的总页数。比如www.JQK.com这个网站，今天有100个用户登录，平均每个用户翻阅了里面5个网页。那么这个网站的PV值就是500。若一个IP地址，对一个页面刷新10000次，PV值也是1.要查询网站的PV值登陆http://www.alexa.cn就行。 Hit值：这个就是对网页里每个元素的点击量，一个网页里的图片就是一个元素，一个flv文件也是一个元素，一首歌曲也是一个元素。这些的总量就是hit值，hit值越高就证明这个网站被人查看的情况越高，那么也证明网站的高人气，那么自然广告也会卖出去很多钱。 因为建网站这事儿关心到了金钱利益，网站越被人关注，自然价值也越大。于是会有一个公式来评判网站的“每日贡献”：总流量=访问流量+下载流量= Page view值 x 页面大小+下载文件大小 x 下载次数 作为管理者，每天观察一下自己一亩三分地儿的网站数据情况是本职工作。但是有时候也会遇到网站流量很惊人的情况，一般来说，网站流量过大（CPU运转很多）的原因如下： 1）网站是一个很大的网站：比如说淘宝，京东，网易，youtube,facebook那种大网站，里面成万上亿的网页，而且每天又有那么多人登陆，自然浏览量很大。虽然这些大集团的服务器也是少则几千，多则上万，甚至在不同地区也会有不少的服务器集群，但是这几万台服务器需要提供的数据会很多也是不争的事实。这种现象是正常的。 2）网页内容太大：可能本身网站是一个小网站，加起来也就十页二十页的内容，但是每一天的流量依旧很惊人，那么很有可能是单页或者某几页的字节太大。比如网页里有太多的图片，太多的视频，太多的其他链接，也有可能是前端码农们给这个网页的规划不合理。导致这个网页每一次被点击都要大费周折（hit值和PV值不高，但是日流量很高），长此以往不仅会耽误用户的整体体验，对服务器也是一个重大伤害。 3）搜索引擎产生了大量的数据流量：网站需要推广，于是就在各种搜索引擎上打广告，也有自己网站的很多图片用于外部调用。这样的结果就是本身来观摩网站的人很少，但是“借着引擎经过”的人很多，所以就会有PV值不高，但是Hit值和日流量很高的现象出现。 4）图片或者其他元素被盗链：第一部分就说过了，别人拿我们的图片去吸引别人关注，然后别人想要深入了解，还要来使用我们的服务器去提供详细数据。这种“用我们的牌子住我们的房，吃我们的饭却不给我们钱”的现象实在应该被弄死。这种现象的特征也是PV值不高（没人真正点击网站），但是Hit值和日流量很大（自己服务器的数据都给别的网站提供了）。 5）网站被DDos攻击了：被一些恶意的IP地址频繁登陆，来回的刷流量。这样迫使CPU做出运算的行为其实就是在远程的破坏服务器的硬件CPU，遇到这种现象，之前Nginx文章里有写，要么通过access.log找到这些IP封掉，要么就在配置文件里加上限制limit-rate。 服务器是如何知道图片是从站外而来的呢？在http协议里有一个重要的选项叫refer，这个选项的内容就是该元素的来源地址。如果这个元素是服务器自己提供的，那么头文件里是没有refer这个选项的。通过refer这个信息，我们也可以知道登陆网站的客户是从哪个网站点击链接而来的。这样方便进行一个统计和规划。 假如，我在QQ空间里面发现一个图，然后右键图片，选择”在新标签栏里打开图片”，这时候通过浏览器“审查元素”的功能，能查查看请求头信息和响应头信息，发现响应头信息里多了一个refer，里面的内容就是图片的源地址： 我在QQ空间里看腾讯的照片自然是可以的，但是如果我在别的网站里看腾讯的照片，加重了腾讯服务器的负担，自然腾讯公司会不满意。于是腾讯服务器发现当前要引用这个图片的地址与refer头信息不是一个来源之后，就不会把这个图片的数据传送过来，于是就看到那个“此图片来自QQ空间，未经准许不可饮用”的警告图片。 既然知道了服务器是如何判断文件是否盗链，那么只要伪装一个refer就可以欺骗服务器达到“反防盗链”的目的了。至于这部分，可以自己单独研究。如何使用Nginx反盗链？ 同样的使用Nginx.conf，在http的大括号下面，新建一个location，加入如下信息： 12345678910111213141516location ~ .*\.(wma|wmv|asf|mp3|mmf|zip|rar|jpg|gif|png|swf|flv)$ &#123;#指定对以上几种类型的文件建立防盗链 valid_referers none blocked *.alala.com alala.com;#盗链的范围不包括alala.com和alala.com下的二级网站， if($invalid_referer) &#123; #rewrite ^/ http://www.alala.com/error.html; return403;#如果发现有引用以上文件的地址与refer头信息不符的情况，直接重定向成error.html这个网页，服务器返回403，forbidden。 &#125;&#125; 使用第三方模块ngx_http_accesskey_module实现Nginx防盗链实现方法如下： 下载NginxHttpAccessKeyModule模块文件：http://wiki.nginx.org/File:Nginx-accesskey-2.0.3.tar.gz； 解压此文件后，找到nginx-accesskey-2.0.3下的config文件。编辑此文件：替换其中的$HTTP_ACCESSKEY_MODULE为ngx_http_accesskey_module； 用一下参数重新编译nginx： ./configure –add-module=Nginx目录/to/nginx-accesskey然后执行: make &amp;&amp; make install 修改nginx的conf文件，添加以下几行： 123456location /download &#123; accesskey on; accesskey_hashmethod md5; accesskey_arg "key"; accesskey_signature "mypass$remote_addr";&#125; 其中：1.accesskey为模块开关；2.accesskey_hashmethod为加密方式MD5或者SHA-1；3.accesskey_arg为url中的关键字参数；4.accesskey_signature为加密值，此处为mypass和访问IP构成的字符串。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>网络相关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次配置http跳转https的过程]]></title>
    <url>%2F2018%2F01%2F18%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E9%85%8D%E7%BD%AEhttp%E8%B7%B3%E8%BD%AChttps%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[公司最近搞了一个数据运营平台，这个平台会以web界面的形式把各个数据展示出来，这个项目是我们一个经理的重点关照项目。把平台模块部署完毕并且启动之后，又把这个平台服务器的外网IP绑定到alkaid.lechange.com这个域名上，在浏览器里输入https://alkaid.lechange.com,就看到了前端同行们写的网页。 但是我们的霸气经理说这样不行，说要更多要求更高标准更好体验，于是乎提出一个需求就是：在输入alkaid.lechange.com的时候会自动跳转到https://alkaid.lechange.com。 既然如此，我们就在nginx上原有的nginx.conf里补充几个配置文件： 12345#include upstreaminclude upstream.conf;# include serversinclude alkaid.conf;include alkaid-https.conf; 这样在执行nginx.conf的时候，就会调用upstream.conf、alkaid.conf和alkaid-https.conf，我们主要看一下这三个文件。 alkaid.conf文件如下： ```js server { listen 80; server_name *.lechange.com; proxy_buffering off; location / { rewrite ^/ https://alkaid.lechange.com permanent; client_max_body_size 100m; } } 这里我们监听了80端口，下面那个client_max_body_size 100m是用来设定nginx+php上传文件的大小，这里规定是100m，这个可以写进nginx.conf里，如果有对上传文件方面感兴趣，可以看http://www.cnblogs.com/zhwl/archive/2012/09/18/2690714.html 。 再来看看alkaid-https.conf，如下： ``js server { listen 10000; server_name *.lechange.com; proxy_buffering off; location / { proxy_pass http://alkaid_backend; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_redirect off; } } 这里监听了10000端口，location写的是http://alkaid_backend`,这个`alkaid_backend`是啥东西? 这个时候我们就需要看一下upstream.conf，里面内容是: ```js upstream alkaid_backend { server X.X.X.X:JQK; check interval=5000 rise=2 fall=5 timeout=1000 type=tcp default_down=false; } X.X.X.X是模块服务器的内网IP地址，而JQK是模块服务器的模块端口，这里要根据实际的情况来写。可见alkaid_backend对应的就是模块服务器和它的端口，下面是检查间隔等等数值。 现在我们启动nginx，然后把nginx的外网地址绑定去alkaid.lechange.com这个域名，在浏览器里输入alkaid.lechange.com，就会达到自动跳转的目的了！ 这里要额外多说一下，我们这里设定了80的配置文件也设置了443的文件，但是这俩文件的转发过程却不同：alkaid-https.conf文件把443的请求转向了平台模块服务器的服务，而alkaid.conf文件把凡是从80端口进来的请求直接全部永久重定向到https://alkaid.lechange.com ，但是这个alkaid.lechange.com还是会去访问平台模块服务器的服务，也就是说alkaid.conf文件多了一步重定向。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将电商平台测试环境添加了域名和https]]></title>
    <url>%2F2018%2F01%2F18%2F%E5%B0%86%E7%94%B5%E5%95%86%E5%B9%B3%E5%8F%B0%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E6%B7%BB%E5%8A%A0%E4%BA%86%E5%9F%9F%E5%90%8D%E5%92%8Chttps%2F</url>
    <content type="text"><![CDATA[情况描述今天电商平台来了新的产品经理。摸了一遍情况之后，提出了两个需求，第一个是要把测试环境也要上https，达到与线上一致；第二个就是测试环境要配上域名，不要再用IP地址登陆。 配置域名是很简单的，在阿里云的云解析上直接给测试环境新加一个域名，然后对应添加阿里云外网SLB的IP地址即可。进入页面也发现首页地址显示正常，但是再点点就发现了里面有点不对。 没错，现象就是“只有首页是域名，其他网站都是IP”， 遇到这个情况，我就跑去nginx.conf里，看一下server_name的配置，看到的确写得是func.lechange.com，如图： 于是就在页面上使用ctrl+shift+c查看具体情况，发现里面的代码是这个样的： 这就人赃俱获了，开发已经在html里把地址写死了，使用了绝对路径而不是相对路径，于是就打回让开发自己慢慢改。 然后又回到SLB界面，新增新的https监听，前端端口443，后端是80，搭配正确的证书，SLB保存之后，在浏览器输入测试环境的https://网址之后，发现整个界面全乱了，如图： 但是使用http://网址去访问还是正常的，如图： 很明显，这是因为https下跨协议调用http的是不行的，所以那些css、js如果不支持https的话就无法正常显示。使用ctrl+shift+c看错误更加明显。 遇到这个问题，就有如下几种方法： 第一种：将所有的访问路径都写死https，不过这个我们公司代码规范不准许;第二种：去掉URL中的http://或https://，将其替换为//，这样，浏览器就可以根据当前页面的请求方式来动态切换了；第三种：可以在&lt;head&gt;中添加&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;upgrade-insecure-requests&quot;&gt;,浏览器会在加载HTTP资源时自动替换成HTTPS请求；第四种：在nginx里写一个proxy_redirect跳转，这个就比较有技术含量了； 参考资料https://thehackernews.com/2015/04/disable-mixed-content-warning.htmlhttps://www.tuicool.com/articles/ARVVFjIhttps://developer.mozilla.org/en-US/docs/Web/Security/Mixed_content/How_to_fix_website_with_mixed_content]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>网络基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维工程师笔试题第十四套]]></title>
    <url>%2F2018%2F01%2F17%2FLinux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%AC%94%E8%AF%95%E9%A2%98%E7%AC%AC%E5%8D%81%E5%9B%9B%E5%A5%97%2F</url>
    <content type="text"><![CDATA[前言这几天一边看着《nginx高性能WEB服务器详解》，一边看着基础知识。那么最容易入眼的基础知识是什么呢？当然是面试题了，于是乎就找出来一些阿里（含滴滴和蚂蚁金服）的运维面试题，以题带看。 看完之后觉得阿里真的不是盖的，面试题的质量比那些晚上乱七八糟的题质量好多了，细节抠的真是非常细。我记得曾经有一个前辈曾经说过，工作中我们经常注意一些奇淫技巧，但是忽视了基础知识的重要性，现在好多程序员不会认认真真地读本书，喜欢快餐文化，受了市面上很多培训机构的影响，这是要不得的。 最后再说一句，以下所有的题都属于“开放性”试题，可以根据基本点去发散，说出你的理解和认识。但是注意，不要避重就轻耍滑头，问A，可以发散到A1、A2…但是不要发散到X、Y、Z，然后大谈特谈XYZ，这种“小聪明”就是找死的行为。 废话到此为止，上题1）http一般是无状态的，怎么让它变成有状态的？[我的答案]http协议跟IP协议、UDP协议一样都是无状态的，http的无状态意思是“每次的请求都是独立的，它的执行情况和结果与前面的请求和之后的请求是无直接关系的，它不会受前面的请求应答情况直接影响，也不会直接影响后面的请求应答情况”。补充一下，TCP是有状态的，它的请求并不独立，它通过包头的一些控制字段来分别包的关系，这里可以自行脑补一下“三次握手”的图。 那么http是无状态的这一点是无法改变的，那么要变得“有状态”，就需要引入cookie和session，通过这两个机制去实现一个有状态的WEB应用。用一个表达式可以这么理解：Web应用=http协议+session、cookies等状态机制+其他辅助的机制。 2）解释一下cookie和session的区别[我的答案]session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中，session是一个抽象概念，开发者为了实现中断和继续等操作，抽象出来的一个“会话”，接上面那道题，session这个东西能不用就不要用，因为它是有状态的，服务器要维护一个有状态的东西是很消耗资源的（比如内存和空间），我估计天猫京东那规模的电商，肯定有一个专门的session集群。 Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式，cookie是一个实际存在的东西，它是在http协议中定义在header中的字段。 session的常见实现要借助cookie来发送sessionID给客户端，如果浏览器禁用cookie，那么就要通过重写url来获取sessionid，各位可以联想一下电商的购物车，购物车可以实现在一个网站的不同页面把东西都放进一个购物车，这就是session的重点应用。现在也很流行一个token，其实token和sessionid是一个意思。 3）多进程和多线程的区别，自己喜欢用哪个？为什么？[我的答案]多进程：服务器每当接收到一个客户端信息的时候，从主进程里生成一个子进程与客户端建立连接开始交互，每一个子进程之间互相独立不受干扰，完成任务就收回资源，内存等也会被回收；多线程：服务器每当接收到一个客户端信息的时候，从主进程里生成一个线程与客户端建立连接开始交互,多个线程位于同一个进程内，可以互相访问同样的内存等资源，彼此之间会有影响；我个人更喜欢多进程，因为简单粗暴！ 关于多进程、多线程、同步、异步的原理，可以去看一下《nginx高性能WEB服务器详解》，第54页到56页的内容。 4) lvs脑裂如何解决，为什么会产生双master？双master时VIP通不通?[我的答案]产生双master的原因：1）服务器开启了iptables防火墙，阻碍了心跳信息传输；2）服务器心跳网卡等信息写错了，导致心跳信息发送失败；3）心跳方式不搭配，心跳广播冲突；4）软件出bug了； 额外补充一句，要排除脑裂问题，第一步是检查iptables,是不是由于iptables把心跳信息隔断了，重要的话不说三遍也重要！ 其他两个问题不会了，我在实际工作里没有接触到。 5) 为什么TCP比UDP的信息更加可靠？详细说说tcp滑动窗口原理，窗口的大小如何确定。TCP可靠性由三个机制保证：1. 序号（TCP报文的序号）2. 确认（ACK机制）3. 重传（超时或者冗余的 ACK）tcp在传输的时候，因为接受方B能力有限，不可能一口气吃下所有发送方A所有的数据流信息，所以B要限制A每次发送的字节数量，并且一一确认，确认了之后A才可以继续发。这样的话，A的在发送数据流的时候就会有四种形态：1.已发送已确认；2.已发送但没被确认；3.未发送但是接受方已经准备好空间来接收；4.未发送但是接受方尚未准备好空间来接收；随着数据流的传输，这个形态是会时刻发生变化的，通过接受方B返回的确认信息来改变2的大小，同时B也会根据一次关于发送方A要发送多少字节确认自己的空间来改变3的大小。 6) 简单说说cdn的工作原理，如何评估一个cdn sp做的好不好。[我的答案]cdn的工作原理：通过权威dns服务器来实现优质节点的选择，通过缓存来减少源站的压力。 IT界有个很有名的比喻，正向代理是“找马云借钱”，反向代理是“给10086打电话”，而反向代理就是CDN的实现原理雏形的一部分。详情可以看：http://www.iweir.cn/zheng-xiang-dai-li-yu-fan-xiang-dai-li/ 。 7）dns查询的过程说一下，为什么要有cname而不是直接返回一个cdn边缘节点的ip。[我的答案]先说一句题外话，dns主要是基于udp的！dns查询的过程以www.taobao.com为例：1.在浏览器键入www.taobao.com,其实真正dns协议里用到的是www.taobao.com.最后还有一个点，可能是因为美观等原因，一般都不显示;2.查询本地缓存（host文件或者是浏览器的缓存）中有没有该域名对应的记录，有的话就直接用了;3.向运营商的DNS服务器发起dns解析的请求，一般称运营商的DNS服务器为local dns;4.local dns会查询本地的缓存，local dns设置的缓存时间是有讲究的，过长过短都不好。另外local dns的查询是运营商的事，这里面水很深，外部不可控(这也是天朝能搭建特色墙的根源)；5.local dns如果没有缓存，会把域名从右往左扫描，依次请求对应的服务器，例如对于域名www.taobao.com.，先去问负责.的根域名服务器，就是传说中全球只有几台的那些服务器，他们会答复.com是谁管理的，然后local dns又去找管理.com的服务器（假设名字为S1），去问问taobao.com是谁管，一般来说，在S1查到的记录是一条cname记录（阿里毕竟大公司，自己管理自己旗下的域名），然后就转到了阿里自己的DNS服务器上来了，一般称之为权威服务器；6.权威服务器是阿里自己建的，然后根据公司内部的一些配置啊，调整啊，查到www.taobao.com.对应的服务器是谁，返回一个IP地址；7.local dns缓存这个IP地址，并且回复浏览器；8.浏览器和对应的IP地址的服务器建立TCP连接，发送HTTP报文； 用图表示就是： 8）举例说下正则表达式和扩展正则表达式、例如：url、ip、邮箱的正则表达式？[我的答案]这三个都是网上找的，正则这个东西还是要多练多写。url的正则表达式：([/w-]+/.)+[/w-]+.([^a-z])(/[/w- ./?%&amp;=]*)?|[a-zA-Z0-9/-/.][/w-]+.([^a-z])(/[/w- ./?%&amp;=]*)?ip的正则表达式：^(1\d{2}|2[0-4]\d|25[0-5]|[1-9]\d|[1-9])\.”+”(1\d{2}|2[0-4]\d|25[0-5]|[1-9]\d|\d)\.”+”(1\d{2}|2[0-4]\d|25[0-5]|[1-9]\d|\d)\.”+”(1\d{2}|2[0-4]\d|25[0-5]|[1-9]\d|\d)$邮箱的正则表达式：^[a-zA-Z0-9.!#$%&amp;’+\/=?^_`{|}~-]+@a-zA-Z0-9?(?:.a-zA-Z0-9?)$ 9）解释raid0、raid1、raid01、raid10、raid5、raid6，并分析各自读写性能？[我的答案]https://rorschachchan.github.io/2018/01/31/简析raid0-raid1-raid10-raid01等等硬盘搭配/ 10）raid为什么不搞个raid50、raid15，不能搞是因为有什么冲突还是什么等等?[我的答案]raid50是有的，但是用途不广泛。raid15我是没听说过，因为raid1的写本身就不强（一样的内容要写两个盘里），raid5的写入能力更烂，那么raid15的磁盘写能力简直就是灾难。而且花了硬盘的钱只能存实际一半的量，正常人都不会这么做的。 拓展阅读https://segmentfault.com/a/1190000007243675http://mertensming.github.io/2016/10/19/cookie-session/https://wizardforcel.gitbooks.io/network-basic/content/index.htmlhttps://coolshell.cn/articles/11564.htmlhttps://coolshell.cn/articles/11609.htmlhttp://blog.sina.com.cn/s/blog_93b45b0f0101a4ix.htmlhttp://www.cnblogs.com/549294286/p/5172435.htmlhttps://wizardforcel.gitbooks.io/network-basic/content/7.html（这个墙裂推荐，基础知识）http://blog.jobbole.com/105500/http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.failover.html]]></content>
      <categories>
        <category>大牛之路</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实战Kibana的日志关键词搜索和日志可视化]]></title>
    <url>%2F2018%2F01%2F17%2F%E5%AE%9E%E6%88%98Kibana%E7%9A%84%E6%97%A5%E5%BF%97%E5%85%B3%E9%94%AE%E8%AF%8D%E6%90%9C%E7%B4%A2%E5%92%8C%E6%97%A5%E5%BF%97%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[准备工作首先，先下载一个elastic网站上下载一个它提供的demo—莎翁的《亨利四世》，下载地址是https://download.elastic.co/demos/kibana/gettingstarted/shakespeare.json 。 打开这个json字符串，里面就是《亨利四世》的话剧剧本，长得是这个样子： 可以看到里面有play_name、speaker、speech_number、line_id等等名称，每个名称后面都有一个对应的值。 然后启动elasticsearch，按照上面的文件格式生成索引。语句如下： 1234567891011121314curl -XPUT http://localhost:9200/shakespeare -d '&#123; "mappings" : &#123; "_default_" : &#123; "properties" : &#123; "speaker" : &#123;"type": "string", "index" : "not_analyzed" &#125;, #确定type是字符 "play_name" : &#123;"type": "string", "index" : "not_analyzed" &#125;, "line_id" : &#123; "type" : "integer" &#125;, #确定type是数字 "speech_number" : &#123; "type" : "integer" &#125; &#125; &#125; &#125;&#125;'; 导入刚刚下载的那个json：curl -XPOST &#39;localhost:9200/shakespeare/_bulk?pretty&#39; --data-binary @shakespeare.json 具体elasticsearch的增删改查语法可以参看阮大师的http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html ，个人建议将elasticsearch和mysql对比一下，这样更方便理解。 然后后台启动kibana，确认5601端口已经stand by，如图： 然后在浏览器地址栏输入服务器外网ip：5601打开kibana。 导入数据结束之后，使用curl &#39;localhost:9200/_cat/indices?v&#39;，去查看一下效果，如果看到index里有shakespeare那一栏就是导入成功了，如图： 在启动Kibana后，Kibana会自动在配置的es中创建一个名为.kibana的索引（上图第二个），这个索引用来存储数据，注意！不要删除了它。 Kibana的界面搜索如果此时的kibana里是第一次配置的话，那么第一步就是配置新索引，我们之前在生成索引的时候写的是shakespeare，那么现在也写shakespeare，然后点击create，如图： 然后在菜单栏左侧的discover里选择刚刚建立的shakespeare，就会看到这样的东西： 在Search上就可以进行搜寻，比如说我搜寻freedom，如图： 如果我搜寻KING HENRY IV，他不分大小写的把所有king、henry、iv都搜索出来。 如果我想搜寻line_id的第一行到第三行，那么语句就是line_id:[1 TO 3]，如图： 如果想在上面的基础上进一步细化，比如说要在line_id是从第一行到第三行，同时_type是scene的语句：line_id:[1 TO 3] AND _type:scene： 假如不想要scene，那么就把AND改成NOT。 如果这个时候只想关注一些指定的字段，那么可以将鼠标移动到索引下面的字段上，然后选在add即可，同样的移动上面已经选择的字段选择remove进行移除，比如我们试一下这个speaker： add之后在点击右侧的具体的speaker，就会看到里面的细节，比如这位westmoreland（威斯摩兰伯爵）： 这个时候就能看见这位伯爵大哥的台词细节，在第几场的第几节，说的是什么台词。再返回菜单左侧点击这个speaker，我们还会看到一个比重： 从这里就很清晰的看到，FALSTAFF（法斯塔夫）这个哥们的台词最多，也符合书里塑造的那个嗜酒话痨的艺术形象。而我们的KING HENRY IV(亨利四世)的台词只是第四位，占比重11%而已… 这样具体的搭配搜索之后，可以点击界面右上侧的save进行保存搜寻结果，再搭配share分享搜索结果的url网址，如图： Kibana的图像化展示Kibana也能做到类似grafana那样的炫酷图象化展示，更加立体的表现日志情况，首先选择左侧菜单栏里的Visualize（可视化）： 然后点击Create a Visualization,里面既有很多种图形供你选择，有饼型，有箭头的，有文字的，有仪表盘的，如图： 我们这里先建立一个饼型的，还是上面那个台词多少的例子，首先选择shakespeare作为数据源，然后点击split slices，如图： 然后在Aggergation里选择Terms，然后在Field里选择Speaker,size那里写8,最后点击上面的那个三角播放键，看看结果： 这就很清晰的看出，亨利四世一共说了1086句话，占比11.11%。 如果我们再加一个Split Slices，这一次在原有的specker的基础上选择play_name，图象变成了一个同心圆，最外面的一层就是新增的“play_name”的情况，如图显示FALSTAFF的所有台词会在两个play_name里出现： 如果这个盘子里不想统计FALSTAFF这个话包，就添加一个过滤器，选择speaker is not，后面写上FALSTAFF即可，如图： 效仿刚才的方法也可以做一个仪表盘，如图： 可视化的数据也可以save和share，同样在web界面的右上角。保存的数据是可以在左侧菜单栏里的Dashboard里展示，做成一个类似zabbix那样的展示！]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>elk</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作所用的模块回滚脚本]]></title>
    <url>%2F2018%2F01%2F17%2F%E5%B7%A5%E4%BD%9C%E6%89%80%E7%94%A8%E7%9A%84%E6%A8%A1%E5%9D%97%E5%9B%9E%E6%BB%9A%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[前言与脚本内容部署中常备一个回滚脚本也是很有必要的，我所在公司的服务器模块名都是在初始化的时候写进/etc/role_install这个文件里，如下图的这个服务器就是fss服务器： 再比如下面这个服务器，虽然包含nginx的组件但是httpproxy的服务器： 那么有了这样的前提，整个回滚的脚本内容如下： 12345678910111213141516171819202122232425262728293031#!/bin/bash#Written by ChrisChan @July-4th-2017#Desription:这是一个回滚的脚本。module=$(cat /etc/role_install |grep -v zkclient|grep -v nginx)echo -e '\033[31m现在将执行回滚操作，本次回滚只回滚普通模块，不包含nginx和zkclient!\033[0m' echo "回滚的模块名称："$moduleecho -e '\033[33m如果想取消回滚操作，请ctrl+c立即停止本脚本...\033[0m'sleep 5cd /dxpbackup/hswx/$module &amp;&amp; zip $module.zip -x "*og*" -r . #到备份的文件夹里去压缩mv /dxpbackup/hswx/$module/$module.zip /mnt/hswx echo $module".zip文件已经生成！" until [ "$decision" == "Y" -o "$decision" == "y" -o "$decision" == "N" -o "$decision" == "n" ]do read -p "请问是否用回滚的压缩包覆盖到/mnt/hswx下？(y/n)" decision echo "您的选择是："$decision if [ $decision == Y -o $decision == y ] then echo "现在已经开始覆盖..." rm -rf /mnt/hswx/$module #先把原来的内容删除 unzip /mnt/hswx/$module.zip -d /mnt/hswx/$module #重新解压缩进去 echo -e '\033[32m覆盖已经完成，可以直接执行/startall脚本!\033[0m' elif [ $decision == N -o $decision == n ] then echo -e '\033[32m生成的'$module'.zip文件保存在/root文件夹里\033[0m' else echo -e '\033[31m输入字符不符合!请重新输入!\033[0m' fidone 新的知识点！1）zip在压缩文件夹的时候要过滤掉某些文件使用“-x”参数，比如说要在AAA文件夹里面过滤掉abc和jqk这两个文件，那么语句就是zip AAA.zip -x &quot;abc&quot; -x &quot;jqk&quot; -r .或者是zip -r -x=abc -x=jqk AAA.zip . 这样两个语句。 如果你要过滤掉的是一个文件夹，比如那么就要在文件夹后面名字加上一个，下图就是要压缩整个auc文件夹为456.zip但是又不想要lib这个文件夹，就使用了`zip 456.zip -x “lib“ -r .`： 不过如果文件夹里还有其他lib开头的文件夹也会被过滤掉，这一点要注意。 2）本shell里面涉及了逻辑判断，而[[和[的区别如下图： 3）如果if语句中出现报错“[: too many arguments”，很有可能就是字符串变量中可能存在空格，shell解析时将其认为是多个参数，再进行判断时，无法知道该获取哪个值，所以最好都用双引号括起来； 4）如果是“变量a等于aa且变量b等于bb 或者 变量c等于cc且变量d等于dd ” 这样的判断句怎么写？答曰： [ $a = “aa” -a $b = “bb” ] || [$c = “cc” -a $d = “dd” ] 参考资料https://zhangge.net/4776.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible的几个基本语句]]></title>
    <url>%2F2018%2F01%2F17%2FAnsible%E7%9A%84%E5%87%A0%E4%B8%AA%E5%9F%BA%E6%9C%AC%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[开篇的废话批处理工具我最早接触的是pssh，因为它实在很简单粗暴，但是它由于太简单粗暴了，应付十台二十台机器还OK，应付五十台一百台服务器就心有余力不足了（而且xshell右键有一个“发送键入到所有会话”的功能，与pssh效果几乎一样），而且我还不太喜欢puppet，总觉得那玩意跟我八字不合，于是乎，在新头头的推荐下，我把目光放在了Ansible。 Ansible的安装很简单，在Redhat环境下直接yum install -y ansible就行。Redhat已经将Ansible公司收购了，所以在安装上提供了不小的便利。 Ansible在安装完毕之后，会在/etc/ansible/目录下看见一个叫hosts的文件，这里是所有你要控制的服务器的ip们，可以排列写，比如： 123192.168.1.122192.168.1.133192.168.1.144 也可以分组写，比如： 1234567[aliyun]10.22.33.4410.22.33.45[jinshanyun]121.23.45.66121.23.45.67121.23.45.68:2222 （这个不是使用ssh默认的22端口，就需要特别指出） 默认情况下，Ansible会把命令全用于这个hosts文件，比如 ansible all -m ping -u ashin这句话意思是整个hosts里的机器以ashin账户启动，而且都要ping 一下当前本机。 具体语句怎么连接主机与要控制的远程机器请按之前写的“http://chenx1242.blog.51cto.com/10430133/1763978”一文进行操作，这里先说几个命令语句： 1)ansible all -m shell -a &quot;/bin/echo hello&quot;对hosts里所有的机器一起使用”输出hello这个文字”。-m shell可以忽略不写，但是不是shell而是其他的模块就要写出来； 2)ansible aliyun -m copy -a &quot;src=~/projects/tests/t.py dest=~&quot;把hosts里aliyun组的机器的/projects/tests/t.py复制到~目录下；[注意！]copy模块不支持变量路径，也就是说如果目标服务器的部署路径不同，copy不会很智能的去访问.bash_profile来得到用户的自定义变量，写变量替换路径是不会达到目的的。 3)ansible jinshanyun[0:9] -i -m file -a &quot;dest=~/tests state=absent&quot;把hosts里jinshanyun组中从0~9这十台机器的/tests文件夹删除掉，absent是“缺席，不在”的意思； 4)ansible 192.168.1.133 -m ping这句话=ping 192.168.1.133； 5)ansible v1 -m service -a &quot;name=mysql state=started&quot; -u ashin --sudo -K以用户名为ashin登陆hosts里所有v1组的机器，然后检查mysql是否是started状态，若不是就start，同时要输入root的密码作为确认； 6)ansible 10.11.22.* -m user -a &quot;name=foo password=foo&quot; --sudo -Khosts文件里所有10.11.22开头的机器，都要添加一个新的用户名foo，同时密码是foo，并且输入root密码确认身份； 7)ansible v1:!v2 -m apt -a &quot;name=git state=latest&quot;检查所有属于v1组同时还不属于v2组的机器里的git文件是否是最新版本； 8)ansible webservers:&amp;dbservers -a &quot;/sbin/reboot&quot; -f 10 --sudo -K重新启动既是webservers组又是dbservers组的所有机器； 9)ansible webservers -m raw -a &#39;yum -y install python-simplejson&#39;用ansible去链接低版本的centos时，就乎出现“ansible requires a json module, none found! ”的错误，需要远程机安装samplejson包。raw模块是靠底层ssh的通讯，不依靠python的模块，所以如果碰到低版本的系统，如果command和shell模块无法使用，可以先用这条命令安装完需要的包。 10)ansible all -m synchronize -a &quot;src=/chenshuo/1.sh dest=/chenshuo delete=yes&quot;synchronize原意是“同步”，而这个模块是分发模块，这句话的意思是把控制端的/chenshuo/1.sh分发给host文件里的所有ip服务器，delete=yes意思是以控制端服务器的文件为准。 11)ansible 10.168.194.89 -m synchronize -a &quot;mode=pull src=/chenshuo/nba.txt dest=/chenshuo/a.txt&quot;将10.168.194.89这台服务器上的/chenshuo/nba.txt拉到控制服务器的/chenshuo文件夹下，顺便改名叫a.txt。 12)ansible all -m get_url -a &quot;url=https://pypi.python.org/packages/56/2b/9c9c113fb88082950067a42cc99e3c61f1df72035f89bb0bdf0a60308ca0/pexpect-4.1.0.tar.gz#md5=562a1a21f2a60b36dfd5d906dbf0943e dest=/chenshuo&quot;把那一大串网址的下载连接下载到host文件里的所有ip的/chenshuo文件夹下。 13)ansible 10.117.14.37 -m script -a &quot;/chenshuo/free.sh&quot;在10.117.14.37上执行操作端的free.sh，注意操作端必须要有free.sh这个脚本，而10.117.14.37这台机器上并不一定要有。 参考资料http://blog.csdn.net/iloveyin/article/details/46982023]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix用户密码忘记怎么办]]></title>
    <url>%2F2018%2F01%2F17%2FZabbix%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%E5%BF%98%E8%AE%B0%E6%80%8E%E4%B9%88%E5%8A%9E%2F</url>
    <content type="text"><![CDATA[zabbix的超级用户也是人，人就难免会忘记密码（或者清除了当前浏览器的缓存），忘记密码不要怕，因为zabbix所有的用户数据都是保存在server机器上的mysql里，只要打开zabbix_server.conf，就会查得到mysql的登录账号密码以及zabbix对应的数据库。（这里多说一句，zabbix自带的guest基本就是一个废物，forget it~） 在zabbix_server机器上输入mysql的账号密码来到mysql里，USE zabbix，然后SELECT * FROM users,就会看到笔者的画面。 这个时候就可以使用数据库的update命令去更改密码，比如说新的密码是“woshitiancai”，就可以写update users set passwd=md5(&quot;woshitiancai&quot;) where userid=&#39;1&#39;;然后就可以用woshitiancai来登陆啦~ 但是！！！你以为这就结束了吗？nononono！！！ 很多人即使更改了密码还是登陆不上去，很简单，那就是你连用户名都忘记了！或者是用户名你记得但是你手贱在zabbix的administration里的users对原来的设定增加了新东西，而且这些东西还特么的是中文！！！于是就像我上面图那样出现了???的字样。 那些？？？很重要吗？当然了！！！因为那些才是zabbix的登录用户名！！！看见了吗，zabbix使用蛋疼的alias作为真正的登录名而不是用name or surname，这真是一个蛋疼的事儿！ 那么剩下的问题很简单了，就是把???改变成中文，使用语句set names utf8; 然后界面就成了这样： 这次再使用“主管理员”搭配新的密码就可以华丽的登录了！~~我他妈当时都差点要把这个user表格删掉然后重拽一个表格进来，但是终于还是被我识破了，啊哈哈哈哈，我真是个天才！！！]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker出现客户端与服务端有差的错误...]]></title>
    <url>%2F2018%2F01%2F16%2FDocker%E5%87%BA%E7%8E%B0%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%9C%89%E5%B7%AE%E7%9A%84%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[今天用docker搞redis镜像的的时候，出现了这样的错误提示：Error response from daemon: client is newer than server (client API version: 1.24, server API version: 1.22)，如图： 可见使用了docker version的时候也有提示：当前docker客户端比服务端版本更新。这样是无法创建镜像的，遇到这个问题很简单，那就是重启一下docker，命令如下： 12systemctl stop dockersystemctl start docker 然后我们再docker version看一下效果： 我做这个的时候，docker升级了也一样可以读到原先的镜像，但是出于保险起见我们也应该学会如何保存和导入镜像，比如现在我现在有这个叫docker.io/ubuntu的镜像，如图： 如果要备份它的话，语句就是： 1docker save docker.io/ubuntu &gt; /root/ubuntu.image 这里备份后的文件名就是ubuntu.image。 如果要导入的话，语句就是： 1docker load &lt; /root/ubuntu.image 这样导入的话，images create时间是不变的。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录日志系统ELKB 5.6.4的搭建过程]]></title>
    <url>%2F2018%2F01%2F16%2F%E8%AE%B0%E5%BD%95%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9FELKB-5-6-4%E7%9A%84%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言ELK是最近比较流行的免费的日志系统解决方案，注意，ELK不是一个软件名，而是一个结局方案的缩写，即Elasticsearch+Logstash+Kibana（ELK Stack）。这哥几个都是java系的产品，但是众所周知，java的东西很吃内存和CPU，Logstash在当作为收集日志的Agent时，就显得太过臃肿了。听说直播平台“斗鱼”团队很为logstash占用资源的情况很而苦恼，后来为了解决这个问题，他们自己写了一个agent。不过后来官方在logstash-forwarder的基础上推出了beat系列，里面包括四个兄弟，分别是：Packetbeat（搜集网络流量数据）；Topbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）；Filebeat（搜集文件数据）；Winlogbeat（搜集 Windows 事件日志数据）。而Filebeat也就这样加入了“日志收集分析”的团队里，所以虽然大家还是习惯性的叫ELK，其实准确的说法已经是ELKB了。 ELKB这几个哥们的分工如下： Elasticsearch：分布式搜索和分析引擎，具有高可伸缩、高可靠和易管理等特点。基于 Apache Lucene 构建，能对大容量的数据进行接近实时的存储、搜索和分析操作。通常被用作某些应用的基础搜索引擎，使其具有复杂的搜索功能； Logstash：数据收集额外处理和数据引擎。它支持动态的从各种数据源搜集数据，并对数据进行过滤、分析、丰富、统一格式等操作，然后存储到用户指定的位置； Kibana：数据分析和可视化平台。通常与 Elasticsearch 配合使用，对其中数据进行搜索、分析和以统计图表的方式展示； Filebeat：ELK 协议栈的新成员，在需要采集日志数据的 server 上安装 Filebeat，并指定日志目录或日志文件后，Filebeat 就能读取数据，迅速发送到 Logstash 进行解析，亦或直接发送到 Elasticsearch 进行集中式存储和分析。 设计架构 本文的设计结构就是这样，其中红色的redis/RebbitMQ部分可以省略（我这个例子里暂省略），让日志直接传递到logstash，如果日志量较大，最好还是添加上redis，同时再横向扩容Elasticsearch，搞成一个集群。 对于这几个模块服务器多说几句：1）Logstash要选择计算能力强的，CPU和内存比较丰满的；2）Elasticsearch要选择磁盘容量大的，同时CPU和内存也比较丰满的； 实验软件版本Elasticsearch 5.6.4Logstash 5.6.4Kibana 5.6.4Filebeat 5.6.4Java 1.8+，安装方法：http://blog.51cto.com/chenx1242/2043924由于ELKB这几个东西都是墙外的，墙内的下载可能会比较费劲。所以我稍后会把所有ELKB的5.6.4程序都放在51CTO的存储空间里，需要的朋友可以去下载，还是那话，虽然ELK升级频率很快，但是5.6.4已经足够稳定了。 实验服务器情况 安装Elasticsearch 5.6.4（以下所有操作都是root下进行的）12curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.4.rpmrpm -ivh elasticsearch-5.6.4.rpm 然后编辑/etc/elasticsearch/elasticsearch.yml，不然的话logstash无法与之相连： 123cluster.name: my-application #如果是集群的es就把这个打开，Elasticsearch 启动时会根据配置文件中设置的集群名字（cluster.name）自动查找并加入集群，端口是9300network.host: 0.0.0.0 #取消注释，并且改成0.0.0.0http.port: 9200 #取消注释 保存之后，启动并且添加开机启动： 12systemctl start elasticsearch systemctl enable elasticsearch 使用curl localhost:9200能看到这样的情景就证明已经成功启动了： 安装kibana 5.6.4 (以下所有操作都是root下进行的)1234curl -L -O https://artifacts.elastic.co/downloads/kibana/kibana-5.6.4-linux-x86_64.tar.gztar xzvf kibana-5.6.4-linux-x86_64.tar.gzcd kibana-5.6.4-linux-x86_64/vim config/kibana.yml 把kibana.yml里的server.host: localhost改成server.host: 0.0.0.0，然后保存退出，在kibana的bin文件夹里执行./kibana即可。如果要后台启动就是nohup /kibana安装路径/bin/kibana &amp;。 启动之后，如图： 安装Logstash 5.6.4（以下所有操作都是root下进行的）12curl -L -O https://artifacts.elastic.co/downloads/logstash/logstash-5.6.4.rpm rpm -ivh logstash-5.6.4.rpm 如果安装的时候爆错：/usr/share/logstash/vendor/jruby/bin/jruby: line 388: /usr/bin/java: No such file or directory。那么就先which java查看一下java的文件，然后做一个软连接过去，然后重装logstash即可，如图： 用户可以使用TLS双向认证加密Filebeat和Logstash的连接，保证Filebeat只向可信的Logstash发送加密的数据（如果你的logstash和filebeat是内网通信，而且你认可当前内网的安全度，这一步可以省略）。同样的，Logstash也只接收可信的Filebeat发送的数据。这个功能默认是关闭的，要开启的话需要先vim /etc/pki/tls/openssl.cnf，如图： 找到[ v3_ca ]的字段，在底下添加subjectAltName = IP:logstash的内网IP字段，保存退出来到/etc/pki/tls/，执行下面命令： 1openssl req -x509 -days 365 -batch -nodes -newkey rsa:2048 -keyout private/logstash-forwarder.key -out certs/logstash-forwarder.crt 来生成一个期限为365天的IP SAN证书对，如果想生成一个十年的证书，就把365改成3650即可，如图： 安装完毕之后，vim /etc/logstash/logstash.yml，编辑成如下的样子： 然后在/etc/logstash/下手动建立一个目录conf.d，在conf.d里新建一个logstash.conf的文件，如下： 123456789101112131415161718192021222324252627282930313233343536373839$ cat /usr/local/logstash/config/conf.d/logstash.conf#在输入部分，配置Logstash通信端口以及添加SSL证书，从而进行安全通信。input &#123; beats &#123; port =&gt; 5044 ssl =&gt; true ssl_certificate =&gt; "/etc/pki/tls/certs/logstash-forwarder.crt" ssl_key =&gt; "/etc/pki/tls/private/logstash-forwarder.key" &#125;&#125; #在过滤器部分，我们将使用Grok来解析这些日志，然后将其发送到Elasticsearch。以下grok过滤器将查找“syslog”标记的日志，并尝试解析它们，以生成结构化索引。filter &#123; if [type] == "syslog" &#123; grok &#123; match =&gt; &#123; "message" =&gt; "%&#123;SYSLOGTIMESTAMP:syslog_timestamp&#125; %&#123;SYSLOGHOST:syslog_hostname&#125; %&#123;DATA:syslog_program&#125;(?:\[%&#123;POSINT:syslog_pid&#125;\])?: %&#123;GREEDYDATA:syslog_message&#125;" &#125; add_field =&gt; [ "received_at", "%&#123;@timestamp&#125;" ] add_field =&gt; [ "received_from", "%&#123;host&#125;" ] &#125; syslog_pri &#123; &#125; date &#123; match =&gt; [ "syslog_timestamp", "MMM d HH:mm:ss", "MMM dd HH:mm:ss" ] &#125; &#125;&#125; #输出部分，我们将定义要存储的日志位置output &#123; elasticsearch &#123; hosts =&gt; [ "10.162.80.192:9200" ] #这个地址是elasticsearch的内网地址 index =&gt; "filebeat-%&#123;+YYYY.MM.dd&#125;" #设定这个是索引 #index =&gt; "auclogstash-%&#123;+YYYY.MM.dd&#125;" #这行是后来作实验的，可以忽视 user =&gt; elastic #这个是为了将来装x-pack准备的 password =&gt; changeme #同上 &#125;stdout &#123; codec =&gt; rubydebug &#125;&#125; 然后就是启动并且添加开机自启动: 12systemctl start logstash systemctl enable logstash 安装filebeat（以下所有操作都是root下进行的）在模块服务器上安装filebeat的方法如下: 12curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.6.4-x86_64.rpm rpm -ivh filebeat-5.6.4-x86_64.rpm 之前在logstash上生成了一个IP SAN证书，现在需要把这个证书传递给filebeat的机器里，使用scp语句如下： 1scp -pr root@10.162.80.171:/etc/pki/tls/certs/logstash-forwarder.crt /etc/ssl/certs/ #10.162.80.171就是logstash的内网IP 输入logstash的密码，并且密钥文件复制完毕之后，需要修改filebeat.yml，于是#vim /etc/filebeat/filebeat.yml： 12345678910111213141516[root@func-auc-001 log]# grep -iv '#' /etc/filebeat/filebeat.yml | grep -iv '^$'filebeat.prospectors:- input_type: log paths: - /mnt/hswx/auc/logs/*.log #这个是那个auc模块的路径 - /第二个日志路径/*.log #如果有第二个文件路径的话 tail_files: true #从文件末尾开始读取 document_type: "newnginx-api" #logstash那里已经设定了index，如果要使用了document_type，那么在logstash的index就要这么写："%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;" # 以下是规避数据热点的优化参数： spool_size: 1024 # 积累1024条消息才上报 idle_timeout: "5s" # 空闲5s上报 output.logstash: hosts: ["10.162.80.171:5044"] #这个地方要写logstash的内网地址 ssl.certificate_authorities: ["/etc/ssl/certs/logstash-forwarder.crt"] #这里就是刚刚复制的那个密钥文件路径 #注意上面是ssl而不是tls，1.0版本才是tls，如果这个写错了，启动的时候会出现“read: connection reset by peer”的错误 注意！Filebeat的配置文件采用YAML格式，这意味着缩进非常重要！请务必使用与这些说明相同数量的空格。 保存之后，使用/etc/init.d/filebeat start启动filebeat，如图： 故障解决ELK几个部件现在都已经启动了，并且互相telnet端口都是通的，在elasticsearch的服务器上使用curl -XGET &#39;http://elasticsearch内网IP:9200/filebeat-*/_search?pretty&#39;却出现这样的情况： 而使用tailf /var/log/filebeat/filebeat去查看filebeat的日志是这样的： 再看看logstash-plain.log，里面的情况是这样的： 从此可见，filebeat与logstash的联系是error状态，那么停止filebeat的进程，改用/etc/init.d/filebeat start -c /etc/filebeat/filebeat.yml，重新在elasticsearch的服务器上使用curl -XGET &#39;http://elasticsearch内网IP:9200/filebeat-*/_search?pretty&#39;发现已经成功读到了我们之前配置的目录“/mng/hswx/auc/log”，如图： 配置kibana在浏览器输入kibana服务器外网IP：5601打开kibana的web界面，把idenx pattern的地方改成filebeat-*(同之前配置的index索引一致)，然后点击create，如图： 然后就得到了细节的web界面，如图： 点击左侧框的Discover，就会看到梦寐以求的日志web界面，如图： 看一下红色框的内容里面有时间，有host主机，有source来源，还有具体的日志信息，我们再去func-auc-001这个日志源主机上查询一下日志： 两个日志是一样的，可见实现了预期的日志展示的目标！ 最后一步，就是把kibana与nginx联系起来（也可以把kibana做阿里云负载均衡的后端服务器），这样通过nginx/负载均衡来访问kibana的界面，对kibana来说更安全。配置端口监听如图，再把kibana服务器挂在负载均衡后面即可。 参考资料https://www.ibm.com/developerworks/cn/opensource/os-cn-elk-filebeat/index.htmlhttps://www.ibm.com/developerworks/cn/opensource/os-cn-elk/http://www.jinsk.vip/2017/05/24/elksetup/https://renwole.com/archives/661https://www.zybuluo.com/dume2007/note/665868https://www.elastic.co/guide/en/beats/libbeat/5.6/getting-started.htmlhttps://discuss.elastic.co/search?q=ERR%20Failed%20to%20publish%20events%20caused%20by%3A%20read%20tcphttp://jaminzhang.github.io/elk/ELK-config-and-use-Filebeat/ （这个博主很好，但是就是博客无法留言，这点比较坑）]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>大数据分析</tag>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从“No space left on device”到删除海量文件]]></title>
    <url>%2F2018%2F01%2F16%2F%E4%BB%8E%E2%80%9CNo-space-left-on-device%E2%80%9D%E5%88%B0%E5%88%A0%E9%99%A4%E6%B5%B7%E9%87%8F%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[开发发现某个云服务器无法启动进程，提示“No space left on device”，但是使用df -h查看容量的时候，明明还有很多的空间。于是使用df -i，发现inode节点已经全部用光了，所以现在不能建立任何新的文件。如图： 既然如此就要查出来是哪个文件夹里会有如此多的文件来占用这些inode,使用一个小脚本：for i in /*; do echo $i; find $i | wc -l; done，获取到/mnt下有一个文件占用了绝大多数的inode，如图： 于是就进入到mnt这个文件夹里，慢慢找寻到底是哪个文件夹，用上面那个语句一点一点缩小范围，最后确定文件夹原来就是data文件夹，如图： 现在如果要rm -rf data/*的话，是没有效果的，有效果的话也很慢。而且很有可能报-bash: /bin/rm: Argument list too long的错，因为这个文件夹里面的小文件实在太多了，有足足两百五十多万个，那么怎么样处理这样的情况？ 用find搭配-type f -exec rm {} \;可能会引起内存溢出，用文件夹重置命令搭配”–reference” 也没什么效果。 这时最好的方法就是使用rsync! 先yum install rsync，当然了现在inode是饱和的状态，yum install是会报错的： 那么就需要手动删除一些文件，腾出来一部分inode供yum使用，安装完毕rsync之后，找到一个空文件夹，如果没有空文件夹，就手动建立一个。 使用命令：rsync --delete-before -a -H -v --progress --stats /空文件夹的路径/ /海量小文件的路径/ –delete-before 接收者在传输之前进行删除操作 –progress 在传输时显示传输过程 -a 归档模式，表示以递归方式传输文件，并保持所有文件属性 -H 保持硬连接的文件 -v 详细输出模式 -stats 给出某些文件的传输状态 如果你开了这个服务器的两个窗口，一个是执行上面的命令，另一个是在海量文件夹里执行ls，这个时候ls命令是卡死的，过了大约2分钟，就会看到ls展示的文件喷涌而出，整个电脑屏幕好比黑客帝国一样，异常壮观。 静等大约20分钟，整个文件夹删除干净，inode也释放了97%，世界恢复了清静。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Google Authenticator给ssh进行登录验证]]></title>
    <url>%2F2018%2F01%2F16%2F%E4%BD%BF%E7%94%A8Google-Authenticator%E7%BB%99ssh%E8%BF%9B%E8%A1%8C%E7%99%BB%E5%BD%95%E9%AA%8C%E8%AF%81%2F</url>
    <content type="text"><![CDATA[普通情况下的服务器登录，是“服务器+密码”这种直白的验证方式，但是这种方式太过简单，一旦密码泄露，服务器就有危险，于是为了安全我们就要在登录上再加一把锁，那就是使用Google Authenticator（谷歌身份验证器）这个工具，在登录的时候进行一次验证，只有“验证通过了”+“密码正确”才能登陆服务器。 安装前准备1）关闭Selinux ：setenforce 02）安装依赖：yum -y install gcc make pam-devel libpng-devel libtool wget git3）添加阿里云epel 源： 1234RHEL 6/Centos 6wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.repoRHEL 7/Centos 7wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 4）安装Qrencode，谷歌身份验证器需要调用该程序生成二维码并显示：yum install -y qrencode 安装谷歌身份验证器这个时候很多教程会让你去执行git clone https://github.com/google/google-authenticator.git，然而现在这个git里面已经不再含有libpam这个文件夹了，下载下来是一个错误的包，那么这个时候你可以使用yum install google-authenticator，不过yum安装的身份验证器的版本很老，这个时候可以执行wget https://github.com/google/google-authenticator-libpam/archive/1.04.tar.gz。 下载下来1.0.4版本的然后拆包解压缩，里面是这样几个文件： 然后就./bootstrap.sh &amp;&amp; ./configure &amp;&amp; make &amp;&amp; make install进行编译和安装。 安装过程完毕之后，还要复制google身份验证器pam模块到系统下，命令是：cp /usr/local/lib/security/pam_google_authenticator.so /lib64/security/。 调整登陆方式1）编辑/etc/pam.d/sshd这个文件，我这个centos的版本是7.0的，里面的内容可能跟centos 6.x的优点不同，不过没关系，就需要插入黄色框内的auth required pam_google_authenticator.so，如图： 修改完毕之后，保存退出。 注意！修改了这步之后，服务器千万不能断开连接，否则再连是需要google验证码的，而我们现在还没有生成码，所以肯定是无法连接服务器，如果是云服务器，可以通过登陆控制台的方式把这个文件修改回来，如果是实体服务器，那就呵呵呵了。 2）编辑/etc/ssh/sshd_config，就修改一个地方：ChallengeResponseAuthentication yes3）保存退出之后，重启一下ssh服务： 12RHEL6 /Centos6：Service sshd restartRHEL7 /Centos7：Systemctl resart sshd 生成登陆验证码这次以root用户为例，那么切换成root用户执行下面的过程。1）执行google-authenticator，由于我们之前已经安装了qrencode，那么这个时候会生成一个超级超级巨大的二维码，给各位感受一下： 红色内容是生成的密钥，很重要。绿色的内容是备用的紧急救助码，紧急救助码就是当你无法获取认证码时（比如手机丢了），可以当做认证码来用，每用一个少一个，但其实可以手动添加的，建议如果 root 账户使用 Google Authenticator 的话一定要把紧急救助码另外保存一份。 Do you want me to update your &quot;/home/test/.google_authenticator&quot; file? (y/n) y 是否更新用户的 Google Authenticator 配置文件，选择 y 才能使上面操作对当前用户生效，其实就是在对应用户的 Home 目录下生成了一个 .google_authenticator 文件，如果你想停用这个用户的 Google Authenticator 验证，只需要删除这个用户 Home 目录下的 .google_authenticator 文件就可以了。 Do you want to disallow multiple uses of the same authentication token? This restricts you to one login about every 30s, but it increases your chances to notice or even prevent man-in-the-middle attacks (y/n) y 每次生成的认证码是否同时只允许一个人使用？这里选择 y。 By default, tokens are good for 30 seconds. In order to compensate for possible time-skew between the client and the server, we allow an extra token before and after the current time. If you experience problems with poor time synchronization, you can increase the window from its default size of +-1min (window size of 3) to about +-4min (window size of 17 acceptable tokens). Do you want to do so? (y/n) n 是否增加时间误差？这里随便选择， ny都可以。 If the computer that you are logging into isn&apos;t hardened against brute-force login attempts, you can enable rate-limiting for the authentication module. By default, this limits attackers to no more than 3 login attempts every 30s. Do you want to enable rate-limiting (y/n) y 是否启用次数限制？这里选择 y，默认每 30 秒最多尝试登录 3 次。 如果想要写成脚本的话，那么上面交互式的设置也可用通过参数一次性设置：google-authenticator -t -f -d -l test@chen.super -i MR.chen -r 3 -R 30 -W。 -I和-i是可以随便写的，但是-i后期可以改，-I不能改。 搭配手机端如果手机是ios，就去apple store里搜索“Google Authenticator”，如果是安卓，就去应用商店搜索“谷歌动态口令”。 安装完后，打开App，点击“开始设置”，选择“扫描条形码”扫描上面google-authenticator命令生成的二维码，或者是选择“输入密钥”，然后手机上就能看到对应的六位数认证码了。 最后一步，返回xshell，修改登陆方式，设置登陆方法为Keyboard Interactive，如图： 这个时候，推荐各位保留原有的ssh不要动，在另外一个xshell窗口登陆一下看看效果，如果正常的话，这个时候会看到系统会让你先输入一个Verification code。这个值就是手机里的那个六位数，然后再输入密码，只有两个都是正确的，才能登陆！ 至此整个配置完成，如果登陆时遇到问题，请查看日志文件/var/log/secure。 更改存储位置在生成二维码那一步的时候，如果你错过了记住密钥也不要怕，系统会自动把密钥和紧急救助码保存在~/.google_authenticator这个文件里。 如果想要改变密钥存储位置，请使用–secret参数:google-authenticator --secret=&quot;/文件路径/用户名&quot;。 然后更改/etc/pam.d/sshd内的路径配置:auth required pam_google_authenticator.so user=root secret=/PATH_FOLDER/${USER}。 上面那句话里“user=root” 用于强制PAM使用root用户权限来搜索文件。 另外请注意，由于我们当时切换成了root用户，所以密钥文件的所有者是root，生成文件的用户只能读取文件(chmod: 400)： 12chown root.root /PATH_FILE/SECRET_KEY_FILESchmod 400 /PATH_FILE/SECRET_KEY_FILES]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次处理https监听不正确的过程]]></title>
    <url>%2F2018%2F01%2F12%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E5%A4%84%E7%90%86https%E7%9B%91%E5%90%AC%E4%B8%8D%E6%AD%A3%E7%A1%AE%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[今天开发反馈在测试金山云设备的时候遇到了这样的一个现象：123456wget https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 11:49:26-- https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 Resolving funchlscdn.lechange.cn... 120.92.158.134 Connecting to funchlscdn.lechange.cn|120.92.158.134|:443... connected. OpenSSL: error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol Unable to establish SSL connection. 爆“error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol”的错误，就是在当向只提供http的服务发送https请求造成的。 ping funchlscdn.lechange.cn，获得了这个域名对应的IP之后，返回到金山云的控制台查询这个IP，发现这个IP是一个负载均衡，但是这个负载均衡配置的时候对80端口是http协议，而对443端口还是http协议，于是更改成https，重新测试之后，发现错误变成了这样：123456[root@js-develop ~]# wget https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 16:08:15-- https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Resolving funchlscdn.lechange.cn... 120.92.158.134Connecting to funchlscdn.lechange.cn|120.92.158.134|:443... connected.HTTP request sent, awaiting response... 502 Bad Gateway2017-07-26 16:08:15 ERROR 502: Bad Gateway. 在浏览器打开效果如图： 502 Bad GatewayThe proxy server received an invalid response from an upstream server. KSYUN ELB 1.0.0 同时发现金山云负载均衡里对nginx的8000健康检查是“异常”。但是使用http访问却是可以的，效果如下：12345678910111213[root@js-develop ~]# wget http://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 15:31:55-- http://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Resolving funchlscdn.lechange.cn... 120.92.158.134Connecting to funchlscdn.lechange.cn|120.92.158.134|:80... connected.HTTP request sent, awaiting response... 302 FoundLocation: http://120.92.133.76:8090/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 [following]--2017-07-26 15:31:55-- http://120.92.133.76:8090/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Connecting to 120.92.133.76:8090... connected.HTTP request sent, awaiting response... 200 OKLength: 66 [application/x-mpegURL]Saving to: “dev_20170726085033_lpxh73ezzb92xxa8.m3u8”100%[========================================================================================================================================================&gt;] 66 --.-K/s in 0s 2017-07-26 15:31:55 (3.02 MB/s) - “dev_20170726085033_lpxh73ezzb92xxa8.m3u8” saved [66/66] 于是就叫来开发问一下http和https详细的流程，开发说在http里，设计路线如下：1http(80)-&gt;开发模块(9001) 而在https里，设计路线如下：1https(443)-&gt;nginx(8000)-&gt;开发模块(9001) 这时候就发现了问题，原来最早的时候金山云是没有配置https证书的，于是开发们就用nginx的8000端口去监听ssl这样达到https证书的效果，但是后来金山云控制台添加了https证书，就不再需要nginx去配置ssl证书了，再去https监听8000这一步也就是错误的了，于是在负载均衡那里改成了：1https(443)-&gt;开发模块(9001) 同时关闭了nginx，这时候再来测试一下https请求，就成功了！ 其实如果非要用nginx的ssl证书的话，那么的套路就是：开启nginx，但是在负载均衡那里使用tcp协议去监听nginx的8000端口，这样一样能达到效果。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Next主题添加音乐和将侧栏移动到左边]]></title>
    <url>%2F2018%2F01%2F12%2Fnext%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E9%9F%B3%E4%B9%90%E5%92%8C%E4%BE%A7%E6%A0%8F%E5%B7%A6%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[玩Github博客也有一个多月的时间了，现在这个博客也被我折腾的有点样子了，目前博客里添加了如下功能：1.支持头像图片旋转，同时点击头像可以返回主页；2.背景图片随机出现，而且墙内用户也可以顺利访问；3.增加文章打分系统，觉得好可以给五星好评；4.开放评论系统，无需注册直接评论；5.添加了可视加载栏和公益404页面；6.添加桌面小宠物和访客统计；7.添加博客运行时间和代码橙色高亮； 目前欠缺的功能一个是“相册”，还有一个就是博客标题的加载方式希望更加高逼格。至于SEO和单独域名，我暂时还没有想去做，等将来再加上吧。而这篇文章里主要说的就是“博客添加音乐”和“侧栏左移”这两个事儿。 博客添加音乐Next主题添加网易云音乐不是一个很难的事儿，但是我发现对于非大陆的IP地址（比如我用的是公司VPN，香港IP），侧栏的网易云音乐就无法播放，而且打开博客页面就自动播放音乐这点对来访的用户来说，体验感觉是见仁见智。所以我打算把侧栏的网易云音乐撤掉，在“关于我”里单独放进音乐歌单。 若单独配置音乐同时不想被IP地址打扰的话可以使用由DIYgod所制作的APlayer。官方材料在这里：https://aplayer.js.org/docs/#/?id=options 。 要使用APlayer需要先在hexo根目录里安装插件：npm install aplayer --save 安装插件OK了后，具体在文章里添加的语法就是： 注意：如果lrc用的是这种URL形式，hexo g时请保持网络通畅，如果没有歌词，可以不用添加。 现在的世面上很少有在线提供歌曲MP3地址的网站了，很多都是下载mp3到本地，这里我推荐一个免费下载MP3的网站：https://www.tikitiki.cn 。里面有QQ音乐、网易云音乐和酷狗的资源，基本上大陆没有被封杀的艺人作品都能在里面找到（抱歉了，陈升先生和黄耀明先生）。然后再搭配七牛云，把下载的MP3和封面图片上传到七牛云存储里，然后搭配提供的外网域名就可以填写MP3地址和封面地址了。如图： 如果想做一个歌单，也很简单，如下：1234567891011121314151617181920212223&#123;% aplayerlist %&#125; &#123; "autoplay": false, "showlrc": 3, "mutex": true, "music": [ &#123; "title": "歌曲名", "author": "歌手名", "url": "https://具体地址.mp3", "pic": "https://封面图.jpg", "lrc": "https://歌词.lrc" #不愿意加歌词可以不写，注意逗号 &#125;, &#123; "title": "歌曲名", "author": "歌手名", "url": "https://具体地址.mp3", "pic": "https://封面图.jpg", "lrc": "https://歌词.lrc" &#125; ] &#125;&#123;% endaplayerlist %&#125; 不过我这个七牛云的账号比较挫，没有做https，只好用http了… 把侧栏移动到左边博客自从安装了宠物之后，发现小宠物与侧栏重叠，看上去感觉很不友好，但是很奇怪，默认的宠物即使调整了botton依旧无法移动，所以我就想那就把整个侧栏移动到了左边，但是发现更改next主题的_config.xml里的“sidebar的position属性”发现并没有效果，后来经过一顿查找，找到了改成左侧栏的方法(适用于next 5.1.3版本)。 首先，先更改\themes\next\source\css\_common\components\sidebar\sidebar.styl，把第三行的right改成left,如下：123.sidebar &#123; position: fixed; left: 0; 保存之后，打开\themes\next\source\js\src\motion.js，把101行和167行的paddingRight全改成paddingLeft,同时找到类似如下的代码，并替换成如下代码:123456789101112131415161718192021var sidebarToggleLine1st = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-first', status: &#123; arrow: &#123;width: '50%', rotateZ: '45deg', top: '2px', left: '5px'&#125;, close: &#123;width: '100%', rotateZ: '45deg', top: '5px', left: 0&#125; &#125;&#125;);var sidebarToggleLine2nd = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-middle', status: &#123; arrow: &#123;width: '90%'&#125;, close: &#123;opacity: 0&#125; &#125;&#125;);var sidebarToggleLine3rd = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-last', status: &#123; arrow: &#123;width: '50%', rotateZ: '-45deg', top: '-2px', left: '5px'&#125;, close: &#123;width: '100%', rotateZ: '-45deg', top: '-5px', left: 0&#125; &#125;&#125;); 保存完毕之后，hexo clean和hexo d -g。刷新一下页面，就大功告成了！ 参考资料https://reuixiy.github.io/technology/computer/computer-aided-art/2017/06/09/hexo-next-optimization.html#hcm=1515719347596232 （这篇文章强烈推荐！）http://www.lmnsyunhao.cn/2017/03/29/hexo-next-themes-left-sidebar/http://mashirosorata.vicp.io/HEXO-NEXT主题个性化配置.html]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
        <tag>博客美化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix监控ActiveMQ队列数以及结合Grafana展示]]></title>
    <url>%2F2018%2F01%2F11%2FZabbix%E7%9B%91%E6%8E%A7ActiveMQ%E9%98%9F%E5%88%97%E6%95%B0%E4%BB%A5%E5%8F%8A%E7%BB%93%E5%90%88Grafana%E5%B1%95%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[在ZABBIX上监控MQ队列众所周知，Zabbix是可以自定义监控项的，那么就代表只要能获得到的数字都可以进入Zabbix的监控范围内。作为消息队列，Activemq里的“消息堆积数”是监控的重点项目之一。 获取消息堆积数并不是一个很难的事儿，浏览器里登陆MQ的web网页控制台，输入账号密码之后，在Queues的网页里就能看到如下的界面： 其中Pending Messages就是“等待消息”，Consumers是“消费者”，Enqueued是“入队”，Dequeued是“出队”。入队数=出队数+等待数。 现在我们要获取到图中的队列叫AggregateQueue里的那个23596，很简单，shell语句是： 1curl -s -u网站用户名:网站密码 http://网站外网IP地址:8161/admin/queues.jsp | grep -A 5 "具体的队列名&lt;/a&gt;&lt;/td&gt;"|awk -F '&lt;' '&#123;print $2&#125;'|sed 's/td&gt;//g'|head -2|tail -1 这里curl有一个-s的参数，不然会显示curl的状态。如图： 语句在此，写脚本就很easy了。不过我这里就直接监控具体数字了，没有写脚本，如果要写python脚本的话，我推荐各位移步：http://blog.51cto.com/sfzhang88/1316789 ，看一下这篇文章。 现在把这个监控项添加到具体的zabbix_agentd.conf里吧，具体添加过程可以参看 http://blog.51cto.com/chenx1242/1839829 ，由于是curl网站，那么直接把这个监控项加到Zabbix-server里就好，然后使用zabbix_get检查一下。有的zabbix 3.x里没有zabbix_get，安装zabbix_get方法：yum install zabbix-get.x86_64。 zabbix_get检查情况和具体的trigger情况如下： 配置Zabbix结合Grafana我使用的Grafana版本是4.3.2，下载地址：https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.3.2-1.x86_64.rpm ，下载完毕之后，直接yum install /路径/grafana-4.3.2-1.x86_64.rpm，由于Grafana使用的是AWS的云存储，可能在墙内的下载会比较吃力，有断开的情况就多试几次。话说Grafana的升级是比较频繁的，半年不到的时间升级了三次，现在最新版本已经是4.6.2。所以说这玩意，其实选择一个稳定的就好。 启动grafana的方法就是：systemctl start grafana-server.service，配置开机自启动的方法：chkconfig grafana-server on。然后在浏览器里输入grafana外网ip地址：3000就能看到grafana的界面，默认密码：admin/admin，grafana默认的日志存储路径是/var/log/grafana/。 Grafana与ZABBIX联系的插件下载方式：grafana-cli plugins install alexanderzobnin-zabbix-app，安装之后，重启一下grafana-server，在web界面就会看到插件已经成功安装，如图： 其他更多的插件下载可以在grafana的官方网站查看到：https://grafana.com/plugins ，用grafana-cli都能搞定，还是那话，墙里的同学速度要慢一点。 现在配置Zabbix作为Grafana的数据源，首选点击网站上面的红色漩涡标志，选择zabbix，点击Plugin Config，点击Enable，启动Zabbix插件。如图： 再次点击红色漩涡，这次选择Data Sources，点击Add data source，如果插件启动成功，那么在Type里是可以选择zabbix的，然后就是填各种东西，如图： 这里有一些要额外说明：1）url这个是zabbix的API地址http://ip/zabbix/api_jsonrpc.php，这个可以在zabbix服务端上可查找find / -name api_*.php；2）username和passwd是zabbix WEB界面的登录用户名和密码，有读的权限即可；3）alerting选择启动，min severity选择high； 然后点击save &amp; test，如果都正确的话，就会出现success，如图： 在Grafana展示趋势图点击左上方红色漩涡，Dashboards的地方点击+new，然后在小齿轮的地方选择Templating,如图： 在Templating里要建立4个模板，其中group的添加方法如下，如果Query正确的话，在点击Include All option的时候，就会有“组”显示出，而且和zabbix里完全一致： group添加完了，还有host、application、iteams，添加的大同小异，需要注意的是Query的不同：host的Query：$group.*application的Query: $group.$host.*iterm的Query:$group.$host.$application.* 以上四个template都搞定之后，应该是这个样子： 模板搞定了，下面就是图形展示，选择对应的hosts、application和items就自动有图像生成了！ 最后说一下页面自动刷新，点击右上角“Last 6 hours”, 在弹出的下拉框中，选择Time range下的Refreshing every选项，点击下拉框按钮，默认应该有“off”和“1m”两个选项。点击“1m” 然后Apply设置，即为每一分钟刷新一次数据的意思。设置成功后，在原来Last 6 hours的后面会出现Refresh every 1m的橙色文字！ 参考资料《实践MQ的小demo》http://www.jianshu.com/p/3a39c8dd4f29]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>grafana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Python使用yaml的几个例子]]></title>
    <url>%2F2018%2F01%2F11%2F%E5%9C%A8Python%E4%BD%BF%E7%94%A8yaml%E7%9A%84%E5%87%A0%E4%B8%AA%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[python版本：2.7.5安装方法：pip install PyYaml “把变量写进yaml做配置文件，然后python脚本从yaml文件里面取到变量”的方法最近是在python编程里比较流行的配置项方法。yaml更加易读，而且通过缩进表示结构，这一点与python不谋而合。 Yaml有四个比较常用的用法，分别是load()、dump()、load_all()、dump_all()。这篇文章主要就是了解一下这四个方法。 首先我们先写一个很简单的test.py： 12345678910111213# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlyaml_str = """name: Gakkiage: 29job: Actressrelationship: Wife""" aaa = yaml.load(yaml_str)print aaa 执行的话，看到的效果就是： 12[root@paas-online-crs-001 chentest]# python test.py &#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125; 这个aaa的类型是一个字典（dict），如果要得到里面那个”Gakki”，那么就是aaa[‘name’]。通过load方法，一个字符串变成了一个字典。 现在把test.py换成如下： 123456789101112# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlyaml_dict = &#123;"name": "Gakki", "age": 29, "job": "Actress", "relationship": "Wife" &#125;aaa = yaml.dump(yaml_dict, default_flow_style=False)print aaaprint (type(aaa)) 执行后的效果如下： 123456[root@paas-online-crs-001 chentest]# python test.py age: 29job: Actressname: Gakkirelationship: Wife&lt;type 'str'&gt; 可见，通过dump方法，把一个dict变成了一个字符串。 现在写一个配置文件，假如它叫test.yaml: 1234- Gakki- 29 - Actress- Wife 再来一个test.py，内容如下: 1234567# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yaml aaa = yaml.load(file('test.yaml', 'r'))print aaaprint (type(aaa)) 执行这个test.py： 123[root@paas-online-crs-001 chentest]# python test.py ['Gakki', 29, 'Actress', 'Wife']&lt;type 'list'&gt; #得到了一个列表 如果把那个test.yaml升级成字典和列表的混合结构，如下： 1234567- name: Chris age: 29 job: OM Engineer- name: Gakki age: 29 job: Actress relationship: Wife 执行test.py的效果如下： 123[root@paas-online-crs-001 chentest]# python test.py [&#123;'job': 'OM Engineer', 'age': 29, 'name': 'Chris'&#125;, &#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125;]&lt;type 'list'&gt; 既然获得的结果是一个包含字典的列表，那么如果要获得“Gakki”就是aaa[1][‘name’] 如果想要复制和引用，那么要用&amp;和*，比如把test.yaml改成这样： 12name: &amp;name Gakkiwife: *name 执行test.py的效果如下： 123[root@paas-online-crs-001 chentest]# python test.py &#123;'name': 'Gakki', 'wife': 'Gakki'&#125;&lt;type 'dict'&gt; 在同一个yaml文件中，可以用 — 来分段，这样可以将多个文档写在一个文件中： 123456789--- name: Chris age: 29 job: OM Engineer--- name: Gakki age: 29 job: Actress relationship: Wife 再写一个新的test.py如下: 123456# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlys = yaml.load_all(file('gakki.yaml', 'r')) #load_all() 方法会生成一个迭代器，可以用for输出出来for y in ys: print y 执行这个py的效果： 123[root@paas-online-crs-001 chentest]# python test.py &#123;'job': 'OM Engineer', 'age': 29, 'name': 'Chris'&#125;&#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125; 参考文档：https://huilansame.github.io/huilansame.github.io/archivers/recommond-case-file-type-yaml]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Zabbix去监控Redis]]></title>
    <url>%2F2018%2F01%2F10%2F%E4%BD%BF%E7%94%A8Zabbix%E5%8E%BB%E7%9B%91%E6%8E%A7Redis%2F</url>
    <content type="text"><![CDATA[了解Redis的info要获得Redis的当前情况，使用info命令即可。具体用法：redis-cli -h 127.0.0.1 -p 6379 -a redis_passwd info [参数] 。针对不同的参数就会看到具体的数字，如果没有带参数，那么就会把默认情况写出来，如果带上all参数，那么就会把所有情况都写出来。比如：redis-cli -h 127.0.0.1 -p 6379 -a redis_passwd info server，就会看到redis关于server的一些数据，如下：可以看出，从server里可以查询到的是版本号、pid号、配置文件路径等等东西。 如果参数是client，记录了是客户端的相关信息： 123456[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info clients# Clientsconnected_clients:64 #已连接客户端的数量（不包括通过从属服务器连接的客户端）client_longest_output_list:0 #当前连接的客户端当中，最长的输出列表client_biggest_input_buf:0 #当前连接的客户端当中，最大输入缓存blocked_clients:0 #正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量 如果参数是memory，记录的是内存的相关信息： 12345678910[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info memory# Memoryused_memory:2252984 #由 Redis 分配器分配的内存总量，以字节（byte）为单位used_memory_human:2.15M #上面的数字加上了单位used_memory_rss:9293824 #常驻集大小，即Redis已分配的内存总量。这个值和top、ps等命令的输出一致used_memory_peak:2607520 #Redis 的内存消耗峰值（以字节为单位）used_memory_peak_human:2.49M #上面的数字加上了单位used_memory_lua:33792 #Lua 引擎所使用的内存大小（以字节为单位）mem_fragmentation_ratio:4.13 #used_memory_rss 和 used_memory 之间的比率mem_allocator:jemalloc-3.2.0 #在编译时指定的，Redis所使用的内存分配器。可以是libc、jemalloc或者tcmalloc。 这里要注意！在理想情况下， used_memory_rss 的值应该只比 used_memory 稍微高一点儿（我这个机器就已经属于严重的级别了）。当 rss &gt; used ，且两者的值相差较大时，表示存在（内部或外部的）内存碎片。内存碎片的比率可以通过 mem_fragmentation_ratio 的值看出。当 used &gt; rss 时，表示 Redis 的部分内存被操作系统换出到交换空间了，在这种情况下，操作可能会产生明显的延迟。 如果参数是stats，那就是统计的相关信息： 12345678910111213141516[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info stats# Statstotal_connections_received:150383 #服务器已接受的连接请求数量total_commands_processed:500935 #服务器已执行的命令数量instantaneous_ops_per_sec:0 #服务器每秒钟执行的命令数量rejected_connections:0 #因为最大客户端数量限制而被拒绝的连接请求数量sync_full:0 sync_partial_ok:0 sync_partial_err:0 #查找数据库键成功的次数expired_keys:41 #因为过期而被自动删除的数据库键数量evicted_keys:0 #因为最大内存容量限制而被驱逐（evict）的键数量keyspace_hits:78121 #查找数据库键成功的次数keyspace_misses:56 #查找数据库键失败的次数pubsub_channels:0 #目前被订阅的频道数量pubsub_patterns:0 #目前被订阅的模式数量latest_fork_usec:878 #最近一次 fork() 操作耗费的微秒数 如果参数是CPU，那么就会返回CPU的相关信息： 123456[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info cpu# CPUused_cpu_sys:63.95 #Redis服务器耗费的系统CPUused_cpu_user:129.54 #Redis服务器耗费的用户CPU used_cpu_sys_children:1.70 #子进程耗费的系统CPUused_cpu_user_children:1.03 #子进程耗费的用户CPU 如果参数是keyspace，那么就会返回数据库相关的统计信息： 123[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info keyspace# Keyspacedb0:keys=262,expires=183,avg_ttl=284091259423 #据库的键数量、数据库设置有过期时间的key的数量（这个值减少是正常的） 除了以上之外其他还有更多信息，请移步：http://redisdoc.com/server/info.html 。感谢前人栽树！！！ 使用zabbix监控redis用zabbix监控redis是一个很简单的事儿，只需要把需要监控的数据提取出来即可。而提取数据的方法就是利用info去得到对应的数值。 首先先来一个判断redis服务器连接的脚本： 1234567891011[root@func-redis-001 ~]# cat check_redis.sh#这个脚本是用来zabbix监控自建redis的#!/bin/bashPORT='6379'PASSWD=‘REDIS密码’ STATUS_redis=$(redis-cli -h '127.0.0.1' -p $PORT -a $PASSWD ping)if [ "$STATUS_redis" == 'PONG' ];then echo '1'else echo '0'fi 然后更改zabbix_agentd.conf,如下： 12UserParameter=redis_status[*],redis-cli -h '127.0.0.1' -p $1 info | grep -w $2 | awk -F':' '&#123;print $NF&#125;'UserParameter=redis_ping,sudo sh /root/check_redis.sh 修改/etc/sudoers文件如下： 1234## Allow root to run any commands anywhereroot ALL=(ALL) ALLzabbix ALL=(ALL) NOPASSWD:ALL #这个是新增Defaults:zabbix !requiretty #这个是新增 保存之后，重启zabbix-agent服务，由于我这个redis是通过zabbix-proxy监控的，所以在zabbix-proxy一端用zabbix_get来查看结果： 然后在zabbix-proxy的模板里面添加一些需要监控的item即可，有必要的话可以设置trigger+action用来报警，如图： 最后就是grafana搞一个炫酷的图表来，如图： 最后一点，关于redis的内存优化，各位可以来看看：https://cachecloud.github.io/2017/02/16/Redis%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/ ，写的很全面了。还有zabbix各种模板整理，有需要的同学也可以去下载：https://monitoringartist.github.io/zabbix-searcher/ 。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过nginx配置修改网页cookie属性]]></title>
    <url>%2F2018%2F01%2F10%2F%E9%80%9A%E8%BF%87nginx%E9%85%8D%E7%BD%AE%E4%BF%AE%E6%94%B9%E7%BD%91%E9%A1%B5cookie%E5%B1%9E%E6%80%A7%2F</url>
    <content type="text"><![CDATA[需求与具体配置公司的电子商城在十九大等保安检时期被折腾出去，结果这几天又折腾回来了，据说还会是明年大数据研究院的主要开发项目。结果回来没几天被测试中心的人在cookie方面发现了几个问题，如下： cookie没有使用http-only； cookie没有携带secure属性； http头中需要配置“X-Frame-Options：SAMEORIGIN”； 以上这几点可以通过nginx的配置来轻松实现，具体方法就是在需要更改的网页server的配置里面添加下面几句话。如图： 123add_header Set-Cookie "HttpOnly";add_header Set-Cookie "Secure";add_header X-Frame-Options "SAMEORIGIN"; 然后保存配置文件，nginx -s reload平滑重启即可，通过chrome在目标网页里按下ctrl+shift+c，先选择好network，然后重新刷新一下界面，选择域名，对应域名下点击headers，就会看到cookie的配置情况，如图： 扩展内容看到配置已经生效。那么这几个配置主要是干什么的呢？其实主要都是防范XSS攻击（跨域脚本攻击）的。 Cookie的Secure属性，意味着保持Cookie通信只限于加密传输，指示浏览器仅仅在通过安全/加密连接才能使用该Cookie。如果一个Web服务器从一个非安全连接里设置了一个带有secure属性的Cookie，当Cookie被发送到客户端时，它仍然能通过中间人攻击来拦截。 Cookie的HttpOnly属性，指示浏览器不要在除HTTP（和HTTPS)请求之外暴露Cookie。一个有HttpOnly属性的Cookie，是不可以通过例如调用JavaScript(引用document.cookie)这种非HTTP方式来访问。因此，也不可能通过跨域脚本（一种非常普通的攻击技术）来偷走这种Cookie。 X-Frame-Options HTTP 响应头是用来给浏览器指示允许一个页面可否在frame, iframe或者object中展现的标记。网站可以使用此功能，来确保自己网站的内容没有被嵌到别人的网站中去，也从而避免了点击劫持 (clickjacking) 的攻击。它有三个可选择项： 123DENY：表示该页面不允许在 frame 中展示，即便是在相同域名的页面中嵌套也不允许；SAMEORIGIN：表示该页面可以在相同域名页面的 frame 中展示；ALLOW-FROM uri地址：表示该页面可以在指定来源的 frame 中展示； 如果设置为 DENY，不光在别人的网站 frame 嵌入时会无法加载，在同域名页面中同样会无法加载。另一方面，如果设置为 SAMEORIGIN，那么页面就可以在同域名页面的 frame 中嵌套。 这里还要额外注意一下！配置了Cookie的HttpOnly属性和Secure属性之后，如果测试中心的人使用的协议是http而不是https的话，会有“浏览器请求后端服务时header不会带上cookie参数”的现象，那是因为“由于secure属性的存在，导致浏览器在与服务器通信时不会使用该cookie”。这个时候就需要把secure=”true”这个配置去掉才可以达到正确测试的目的。 参考资料https://imququ.com/post/my-nginx-conf-for-security.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django新增class的时候数据库格式出错]]></title>
    <url>%2F2018%2F01%2F10%2Fdjango%E6%96%B0%E5%A2%9Eclass%E7%9A%84%E6%97%B6%E5%80%99%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A0%BC%E5%BC%8F%E5%87%BA%E9%94%99%2F</url>
    <content type="text"><![CDATA[这几天开发频繁要求查看生产环境zookeeper的配置，于是就想在django里添加一个新的栏，以文本的形式随时更新zookeeper的情况。 于是我就登陆了django，在model.py里添加一个新的class，如下： 12345678#建立杭州测试ZK配置class HZfunczk(models.Model): hzfunczk_remark = models.CharField(verbose_name='杭州测试ZK配置',max_length=50000,blank=true) hzfunczk_signer = models.CharField(verbose_name='登记人',max_length=30,default='system') hzfunczk_signtime = models.DateField(auto_now_add=True) def __unicode__(self): return self.domain_name 然后在django的目录下执行python manage.py makemigrations，这一步没问题，但是在执行python manage.py migrate的时候，就出现了下面的错误： 我开始认为是charfield写错了，应该写Textfield，于是更改了一下，但是保存之后，再执行python manage.py migrate还是出错。其实这个错误主要原因就是因为我那个50000设置错了，因为字段hzfunczk_remark定义的长度50000超出了mysql的varchar的最大长度21845（在utf8编码情况下）。于是我就在model.py里把这个长度改成20000，保存之后，还是执行到python manage.py migrate这一步，依旧爆上面的错误。于是我就干脆把这个class先删除掉，没想到都删除光了，还是在make的时候会爆错。 这就很奇怪了，我已经删掉了为啥还有这样的事儿？于是就干脆进入到数据库去看，由于我现在只知道列名叫hzfunczk_remark，所以我要根据这个列名去查它所在的表，maria反馈如下： 12MariaDB [abccs]&gt; select TABLE_SCHEMA, TABLE_NAME from information_schema.columns where COLUMN_NAME = 'hzfunczk_remark'; Empty set (0.02 sec) 好尴尬呀，数据库里压根就没有列名为“hzfunczk_remark”的表。然后由于python manage.py migrate报错，现在无法启动django。怎么办？ 遇到这种状况，就去django里的migrations文件夹，这个文件夹里有很多的以时间命名的py文件，它们记录着数据库的每一步操作，不过这里面的py还没有真正执行到数据库里，我找到当时添加class那个时间段的py文件，里面是这样的： 先把里面CharField改成TextField，然后把50000改成小于21845的就行了。如果你性子比较烈，那就干脆把这个文件以及之后产生的所有文件都删除掉。重新的去make。 如果还是实在不行，还有一个万不得已的办法，几乎所有的数据库错误都可以用这个方法解决：将migrations文件夹下的文件除了init.py全部删掉，然后将数据库drop掉，重新建数据库。然后make和migrate，就可以使用一个新的数据库（但愿你永远用不到这个方法）。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通道信息加密工具--Qtunnel]]></title>
    <url>%2F2018%2F01%2F10%2F%E9%80%9A%E9%81%93%E4%BF%A1%E6%81%AF%E5%8A%A0%E5%AF%86%E5%B7%A5%E5%85%B7-Qtunnel%2F</url>
    <content type="text"><![CDATA[前言数据库做异地容灾是一个很常见的现象，既然信息要跨地域传递，要么就很土豪的打通机房之间的链路或者动用VPN，要不然就不可避免的走公网网络传输信息。既然选择了公网，那么数据库的语句就很容易被人监听到，所以把那些明文加密是必不可少的环节。 mysql支持tls/ssl加密方法对信息进行加密，这个方法的配置也很简单，就是两边各加上一个nginx，一个是正向代理一个是反向代理，配上ssl证书，然后就像配置网站https协议那样，在nginx.conf里开启ssl监听即可。 但是这种方法有一点小问题，就是在进行SSL握手之前，mysql会发送Server Greeting和Login Request数据包，然后才有可能使用SSL握手。这样步骤就多了一步鉴权，对访问性能有所影响。所以这个时候，我选择了另一个用于加密client和server之间链路通信的工具—-Qtunnel，因为它直接加密，速度更快。 Git的地址在这里：https://github.com/arstercz/qtunnel ，感谢arstercz大神的再加工！ 上面说过了Qtunnel是不需要认证的，默认加密方法是RC4，以字节流的方式加密明文的每一个字节，而且密钥长度最长支持256位，可以很好的抵御暴力搜索密钥的攻击，总而言之，Qtunnel是一个轻量且快速的加解密工具，而且还可以搭配atlas等数据库中间件使用。 下载与准备由于Qtunnel是用go语言写的，所以需要先安装golang，centos服务器的yum安装方法如下: 12rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpmyum install -y golang go语言安装完毕之后，我们就git clone https://github.com/arstercz/qtunnel.git ，获得qtunnel文件夹，文件夹内容如下： make，如果没有任何报错，那么就是安装成功了，使用./bin/qtunnel -h语句验证一番： 本次实验的计划是这样的：用A机器访问B机器的mysql，并且插入数据，在B机器上的3306端口抓包，查看数据是否是明文；然后再在A机器和B机器上都安装qtunnel并且启动，然后重新插入数据，在B机器上的端口抓包，查看数据是否被加密。流程图如下： 实验开始A机器和B机器都是使用阿里云虚拟服务器，版本都是centos 6.4，现在我们的加密实验正式开始。 首先A和B机器上都不启动qtunnel，然后我们在A机器上登陆B机器的数据库，如果之前没有授权，那么授权语句是： GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;A机器的IP地址&#39; IDENTIFIED BY &#39;密码&#39; WITH GRANT OPTION; 登陆mysql之后，我们随意的插一个语句，然后通过抓包发现无论这个语句还是数据库的反馈都是以明文的形式呈现，如图： 这种让数据裸奔的行为无疑于找死，那么这个时候我们就要配置一下qtunnel，来看一下它的加密效果。 在A服务器上，我们设定qtunnel是客户端，手动建立一个conf文件，比如vim /etc/conn.conf，内容如下： 123456[client1]faddr = 10.252.215.108:3309 #这里是qtunnel客户端的IPbaddr = 10.175.193.239:3310 #这里是qtunnel服务端的IPcryptoMethod = rc4 #这里选用rc4的方式加密secret = 3301_test%Iad #rc4密钥，服务端的密码必须跟这个一致！clientmode = true #表示这端是客户端 然后使用./bin/qtunnel -conf=/etc/conn.conf -daemon -logto=syslog启动qtunnel，看一下进程和端口情况，如图： 在B服务器上，同样手动建立一个配置文件，假设也叫conn.conf，内容如下： 123456[server1]faddr = 10.175.193.239:3310 #这里是qtunnel服务端的IPbaddr = 10.175.193.239:3306 #这里是数据库的地址，由于在同一台机器上，所以地址一样cryptoMethod = rc4 secret = 3301_test%Iad #rc4密钥，跟client密钥一致clientmode = false #表示这是服务器端 也用同样的语句启动qtunnel，查看3310这个端口已经被监听了： 现在，我们在A服务器上来重新连接B数据库，但是要注意！这个时候mysql里的-h不能再是B的IP地址了，而是A的地址！因为qtunnel现在已经打通了一个通道，访问qtunnel的3310端口就等于是访问B数据库的3306端口（有点类似atlas的意思）。 连上之后，我们随意插入一些语句，看一下qtunnel的能力: 可见这个时候，抓包显示都是加密的文字了，实验成功！ 总结与参考资料总结一下：qtunnel采用rc4加密，在算法强度和速度方面是很好的选择，不会引起slave太大的延迟，对管理员或开发而言数据都是透明的（如果在上面的实验启动了qtunnel之后，不监听3310端口，而是监听3306端口，得到的依旧是明文），只是在两端传输的过程中增加了加解密处理。核心的业务(比如用户和充值)在做异地架构的时候可以考虑该方式增强数据的安全性。 《mysql使用ssl简析》：https://hsulei.com/2017/10/19/mysql%E4%BD%BF%E7%94%A8ssl%E7%AE%80%E6%9E%90/《使用ssl加密mysql 5.6的官方文档》：https://dev.mysql.com/doc/refman/5.6/en/encrypted-connections.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>加密技术</tag>
        <tag>Qtunnel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix3.0搭配微信企业号报警]]></title>
    <url>%2F2018%2F01%2F10%2FZabbix3-0%E6%90%AD%E9%85%8D%E5%BE%AE%E4%BF%A1%E4%BC%81%E4%B8%9A%E5%8F%B7%E6%8A%A5%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[Zabbix搭配微信企业号报警是一个很流行的手段，这里说一下如何配置。 准备工作建立一个企业号以及具体应用的链接在此：http://chenx1242.blog.51cto.com/10430133/1954634，里面写的都很明白了。 现在打开微信企业号的官方网站https://work.weixin.qq.com，然后扫描一下微信二维码登录到企业号的控制台。 在控制台网页里，需要查找几个元素，分别是CorpID、应用AgentId、应用Secret还有用户账号。 首先，在控制台里选择“我的企业”，然后就可以看见CorpID，如图： 然后点击“企业应用”，如果没有应用，那么就新建立一个应用。比如我已经建立了一个应用叫“zabbix告警”，那么应用AgentId和应用Secret就在如图的位置： 有了上面的CropID和Secret，就可以去验证一下accesstoken，登录http://qydev.weixin.qq.com/debug ，后在填入对应的CropID和Secret，看一下返回结果是否是“HTTP/1.0 200 OK”，如图： 在这个“zabbix告警”的应用里可见范围里添加对应需要通知的人，然后在“通讯录”里，找到对应的人，记录他们的账号，如图： 材料已经俱备完毕，现在需要做的是更改zabbix-server配置。 首先，在zabbix-server.conf里添加一句AlertScriptsPath=/usr/lib/zabbix/alertscripts，这是为了说明一下脚本所在的路径。当然，这个路径你可以自己更改，然后重启一下zabbix-server。 编写脚本cd /usr/lib/zabbix/alertscripts，在这个目录下我们要新写一个微信脚本，比如脚本名称叫wechat.py。 这个python脚本是需要requests模块的，所以需要先安装这个模块，安装方法如下： 12pip install requestspip install --upgrade requests 而python脚本内容如下，感谢https://github.com/X-Mars/Zabbix-Alert-WeChat/的脚本： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/usr/bin/python2.7#_*_coding:utf-8 _*_#this script is used for alarm by WECHATimport requests,sys,jsonimport urllib3urllib3.disable_warnings()reload(sys)sys.setdefaultencoding('utf-8')def GetToken(Corpid,Secret): Url = "https://qyapi.weixin.qq.com/cgi-bin/gettoken" Data = &#123; "corpid":Corpid, "corpsecret":Secret &#125; r = requests.get(url=Url,params=Data,verify=False) Token = r.json()['access_token'] return Token def SendMessage(Token,User,Agentid,Subject,Content): Url = "https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=%s" % Token Data = &#123; "touser": User, # 企业号中的用户帐号，在zabbix用户Media中配置，如果配置不正常，将按部门发送。 #"totag": Tagid, # 企业号中的部门id，群发时使用。 "msgtype": "text", # 消息类型。 "agentid": Agentid, # 企业号中的应用id。 "text": &#123; "content": Subject + '\n' + Content &#125;, "safe": "0" &#125; r = requests.post(url=Url,data=json.dumps(Data),verify=False) return r.text if __name__ == '__main__': User = sys.argv[1] # zabbix传过来的第一个参数 Subject = sys.argv[2] # zabbix传过来的第二个参数 Content = sys.argv[3] # zabbix传过来的第三个参数 Corpid = "这里填写Corpid" Secret = "这里填写Secret" Agentid = "这里填写应用的agentid" Token = GetToken(Corpid, Secret) Status = SendMessage(Token,User,Agentid,Subject,Content) print Status 脚本保存后，chown -R zabbix:zabbix wechat.py，然后小试一下，上面看到“Zabbix告警”这个微信应用里有一个用户账号叫ChenShuo，那么wechat.py执行语句是：python wechat.py ChenShuo 这个是标题 这里是正文！！ 然后看一下微信，如图： 正确出现了微信提示，可见这个脚本是OK的了。 配置zabbix现在我们要登录到zabbix网站，最上面的“Administration”里选择“Media types”，新建立一个Media type，如图： 保存之后，在“Administration”里选择“Users”，在Admin用户里点击“media”,把刚刚新增的“微信告警”这个media type添加进去，如图： 通知手段配置完毕，现在就是要在具体的Trigger上把微信告警这个新手段添加到active里。首先打开Configuration里的actions界面。此时假设现在有一个告警Trigger叫“模块发生了重启”，判断模块是否重启的依据就是pid值是否发生了变化。那么点击这个Trigger，在action里把“微信告警”添加到报警手段里，如图： 保存之后，整个的微信告警配置就完成了。为了验证配置是否生效，我冒死重启了一台生产环境的服务器，当然啦，好孩子千万不要效仿。 收到微信提示如图：不过考虑到微信告警可能会有所延迟，所以在这建议大家把告警阈值配置稍微早一点，避免“孩子死了奶来了”这种尴尬的情况。 参考资料http://www.yfshare.vip/2017/04/13/Zabbix%E4%B9%8B%E5%BE%AE%E4%BF%A1-Wechat-%E5%91%8A%E8%AD%A6/https://github.com/X-Mars/Zabbix-Alert-WeChat/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自己动手搭建一个hexo博客demo]]></title>
    <url>%2F2018%2F01%2F10%2F%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AAhexo%E5%8D%9A%E5%AE%A2demo%2F</url>
    <content type="text"><![CDATA[曾几何时，自己动手做一个博客的想法愈加强烈，想在里面放一些更多除了技术之外的东西，比如烹饪的美食，比如PVP的视频，比如拍摄的照片，比如篮球足球的评论。在这种需求下，我从众多博客框架里面选择了hexo，原因就是“很多人都推荐hexo”….（囧）于是乎我在windows里搞一个，由于我在公司的网络是可以跨越长城的，所以搞github有一点天然的优势。而且github的博客不用花钱搞域名，他直接免费提供… 在搞github的时候墙裂推荐各位去用命令行，有linux的基本基础就可以很熟练的使用命令行搞github， 它的客户端真的不如命令行好用。 准备工作先去注册一个github，然后去https://git-scm.com 上下载一个最新的git windows的客户端，我下载的是2.15.1版本，如图： 下载完毕之后，就把这个exe文件安装，然后在“开始”里找到git再打开“Git Bash”，我的github账号是RorschachChan，电子邮件也已经配置过，所以现在就在这个bash窗口里写入如下语句： 12git config --global user.name "RorschachChan"git config --global user.email "chenx1242@163.com" 上面git config --global参数，表示你这台机器上所有的Git仓库都会使用这个配置。 再去https://nodejs.org/en/download/上根据自己windows的情况，下载最新的nodejs，下载完了之后就一路next，然后需要退出重进一下git bash，在bash的命令行里输入node -v，看到版本号就是OK，同时输入node，$会变成&gt;，然后输入.exit就可以退出返回到bash。 然后就是安装hexo，hexo的安装比较简单，就是在git bash里输入npm install -g hexo-cli和npm install -g hexo，然后需要等待一会，如果出现了npm ERR!不要怕，重新输入一次应该就会好了，安装完毕之后，输入hexo -v查看hexo的版本，如图： 然后建立一个github ssh密钥，在git bash里输入ssh-keygen -t rsa -C &quot;你的邮箱&quot;，然后告诉密钥生成的路径（下图黄框）以及会让你输入对应的口诀（红色箭头），这个口诀很重要，要妥善保存，如图： 这个密码会在你提交项目（hexo d）时使用，如果为空的话提交项目时则不用输入。这个设置是防止别人往你的项目里提交内容。这时候去C:\Users\33664\.ssh的路径里就会看到一对钥匙，id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。 来到github的个人配置里，选择SSH and GPG keys，然后输入title和id_rsa.pub的内容，点击add ssh key。如图：准备工作的最后一步，就是建立一个文件夹，我的文件夹建立在E盘下，名字就叫hexo。 开始搭建博客首先在git bash里进入/e/hexo，然后输入hexo init，这个命令是初始化命令，再输入hexo -g来生成静态文件，执行之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github上你的用户名.github.io的仓库上去的。然后可以输入hexo s来本地启动hexo，这个时候跑到浏览器里输入localhost:4000就会看到hexo博客最初的一个样子，如图： 这个默认的主题比较难看，我们去https://github.com/iissnan/hexo-theme-next下载最近一个比较火爆的主题next,并且把这个下载到hexo文件夹里的themes/next里，语句是：git clone https://github.com/iissnan/hexo-theme-next.git themes/next 然后打开hexo文件夹里的_config.xml，把原有的theme注释，换成新的next，注意，中间是有空格的！ 12#theme: landscapetheme: next 然后hexo clean和hexo g清除 Hexo 的缓存和重新生成静态文件，再次hexo s启动进程，来到浏览看一下发现博客的样子就变成下面的样子了： 这个看上去就简单大方很多了吧。 把博客上传到github现在有人问了，这个博客看上去好像很美，但是有两个致命的缺陷：第一，内容都是在我的windows里，如果我这个电脑坏了/出差/换新硬盘，那么如何保证我以前文件？第二，我启动进程需要执行 hexo -s，如果我电脑关机了，岂不是博客无法打开？ 需要解决就要把磁盘上的内容传递到github库里了，同时github是常开进程的，这样既可以更新我们的内容又不会关闭博客进程，除非github这个网站黄了。 先去github网站去建立一个库（repository），这里我直接选择了公共读，如图： 然后在hexo文件夹里面，修改一下_config.xml的几个地方： 1234567891011121314# Sitetitle: 石锤淡啤酒 #这个是网站在标签页的标题subtitle: 生活就是等待戈多 #这个是副标题description: 这里记录的不只有代码，还有生活和思想！ #这里也可以写网站的关键词，也可以矫情的写点别的author: Chris Chan #这个作者会在网页最下面显示language: zh-Hans #这里表示简体中文timezone:# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: git@github.com:RorschachChan/RorschachChan.github.io.git #这里写的就是刚刚申请的库名 branch: master 建立完库以及修改保存了_config.xml之后，我们执行一句hexo d部署命令，在执行的时候需要输入当时你建立id_rsa时候的口诀，刚刚申请的那个口诀不会这么快就忘了吧。 返回到github的网站就看到hexo里所有的内容都上传到了github网站里了，如图: 在浏览器里输入“https://你的用户名.github.io”，就看到了博客界面： 同理，如果你的github用户名是test，建立的是test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是http://test.github.io了，每一个github账户最多只能创建一个这样可以直接使用域名访问的仓库。 至此，建立一个博客demo就到此结束了！ 参考资料https://baoyuzhang.github.io/2017/04/28/【Hexo搭建独立博客全纪录】（一）使用Git和Github/https://github.com/iissnan/hexo-theme-nexthttp://opiece.me/2015/04/09/hexo-guide/http://shenzekun.cn/hexo的next主题个性化配置教程.html 强烈推荐这篇文章，可以让你把next主题的博客做的更加漂亮！]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>hexo</tag>
        <tag>博客搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Query String跟Arg的差异]]></title>
    <url>%2F2018%2F01%2F09%2FQuery-String%E8%B7%9Farg%E7%9A%84%E5%BC%82%E5%90%8C%2F</url>
    <content type="text"><![CDATA[前言与需求在https://rorschachchan.github.io/2018/01/09/记一次配置rewrite和return的经历/ 里记录了一次rewrite和return的故事，不过我当时在最后的return里是把域名给写死了：rewrite ^.*$ http://dvlshop.lechange.com/index.php/wap/$id$query last;。 现在新的需求又来了，说域名不要写死，http://dvlshop.lechange.com/index.php/这部分要跟整个uri的state部分保持一致。 于是我这里再把整个uri贴出来，辣一下各位的眼睛：http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp; #满足条件的话把这个改成+auto+scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 也就是说现在只需要变量state那点部分，那么这个时候就不能再使用$query_string了，要使用$arg。 $arg可以精确匹配变量，比如说我有一个参数（uri里？后面的那部分全叫参数）：&amp;p=你大爷&amp;q=你大娘，用$query_string和$arg就是获取所有，而使用$arg_p就是可以获取“你大爷”。 于是说动手就动手，把nginx.conf改成了：123456789101112131415161718location ~ .*\.php.*&#123; include php_fcgi.conf; include pathinfo.conf; set $flag "0"; if ( $args ~ "source_type=lc_app" ) &#123; set $flag "1"; &#125; if ( $args ~ "(.*)response_type(.*)" )&#123; set $Flag "$flag$flag"; set $id $1; set $query $2; &#125; if ($Flag = "11")&#123; set $flag "0"; return 301 $arg_state$id+auto+$query; &#125;&#125; 但是通过日志查看，发现$arg_state得到的是/http%3A%2F%2Fdvlshop.lechange.com%2Fproduct-79.html,这就很囧了，我希望获取http%3A%2F%2Fdvlshop.lechange.com%2Fproduct-79.html（不要前面的反斜杠）或者是/product-79.html（不要中间的网站）。这可怎么办？ 答案是，原生的nginx是做不到这一点，因为nginx不参与业务层逻辑方面的业务。如果说要达到改写的目的，就要搭配lua或者把nginx换成openresty。于是乎就让开发修改一下传递的state来达到目的。 扩展与补充看到这个结果突然让我想起来一道面试题，说开发有一个模块，同时这个模块会给nginx提供几个状态码，比如状态码是111，那就是代表OK，状态码不是111，那就是代表不OK，现在想写一个语句，如果nginx获得的状态码不是111，返回一个404的页面，怎么写？ 没错，答案也是“原生nginx写不了”，原因跟上面的一样，应用模块状态码是业务层的，nginx是http层的，不在一层压根就无法交流。 在这里也顺道补充一下“在浏览器中输入一个URL后都发生了什么？”，以下是一个大概流程： 浏览器向DNS服务器查找输入URL对应的IP地址； DNS服务器返回网站的IP地址； 浏览器根据IP地址与目标web服务器建立TCP连接； 发送HTTP请求； 服务器处理请求； 返回响应结果； 关闭TCP连接； 浏览器解析HTML； 浏览器布局渲染；]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次配置rewrite和return的经历]]></title>
    <url>%2F2018%2F01%2F09%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E9%85%8D%E7%BD%AErewrite%E5%92%8Creturn%E7%9A%84%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[前言与需求自动电商平台归属了大数据研究院之后，我又恢复了那个“把nginx当成爸爸”的日子。开发不断地提出了的要求，我一样一样的疲命应付，并且在应付后记录下来，就怕以后再遇到类似的问题。 这次的需求是一个跳转，满足某个条件之后把“http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp;scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 ”改成“http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;=code&amp;scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27” 具体条件是: 先判断是否有source_type=lc_app； 再判断是否有response_type； 如果以上两个都满足，将“response_type”改成“+auto+”； 各位看官，我理解你们此时不想继续看下去的心情，其实我当初看着那么一大坨uri心里也直犯闹，但是没办法，“食君之禄，分君之忧”，我只能耐着性子一个一个的拆开，还别说，拆开的话就清晰许多了，如下：http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp; #满足条件的话把这个改成+auto+scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 开始操作针对这次需求我的计划是这样的：把原地址看成”$1+ response_type +$2”这样的一个样式，确定$1和$2，然后rewrite成”$1+ +auto+ +$2”不就搞定了么？ 于是乎我就凭着我那二把刀的nginx技术开始动手。折腾了大约半个小时，拿出来这样一个配置： 123456789101112131415161718location ~ .*\.php.* &#123; include php_fcgi.conf; include pathinfo.conf; set $flag "0"; if ( $request_uri ~ "source_type=lc_app" ) &#123; set $flag "1"; &#125; if ( $request_uri ~ "(.*)response_type(.*)" )&#123; set $Flag "$flag$flag"; set $id $1; set $query $2; &#125; if ($Flag = "11")&#123; #注意这个地方是11 set $flag "0"; rewrite ^.*$ http://dvlshop.lechange.com/index.php/wap/$id$query last; #前面那一段是写死的 &#125; &#125; 但是很不幸，nginx -s reload之后的结果是“$1+$2+$1+ response_type +$2”的格式（地址太长太恶心了，我就不写了）。 然后在arstercz大神的指点下，把那句rewrite改成了return 301 http://dvlshop.lechange.com/index.php/wap/?$id$query;。就达到了效果。 原因确定后来追寻原因，原来是： rewrite后面接的$uri不需要$args，因为$args会被自动带过来。而return的则会丢失$args，需要手动补上$args。而我上面的$1,$2恰巧就是$args，所以用rewrite的话就会重复。举个例子，比如请求「http://localhost/?a=1」想被 301 到「https://localhost/?a=1?a=1」，要么 1234server &#123; listen 80; rewrite / https://$host$uri permanent;&#125; 要么就 1234server &#123; listen 80; return 301 https://$host$request_uri;&#125; 补充说明PS，这里补充一下uri、request_uri、document_uri之间的区别： $request_uri: /stat.php?id=1585378&amp;web_id=1585378 $uri: /stat.php (不带？后面) $document_uri: /stat.php （与uri完全相同）]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维工程师面试题第一套]]></title>
    <url>%2F2018%2F01%2F04%2FLinux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E9%A2%98%E7%AC%AC%E4%B8%80%E5%A5%97%2F</url>
    <content type="text"><![CDATA[这套题的出处是http://blog.51cto.com/nolinux/1670406，看到了闲着没事周末就做一做，答案都是我自己在工作里得到的，不一定百分百准确，只是无聊的时候做做，现在拿出来跟各位分享一番。 1、请写出五种系统性能分析工具，并简述其作用和特点[我的答案] top、free、vmstat、iostat、perf等等等等，如果你想装逼，可以回答fio,blktrace，oprofile。具体的作用和特点这里不多说了，但是我着重要推荐vmstat，很实用很棒的一个命令。 2、请写出web服务器的调优要点[我的答案]以nginx为例，个人总结有如下几个要点：1）尽可能的少用http，因为http是有开销的；2）尽可能的使用CDN；3）添加Expire/Cache-Control头，这个头是缓存用的，可以缓存图片和flash那样不轻易更改的文件，减少访问时间；4）启动gzip压缩，这个没啥好说的了；5）尽可能少的重定向，能rewrite就不要return，我也知道return比rewrite好写，但是重定向是需要时间的，增加一次重定向就会多一次web需求；6）如果可以，把ajax也做缓存；7）减少dns查询，很多网页会有外站的广告，这些广告也是会启动dns查询的，所以如果不缺钱，减少这种广告；8）调好服务器里的TCP协议栈，这个无论是web服务器还是应用服务器都是必须的； 3、请写出你知道或使用过的nginx扩展模块（注意标注知道和使用）[我的答案] 随便说几个，这玩意到时候结合工作过的情况说说吧：Nginx负载均衡模块：nginx-upstream-fair非阻塞访问redis模块：redis2-nginx-module分布式图片实时动态压缩：ngx-fastdfs 4、请简述你了解的自动化配置管理工具特点和运行原理[我的答案]我用的最多的就是ansible和saltstack，这俩都是python的，对于我这个半路出家的更亲切。ansible基于SSH协议传输数据，不用装agent，配置比较简单，对windows支持惨不忍睹；saltstack使用消息队列zeroMQ传输数据，如果1000台以上的话它速度比ansible还要快,要安装agent，对windows支持同样惨不忍睹； 5、目前，有一个文件，内容如下： 172.16.100.1 172.16.100.2 172.16.100.3 172.16.100.4 请使用while和ssh命令，登录文件内的ip并执行hostname命令[我的答案]这个我还真没有什么思路，不过应该是跟“&lt;”输入重定向命令结合的一个脚本吧。PS,为啥不用ansible…哪怕pssh也可以啊！ 6、请使用awk命令将如下两份文件中名字相同的两行合并起来 A文件： 大广州 21岁 广州大 23岁 州广大 22岁 广州大 24岁 B文件： 广州大 男 大广州 男 州广大 男 广州大 男输出效果： 大广州 21岁 男[我的答案]awk ‘NR==FNR{a[$1]=$2}NR&gt;FNR{print $0,a[$1]}’ 第2个文件名 第1个文件名PS，做完这道题，我已经不认识“广”“州”这两个字了… 7、请使用绘图的方式简述TCP/IP三次握手和四次断开的交互过程[我的答案]这种图满大街都是了，我这个灵魂画师在这里就不污染各位的眼睛，不过这里推荐各位去看一篇文章：https://mp.weixin.qq.com/s?__biz=MjM5NzA1MTcyMA==&amp;mid=2651160450&amp;idx=2&amp;sn=1128438fa5287b6cee503880698642b2&amp;scene=21 对原理讲的浅显易懂。多说一句，网易招聘java的时候也问这个问题，不过他们问的是“为什么要三次握手？” 8、请根据你的理解，简述高可用服务体系的相关组件，并列举该组件的具体实现服务名字[我的答案] 我觉得这个题是要问一些架构上的东西，以我工作环境为例：统一配置:zookeeper、Consul、Etcd+Confd(这俩比较常见于动态管理nginx)前端展示:nginx消息队列:activemq、kafka读写分离中间件:atlas日志分析:elk 9、请根据你的理解，简述负载均衡的实现方式[我的答案]负载均衡主要分为两种，硬件（F5）和软件（NGINX、Haproxy、LVS），硬件效果比较牛逼，它是把4-7层的负载均衡功能做到一个硬件里面，但是价格昂贵最近用的越来越少了。软件的负载均衡又分两种，四层和七层：四层是在IP/TCP协议栈上把网络包的IP地址和端口进行修改，达到转发的目的；七层就是在应用层里把HTTP请求、URL等具体的应用数据发送到具体的服务器上。四层的效率比七层的高，四层一般安排在架构的前端，七层一般就是在具体服务器的前端。软件负载均衡比较常见的几个分配方式如下：轮询：访问请求依序分发给后端服务器；加权轮询：访问请求依序分发后端服务器，服务器权重越高被分发的几率也越大；最小连接数： 将访问请求分发给当前连接数最小的一台后端服务器，服务器权重越高被分发的几率也越大； 10、请根据你的理解，简述数据迁移工具和数据存储服务有哪些以及相关特点[我的答案]由于我公司主要都放在了阿里云，数据库用过的就这么几个:mysql、redis和elasticsearch。对于Storm和Hadoop这俩我还是初学者。mysql:关系型数据库elasticsearch:全文检索框架，这玩意逐渐向一个数据库靠拢了redis:键值储存数据库 mysql的数据迁移最常见的就是mysqldump，但是要注意使用不当会锁表，redis的数据迁移最稳妥的方法就是主从同步：在slave端启动redis，然后执行slaveof master机器IP地址 6379，然后使用info的时候查看master_link_status如果是up那就是OK了，再执行slaveof no one,提示OK就是OK了；Elasticsearch的数据迁移工具就是Elasticsearch-Exporter，不过我对它仅仅只是了解，用的并不多； 总结这套题不算难，方向是偏应用的，但是对云端服务的运维来说不算很友好，因为云厂商基本都把数据备份和数据迁移都做成自己的工具（比如阿里云的DTS），所以很多云服务的运维对这种东西了解不多。]]></content>
      <categories>
        <category>大牛之路</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx动态编译新的模块]]></title>
    <url>%2F2018%2F01%2F03%2FNginx%E5%8A%A8%E6%80%81%E7%BC%96%E8%AF%91%E6%96%B0%E7%9A%84%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[开始动手打算给电脑上的nginx添加一个当时没有编译安装的echo-nginx-module模块，这是一个第三方模块，要知道nginx要添加模块是需要重新编译的，这一点跟apache不同，apache是在配置文件里引用.so文件的。 首先先nginx -V，查看一下nginx已经编译的模块都有啥，如图： 于是我就git clone https://github.com/openresty/echo-nginx-module，但是发现竟然告诉我“git: command not found”。oh shit，原来这台nginx实验机器压根就没有装过git啊！而yum源里的软件基本上已经过时的太久了，就拿git来说吧，使用yum info git看到的版本是1.8.3.1。但是在https://github.com/git/git/releases 里可以看到，git的版本现在已经丧心病狂的到达了2.16的版本了。 那么我们先安装git!通过yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel和yum install gcc perl-ExtUtils-MakeMaker来安装依赖库。wget https://github.com/git/git/archive/v2.16.0-rc0.tar.gz来下载2.16的git保存到centos里。tar -xzvf v2.9.2.tar.gz -C /目标目录/，然后在目标目录里面执行make prefix=/usr/local/git all和make prefix=/usr/local/git install，编译过程可能会比较长，请耐心等待。 编译结束之后，echo &quot;export PATH=$PATH:/usr/local/git/bin&quot; &gt;&gt; /etc/bashrc，把git添加到环境变量，再source /etc/bashrc让它实时生效，最后再一次看看git --version，大功告成！ 编译新模块git搞定了之后，重新git clone https://github.com/openresty/echo-nginx-module，然后在nginx的configure文件夹里面，把echo-nginx-module模块添加上。命令如下： ./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/root/pcre-8.41 --with-http_v2_module --add-module=/root/echo-nginx-module-0.61,我这里还附赠了一个“http_v2_module”。 configure完毕之后，去make一下就可以了，不要轻易make install，不然就是重新安装了。原来的nginx.conf等配置都没了。 养成替换nginx二进制文件的好习惯，如下： cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bak cp nginx编译目录/objs/nginx /usr/local/nginx/sbin/ 然后再打开看一下nginx -V]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从vmstat命令里看服务器瓶颈]]></title>
    <url>%2F2018%2F01%2F03%2F%E4%BB%8Evmstat%E5%91%BD%E4%BB%A4%E9%87%8C%E7%9C%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%93%B6%E9%A2%88%2F</url>
    <content type="text"><![CDATA[这几天重新翻看基础知识，看到了vmstat，我认为它是一个非常优秀的命令,因为它包括了top和free，甚至还包含了一些io的信息，可以说是运维人员常备命令之一。常用方法：vmstat (-a) 多少秒刷一次 刷多少次。 对上面这个图来一个简单的解释： r: 运行队列中进程数量，这个值长期大于1就要判断是否需要增加CPU。b: 等待IO的进程数量 swpd: 使用虚拟内存大小(如果swpd的值不为0，但是SI，SO的值长期为0，这种情况不会影响系统性能）free: 空闲物理内存大小buff: 用作缓冲的内存大小cache: 用作缓存的内存大小(如果cache的值大的时候，说明cache处的文件数多，如果频繁访问到的文件都能被cache处，那么磁盘的读IO bi会非常小)inact: 非活跃内存大小（当使用-a选项时显示）active: 活跃的内存大小（当使用-a选项时显示） si: 每秒从交换区写到内存的大小，由磁盘调入内存so: 每秒写入交换区的内存大小，由内存调入磁盘注意：内存够用的时候，这2个值都是0，如果这2个值长期大于0时，系统性能会受到影响，磁盘IO和CPU资源都会被消耗。有些朋友看到空闲内存（free）很少的或接近于0时，就认为内存不够用了，不能光看这一点，还要结合si和so，如果free很少，但是si和so也很少（大多时候是0），那么不用担心，系统性能这时不会受到影响的。 bi: 每秒读取的块数bo: 每秒写入的块数注意：随机磁盘读写的时候，这2个值越大（如超出1024k)，能看到CPU在IO等待的值也会越大。 in: 每秒中断数，包括时钟中断。cs: 每秒上下文切换数。注意：上面2个值越大，会看到由内核消耗的CPU时间会越大。 us: 用户进程执行时间百分比(user time)注意： us的值比较高时，说明用户进程消耗的CPU时间多，但是如果长期超50%的使用，那么我们就该考虑优化程序算法或者进行加速。 sy: 内核系统进程执行时间百分比(system time)注意：sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因。 wa: IO等待时间百分比注意：wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。 id: 空闲时间百分比 最后总结：如果r经常大于4 ，且id经常少于40，表示cpu的负荷很重。如果bi，bo长期不等于0，表示内存不足。 r（运行队列）展示了正在执行和等待CPU资源的任务个数。当这个值超过了CPU数目，就会出现CPU瓶颈了。 CPU 100%并不能说明什么，Linux总是试图要CPU尽可能的繁忙，使得任务的吞吐量最大化。唯一能够确定CPU瓶颈的还是r（运行队列）的值。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于阿里云CDN的两个故障解决]]></title>
    <url>%2F2017%2F12%2F28%2FCDN%E7%BD%91%E7%AB%99%E4%B8%80%E6%AC%A1%E6%89%93%E4%B8%8D%E5%BC%80%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[测试中心今天在测试时候发现了一个问题：官方的A网站做了域名跳转，跳转到阿里云CDN，但是在浏览器里输入A地址栏的时候，发现域名的确变成了CDN的域名，但是页面是403。 如图： 但是奇怪的是，再在浏览器点击一下回车，网页就神奇的打开了。 这个原因就是阿里云的CDN有一个“Refer防盗链”，需要在防盗链里面把A域名添加到白名单，这样的话就可以直接访问了。至于为什么第二次回车就可以访问，是因为那时候域名已经成CDN自己的域名了，当然可以访问。 但是这个防盗链也要注意！毕竟白/黑名单添加都是一个危险举动，一定三思后行。有可能你的css\js是用cdn加速的，一旦加上了白名单，可能css就会变得很难看。 不就之后，商城也下来一个需求，说公司有两个多年不用的域名B和C，打算废物利用，两个都要达到直接“跳转官网”的目的。 于是我就到阿里云域名管理的那里搜索一下，发现目前官网域名后端绑定的是一个CDN，于是也把域名B和域名C做一个CNAME到这个域名，不过登陆浏览器发现域名B和域名C都反馈502。 于是我就到电子商城后端的nginx.conf里查看，确认server_name字段没有写错，然后把域名B和域名C的CNAME直接改成了CDN的域名，再通过了dig确认。但是等于浏览器还是发现502。 最后找了阿里云的人了解，原来阿里云规定“一个CDN只能绑定一个域名，因为节点上没有那两个域名的配置，所以只要不符合节点上有配置文件信息的，全部502”。所以B和C是无法访问的。要解决这个问题有两招，1）把域名B和域名C直接A记录绑定CDN后面的SLB上，但是代价就是访问速度不如CDN快；2）重新购买两个CDN，都绑定SLB，然后把这两个CDN分别绑定到域名B和域名C上，代价是多收一点流量费…]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>CDN</tag>
        <tag>网站技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[screen的用法]]></title>
    <url>%2F2017%2F12%2F21%2Fscreen%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[很多时候在Linux要后台执行程序，都是使用“&amp;”，或者是nohup，不过这两个更多应用于临时的脚本。一个比较高科技的方法就是使用screen。 安装screen的方法很简单：yum install -y screen。 如果新建一个screen，就输入screen -S name，这样会新开一个窗口，然后执行命令。比如我要启动django，那么就输入python manage.py runserver 0.0.0.0:9000即可。 这个重开一个窗口，列出所有screen进程，就这样： [root@docker ~]# screen -ls There are screens on: 3029.xiedi (Attached) 如果想链接上之前那个django，执行命令screen -r 3029即可。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>其他软件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pictest]]></title>
    <url>%2F2017%2F12%2F13%2Fpictest%2F</url>
    <content type="text"><![CDATA[这是一个我用来测试图片上传的文章 啊！五环，你比四环多一环！啊！五环，你比六环少一环！终于有一天，你会修到七环]]></content>
      <categories>
        <category>用来保护视力的图片</category>
      </categories>
      <tags>
        <tag>美女</tag>
        <tag>图片</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这里记录的不只有代码，还有生活和思想！]]></title>
    <url>%2F2017%2F12%2F13%2F%E8%BF%99%E9%87%8C%E8%AE%B0%E5%BD%95%E7%9A%84%E4%B8%8D%E5%8F%AA%E6%9C%89%E4%BB%A3%E7%A0%81%EF%BC%8C%E8%BF%98%E6%9C%89%E7%94%9F%E6%B4%BB%E5%92%8C%E6%80%9D%E6%83%B3%EF%BC%81%2F</url>
    <content type="text"><![CDATA[var ap = new APlayer({ element: document.getElementById("aplayer1"), narrow: false, autoplay: false, showlrc: 0, music: { title: "一个人去旅行", author: "陈升", url: "http://p1x3hd2at.bkt.clouddn.com/一个人去旅行.mp3", pic: "http://p1x3hd2at.bkt.clouddn.com/五十米深蓝.jpg", } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 你说要一个人去旅行 但是归期却没有约定 亚得里亚海边风中的吉他声你说你带着苍白的回忆 却谢谢能与我相逢 我怕你在异乡夜里孤独醒来要拒绝两人单调的生活 想寻找自由 迷信了爱情 就迷失了我自己你就这样 离开吧 抛弃吧 他乡的旅人你就那样 离开吧 抛弃吧 一个人生活 你说要一个人去旅行 眼里藏着一朵乌云 知道你藏不住秘密 天空就会飘着雨你说你带着一本日记 却不想再拥有回忆 我怕你在异乡孤独的醒来要拒绝两人单调的生活 不想再随波逐流 迷信了孤独 就软弱的抛弃了我的等待 你就这样 离开吧 抛弃吧 他乡的旅人你就那样 离开吧 抛弃吧 让我孤独生活 你就这样 离开吧 抛弃我 孤独的旅人你就这样 离开我 抛弃我 让我孤独生活 我想要一个人去旅行 但愿归期会有约定 每个人都在问我 是否可以找到自由的你亚得里亚海边他乡的人和风中的吉他声 我怕你一个人在异乡孤独醒来我会带着你回来]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>音乐</tag>
        <tag>感悟</tag>
      </tags>
  </entry>
</search>
