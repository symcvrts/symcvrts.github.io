<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[一个批量部署脚本]]></title>
    <url>%2F2019%2F04%2F12%2F%E4%B8%80%E4%B8%AA%E6%89%B9%E9%87%8F%E9%83%A8%E7%BD%B2%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[]]></content>
  </entry>
  <entry>
    <title><![CDATA[将Redis监控细节添加到Django页面里]]></title>
    <url>%2F2019%2F04%2F09%2F%E5%B0%86redis%E7%9B%91%E6%8E%A7%E7%BB%86%E8%8A%82%E6%B7%BB%E5%8A%A0%E5%88%B0Django%E9%A1%B5%E9%9D%A2%E9%87%8C%2F</url>
    <content type="text"><![CDATA[Redis的监控一直是重点中的重点，市面上开源的Redis界面监控也不在少数了，但是自己做一个监控页面更加有针对性，而且更加有逼格。我们主要监控redis除了常规的cpu、内存、Key数之外，还有如下几个方面：阻塞客户端数量、使用内存峰值、内存碎片率、缓存命中率、失效KEY、慢日志和连接数。这里挑几个简单的说。 获取连接细节情况首先先来搞定“获取redis的连接细节”。在django里先做一个model,如下： 123456789class redisconnection(models.Model): rank = models.CharField(verbose_name='排名',max_length=10) num = models.CharField(verbose_name='服务器连接数',max_length=50) ip = models.GenericIPAddressField(verbose_name='服务器内网IP地址') date = models.DateField(auto_now_add=True) time = models.TimeField(auto_now_add=False, auto_now=True) def __unicode__(self): return self.host 可见我们只是需要排名、具体的IP、当时有多少连接以及当时时间这4个指标而已。 我承认我道行不够，捅咕两个小时也没有研究出来怎么用python2.7去获取redis的连接数细节，于是乎就用shell写了一个简单的脚本。如下： 1234567891011#!/bin/bash#获取当前连接最多的前五个IP地址和数量到Mysqlredis-cli -h redis地址 -p 6379 -a redis密码 client list | awk &apos;&#123;print $2&#125;&apos;| cut -d = -f 2| cut -d : -f 1 | sort | uniq -c | sort -rn |head -5 &gt; clientip.txtMYSQL=&quot;mysql -h数据库地址 -u数据库账号 -p数据库密码 --default-character-set=utf8 -A -N&quot;cat -n clientip.txt | while read rank num IPdo echo $&#123;num&#125; echo $&#123;IP&#125; sql=&quot;insert into databases.table(num,ip,date,time,rank) values(&apos;$&#123;num&#125;&apos;,&apos;$&#123;IP&#125;&apos;,curdate(),now(),&apos;$&#123;rank&#125;&apos;);&quot; $MYSQL -e &quot;$sql&quot;done 这里先简单解释一下：1.client list是查看redis连接细节的命令，然后通过awk获取第二列，再分别通过“=”和“，”来分割两次，排序去重统计个数最后取出前五名输入到clientip.txt这个文件里；2.连接mysql，-A的含义是不去预读全部数据表信息；-N的含义是获取数据信息省去列名称;3.使用cat -n自动获取到行号当做排名，循环赋值；4.curdate(),now()这俩是sql，但是需要shell里正确使用sql就要-e; 执行效果如下： 剩下的内容就是在views.py里拿值然后通过render反馈到前端页面，这里不说了。 如果使用了Redis中间件，那么就不能统计redis的client list了，而是到中间件服务器里，使用ss -art | awk &#39;{print $5}&#39; | grep &#39;^[1-9]&#39; | cut -d : -f 1 | sort | uniq -dc | sort -nr获取详细连接情况。 获取缓存命中率缓存命中率是info Stats命令里keyspace_hits/(keyspace_hits+keyspace_misses)的值，比如我这个redis： 这个值正常来说应该是90%以上，如果缓存命中率过低，那么要排查对缓存的用法是否有问题，我这个就很不合格… 获取缓存命中率的shell脚本如下： 1234567891011#!/bin/bash#获取当前缓存命中率到Mysqlhit=$(redis-cli -h redis地址 -p 6379 -a redis密码 info Stats | grep "keyspace_hits" | cut -d : -f 2) miss=$(redis-cli -h redis地址 -p 6379 -a redis密码 info Stats | grep "keyspace_misses" | cut -d : -f 2)HIT=$(echo $hit | tr -d '\r')MISS=$(echo $miss | tr -d '\r')total=$(expr $HIT + $MISS)percent=$(awk 'BEGIN&#123;printf "%.2f\n",'$HIT'/'$total'&#125;')MYSQL="mysql -h数据库地址 -u数据库账号 -p数据库密码 --default-character-set=utf8 -A -N"sql="insert into databases.table(num,date,time) values('$&#123;percent&#125;',curdate(),now());"$MYSQL -e "$sql" 这里要注意！hit和miss结果是自带”\r”的，所以要去掉。不然的话就会有expr: non-numeric argument。而且如果用bc命令获取除法结果的话，低于1的值是不会出现整数0，即如果得到的结果是0.97，那么只会显示.97，至于如何出现这个0，可以去看 http://www.361way.com/linux-bc-point-zero/4960.html 。 现在已经通过脚本取到了值，那么剩下的内容就是django去弄一个model，之后在views.py里拿值然后通过render反馈到前端页面，这里不说了。执行效果如下： 其他补充redis的慢日志操作也是我们比较关注的一点。一般来说我们使用slowlog len来获取当前慢日志的总条数，而是用slowlog reset对其进行清理工作。获取它的shell脚本跟上面两个大同小异，这里也略过不表了。 如果要是想获取redis的cpu和内存，最好的方法通过zabbix拿值，CPU使用率的item是：system.cpu.util[]，内存使用率的item是：vm.memory.size[pavailable]。 整个页面做完的效果如下： 参考资料https://segmentfault.com/a/1190000009915519https://blog.csdn.net/secretx/article/details/73498148http://www.cnblogs.com/iforever/p/4459857.htmlhttps://morrisjs.github.io/morris.js/lines.html]]></content>
      <categories>
        <category>监控与技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>django</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache配置Https]]></title>
    <url>%2F2019%2F04%2F04%2FGitlab%E9%85%8D%E7%BD%AEHttps%2F</url>
    <content type="text"><![CDATA[Httpd配置https事前说明，我的Httpd版本是：Server version: Apache/2.4.6 (CentOS) 首先先准备https证书文件，把他们传递到apache服务器的/etc/httpd/ssl文件夹里，然后安装yum install -y mod_ssl openssl，安装完毕之后，发现/etc/httpd/conf.d文件夹下多了一个ssl.conf，出于安全先备份一份，然后修改ssl.conf的如下几个地方： 12345未涉及的字段保留原样DocumentRoot "/var/www/html" #网站的目录ServerName 自己的域名SSLCertificateFile /etc/httpd/ssl/imoulife.crt #秘钥crt文件及路径SSLCertificateKeyFile /etc/httpd/ssl/imoulife.key #秘钥key文件及路径 保存退出，重启httpd即可生效。注意！因为一个ip只能绑一个SSL，因此这里就算在写了两份&lt;VirtualHost *:443&gt;...&lt;/VirtualHost&gt;，也还是会读取第一个SSL。 Httpd配置http跳转https如果想要达到http跳转https的话，还是在ssl文件里的最下面追加这段内容： 12345&lt;VirtualHost *:80&gt; RewriteEngine on RewriteCond %&#123;SERVER_PORT&#125; !^443$ RewriteRule ^/?(.*)$ https://%&#123;SERVER_NAME&#125;%&#123;REQUEST_URI&#125; [L,R]&lt;/VirtualHost&gt; 如果只是单url跳转，比如http://test.imoulife.com/login跳转到https://test.imoulife.com/login，其他的域名依旧是http。那么就把最后一句改成:RewriteRule ^/logon.do$ https://%{SERVER_NAME}%{REQUEST_URI} [L,R]，重启httpd就生效。 httpd配置ip白名单设置了https不能说很安全，我们还需要设置IP白名单才能让WEB界面更加放心。由于我这个httpd主要是给zabbix使用的，所以就拿访问zabbix的IP白名单为例。 首先打开/etc/httpd/conf.d/zabbix.conf，修改如下地方： 1234567891011Alias /zabbix /usr/share/zabbix&lt;Directory "/usr/share/zabbix"&gt; Options FollowSymLinks AllowOverride None #Require all granted #这句话是任何人都可以访问的意思&lt;RequireAll&gt; Require ip 192.168.1 #准许192.168.1开头的IP地址的访问 Require ip 192.168.1.104 192.168.1.205 #准许固定IP地址访问 Require ip 10.1.0.0/16 #网络/子网掩码的访问 &lt;/RequireAll&gt; 保存退出，重启httpd即可。 Gitlab配置Https我的gitlab是容器做的，其实无论容器还是非容器其实配置都是一样的。 首先先开放443端口给相应的IP，然后进入容器，在/etc/gitlab/下先创建一个ssl文件夹，里面放入https证书，如图： 放好证书文件之后，返回上一级目录，修改一下gitlab.rb文件： 12345external_url 'https的域名'nginx['redirect_http_to_https'] = truenginx['redirect_http_to_https_port'] = 80nginx['ssl_certificate'] = "上面https证书的路径/crt文件名称"nginx['ssl_certificate_key'] = "上面https证书的路径/key文件名称" 然后执行gitlab-ctl reconfigure更新配置，完事之后找到nginx的gitlab配置文件gitlab-http.conf，发现由于更新了配置，所以里面已经生成好了一份新的配置文件，如下： 12345678910111213141516server &#123; listen *:443 ssl http2; server_name https的域名; server_tokens off; client_max_body_size 0; ssl on; ssl_certificate 上面https证书的路径/crt文件名称; ssl_certificate_key 上面https证书的路径/key文件名称; ............................. #剩余的信息省略了 &#125; server&#123;listen*:80;server_name https的域名;rewrite^(.*)$https://$host$1permanent;&#125; 确认各个信息无误之后，退出执行gitlab-ctl restart即可。 参考资料http://tonylit.me/2016/02/29/apache_http%E8%B7%B3%E8%BD%AC/http://zhizhi.tangliangdong.me/2017/10/12/2017-10-12-http-to-https/https://blog.mallux.me/2017/02/27/gitlab/https://blog.csdn.net/leshami/article/details/78521031]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Gitlab</tag>
        <tag>httpd</tag>
        <tag>白名单</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix-api获取值在Django页面展示]]></title>
    <url>%2F2019%2F04%2F02%2FZabbix-api%E8%8E%B7%E5%8F%96%E5%80%BC%E5%9C%A8Django%E9%A1%B5%E9%9D%A2%E5%B1%95%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[背景交代私有云的同学要求把几个涉及录像的模块带宽每小时从zabbix获取一次，然后在django页面展示出来。由于django跟zabbix并不在一个服务器，那么就采取“zabbix上跑脚本，脚本将实时的带宽值存储到某个数据库里，然后django去数据库取值并且展示”这样的思路来解决问题。 python3 + Django 2.1.1APP：accessgateway 建立数据库首先需要先建立数据模型，在app下的models.py里添加如下： 12345678910#这里是数据模型class lbmrs(models.Model): host = models.CharField(verbose_name='MRS服务器名称',max_length=50) inbandwidth = models.FloatField(verbose_name='入网带宽') outbandwidth = models.FloatField(verbose_name='出网带宽') date = models.DateField(auto_now_add=True) time = models.TimeField(auto_now_add=False, auto_now=True) #获取录入时间，而且有新录入就会覆盖 def __unicode__(self): return self.host admin.py里添加对应的值： 12345from .models import lbmrsclass lbmrsAdmin(admin.ModelAdmin): list_display = ('host','inbandwidth','outbandwidth','date','time')admin.site.register(lbmrs,lbmrsAdmin) 注意!由于我们使用了TimeField，所以要修改一下setting.py: 12TIME_ZONE = 'Asia/Shanghai'USE_TZ = False 这样就能输入准确的时间，不然就是UTC时间。然后就是python manage.py makemigrations和python manage.py migrate，如果在python manage.py migrate的时候出现如下MySQL Strict Mode is not set for database connection &#39;default&#39;的提示，如图： 这提示其实不重要，主要是说当前连接mysql的方式不严谨，如果要避免还是修改一下setting.py，新加一个OPTIONS: 1234567891011121314DATABASES = &#123; 'default': &#123;# 'ENGINE': 'django.db.backends.sqlite3',# 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), 'ENGINE': 'django.db.backends.mysql', 'NAME': '这里是database名', 'USER': '这里是用户名', 'PASSWORD': '这里是密码', 'HOST': '这里是数据库地址', 'OPTIONS': &#123; "init_command": "SET sql_mode='STRICT_TRANS_TABLES'", &#125; &#125;&#125; 数据库方面完成，在后台界面里随便添加一个值，如下： 然后在mysql命令行看一下效果： 将值录入数据库由于我使用的是阿里云数据库，所以要现在阿里云数据库里对django服务器和zabbix服务器同时开放白名单。 使用zabbix-api获取zabbix数值的脚本以前在 https://rorschachchan.github.io/2019/01/09/%E4%BD%BF%E7%94%A8Zabbix%E7%9A%84python-api%E5%8E%BB%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E7%9B%91%E6%8E%A7%E5%80%BC/ 里面说过了，要把获取的值保存到mysql里，只需要添加下面的代码： 12345678#将值保存到mysqlconnection = pymysql.connect(host='Mysql地址', port=3306, user='账号', passwd='密码', db='databases名称')cursor = connection.cursor() # 创建游标# 执行SQL,插入多行数据并返回受影响行数sql = cursor.executemany("insert into accessgateway_ldmrs (host,inbandwidth,outbandwidth,time,date) values (%s,%s,%s,now(),curdate()))",[("第一台机器",firstin,firstout),("第二台机器",secondin,secondout),("第三台机器",thirdin,thirdout), ("第四台机器",fourthin,fourthout),("第五台机器",fivethin,fivethout)])connection.commit() # 提交,不然无法保存修改cursor.close() # 关闭游标connection.close() # 关闭连接 依旧是每小时执行一次，看见mysql能成功存储到值，如图： 将数据库的值反馈到页面上数据库现在已经取到了值，那么思路就很简单了：在views.py里设定变量，让变量可以去数据库里通过objects.values取到相应的值，然后再把这个变量通过render反应到前端页面。url.py很简单： 12#前略path(r'lb_mrs_flow.html',views.lb_mrs_flow,name="lb_mrs_flow"), 这次需求要取到以下几个值，分别是“此时的带宽”，“前一小时的带宽”，“昨天此时的带宽”。在数据库里我们也设定了date和time这两个列，所以通过限制条件就能获取到对应的值了！views.py如下： 123456789101112131415import datetime#展示服务器1.1.1.1当前流量@login_required #需要登陆才能访问def lb_mrs_flow(request): today = str(datetime.date.today()) #获取当前日期 yesterday = str(datetime.date.today() - datetime.timedelta(days=1)) #获取昨天日期 hour = str(datetime.datetime.now().hour) #获取现在小时 lasthour = str((datetime.datetime.now() - datetime.timedelta(hours=1)).hour) #获取前一小时 print (today,yesterday,hour) firstin = lbmrs.objects.values("inbandwidth").filter(host='1.1.1.1',date=today,time__istartswith=hour)) #当前值 firstin_last = lbmrs.objects.values("inbandwidth").filter(host='1.1.1.1',date=today,time__istartswith=lasthour) #前一个小时值 firstin_yes = lbmrs.objects.values("inbandwidth").filter(host='1.1.1.1',date=yesterday,time__istartswith=hour) #昨天的值 print (firstin，firstin_last，firstin_yes) return render(request, 'lb_mrs_flow.html',&#123;'firstin':firstin,'firstin_last':firstin_last,'firstin_yes':firstin_yes,&#125;) #传递到前端 数据库里我们只需要inbandwidth这一列的值，所以这里就不用get()方法了，改用vales()方法，同时搭配filter()添加条件筛选。但是这样获取到的结果是一个QuerySet（查询集），元素为字典，如果要获得里面具体的值，那么就是QuerySet[0][&#39;inbandwidth&#39;],用上面的firstin为例子，如果想要得到具体的值就要改成下面： 1firstin = lbmrs.objects.values("inbandwidth").filter(host='172.1.1.19',date=today,time__istartswith=hour)[0]['inbandwidth'] value和value_list都可以获取指定的字段，但是value_list获得是元素是元组。value_list和value返回的并不是真正的列表或字典，通俗地说，就是用的时候才真正的去数据库查，如果查询后没有使用，在数据库更新后再使用，得到的是新内容。 然后就是前端html文件lb_mrs_flow.html里写一个简单的表格，前端内容就略过不表了，直接来看结果： 可以看到如果value()方法得不到值的话，返回一个&lt;QuerySet []&gt;，如果是get()的话，返回就是一个错误，所以从友好度来说，还是value()更佳。 参考资料https://blog.csdn.net/geerniya/article/details/78549182http://yshblog.com/blog/157https://www.kancloud.cn/hiyang/py/348229 （跨表取字段的方法）]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将Gateone添加到django，实现WEB的ssh链接]]></title>
    <url>%2F2019%2F04%2F01%2F%E5%B0%86Gateone%E6%B7%BB%E5%8A%A0%E5%88%B0django%EF%BC%8C%E5%AE%9E%E7%8E%B0WEB%E7%9A%84ssh%E9%93%BE%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[背景交代python3 + django2.1Django project:accessgateway gateone的安装Gateone是一个web界面的交互工具，很多堡垒机都会使用到它，它的生命力很长久也很经得住考验（不过最近github上已经不再对它有更新了）。安装方法如下： 12345pip install --upgrade setuptoolspip install tornado==4.3pip install Pillowdocker pull liftoff/gateone #拉取镜像，个人推荐把原有的镜像修改一下，添加vim等工具docker run -t -p 8008:8000 -h GATEONE --name gateone liftoff/gateone gateone #创建容器 这样我们就创建了一个叫gateone的容器，宿主机端口是8008，此时通过浏览器访问https://IP：8008，就会看到效果： 默认的gateone是https访问，如果要改成http访问。那么就要修改容器里的/etc/gateone/conf.d文件夹下的10server.conf，修改如下两处： 12"disable_ssl": true, #改成http方式"origins": ["localhost:8000", "127.0.0.1:8000", "594f279c70b0:8000", "django的外网IP:django端口"], #添加django的地址和端口 然后重启容器，改用http://IP：8008方式去访问，发现已经改成HTTP协议了。 gateone的配置现在这个gateone容器需要已经指定准许django来访问，但是还要生成一个api，让django通过api来访问。在容器里执行gateone --new_api_key，发现在/etc/gateone/conf.d文件夹下多了一个30api_keys.conf： 然后修改60docker.conf，把&quot;auth&quot;: &quot;none&quot;,改成&quot;auth&quot;: &quot;api&quot;,保存之后，此时如果重启容器，发现web界面已经不能访问了，会出现unauthenticated的提示，如图： gateone集成到djangogateone部分暂时告于段落，现在配置Django，首先是views.py，注意！python2与python3有些地方不同，我这里是python3版本： 12345678910111213141516171819202122232425262728293031323334import time,hmac,hashlib,json#web交互界面gateonedef gateone(request): id = 1 #这里暂时写死只要id为1的服务器 svr = server.objects.get(id = id) ip = svr.outIP port = svr.port username = svr.username #写死端口和用户名 return render(request,'aggateone.html',locals()) #返回aggateone.html页面#gateone认证def create_signature(secret,*parts): hash = hmac.new(secret, digestmod=hashlib.sha1) for part in parts: hash.update(str(part).encode("utf-8")) return hash.hexdigest()def get_auth_obj(request): # 安装gateone的服务器以及端口. gateone_server = 'http://121.41.37.251:8008' #本地gateone的访问地址，注意http格式 # 生成的api_key 和secret api_key = 'OGQxZGM5OGM1MGNlNDZkNmEwMTNmM2IyY2NlMGZlNjA3Z' #这里是30api_keys.conf文件里的key secret = b'MDIzOWQyN2Y2MmU0NDdhMWIwN2Q3MjIzODU1MGFjYWVkY' #这里是30api_keys.conf文件里的secret authobj = &#123; 'api_key':api_key, 'upn':'gateone', 'timestamp':str(int(time.time() * 1000)), 'signature_method':'HMAC-SHA1', 'api_version':'1.2' &#125; authobj['signature'] = create_signature(secret,authobj['api_key'],authobj['upn'],authobj['timestamp']) auth_info_and_server = &#123;'url':gateone_server,'auth':authobj&#125; return JsonResponse(auth_info_and_server) 然后新增两条路由到urls.py： 12path(r'gateone.html', views.gateone),path(r'get_auth_obj.html',views.get_auth_obj,name="get_auth_obj"), 最后就是编写前端页面aggateone.html： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&#123;% extends 'agbase.html' %&#125;&#123;% load staticfiles %&#125;&#123;% block title %&#125;Gateone远程连接&#123;% endblock %&#125;&#123;% block css %&#125;&lt;script src = "/static/jquery-3.3.1.min.js"&gt;&lt;/script&gt;&lt;script src = "/static/gateone/gateone.js"&gt;&lt;/script&gt; &lt;!-- 这里需要手动复制一下gateone.js文件到django的静态文件夹里 --&gt;&#123;% endblock %&#125;&#123;% block content %&#125;&lt;script&gt;$(function () &#123; &lt;!--添加参数--&gt; var ip = '&#123;&#123; ip &#125;&#125;'; var user = '&#123;&#123; username &#125;&#125;'; var port = '&#123;&#123; port &#125;&#125;'; var ssh_url = 'ssh://'+user+'@'+ip+':'+port; //请求认证信息 &lt;!--发起认证请求--&gt; $.ajax(&#123; url:'&#123;% url 'get_auth_obj' %&#125;', type:'GET', dataType:'json', success:function (data) &#123; var auth_message = data.auth; var auth_url = data.url; GateOne.init(&#123; auth:auth_message, url:auth_url, theme:'solarized', goDiv:'#gateone', disableTermTransitions:'true', autoConnectURL:ssh_url &#125;); &#125; &#125;); &lt;!--状态记录--&gt; GateOne.Base.superSandbox("GateOne.SomePlugin", ["GateOne", "GateOne.Net", "GateOne.Terminal.Input", "GateOne.Terminal"], function(window, undefined) &#123; var location = ip; GateOne.prefs.autoConnectURL=ssh_url; GateOne.prefs.fontSize="100%"; GateOne.prefs.scrollback = 10000; // scrollback buffer up to 10,000 lines GateOne.Terminal.loadFont("Source Code Pro", "150%"); GateOne.Net.setLocation(location); &lt;!--记录登录状态--&gt; &#125;);&#125;)&lt;/script&gt;&lt;div id = "gateone_container" style = "position:relative; width: 110em; height: 55em;"&gt; &lt;div id = "gateone"&gt; &lt;/div&gt;&lt;/div&gt;&#123;% endblock %&#125; 重启django进程，浏览器打开gateone.html页面看一下效果： 可见我们已经成功的把gateone嵌入到django里了，而且自动就链接”id=1”这台服务器。大功告成，剩下的就是修改一下细节，给所有服务器一个按钮，只要点击这个按钮就会打开对应的远程链接界面。 事后补充刚才那个views.py里“gateone认证”那两个def函数上面不要加上@login_required，会出现AttributeError: &#39;bytes&#39; object has no attribute &#39;user&#39;错误： 这是因为@login_required这个装饰器首先回去判断user是否是登录状态，会从request里获取User，但是在下面的函数里并没有传递这个User，所以就会报错。如果说非要加上@login_required这个装饰器，那么就要把User传入当做第一个函数。 详情可见：https://stackoverflow.com/questions/13423022/django-str-object-has-no-attribute-user 参考资料http://blog.codecp.org/2018/03/23/Django%E5%9F%BA%E7%A1%80Gateone%E5%AE%9E%E7%8E%B0Web%E7%BB%88%E7%AB%AFSSH%E5%8A%9F%E8%83%BD/https://github.com/liftoff/GateOne/issues/257https://www.jianshu.com/p/b8123a8178de]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>gateone</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Atlas出了一个很诡异的bug]]></title>
    <url>%2F2019%2F03%2F26%2FAtlas%E5%87%BA%E4%BA%86%E4%B8%80%E4%B8%AA%E5%BE%88%E8%AF%A1%E5%BC%82%E7%9A%84bug%2F</url>
    <content type="text"><![CDATA[这几天数据库更换密码，就在原有的atlas文件基础上拷贝出来一个新文件，修改了密码，然后启动进程。但是启动之后，发现虽然端口起来了，但是atlas没有连接数据库成功，如图: 登录到atlas后台一看，竟然是双down: 可是在atlas服务器上单独直连阿里云数据库是没任何问题的，而且数据库的监控也没有任何异常。我怀疑是密码含有了atlas不识别的特殊符号，改成了纯数字和字母的组合，重新启动还是不行，这就很尴尬了，明明原来的配置文件可以启动，我就更改了密码和端口，怎么新的进程就不好使？ 于是我尝试抓包，使用tcpdump -s 0 -i any -v port 3318 and src host 100.114.3.91 -w test.pcap，结果发现3318的包少的可怜，于是我就改用tcpdump -s 0 -i any -v host 100.114.3.91 -w test2.pcap扩大了范围，然后发现包有这样的字样： 可见atlas一直以root去请求数据库，但是我这个是阿里云的RDS服务（Mysql 5.6.7)，本身是没有root的，所以就爆“User not exist”。 这就很尴尬了，为什么会突然以root身份请求数据库？莫非这是atlas的BUG？先把问题记录下来，然后慢慢解决…]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>atlas</tag>
        <tag>mysql</tag>
        <tag>读写分离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django搭配anymail去发送邮件]]></title>
    <url>%2F2019%2F03%2F22%2FDjango%E6%90%AD%E9%85%8Danymail%E5%8E%BB%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[注册mailgun账号首先登陆https://app.mailgun.com/sessions/new 里注册一个账号，填写邮件和密码点击注册，会出现这样的页面： 然后在注册的邮件会接到两个邮件，一个是API的邮件，另一个是激活账号邮件，如下： 点击激活之后，就要添加可信任邮箱，mailgun只能对这些可信任邮箱发送邮件，其他邮件就会失败，在Account里选择Authorized Recipients，然后Invite new Recipients创建新的守信邮箱，创建完毕之后，邮箱应该是Unverified的状态，如下： 点击那个Unverified的状态的邮箱，如果你的机器有装foxmail或者outlook的话，就会自动弹出来，你就可以发送一个邮件到指定的邮箱里，不久邮箱就会收到一个确认信，如下： 点击I agree即完成授信，邮箱状态也变成了绿色的Verified。 点击Domains就可以看到账号的api和domain了，如图： 至此，邮箱账号申请部分完成。 开始配置首先安装pip install django-anymail组件，并且在setting.py里添加如下内容： 12345678910111213INSTALLED_APPS = [ ... "anymail", ...]ANYMAIL = &#123; "MAILGUN_API_KEY": "这里填写API", "MAILGUN_SENDER_DOMAIN": '这里填写domain',&#125;EMAIL_BACKEND = "anymail.backends.mailgun.EmailBackend"# DEFAULT_FROM_EMAIL = "you@example.com" # if you don't already have this in settings# SERVER_EMAIL = "your-server@example.com" # ditto (default from-email for Django errors) 保存退出之后，在views.py里添加如下信息： 1234from django.core.mail import send_mail#只需一个send_mail 函数，便能发送邮件send_mail("It works!这里是标题", "This will get sent through Mailgun，这里是内容","domian的内容，即上面图片里那个mailgun.org结尾的东西", ["授信的邮箱地址"]) 保存之后，django会自动重启，就会看到邮件顺利发出去了！ 可以看出只需要一个send_mail就能发送邮件，的确比SMTP方便多了。在实际运用中，就把send_mail放到对应的函数里，然后灵活搭配标题和内容就能使用了！ 故障排错 如果出现Please activate your Mailgun account. Check your inbox or log in to your control panel to resend the activation email.，即账号没激活； 如果出现Sandbox subdomains are for test purposes only. Please add your own domain or add the address to authorized recipients in Account Settings.，即目标邮箱不是授信邮箱，需要添加到授信名单里。 参考资料https://github.com/anymail/django-anymail]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>anymail</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给Django添加登录拦截器和登录验证码]]></title>
    <url>%2F2019%2F03%2F22%2F%E7%BB%99Django%E6%B7%BB%E5%8A%A0%E7%99%BB%E5%BD%95%E6%8B%A6%E6%88%AA%E5%99%A8%E5%92%8C%E7%99%BB%E5%BD%95%E9%AA%8C%E8%AF%81%E7%A0%81%2F</url>
    <content type="text"><![CDATA[前一篇文章里写了如何做登录、登出界面，看上去效果好像很不错，但是却有一个致命的漏洞：如果有人直接在地址栏里输入对应的url，那么就可以跳过登录验证直接访问！ 这种情况我们需要做一个登录拦截器，这个拦截器的作用就是通过session来判断，如果在没有session的前提下登录网站内部url就会强制跳转到首页，让访问的人登录。 自建的登陆拦截器首先是在APP的目录里（我的project叫Kubernetes）新建一个叫middleware.py的文件，代码如下： 1234567891011121314151617from django.shortcuts import HttpResponseRedirectfrom django.utils.deprecation import MiddlewareMixin#强制登录class SimpleMiddleware(MiddlewareMixin): def process_request(self, request): if request.path != '' and request.path != '/login/': #判断请求的地址不是首页和/login/ if request.session.get('user',None): #如果session里不存在 pass else: return HttpResponseRedirect('/login/') #自动跳回到登录页面#多次访问IP拉黑class BlockedIpMiddleware(object): def process_request(self, request): if request.META['REMOTE_ADDR'] in getattr(settings, "BLOCKED_IPS", []): #如果有IP短时间内多次访问 return http.HttpResponseForbidden('&lt;h1&gt;Forbidden&lt;/h1&gt;') #针对此IP给予403 然后在APP的目录里（我的project叫Kubernetes）的setting.py里把这两个中间件加进去。如下： 12345678910MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', 'Kubernetes.middleware.SimpleMiddleware', #这个就是新加的] 系统自动重启之后，来验证一下效果，是否在不登录的前提下成功拦截直接访问的url。 Django自带的登陆拦截器上面那个方法逻辑上来说比较简单，能实现功能但是并不是很强力，Django也自带一个“强制登录”的功能，效果比那个强一丢丢。 首先我们先把APP目录里setting.py刚刚新加的&#39;Kubernetes.middleware.SimpleMiddleware&#39;注释掉。在文件末尾添加一句： 12#登录路径LOGIN_URL = '/login/' 然后返回到views.py，给需要登陆才能访问的页面添加一个装饰器： 1234567891011from django.contrib.auth.decorators import login_required@login_required #这个页面需要登陆def tt(request): name = ['james','wade','bosh','yaoming'] return render_to_response('test111.html',&#123;'names':name&#125;)def ttt(request): #这个页面就不需要了，公共读 cpu = 9.66 mem = 66.6 disk = 16.88 return render_to_response('test222.html',&#123;'CPU':cpu,'MEMORY':mem,'DISKUSED':disk&#125;) 我在views.py里设定，访问tt这个函数（urls.py里配置的域名是/k8s/test111)的时候需要强制登陆,访问ttt这个函数（urls.py里配置的域名是/k8s/test222）就可以直接打开。系统重启django之后，我们试一下效果： 可见当访问到/k8s/test111的时候，浏览器会自动跳转到/login/?next=/k8s/test111/ 让你登录，登陆完毕之后才能顺利访问。而/k8s/test222就可以直接访问了。这个方法就是可以更加对受保护的网页有针对性配置，而不是上一个方法统一都跳转到登录面去。 测试的时候出现TypeError: object() takes no parameters报错，看一下是否是post方法请求的，因为get方法是产生一个tcp包，而post是两个。 登录验证码为了防止机器人暴力破解密码，我们往往增加验证码来阻挡一下。市面上开源的比较高级的验证码是google recaptcha2，但是由于国内政策，大陆内的网站往往打不开这个界面。所以用Django Simple Captcha这个比较大众的验证码方式。 首先pip install django-simple-captha，然后在setting.py里把captha加入到INSTALL_APPS里。 然后是执行python manage.py makemigrations和python manage.pymigrate，再打开url.py，添加一句 123456789101112from django.contrib import adminfrom django.urls import path,includefrom . import viewsurlpatterns = [ path('',views.login,name='login'), #登录页 path('homepage.html',views.home,name='home'), #首页 path('admin/',admin.site.urls), path('captcha/',include('captcha.urls')), #这句是新加的，验证码专用 path('k8s/',include('createyaml.urls')), #工具平台分支 path('ag/',include('accessgateway.urls')), #堡垒机分支] 修改一下views.py，如下： 12345678910111213141516171819202122232425262728293031from django.contrib import authfrom django import formsfrom captcha.fields import CaptchaFieldclass CaptchaForm(forms.Form): #引入一个类 captcha = CaptchaField()#登陆def login(request): if request.POST: form = CaptchaForm(request.POST) #将类实例化 username = request.POST.get('username', '') password = request.POST.get('password', '') user = auth.authenticate(username=username, password=password) if form.is_valid(): #如果form合法 human = True #判断是人操作，而不是机器人 if user is not None: auth.login(request, user) # 登录 #request.session['user'] = username # 记录session信息 response = HttpResponseRedirect('homepage.html') response.set_cookie('username',username,3600) #将username写入cookie,超时时间是10分钟 return response else: return render(request,'index.html', &#123;'error': '账号密码有误，请联系管理员!','login_form':form&#125;) else: return render(request,'index.html', &#123;'error': '验证码有误，请重新输入!','login_form':form&#125;) else: form = CaptchaTestForm() # 否者要求重新输入 return render_to_response('index.html',&#123;'login_form':form&#125;)#其他部分略 最后修改对应的html页面，在对应的地方加入即可： 1234&lt;div&gt; &lt;font color='yellow'&gt;验证码(看不清请刷新页面):&lt;/font&gt; &#123;&#123; login_form.captcha &#125;&#125;&lt;/div&gt; 保存之后，系统重新启动django，在浏览器输入网址，就能看到效果了： 这个页面还没有完美，应该再加入一个ajax，实现“点击验证码，刷新页面”的功能就更完美了。 登录验证码的方式还有很多，除了这个django-simple-captha，还有像https://pypi.org/project/django_click_captcha/ 点击倒字的登录方法，甚至还有手机短信的登陆方法，这些高级的方法以后再研究吧。 参考资料https://code.ziqiangxuetang.com/django/django-middleware.htmlhttps://www.jianshu.com/p/1a95808faed9https://blog.csdn.net/xxm524/article/details/48370337http://www.calmkart.com/?p=332https://fanquqi.github.io/2018/03/30/Django%E7%99%BB%E5%BD%95%E9%AA%8C%E8%AF%81/https://blog.csdn.net/teavamc/article/details/77566781https://blog.51cto.com/syklinux/2052484]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>url拦截</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给Django添加用户登录登出界面]]></title>
    <url>%2F2019%2F03%2F21%2F%E7%BB%99Django%E6%B7%BB%E5%8A%A0%E7%94%A8%E6%88%B7%E7%99%BB%E5%BD%95%E9%A1%B5%E9%9D%A2%E3%80%81%E9%AA%8C%E8%AF%81%E7%A0%81%E5%92%8C%E6%8B%A6%E6%88%AA%E5%99%A8%2F</url>
    <content type="text"><![CDATA[我的Django运维平台很不幸的被公司安全系统扫描出来了，给了我一个超级大警告。主要也怪我当时偷懒，只是在SLB层面做了IP访问限制但是没有给服务器nginx里做白名单，所以网站是可以通过“IP地址加端口”访问的。恰巧ping里面用了一个AES加解密的脚本，那个算法有问题，可以获取当前用户的权限，我特么的还是直接用root启动的nginx，而且这个机器里面还有ansible，当然后果很严重。 出了问题，不能消极对待而要积极解决，于是要先给网站做一个完善的用户登录鉴权系统。再一次背景介绍： python：3.6.5 Django：2.1.1 Project：Kubernetes，文件夹路径就是/django/Kubernetes/ App：createyaml，文件夹路径就是/django/Kubernetes/createyaml 实现用户登录鉴权首先，先编写一个index.html的页面做登录界面，如下： 12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;请先登录&lt;/title&gt; &lt;link rel="stylesheet" href="/static/bootstrap-3.3.7/css/bootstrap.min.css"&gt; #引入css样式 &lt;link rel="icon" href="/static/pic/batman.ico" type="image/x-icon"&gt; #引入一个标签图 &lt;/head&gt; &lt;body background="/static/pic/easyplane.jpg"&gt; #背景图片设置 &lt;div style="margin-top: 200px"&gt; &lt;div style="text-align:center;"&gt; &lt;font color='brown'&gt;&lt;h1&gt;请输入您的账号密码&lt;/h1&gt;&lt;/font&gt; &lt;div&gt; &lt;div&gt; &lt;form class="ui form" method="post" action=""&gt; &lt;div class="field"&gt; &lt;input type="text" name="username" placeholder="username"&gt;&lt;br&gt; &lt;/div&gt; &lt;div class="field"&gt; &lt;input type="password" name="password" placeholder="password"&gt;&lt;br&gt; &lt;/div&gt; &lt;font color=red&gt;&#123;&#123; error &#125;&#125;&lt;/font&gt;&lt;br&gt; #登录错误红色表示 &lt;button class="btn btn-default" type="submit"&gt;登陆&lt;/button&gt; &#123;% csrf_token %&#125; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 效果如下： 在Kubernetes这个app文件夹里的urls.py里给这个鉴权网站添加一个路由： 12345678910from django.contrib import adminfrom django.urls import path,includefrom . import viewsurlpatterns = [ path('',views.login_action,name='login'), #首页就是login_action的函数 path('homepage.html',views.home,name='home'), #将原来的首页改成叫homepage.html path('admin/', admin.site.urls), ...其余省略 ] 在同级的views.py里编写login_action函数，如下： 123456789101112131415161718192021222324from django.shortcuts import render,render_to_responsefrom django.http import HttpResponse,HttpResponseRedirectfrom django.contrib import auth#登陆def login_action(request): if request.method == 'POST': #通过post形式获取，get的话会在地址栏里看到账号密码 username = request.POST.get('username', '') password = request.POST.get('password', '') user = auth.authenticate(username=username, password=password) #使用django自带方式鉴权 if user is not None: auth.login(request, user) # 登录 request.session['user'] = username # 将session信息记录到浏览器 response = HttpResponseRedirect('homepage.html') #鉴权OK就跳转到homepage.html return response else: return render(request,'index.html', &#123;'error': '账号密码有误，请联系管理员!'&#125;) else: return render(request,'index.html')#首页def home(request): context = &#123;&#125; return render_to_response('homepage.html',context) 登陆的用户/密码就是django后台的账号/密码，可以用superuser来登陆。保存文件之后，系统会重启django，查看效果如图： render和render_to_response的区别上面的login_action函数里，用了render和render_to_response，如果只用render_to_response，同时把所有的render改成render_to_response，那么在访问首页的时候就会出现TemplateDoesNotExist at /这样的错误： 明明他俩都是用来展示模板页面的。为什么会有模板不存在这样？原因是render_to_response()的第一个参数必须是要使用的模板名称。如果要给定第二个参数，那么该参数必须是为该模板创建Context时所使用的字典。如果不提供第二个参数，render_to_response()使用一个空字典。而render第一个参数可以是request。 所以如果都要用render_to_response，那么就要改成如下： 1234else: return render_to_response('index.html', &#123;'error': '账号密码有误，请联系管理员!'&#125;，context_instance=RequestContext(request)) else: return render_to_response('index.html') 但是这样的话，可能在登录的时候就会有csrf的错误，需要把csrf去掉。 实现登出功能有了登录还得有登出，还是老套路，先编写路由如下： 1path(r'logout/', views.logout,name="logout"), 然后对应去views.py里写logout这个函数： 123456from django.http import HttpResponseRedirectfrom django.contrib import auth #引入django默认的auth功能#注销def logout(request): auth.logout(request) return HttpResponseRedirect('/login') #跳转到登录页/login 然后就是在首页里添加一个登出的链接，链接指向就是/logout/。测试一下效果： 参考资料http://www.nowamagic.net/academy/detail/1318431]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>认证鉴权</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[较深入的理解Pod下的"多个容器"定义]]></title>
    <url>%2F2019%2F03%2F19%2F%E8%BE%83%E6%B7%B1%E5%85%A5%E7%9A%84%E7%90%86%E8%A7%A3Pod%E4%B8%8B%E7%9A%84%E5%A4%9A%E4%B8%AA%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[众所周知，k8s能调度的最小单元就是pod，但是pod里面是可以有多个docker容器的。但是pod和docker之间到底一种什么关系？还是需要实际的操作来更加直白的理解。 首先，先写了一个test.yaml用来启动Pod： 1234567891011121314151617181920212223242526272829303132333435363738394041apiVersion: v1 #这里注意版本号kind: Pod #注意这里的大小写metadata: name: nginx-greenbook labels: app: testspec: volumes: - name: test emptyDir: &#123;&#125; containers: - name: nginx image: nginx ports: - containerPort: 80 volumeMounts: - name: test #这里必须要跟Volumes的名称一致，都是test mountPath: /usr/share/nginx/html - name: debian1 image: debian volumeMounts: - name: test mountPath: /html command: ["/bin/sh","-c"] args: - while true; do date &gt;&gt; /html/index.html; sleep 1; done - name: debian2 #每一个容器的名称不能一样 image: debian volumeMounts: - name: test mountPath: /html command: ["/bin/sh","-c"] args: - while true; do echo "woxcwy" &gt;&gt; /html/index.html; sleep 2; done restartPolicy: Never #死了就死了 这个yaml主要是建立了一个存储卷叫html，它默认类型是emptyDir。这意味着当一个POD被分配到一个节点时，卷先被创建，并只要Pod在节点上运行时，这个卷仍存在（node重启的话，卷内容丢失，所以它只能做一个临时行的存储，如果想要持久化存储请使用hostPath）。第一容器运行nginx的服务器并将共享卷挂载到目录/usr/share/Nginx/html。第二容器使用Debian的镜像，并将共享卷挂载到目录/html，每一秒输入当前时间。第三个容器同理，每两秒输入一些字符串。 然后kubectl create -f test.yaml --record创建这个pod，然后使用docker ps -a就能看到生成了四个docker—分别是pod的三个容器和一个pause容器。使用kubectl exec -it pod名 -c 容器名 /bin/bash进入nginx的容器，会发现里面的/usr/share/nginx/html/index.html果然按照我们的要求在不断的输出日期和字符串。可见这三个容器已经挂载了同一个卷，如图： 可见挂载volume到Pod，本质上是将volume挂载到Pod中的每一个容器。如果在这三个容器ps -ef一下，会发现他们的pid=1的进程是各自的进程而不是pause容器的/pause进程，如图： 所以很多人说pod里每个容器的init进程其实是/pause，而pause容器的作用，可以担任init的角色（默认都docker run -ipc:container:pause），及时的清理僵尸进程。但是在我这里的实验结果看来并不是真的。不知道是不是我某个姿势不对… 话说回来，这个例子很明显的体现了“一个pod里可以有多个容器”这句话，每个pod是一个namespace，即这些容器都可以通过localhost来彼此访问，但是不能重复使用同一个端口而且所有的pod都是同时启动的。 k8s的容器编排这里有一个比较不错的例子：https://cloud.tencent.com/developer/ask/180938 ，个人觉得说的很形象。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>云原生</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从Nginx配置缓存到HTTP缓存]]></title>
    <url>%2F2019%2F03%2F18%2F%E4%BB%8ENginx%E9%85%8D%E7%BD%AE%E7%BC%93%E5%AD%98%E5%88%B0HTTP%E7%BC%93%E5%AD%98%2F</url>
    <content type="text"><![CDATA[使用nginx配置缓存proxy_cache_path是nginx配置缓存的关键词，它是1.7.9之后的版本推出的功能。配置它很简单，只需要在nginx.conf里的http段里添加一句话： 1proxy_cache_path /data/httpd/nginx_cache/ecstore levels=1:2 keys_zone=ecstore:100m max_size=2g inactive=168h; 上面的命令先说明/data/httpd/nginx_cache/ecstore就是nginx配置缓存的文件夹，keys_zone指的是缓存空间名称，100m意思是可以存储8000*100个key；max_size指的是缓存文件可以占用的最大空间；nactive指的是如果一个缓存文件多长时间不被访问，就会被删除； 然后手动建立/data/httpd/nginx_cache/ecstore这个文件夹，给予它nginx可访问的权限，然后在具体的配置文件里加上： 1234567891011121314 location = /wap/ &#123; if ($query_string) &#123; proxy_pass http://172.16.0.199:3000/wap/?$query_string; &#125; proxy_pass http://172.16.0.199:3000/wap/; include headerproxy.conf; proxy_cache ecstore; #这里的ecstore就是上面keys_zone的名称 proxy_cache_key "$host$request_uri$cookie_user"; #这里就是缓存的keyproxy_cache_min_uses 5; #至少访问5次就开始缓存，默认情况是访问一次就缓存proxy_cache_methods GET HEAD POST； #对GET、HEAD、POST方法都可以缓存 add_header X-Cache web1$upstream_cache_status; proxy_cache_valid 200 206 302 301 304 2h; #对200、206、302、301、304状态码缓存2小时proxy_no_cache $http_pragma $http_authorization; &#125; 上面这个例子就是“如果访问/wap，会跳转到http://172.16.0.199:3000/，同时记录下缓存” 的配置。重启nginx就会生效。 验证和排错验证nginx是否缓存成功很简单，因为我们在配置文件夹加上了add_header X-Cache web1$upstream_cache_status;这样的配置，那么我们打开目标的网页： 发现看到了add_header的内容，可见缓存是成功的。 如果此刻给这个nginx外面套上一个CDN，那么curl -I在访问页面里具体元素的结果就会是： 我这里用的是阿里云的CDN，可见他们使用Server: Tengine做的CDN，而且这个js元素被CDN成功缓存。如果是TCP_MEM_HIT的字样，那么就说明是是从内存命中的。不同厂家的CDN展示结果不一样的。 如果nginx缓存没有生效，很大可能是Cache-Control和Set-Cookie的问题，那么就要在上面的配置文件里添加： 1proxy_ignore_headers Set-Cookie Cache-Control; 重启nginx看看效果。 Vary跟Etag的差别在上面的截图里看到了Etag和Vary这两个字段，先说Etag。 Etag是一个比较常见的字段，HTTP利用它来判断所访问的元素是否发生了变化—如果浏览器发送请求的请求头If-None-Match里的Etag没有变化（为False）那么服务器就直接304，把缓存内容返给浏览器；如果Etag发生变化了，那么服务器就拿出新的内容给它同时反馈200。它比Last-Modified强的最重要的地方就是Last-Modified只能精确到秒，遇到1s内修改了N次的情况就只能干瞪眼了，而Etag不会。 而说Vary之前要先说一下Cache-Control，Cache-Control有四个比较出名的缓存策略，分别是：1.no-cache：可以在本地缓存，可以在代理服务器缓存，但是这个缓存要服务器验证才可以使用；2.no-store：彻底得禁用缓存，本地和代理服务器都不缓存，每次都从服务器获取；3.private：为仅浏览器客户端可缓存；4.public：为多个用户都可以缓存，比如可以缓存到CDN上。 而图片里的Vary: Accept-Encoding是什么意思呢？它是告诉缓存服务器根据Accept-Encoding头值的不同去缓存不同的版本，比如同一个文件可能有gzip方式压缩的，有compress方式压缩的，甚至还有没压缩的。因为在实际的场景中，我们需要一些特殊的缓存：它会忽略响应头中的Content-Encoding，从而可能给不支持压缩的客户端返回缓存的压缩版本。有两个方案可以避免这种情况发生：1.将响应头中的Cache-Control字段设为private，告诉中继缓存（比如CDN）不要缓存它；2.增加Vary: Accept-Encoding响应头，明确告知缓存服务器按照Accept-Encoding字段的内容，分别缓存不同的版本； 通常为了更好的利用中间实体的缓存功能，我们都用第二种方案。对于css、js这样的静态资源，只要客户端支持gzip，服务端应该总是启用它；同时为了避免有BUG的缓存服务器给用户返回错误的版本，还应该输出Vary: Accept-Encoding。 nginx配置Vary：Accept-Encoding也很简单，在nginx.conf的http段里加上gzip_vary on;即可。 当然Vary还要很多种，比如Vary: User-Agent, Cookie，这表示“服务端同时使用请求头中User-Agent和Cookie这两个字段来生成内容”。注意！客户端如果直接访问源服务器的话，Vary就没意义了。 参考资料https://blog.csdn.net/dengjiexian123/article/details/53386586https://blog.csdn.net/t12x3456/article/details/17301897https://www.jianshu.com/p/625c2b15dad5https://imququ.com/post/vary-header-in-http.htmlhttps://developer.mozilla.org/zh-CN/docs/Web/HTTP/Caching_FAQhttps://segmentfault.com/a/1190000016648967]]></content>
      <categories>
        <category>工作与原理</category>
      </categories>
      <tags>
        <tag>CDN</tag>
        <tag>nginx</tag>
        <tag>HTTP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从limit和request来理解k8s的资源调配]]></title>
    <url>%2F2019%2F03%2F13%2F%E4%BB%8Elimit%E5%92%8Crequest%E6%9D%A5%E7%90%86%E8%A7%A3k8s%E7%9A%84%E8%B5%84%E6%BA%90%E8%B0%83%E9%85%8D%2F</url>
    <content type="text"><![CDATA[背景交代今天用阿里云的k8s做实验，在worker(2核4G)上执行这么一句话： 1kubectl run chengx --image=registry.cn-hangzhou.aliyuncs.com/lechangetest/chentest:chengx --port=80 --replicas=5 --limits="cpu=200m,memory=512Mi" 发现命令执行之后，只剩成了4个pod，一个卡在Pending的状态，如图： 使用kubectl describe pod/chengx-5bb8bcb9c9-tlgz4查看为什么会失败，看到理由是0/4 nodes are available: 1 Insufficient memory, 3 node(s) had taints that the pod didn&#39;t tolerate.，如图： 错误直译过来就是“4个node里已经没有可用的，现在内存爆缸了，其中三个node都因为有污点同时这个pid无法容忍这个污点”。 limit和request的不同我上面的命令里面用到了limit，所以先研究一下limit和request这俩参数，先说request: 123容器使用的最小资源需求, 作为容器调度时资源分配的判断依赖。只有当前节点上可分配的资源量 &gt;= request 时才允许将容器调度到该节点。request参数不限制容器的最大可使用资源 再说limit: 12容器能使用资源的最大值设置为0表示对使用的资源不做限制, 可无限的使用 request和limit的关系: 1234request能保证pod有足够的资源来运行, 而limit则是防止某个pod无限制的使用资源, 导致其他pod崩溃. 两者的关系必须满足:0 &lt;= request &lt;= limit &lt;= Infinity 复制代码如果limit=0表示不对资源进行限制, 这时可以小于request。目前CPU支持设置request和limit，memory只支持设置request， limit必须强制等于request， 这样确保容器不会因为内存的使用量超过request但是没有超过limit的情况下被意外kill掉。 举个例子，在一个2核4G的node里，运行一个(CPU Requst,CPU Limit,Memory Requst, Memory Limit)= (1U, 1U, 2G,2G)的POD是完全OK的，这个POD不一定一定要用满2G，它可以用到0.1G或者1.99G,只要是内存在2G以内，这个POD都是不受影响的。 如果这个时候，又来了一个POD，他的资源参数为(CPU Requst,CPU Limit,Memory Requst, Memory Limit)= (1U, 1U, 1G,2G)，那么这个POD2的内存在2G以内的情况下，POD1和POD2都是OK的。如果POD2的超过了2G，那么POD2会挂掉，而POD1安全无事。 若namespace里事前设定了CPU和内存的request和limit，那么在生成pod的时候，若无特殊说明，pod的request和limit值与所处的namespace相同。如果pod说明了request没说明limit，那么pod的limit等于声明的request。如果pod说明了request没有说明limit，那么limit值等于namespace默认的limit。 注意！namespace的limit值是可以比实际pod的limit值小的，如图： 可见这个叫default-mem-example的namespace默认的request是256Mi，limit是512Mi，而我是可以在这个namespace里创建一个request是1G的pod，如图： 额外补充一下，k8s里的计量单位：1Mi=1024x1024，1M=1000x1000，其它单位类推，如Ki/K、Gi/G。 重新说回来再次说回0/4 nodes are available: 1 Insufficient memory, 3 node(s) had taints that the pod didn&#39;t tolerate.，从这句话里我们看到虽然这个k8s集群有4个node（3个master+1worker)，使用kubectl describe node master节点名称来查看master上是否存在默认的taint: 再看一下worker节点的taint: 在master上默认是不会将Pod调度到具有该污点的Node上，也就是说所有pod都是在worker这个节点上的。worker上只有4G，而我生成了5个limit=512Mi的pod，需要2.5G的内存空间。然而worker这个pod现在有多少可用的内存呢？kubectl describe node worker名称可见剩余的memory已经不足，如图: 1234567Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 200m (10%) 0 (0%) memory 1736Mi (62%) 2248Mi (80%)Events: &lt;none&gt; 现在剩余的内存值仅有20%，所以由于内存不够而生成失败，需要在kubectl run里适当调小内存的limit值，或者干脆扩容一个worker，让它在另一个worker里出现。 如果想要查看某个pod是具体落在哪个node里，使用命令：kubectl get pods -o wide即可。 参考资料https://www.qikqiak.com/post/understand-kubernetes-affinity/https://blog.frognew.com/2018/05/taint-and-toleration.htmlhttps://jimmysong.io/kubernetes-handbook/concepts/taint-and-toleration.htmlhttps://stackoverflow.com/questions/53192999/pod-dont-run-insufficient-resourceshttp://dockone.io/article/2509https://www.yangcs.net/posts/understanding-resource-limits-in-kubernetes-cpu-time/http://blog.whysdomain.com/blog/171/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>云原生</tag>
        <tag>k8s</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用gdb去进入Too many connections的Mysql]]></title>
    <url>%2F2019%2F03%2F11%2F%E4%BD%BF%E7%94%A8gdb%E5%8E%BB%E8%BF%9B%E5%85%A5Too-many-connections%E7%9A%84Mysql%2F</url>
    <content type="text"><![CDATA[今天在登录mysql的时候，发现Too many connections的错误，如图： 很明显，连接数不够用了，在my.cnf里看到当前的最大链接是500。一般来说很多人就会修改my.cnf将max_connections改大然后重启mysql生效。但是我这个mysql是生产环境的，如果重启势必产生不小的影响，于是就需要不重启mysql还要能达到修改max_connections的目的。 那就用gdb，语句如下： 1[root@db-02 data]# gdb -p $(cat /opt/mysql/data/Storage.pid) -ex "set max_connections=1024" -batch 执行完毕之后，就可以正常登录到mysql的交互页面了： 此时查询一下最大连接数： 可见已经生效了，但是如果这个时候mysql有重启的话，还是会读取my.cnf里的max_connections配置，所以再手动改下max_connections即可。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安装部署Hadoop集群]]></title>
    <url>%2F2019%2F03%2F07%2FCentos6%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2Hadoop%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[目前大环境感觉不好，哪哪都是裁人的消息，所以这个时候更是要摆正心态、沉淀自己。 今年我个人的小目标是：Hadoop+k8s+python开发，这次就先写Hadoop的部署过程，可能会有一些名词看不懂，等下一篇再说名词解释。 先说环境： 12192.168.1.86 Master 华为云Centos7.5192.168.1.165 Salve 华为云Centos7.5 为了高可用，还要部署zookeeper来监视节点心跳情况，我这个例子里没有，如果有需要可以单独部署。 所有机器都要操作本段过程是所有的服务器都要一起操作的！ 先yum update -y，在等待的时候，我们就新开一个窗口，wget http://apache.01link.hk/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz 下载3.1.2版本的hadoop，下载完毕后，解压缩hadoop-3.1.2.tar.gz到/opt下，然后把hadoop-3.1.2改名叫hadoop。 在yum update -y完成之后，我们还要yum install java-1.8.0-openjdk* -y，安装完毕之后，执行java -version确认已经安装java 1.8成功。 在/etc/hosts文件里添加： 12192.168.1.86 master192.168.1.165 slave 修改配置文件，hadoop所有的配置文件都在/opt/hadoop/etc/hadoop路径下。先修改hadoop-env.sh，添加一句export JAVA_HOME=/usr，因为我们直接用yum安装的，java默认就会安装到/usr/bin/java。所以这里写/usr即可，如果是另外方法安装需要写具体的路径而且要修改/etc/profile和source /etc/profile。 在core-site.xml里的configuration里添加如下内容： 12345678910&lt;!-- 指定hadoop运行时产生文件的存储目录,可以指定自己熟悉的目录，默认/tmp/hadoop-$&#123;user.name&#125; --&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/tmp&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定hadoop使用的文件系统，HDFS的老大NameNode的地址 --&gt;&lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt;&lt;/property&gt; 在hdfs-site.xml里的configuration里添加如下内容： 12345678910111213141516171819202122 &lt;!-- 指定HDFS副本数量，默认3 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.name.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:50070&lt;/value&gt;&lt;!-- 如果不加这句话，50070端口打不开 --&gt; &lt;/property&gt; 在mapred-site.xml里的configuration里添加如下内容： 12345678910111213&lt;!-- 指定mapred运行时的框架：yarn，默认local --&gt;&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;master:49001&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapred.local.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/var&lt;/value&gt;&lt;/property&gt; 在yarn-site.xml里的configuration里添加如下内容： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;description&gt;The address of the applications manager interface in the RM.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8032&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;description&gt;The address of the scheduler interface.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8030&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;description&gt;The http address of the RM web application.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8088&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;description&gt;The https adddress of the RM web application.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.webapp.https.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8090&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8031&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;description&gt;The address of the RM admin interface.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8033&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt; &lt;value&gt;1024&lt;/value&gt; &lt;discription&gt;每个节点可用内存,单位MB,默认8182MB&lt;/discription&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt; &lt;value&gt;2.1&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;1024&lt;/value&gt;&lt;/property&gt; 把workers这个文件里的localhost替换成slave，2.X版本hadoop里的workers文件叫slaves。 至此，所有机器操作的部分完毕，要确认两边的内容必须保持一致，不然启动的时候就会出现优先级出错的故障。 只有Master操作以下操作只有master操作！ 由于Master是namenode，slave是datanode，现在就需要对namenode进行一个初始化的操作，即是hdfs的一个初始化。 进入/opt/hadoop/bin里，执行./hadoop namenode -format ，格式化一个新的分布式文件系统，如果不报错那就说明成功。完毕之后，可以去/opt/hadoop/dfs/name这个目录下发现多了一个current文件夹。 配置普通用户免密码登录至此整个部署过程就完毕了，如果是root用户就可以直接去/opt/hadoop/hadoop-2.8.0/sbin下执行./start-all.sh了，但是为了安全，我们不要用root用户去启动hadoop，而是用普通用户去启动它。 于是我们先在两台机器上adduser hadoop，这里不设置密码。然后chown -R /opt/hadoop，把整个hadoop文件夹的权限都给hadoop用户。 然后执行ssh-keygen -t rsa，一顿回车之后发现在/home/hadoop/.ssh下有了id_rsa和id_rsa.pub这俩文件。这俩就是root用户的ssh公钥和私钥文件，su hadoop切换到hadoop用户上，同样的操作一遍，获取到hadoop用户的ssh公钥和私钥文件。 master和slave都在/home/hadoop/.ssh下新建一个文件叫authorized_keys，并且互相复制对方的hadoop的id_rsa.pub到自己的authorized_keys里，然后再复制自己的root的id_rsa.pub到自己的authorized_keys里。 修改authorized_keys的权限是600，此时无论是master还是salve的hadoop用户都应该可以无密码登录自己和对方，如图： 启动Hadoop当前用户是hadoop，在master机器上执行/opt/hadoop/sbin/start-all.sh即启动hadoop，如图： 此时在slave机器上会看到有两个进程启动： 12hadoop 13552 1 2 10:35 ? 00:00:03 /usr//bin/java -Dproc_datanode -Djava.net.preferIPv4Stack=true -Dhadoop.security.logger=ERROR,RFAS -Dyarn.log.dir=/opt/hadoop/logs -Dyarn.log.file=hadoop-hadoop-datanode-slave.log -Dyarn.home.dir=/opt/hadoop -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/hadoop/lib/native -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=hadoop-hadoop-datanode-slave.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml org.apache.hadoop.hdfs.server.datanode.DataNodehadoop 13670 1 3 10:35 ? 00:00:04 /usr//bin/java -Dproc_nodemanager -Djava.net.preferIPv4Stack=true -Dyarn.log.dir=/opt/hadoop/logs -Dyarn.log.file=hadoop-hadoop-nodemanager-slave.log -Dyarn.home.dir=/opt/hadoop -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/hadoop/lib/native -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=hadoop-hadoop-nodemanager-slave.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.yarn.server.nodemanager.NodeManager 或者使用jps命令在双方机器上查看启动的进程名： 12345[root@slave hadoop]# jps13552 DataNode13670 NodeManager1543 WrapperSimpleApp13790 Jps 在华为云的安全组里对这俩服务器打开50070端口和8088的公网访问端口，然后在浏览器里输入http://master公网IP:50070即可查看效果： 而输入http://master公网IP:8088就会看到cluster页面： 如果要关闭，就在master执行/opt/hadoop/sbin/stop-all.sh，至此一个简单的hadoop集群搭建和启动完毕。 参考资料https://www.cnblogs.com/charlesblc/p/6030008.htmlhttps://blog.wuwii.com/linux-hadoop.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>大数据</tag>
        <tag>Hadoop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix出现数据库IIllegal mix of collations的报错]]></title>
    <url>%2F2019%2F03%2F05%2FZabbix%E5%87%BA%E7%8E%B0%E6%95%B0%E6%8D%AE%E5%BA%93IIllegal-mix-of-collations%E7%9A%84%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[接到新的私有云工作，登录到甲方爸爸的服务器一看是centos6.1，上面安装了zabbix-server但是仅仅做了auto-discovery，于是我就做templates，可见名称是中文的。但是发现在保存的时候，出现了这样的错误： 定眼一看，这是数据库的编码问题，整个database都是拉丁编码而不是utf8编码，所以无法输入中文。 要解决这个问题比较简单，毕竟zabbix刚启动而已，数据库里还没有数据。于是我就干脆把整个zabbix的database干掉，重建一个新的： 12mysql -hlocalhost -uzabbix -p #登录数据库drop databases zabbix; #暴力全部删光 此时的zabbix-server的web界面是如下的： 然后返回到mysql里： 123create database zabbix character set utf8; # ctrl+c 退出数据库zcat /usr/share/doc/zabbix-server-mysql-3.4.15/create.sql.gz |mysql -uzabbix -p26e9p69r zabbix #重新导入初始化表 然后在web界面点击retry，然后重新登陆一下zabbix-server。再次尝试编辑带有中文的监控项，就能顺利保存了！]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[不要轻易去打开tcp_tw_recycle！]]></title>
    <url>%2F2019%2F03%2F04%2F%E4%B8%8D%E8%A6%81%E8%BD%BB%E6%98%93%E5%8E%BB%E6%89%93%E5%BC%80tcp-tw-recycle%EF%BC%81%2F</url>
    <content type="text"><![CDATA[挖坑过程有时候，我们可能发现服务器里存在大量的TIME_WAIT，如图： 其实这2000+的TIME_WAIT真的不算多，至少低于10000条都不算多。但是TIME_WAIT本身是一个占用内存和CPU的东西，所以很多人就想把它干掉。往往这个时候，就会看到这样的答案： 1234打开 sysctl.conf 文件，修改以下几个参数：net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_timestamps = 1 #只有打开这个，前俩才能生效 修改完毕之后，再/sbin/sysctl -p一下，就会看到TIME_WAIT果然大量减少，效果立竿见影！但是不要高兴太早，其实你给自己埋下了一个大坑… TIME_WAIT是干啥的只有主动关闭连接的一方，才会转移到TIME_WAIT。只有被动断开连接的一方会出现CLOSE_WAIT，等待close()执行完毕之后，状态变成LAST_ACK。 TIME_WAIT的主要目的有2个： 避免误收延迟到达的报文：因为报文又快又慢，而若TIME_WAIT太短就会放弃原来的链接，生成新的链接，而新的链接此时接到迟到了报文，这就出现了数据错误的现象； 保证对端已经关闭了连接：由于TIME_WAIT的时间被缩短了，对端还处于LAST_ACK状态，本段发送的syn报文被直接RST掉了。 再说结论当配置了net.ipv4.tcp_tw_recycle = 1之后，TIME_WAIT这个阶段就几乎是不存在了，因为原本它的存活时间是2MSL时间，现在改成了一个RTO，这个RTO可以远远小于2MSL的。当一个socket连接进入TIME_WAIT状态后，内核里会记录包括该socket连接对应的五元组中的对方IP等在内的一些统计数据，当然也包括从该对方IP所接收到的最近的一次数据包时间。当有新的数据包到达，只要时间晚于内核记录的这个时间，数据包都会被统统的丢掉。 那怎么会影响具体业务呢？如果你所在的网络是NAT网络，即“多个客户端，但是同一个IP出口”这样的网络环境，这样很多人其实使用的是同一个IP。但是在服务器端它是始终在跟同一个host打交道，那么在一个RTO的时间内，只能有一个客户端和自己连接成功，而其他人要连接就会出现超时的现象。 抓包体现是客户端发送了syn给服务端，但是服务端不会回复ack，然后客户端就一直处于等待，通畅以为服务器端此时卡死了，可是此时服务器的负载并不高。 为什么TCP4次挥手时等待为2MSL？MSL是Maximum Segment Lifetime,译为“报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。等待2MSL时间主要目的是怕最后一个ACK包对方没收到，那么对方在超时后将重发第三次握手的FIN包，主动关闭端接到重发的FIN包后可以再发一个ACK应答包。TCP只有断开了才会释放占用端口等资源，新来的链接才能复用这个端口。若被动断开的一方一直收不到最后一个ACK,那就会等待retry times到了上限，会reset连接。 如果不等，释放的端口可能会重连刚断开的服务器端口，这样依然存活在网络里的老的TCP报文可能与新TCP连接报文冲突，造成数据冲突，为避免此种情况，需要耐心等待网络老的TCP连接的活跃报文全部死翘翘，2MSL时间可以满足这个需求。 正确做法解决办法就是不建议同时开启tcp_timestamp和tcp_tw_recycle。 正确的解决这个总是办法应该是： 1234net.ipv4.ip_local_port_range = 9000 6553 #默认值范围较小net.ipv4.tcp_max_tw_buckets = 10000 #默认值较小，还可适当调小net.ipv4.tcp_tw_reuse = 1 #net.ipv4.tcp_fin_timeout = 10 # 插播一句，tcp_tw_recycle这个参数已经在新的内核kernel 4.12里已经去掉了。 参考资料https://www.cnxct.com/coping-with-the-tcp-TIME_WAIT-state-on-busy-linux-servers-in-chinese-and-dont-enable-tcp_tw_recycle/https://ieevee.com/tech/2017/07/19/tcp-tw-recycle.html#TIME_WAIT%E6%98%AF%E5%B9%B2%E5%95%A5%E7%9A%84https://www.jianshu.com/p/893b5d7e9f30https://www.zhihu.com/question/67013338https://mp.weixin.qq.com/s?__biz=MzI4MjA4ODU0Ng==&amp;mid=2650910938&amp;idx=2&amp;sn=8b0aa87b0f45b8465e3fe9a70f51c895&amp;chksm=f06a55d7c71ddcc120d49d4808ac471d6ae37c105cf37cbfdf142384a3bb2fb5b94ff76b904a&amp;mpshare=1&amp;scene=1&amp;srcid=0226ijYLsAmX7LdKO206NINd&amp;key=d98c1a7a91040c8d88006a294b27c49cb4fc4e200242db9cfabf2f4d98e420954e2210ce8d72d0ea778a548e2596bef617479a59cc23a4164f93cfd0cfa85a8d460c21de5501f934e13fd0fc2e50cbce&amp;ascene=1&amp;uin=MTE4NTkxNTEwMA%3D%3D&amp;devicetype=Windows+7&amp;version=62060720&amp;lang=zh_CN&amp;pass_ticket=RxcXlxUz8iYDMMdnmhYX6NfQJkTaZzim2gD9j8q74LaeYI8X1cSH0njnQZXJfH8g]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>tcp链接</tag>
        <tag>内核优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维工程师笔试题第十八套]]></title>
    <url>%2F2019%2F03%2F04%2FLinux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%AC%94%E8%AF%95%E9%A2%98%E7%AC%AC%E5%8D%81%E5%85%AB%E5%A5%97%2F</url>
    <content type="text"><![CDATA[试题内容1.docker的exec与attach命令有啥区别？attach开启一个和正在运行的进程交互的终端，如果该进程结束，原docker container的进程也会结束。exec可以开启多个终端实例，exec -i /bin/bash，由此可见exec其实是在运行中的容器中执行一个命令。 2.docker的CMD与ENTRYPOINT命令有啥区别？CMD的命令会被docker run里的命令覆盖，而ENTRYPOINT命令不会。如果要覆盖ENTRYPOINT，则在docker run里添加--entrypoint标签来覆盖即可。如果dockerfile里指定了WORKDIR，那么无论是CMD还是ENTRYPOINT命令都是在这个WORKDIR目录里执行。 3.docker的kill和stop命令有啥区别？stop是“优雅退出”，先发送SIGTERM信号，在一段时间之后（10s）再发送SIGKILL信号。Docker内部的应用程序可以接收SIGTERM信号，然后做一些“退出前工作”，比如保存状态、处理当前请求等。kill是“暴力退出”，即发送SIGKILL信号，应用程序直接退出。 4.假设有一个AAA的容器，现在需要备份它的挂载卷/DATA里的数据，请问如何操作？ 1docker run --volumes-form A -v /tmp:/backup --name BACKUP ubuntu tar cvf /backup/A.tar /DATA 上面这个语句新建立一个叫BACKUP的容器，它与A容器挂载情况相同（即都是挂载/DATA），同时将本地的/tmp挂载到容器的/backup，在容器生成的时候，执行了tar cvf /backup/A.tar /DATA将DATA文件夹的内容进行了打包，又由于/tmp已经与/backup挂载，所以就可以直接从宿主机上的/tmp里得到A.tar了。 4.linux里删除某个用户的所有进程的语句？ps -u username | grep -v PID | awk ‘{print$1}’| xargs kill -9或者killall -u username 5.linux如何彻底删除一个用户？userdel -r zhidao（前提是这个用户下已经没有程序运行了） 6.ps -ef |grep 进程名|awk “{print $2}”|xargs kill -9 未完待续 参考资料https://stackoverflow.com/questions/30960686/difference-between-docker-attach-and-docker-exechttp://dockone.io/question/469]]></content>
      <categories>
        <category>大牛之路</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>面试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[H5界面实现桌面推送通知]]></title>
    <url>%2F2019%2F03%2F01%2Fh5%E7%95%8C%E9%9D%A2%E5%AE%9E%E7%8E%B0%E6%A1%8C%E9%9D%A2%E6%8E%A8%E9%80%81%E9%80%9A%E7%9F%A5%2F</url>
    <content type="text"><![CDATA[我们产品线的服务器告警模式是：“每十分钟执行一次脚本，脚本会使用zkclient获取当前服务器的CPU、内存、带宽、服务负载，然后以邮件的形式发送到运维人员的邮箱里”，每十分钟一次的频率可想而知，一天下来邮箱要有几百几千封邮件，看着就心烦。于是我就冒出了一个大胆的想法，重构这套土了吧唧的告警模式。 思路是这样的：“依旧是通过后台脚本结合crontab定时获取服务器的相关采集值，然后将值传入到Django的views.py里，呈现到某个页面上，这个页面也会定时自动刷新，每次刷新的时候也就顺便取到了新的采集值，如果有告警，那么页面对应的告警值红色标注，同时弹出通知。” 这么一看感觉高大上了很多，至少不用天天去outlook里清理垃圾邮件。 实现自动刷新页面自动刷新的方法很简单，有如下2种：1.页面自动刷新：把如下代码加入&lt;head&gt;区域中 1&lt;meta http-equiv="refresh" content="20"&gt; //其中20指每隔20秒刷新一次页面. 这个功能也能结合页面自动跳转：把如下代码加入&lt;head&gt;区域中 1&lt;meta http-equiv="refresh" content="20;url=http://www.webjx.com"&gt; //其中20指隔20秒后跳转到http://www.webjx.com页面 我想，QQ好友生日祝福功能里10秒钟自动关闭就应该是这么做出来的。 2.页面自动刷新之js版 123456&lt;script language="JavaScript"&gt;function myrefresh()&#123; window.location.reload();&#125;setTimeout('myrefresh()',1000); //指定1秒刷新一次&lt;/script&gt; 这里多说一下http-equiv，http-equiv是响应头报文。它只能出现在meta标签里，用来代替name，它的值使用content属性描述，HTTP服务器通过此属性收集HTTP协议的响应头报文。 比如： 1&lt;meta http-equiv="Content-Type" Content="text/html; Charset=gb2312″ /&gt; 上面代码告诉浏览器等设备，文件为html文件，且使用了utf8编码; 1&lt;meta http-equiv="Content-Language" Content="zh-CN" /&gt; 上面代码告诉浏览器等设备，语言使用了中文; 1&lt;meta http-equiv="Expires" Content="Wed, 26 Feb 1997 08:21:57 GMT" /&gt; 上面代码指定网页在缓存中的过期时间，一旦网页过期，必须到服务器上重新调阅。注意：必须使用GMT的时间格式，或直接设为0(数字表示多少时间后过期)。 实现桌面通知桌面通知是一个比较优雅的功能，只要你后台打开网页，那么一旦网页里触发了通知，就会在windows桌面上弹出一个小窗口告诉我们页面发生了，如图： 它的实现关键词就是Notification API，这个动作的js代码如下： 123456789101112131415161718192021222324&lt;script type="text/javascript"&gt; //判断浏览器是否支持Notificationif (window.Notification) &#123; var title; var options; title = '服务器告警提醒'; //通知的标题 options = &#123; //通知的所有内容 body: "机器千万台，稳定第一条，服务一瘫痪，运维泪两行。", //通知主体内容 tag: "custom", //代表通知的一个识别标签，相同tag时只会打开同一个通知窗口 icon: "http://img.mp.itc.cn/upload/20160723/a5953dc52c484834ab1ce924bb344da8_th.jpg", //要在通知中显示的图标的URL // images: "https://xxx.jpg" //要在通知中显示的图像的URL requireInteraction: false //通知保持自动关闭 &#125;; Notification.requestPermission(function() &#123; var notification = new Notification(title, options); notificationEvents.forEach(function(eventName) &#123; notification[eventName] = function(event) &#123; &#125;; &#125;); &#125;); &#125; else &#123; alert("你使用的浏览器不支持弹出提示，请更换Chrome内核浏览器！"); &#125;&lt;/script&gt; 再结合上面的自动刷新语句，在浏览器打开的时候，首先会询问是够接受“通知”，如图： 同意了之后，浏览器每10秒钟自动刷新，同时弹出上面那个加菲猫弹窗。 而且Notification API只能对https的网站可用，详情可见： https://stackoverflow.com/questions/30542287/are-push-notifications-possible-in-html5-without-fully-https-site 。 全部整合现在就需要把上面两个功能全部整合到一起，实现每10分钟自动刷新，同时判断传入数值，如果数值超标就发送桌面通知。 首先，先在django的url.py里设定访问的路径和对应的函数: 1234567from django.urls import pathfrom . import views urlpatterns = [ # 前面略 path(r'test222/',views.ttt),] 然后在views.py里简单设置一下这个ttt函数： 12345def ttt(request): cpu = 6.66 mem = 66.6 disk = 26 return render_to_response('test222.html',&#123;'CPU':cpu,'MEMORY':mem,'DISKUSED':disk&#125;) 现在已经传入了三个数值，然后我们加工一下test222.html页面，如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;html&gt; &lt;head&gt; &lt;meta http-equiv="refresh" content="60"&gt; &lt;title&gt;服务器监控页面&lt;/title&gt; &lt;script type="text/javascript"&gt; var cpu="&#123;&#123;CPU&#125;&#125;",mem="&#123;&#123;MEMORY&#125;&#125;",disk="&#123;&#123;DISKUSED&#125;&#125;" // alert(cpu+' '+mem+' '+disk) if ( cpu &gt; 80 || mem &gt; 80 || disk &gt; 80) &#123; if (window.Notification) &#123; var title; var options; title = '服务器告警提醒'; //通知的标题 options = &#123; //通知的所有内容 body: "机器千万台，稳定第一条，服务一瘫痪，运维泪两行。", //通知主体内容 tag: "custom", //代表通知的一个识别标签，相同tag时只会打开同一个通知窗口 icon: "http://img.mp.itc.cn/upload/20160723/a5953dc52c484834ab1ce924bb344da8_th.jpg" //要在通知中显示的图标的URL &#125;; Notification.requestPermission(function() &#123; var notification = new Notification(title, options); notificationEvents.forEach(function(eventName) &#123; notification[eventName] = function(event) &#123; &#125;; &#125;); &#125;); &#125; else &#123; alert("你使用的浏览器不支持弹出提示，请更换Chrome内核浏览器！"); &#125; &#125; &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;h3&gt;服务器名称是test-ooxx-001&lt;/h3&gt; &lt;hr&gt; &lt;h4&gt;CPU情况是：&#123;&#123; CPU &#125;&#125;&lt;/h4&gt; &lt;h4&gt;内存情况是：&#123;&#123; MEMORY &#125;&#125;&lt;/h4&gt; &lt;h4&gt;磁盘容量情况是：&#123;&#123; DISKUSED &#125;&#125;&lt;/h4&gt; &lt;/body&gt;&lt;/html&gt; 界面如下： 现在修改一下views.py里的三个值，只要有一个大于设定的标准值，就会触发桌面推送。 js里“a=空就判断b，b如果也是空再判断C，然后执行func()”的语句是： 123if ( a != null || b != null || c != null ) &#123; fun();&#125; 参考资料https://developer.mozilla.org/zh-CN/docs/Web/API/notificationhttp://www.ptbird.cn/html5-notification-browser.htmlhttps://segmentfault.com/a/1190000011670082]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>html5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[让Nginx鉴权功能保护Kibana网页]]></title>
    <url>%2F2019%2F02%2F28%2F%E8%AE%A9Nginx%E9%89%B4%E6%9D%83%E5%8A%9F%E8%83%BD%E4%BF%9D%E6%8A%A4Kibana%E7%BD%91%E9%A1%B5%2F</url>
    <content type="text"><![CDATA[Kibana本身是一个Web界面，但是出于安全和机密的考虑，我们肯定不会让互联网上所有的人都能随便看到Kibana里的内容，但是X-pack目前又不支持6.2以上的版本，于是我们可以使用Nginx的密码功能来保护Kibana的网页：要访问Kibana时需要先输入密码，正确就登陆到Kibana，如果错误就是403。 Kibana是容器安装的，安装过程可以去查看：https://rorschachchan.github.io/2019/01/21/%E5%B0%86kafka%E5%8A%A0%E5%85%A5%E5%88%B0Elk%E9%9B%86%E7%BE%A4/ 事前准备Nginx也是容器安装，docker pull nginx拉取最新的nginx镜像，在下载的时候呢我们也别对着屏幕干巴巴的等。由于在nginx配置转发的时候，需要知道Kibana的容器IP，这是因为Kibana和正在下载的Nginx是两个不同的容器，Nginx是需要跨容器访问的。 默认的官方Kibana镜像登录是非root的，这种虽然安全，但是不能config也不能yum，于是我们首先要使用root账号登录进去，语句是： 123docker exec -it --user root kibana容器ID /bin/bashyum update -yyum install -y net-tools #下载ifconfig 使用ifconfig和netstat查看容器的IP和工作端口： 可以确认Kibana的IP是172.17.0.4，端口是5601。这时候我们就可以写一个kibana.conf，让nginx容器用这个配置文件达到跳转的目的！ kibana.conf全文如下： 12345678910111213141516171819upstream kibana_server &#123; server 172.17.0.3:5601 weight=1 max_fails=3 fail_timeout=60; #这里写的就是kibana的容器IP和端口，如果是多台kibana想要按权重访问，就写weight&#125;server &#123; listen *:33664; #nginx容器自己的端口 server_name _; auth_basic "Restricted Access"; # 验证 auth_basic_user_file /etc/nginx/conf.d/htpasswd.users; # 验证文件 location / &#123; proxy_pass http://kibana_server; #这个地方就是upstream proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection 'upgrade'; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; &#125;&#125; 把这个文件保存在/mnt/nginx目录里。 配置nginx密码nginx要创建验证文件授权,需要先安装httpd-tools工具： 123yum install -y httpd-tools htpasswd -bc /mnt/nginx/htpasswd.users kibana password123 # 创建验证文件Adding password for user admin 这时我们就创建了一个/mnt/nginx/htpasswd.users，里面的用户是kibana，密码是password123。这个密码在文件里是加密的，用cat命令无法正常查看到的。 启动nginx容器此时nginx镜像应该下载完毕了，那么就直接启动镜像，启动语句是： 1docker run --hostname Kngx -p 80:33664 --name Knginx -v /mnt/nginx/:/etc/nginx/conf.d/ -d nginx 简单说一下这个命令：这个容器名叫Knginx，hostname是Kngx，做了宿主机80端口到此容器33664端口的转发，将宿主机的/mnt/nginx/挂载到容器里的/etc/nginx/conf.d/，同时直接启动nginx。 启动成功之后，我们看到刚刚建立的htpasswd.users和kibana.conf都已经成功被Knginx容器配置上，然后打开浏览器，看看效果： 这样就达到了密码访问页面的效果，如果想加IP白名单呢，也可以直接在kibana.conf里补充相关配置，修改完毕之后，重启Knginx容器即可。 参考资料https://www.hugeserver.com/kb/how-secure-kibana-nginx-centos/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>nginx</tag>
        <tag>kibana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维工程师笔试题第十七套]]></title>
    <url>%2F2019%2F02%2F19%2FLinux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%AC%94%E8%AF%95%E9%A2%98%E7%AC%AC%E5%8D%81%E4%B8%83%E5%A5%97%2F</url>
    <content type="text"><![CDATA[试题内容如果网站配置了多域名，要根据不同的域名分别https访问，应该怎么配置？在rewrite的时候使用$host，如下： 1234567891011server&#123; listen 80; server_name www.test.com www.test.com.cn; index index.html index.htm index.php; root /home/wwwroot; location / &#123; rewrite ^/(.*)$ https://$host/$1 permanent; &#125;&#125; 如果是要笨一点的方法就是： 12345678910111213server &#123; listen 80; server_name www.test.com www.test.com.cn; index index.html index.htm index.php; root /home/wwwroot; if ($host = 'www.test.com.cn' ) &#123; rewrite ^/(.*)$ https://www.test.com.cn/$1 permanent; &#125; if ($host = 'www.test.com' ) &#123; rewrite ^/(.*)$ https://www.test.com/$1 permanent; &#125; ps.阿里云的SLB绑定多个HTTPS证书的文档：https://help.aliyun.com/document_detail/87023.html?spm=a2c4g.11186623.6.741.7e11301bVLBAJz 2.在Nginx中，如何使用未定义的服务器名称来阻止处理请求?只需将请求删除的服务器就可以定义为： 12345Server &#123; listen 80; server_name " "; return 444;&#125; 这里，服务器名被保留为一个空字符串，它将在没有“主机”头字段的情况下匹配请求，而一个特殊的Nginx的非标准代码444被返回，从而终止连接。 3.ajax是同步还是异步，怎么样实现同步?ajax里async属性默认的设置值为true，这种情况为异步方式。即网页里有两个函数func(x)和func(y)，在打开网页的时候，后台会先去执行func(x)，然后等待server返回结果，同时还有一个线程会去执行func(y)。 当把async设为false时，这时ajax的请求是同步的，也就是说，这个时候ajax块发出请求后，他会等待在func(x)这个地方，不会去执行func(y)，直到func(x)部分执行完毕。 4.nginx如何实现http跳转https?需要用到地址重写代码，用以下代码能让http强制跳转到https: 123456server &#123; listen 80; listen [::]:80; #支持ipv6 server_name www.test.com; return 301 https://$server_name$request_uri;&#125; 6.如果某个网站做了两个域名，分别是https://www.aaa.com和https://www.bbb.com，如果做了www.aaa.com cname到www.bbb.com，那么浏览器打开www.aaa.com会是什么界面？打开页面会出现“https证书不正确”的风险提示。 7.接着上面问题，在nginx里做了rewrite或者配置了显性URL，此时取消掉www.aaa.com本身的ip（即www.aaa.com没有ip,但是www.bbb.com有ip），浏览器里打开www.aaa.com会是什么界面？会显示“无法找到www.aaa.com的IP地址”（第一步就失败了…）。 8.要求a.com和www.a.com都跳到www.b.com，而www.a.com/123不跳，如何配置？配置如下： 1234567891011121314server &#123; listen 80; server_name www.a.com a.com; #根目录跳转 location / &#123; rewrite .+ http://www.b.com/ permanent; &#125; #非根目录本地执行 location ~* /.+ &#123; #已省略余下通用配置内容 &#125;&#125; 9.为了安全，Web服务器不要求启用所有可用的方法，只允许GET，HEAD和POST方法，其他的全部过滤掉。实现其功能的代码如下： 123if ($request_method !~ ^(GET|HEAD|POST)$ ) &#123; return 444;&#125; 10.对/download/目录做“最大下载速度20K，同时最多2个并发链接的限制” 123456789http &#123; limit_zone my_zone $binary_remote_addr 10m; #在 http 段配置定义一个limit_zone server &#123; location /download/ &#123; limit_conn my_zone 2; #limit_conn和 limit_rate参数进行限速设置 limit_rate 20k; &#125; &#125; &#125; limit_zone:针对每个 IP 定义一个存储 session 状态的容器。本例中定义了一个my_zone的10m大小的容器。 limit_conn my_zone 2：限制在my_zone中记录状态的每个IP只能发起2个并发连接。本例中，客户端访问/download目录时，会限制2个并发连接。 limit_rate 20k：对每个连接限速20k。注意，这里是对连接限速，而不是对IP限速。如果一个IP允许2个并发连接，那么这个IP就是限速为limit_rate*2，在设置的时候要根据自己的需要做设置调整。 11.简单说明nginx配置文件里面alias和root的区别Nginx配置文件server中指定两个location执行，分别为root和alias指令： 123location /test/ &#123; alias /www/test/;&#125; 按照上述配置，则访问/test/目录里面的文件时，nginx会去/www/test/目录找文件： 123location /test/ &#123; root /www/test;&#125; 按照这种配置，则访问/test/目录下的文件时，nginx会去/www/test/test/目录下找文件。 另一个区别是alias后面必须要用/结束，否则会找不到文件，而root则对/可有可无。 12.CDN缓存命中率下降的因素有哪些？ 客户是否刷新过缓存？答：如果刷新缓存，有可能会短时间表现命中率下降。特别说明下：CDN的url或者目录刷新是清除CDN缓存的动作（这个比较容易理解偏差） 带宽是否突增？并且访问的都是新的URL？答：带宽突增或者访问的新URL较多，会导致CDN节点回源较多，命中率会表现有下降趋势。 源站是否有新内容发布？答：CDN节点访问新内容，导致CDN节点回源较多，命中率会表现有下降趋势。 源站是否出现过异常导致5XX和4XX增加，由于5XX和4XX不缓存，会表现命中率下降。 源站的访问url的header参数，或者在CDN控制管理后台的缓存配置规则是否改变过？答：缓存时长的调整，有可能会带来命中率的变化。 13.如果判断url是否命中CDN缓存？查看响应头信息中的X-Cache字段。 显示MISS，说明没有命中CDN缓存，是回源的。 显示HIT，是命中了CDN缓存。 除了X-Cache还有如下几个参数与CDN有关：X-Swift-SaveTime：内容开始在CDN上缓存的时间。由于系统时间是GMT时间，所以需要折算成北京时间。X-Swift-CacheTime：CDN的默认缓存时间，以秒为单位。Age：该内容在CDN上已经缓存了的时间。 14.AJAX从b.com请求另一个域a.com的地址会有跨域的问题，如何配置？ 123456789server &#123; listen 80; server_name b.com; location /&#123; add_header 'Access-Control-Allow-Origin' 'http://a.com'; add_header 'Access-Control-Allow-Credentials' 'true'; add_header 'Access-Control-Allow-Methods' 'GET'; &#125;&#125; 第一条add_header：授权从a.com的请求第二条add_header：当该标志为真时，响应于该请求是否可以被暴露第三条add_header：指定请求的方法，可以是GET，POST，PUT，DELETE，HEAD如果想允许来自任何域的请求，可以这样： 1234567server &#123; listen 80; server_name b.com; location /&#123; Access-Control-Allow-Origin: * &#125; &#125; 15.如果想配置2-3个域设置为信任，其他的域名被排除，应该如何配置？ 123456789server &#123; listen 80; server_name b.com; location /&#123; if ( $http_referer ~* (a.com|b.com|c.com) ) &#123; Access-Control-Allow-Origin: * &#125; &#125; &#125; 参考资料https://my.oschina.net/mrpei123/blog/1794001http://note.qidong.name/2017/09/nginx-https-hsts/https://www.ssllabs.com/ssltest/index.html（测试ssl安全的网站）]]></content>
      <categories>
        <category>大牛之路</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>面试笔试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Logstash的正则匹配日志格式]]></title>
    <url>%2F2019%2F02%2F15%2F%E4%BD%BF%E7%94%A8Logstash%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%B9%E9%85%8D%E6%97%A5%E5%BF%97%E6%A0%BC%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[牛刀小试在ELK里经常需要写正则来匹配日志里的的具体信息，这样可以在kibana上更加直观的观看，grok就是Logstash最重要的插件。你可以在grok里预定义好命名正则表达式，在稍后(grok参数或者其他正则表达式里)引用它。 grok的格式是：%{SYNTAX:SEMANTIC}，如果需要转义就要加上\。具体的grok匹配规则可以在logstash查看grok-patterns这个文件，如图： SYNTAX代表匹配值的类型，例如，0.11可以NUMBER类型所匹配，10.222.22.25可以使用IP匹配。 SEMANTIC表示存储该值的一个变量声明，它会存储在elasticsearch当中方便kibana做字段搜索和统计，你可以将一个IP定义为客户端IP地址client_ip_address，eg:%{IP:client_ip_address}，所匹配到的值就会存储到client_ip_address这个字段里边，类似数据库的列名。 而检测grok正则的网站：http://grokdebug.herokuapp.com/ 。 举个例子，如果日志里是： 1100.97.73.142 - - [15/Feb/2019:16:54:24 +0800] 可以看到里面有IP、日期、时间、时区，那么对比刚才的grok-patterns文件，就知道要匹配IP这个字段，就是用IP (?:%{IPV6}|%{IPV4})，IP即包含了IPV6也有IPV4，那么具体的匹配就是%{IP:client}，client是自己定义名称。同理，[15/Feb/2019这部分是日期，可以使用如下的配置规则： 如法炮制，匹配结果就是\[%{MONTHDAY:day}/%{MONTH:month}/%{YEAR:year}。 拿到检测网站试一下结果： 上面那个例子比较简单，比如匹配下面这样的一个日志： 1[2019-02-01T08:59:59.124] [INFO] default - [115.63.121.10 GET /wap/_nuxt/vendor.61a8f274bce0acb0de6d.js 200 97s][https://www.lechange.com/wap/node/goodDetail/264 HTTP/1.1 Mozilla/5.0 (Linux; Android 8.1; V1818A Build/OPM1.171019.026; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/57.0.2987.132 MQQBrowser/6.2 TBS/044409 Mobile Safari/537.36] 那么写法就是： 120%&#123;YEAR:year&#125;-%&#123;MONTHNUM:month&#125;-%&#123;MONTHDAY:day&#125;T%&#123;HOUR:hour&#125;:?%&#123;MINUTE:minutes&#125;(?::?%&#123;SECOND:second&#125;)] \[%&#123;LOGLEVEL:level&#125;\] default - \[%&#123;IP:client&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:status&#125; %&#123;NUMBER:duration&#125;s\]\[%&#123;DATA:data&#125;\] 效果如图: 但是要注意!在网站上的匹配可能是OK的，但是在logstash的grok里是不可以有-、&#39;、&quot;等这样的字符出现，比如下面这个日志： 1100.97.73.232 - - [15/Feb/2019:16:54:24 +0800] "GET /public/app/site/statics/favicon.ico HTTP/1.1" 200 4286 "https://www.lechange.com/wap/" "Mozilla/5.0 (Linux; Android 7.1.1; OPPO R11 Build/NMF26X; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/57.0.2987.132 MQQBrowser/6.2 TBS/044409 Mobile Safari/537.36 Imou" 虽然下面的规则是可以正确匹配的： 1%&#123;IP:client&#125; - - \[%&#123;MONTHDAY:day&#125;/%&#123;MONTH:month&#125;/%&#123;YEAR:year&#125;:%&#123;HOUR:hour&#125;:%&#123;MINUTE:minutes&#125;:%&#123;SECOND:second&#125; \+0800] \"%&#123;WORD:method&#125; %&#123;URIPATH:request&#125; HTTP/%&#123;NUMBER:httpversion&#125;" %&#123;NUMBER:status&#125; %&#123;NUMBER:bytes&#125; "%&#123;DATA:website&#125;" "%&#123;DATA:data&#125;" 但是当你把这个配置复制到logstash.conf里的时候，启动logstash就会有参数不合法的报错： 1[2019-02-18T17:33:52,060][FATAL][logstash.runner ] The given configuration is invalid. Reason: Expected one of #, &#123;, -, ", ', &#125; at line 32, column 218 (byte 1226) 。 应该改成这样： 1%&#123;IPORHOST:client_ip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \[%&#123;HTTPDATE:timestamp&#125;\] "(?:%&#123;WORD:verb&#125; %&#123;NOTSPACE:request&#125;(?: HTTP/%&#123;NUMBER:http_version&#125;)?|-)" %&#123;NUMBER:response&#125; (?:%&#123;NUMBER:bytes&#125;|-) %&#123;QUOTEDSTRING:domain&#125; %&#123;QUOTEDSTRING:data&#125; 一般来说对于字符串，有双引号包含的用QS，没有的用DATA类型，如%{DATA:request_body}。 grok配置到logstash假设这个服务的日志输入到kafka里的topic叫lcshop-log，那么对应的logstash如下： 1234567891011121314151617181920212223242526272829303132333435input &#123; kafka&#123; bootstrap_servers=&gt;"172.31.0.84:9092" #这里写的是kafka的ip和端口 topics=&gt;["lcshop-log","lcshop-errorlog"] #这里是对应的topic decorate_events=&gt;"true" codec=&gt;plain &#125; &#125; filter &#123; if [@metadata][kafka][topic] == "lcshop-log" &#123; mutate &#123; add_field =&gt; &#123;"[@metadata][index]" =&gt; "lcshop-log-%&#123;+YYYY-MM&#125;"&#125; &#125; grok &#123; match =&gt; &#123; "message" =&gt; "%&#123;IPORHOST:client_ip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \[%&#123;HTTPDATE:timestamp&#125;\] \"(?:%&#123;WORD:verb&#125; %&#123;NOTSPACE:request&#125;(?: HTTP/%&#123;NUMBER:http_version&#125;)?|-)\" %&#123;NUMBER:response&#125; (?:%&#123;NUMBER:bytes&#125;|-) %&#123;QUOTEDSTRING:domain&#125; %&#123;QUOTEDSTRING:data&#125;"&#125; remove_field =&gt; ["message"] #这里对双引号增加了转义符 &#125; &#125; else if [@metadata][kafka][topic] == "lcshop-errorlog" &#123; mutate &#123; add_field =&gt; &#123;"[@metadata][index]" =&gt; "lcshop-errorlog-%&#123;+YYYY-MM&#125;"&#125; &#125; &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug #日志输出，这个看情况开启，生成日志量非常可观！ &#125; elasticsearch &#123; hosts=&gt;["172.31.0.76:9200"] #这里是es的ip和端口 index=&gt;"%&#123;[@metadata][index]&#125;" #这里对不同的topic分配不同的index &#125;&#125; 然后去kibana里查看结果,然而会发现这是失败的。 为什么明明在grok的测试网站里通过了，但是在实际的kibana里却失败？这是因为在kibana里会自动给双引号添加一个转义符！正式因为多了这个转义符，所以整段正则都不匹配了，自然grok无法生效了。 这个时候需要改成这样： 1%&#123;IPORHOST:clientip&#125; - %&#123;NOTSPACE:remote_user&#125; \[%&#123;HTTPDATE:timestamp&#125;\] \\"%&#123;DATA:request&#125;\\" %&#123;NUMBER:response&#125; %&#123;NUMBER:bytes&#125; %&#123;DATA:data&#125; \\"%&#123;DATA:detail&#125;\\" 重启logstash之后，再去kibana里看结果： 参考资料https://doc.yonyoucloud.com/doc/logstash-best-practice-cn/filter/date.htmlhttps://segmentfault.com/q/1010000003801260https://www.cnblogs.com/Orgliny/p/5592186.htmlhttp://kuring.me/post/elk_nginx/http://blog.51cto.com/seekerwolf/2106509http://blog.51cto.com/liqingbiao/1928653https://www.jianshu.com/p/d46b911fb83e]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>elk</tag>
        <tag>logstash</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维工程师笔试题第十六套]]></title>
    <url>%2F2019%2F02%2F13%2FLinux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%AC%94%E8%AF%95%E9%A2%98%E7%AC%AC%E5%8D%81%E5%85%AD%E5%A5%97%2F</url>
    <content type="text"><![CDATA[试题内容1.Mysql的bin-log有几种形式？分析其特点Statement Level模式: 123简介：每一条会修改数据的sql都会记录到master的bin-log中。Slave在复制的时候sql线程会解析成和原来master端执行过的相同语句来执行。优点：不需要记录每一行数据的变化，减少bin-log的日志量，节约IO，提高性能。因为他只记录在master上所执行语句的细节，以及执行语句时候的上下文的信息。缺点：很多新功能的加入在复制的时候容易导致出现问题。 Row Level模式: 123简介:日志中会记录成每一行数据被修改的模式，然后再slave 端在对相同的数据进行修改。优点：在row level模式下，bin-log中可以不记录执行的sql语句的上下文相关的信息。仅仅只需要记录那一条记录被修改了。所以row level的日志内容会非常清楚记录下每一行数据修改的细节，非常容易理解。而且不会出现某些特点情况下的存储过程，或function 以及triggeer的调用和触发无法被正确复制的问题。缺点：所有执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，可能会产生大量的日志。 Mixed(前两种的混合模式): 1根据执行的每一条具体的sql语句来区分对待记录日志的形式，即Mysql决定什么时候写statement格式的，什么时候写row格式的binlog。； 2.如何在线正确清理MySQL的binlog？手动删除方法如下： 123456#首先查看主从库正在使用的binlog文件名称 show master(slave) status\G#删除之前一定要备份purge master logs before'2017-09-01 00:00:00'; #删除指定时间前的日志purge master logs to'mysql-bin.000001'; 自动删除的方法如下： 1234#通过设置binlog的过期时间让系统自动删除日志#查看过期时间与设置过期时间show variables like 'expire_logs_days'; set global expire_logs_days = 30; binlog记录了数据中的数据变动，便于对数据的基于时间点和基于位置的恢复。但是也要定时清理，不然越来越大。 3.简述MySQL主从复制原理及配置主从的完整步骤。MySQL主从是一个异步过程（网络条件上佳的话，同步效果几乎是实时），原理就是从库得到主库的binlog，然后执行这个binlog的内容，达到两边数据库数据一致的目的。具体工作步骤如下： 主mysql服务器将数据库更新记录到binlog中，使用自己的log dump线程将binlog先读取然后加锁，再发送到从库，在从库当读取完成，甚至在发动给从节点之前，锁会被释放； 当从库上执行start slave命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的binlog。I/O线程接收到主节点binlog dump进程发来的更新之后，保存在本地relay log中。 从库此时还有一个SQL线程，它负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。 切记！在从库上使用show slave status\G；看到结果里的Slave_IO_Running:Yes和Slave_SQL_Running:Yes，才算是同步成功，两个YES缺一不可。注意！MySQL只读实例的Binlog日志是没有记录更新信息的，所以它的Binlog无法使用。4.如何理解MySQL里最大连接数和请求数之间的关系假设某个数据库的最大连接数是1000，并不是指最多只能支持1000个访问，因为数据库与应用之间肯定会隔着中间件，这个中间件的连接池会管理链接，一般如果代码写的好、事物控制得当，一个事物完成连接会被连接池收回重复利用，所以不是说一个用户登录你的系统或网站就一直占用着，一个连接也可以包含多次请求。5.MySQL出现IOPS过高，应该如何处理？IOPS (Input/Output Operations Per Second)，即每秒进行读写（I/O）操作的次数。IOPS是指存储每秒可接受多少次主机发出的访问，主机的一次IO需要多次访问存储才可以完成。IOPS过高比较普遍的原因是实例内存满足不了缓存数据或排序等需要，导致产生大量的物理IO或者是查询执行效率低，扫描过多数据行。6.Sort_Buffer_Size是什么参数？设置它对服务器性能有何影响？Sort_Buffer_Size是一个connection级参数，在每个connection第一次需要使用这个buffer的时候，一次性分配设置的内存。Sort_Buffer_Size并不是越大越好，由于是connection级的参数，过大的设置+高并发可能会耗尽系统内存资源。Sort_Buffer_Size超过256KB的时候，MySQL就会使用mmap()而不是malloc()来进行内存分配，导致性能损耗、效率降低。如果列长度大于max_length_for_sort_data的参数值的话，iowait会增加, 响应时间明显变长。此时通过show processlist查看,发现有很多session在处理sort操作,此时需要适当调大max_length_for_sort_data的参数值。7.如何从MySQL全库备份中恢复某个库和某张表主要用到的参数是–one-database简写-o的参数，举个例子： 1234全库备份[root@HE1 ~]# mysqldump -uroot -p --single-transaction -A --master-data=2 &gt;dump.sql只还原erp库的内容[root@HE1 ~]# mysql -uroot -pMANAGER erp --one-database &lt;dump.sql从全库备份中抽取出t表的表结构: 1sed -e'/./&#123;H;$!d;&#125;' -e 'x;/CREATE TABLE `t`/!d;q' dump.sql从全库备份中抽取出t表的内容: 1grep'INSERT INTO `t`' dump.sql8.随意举出一次解决Mysql故障的事例Mysql反应很慢，发现服务器CPU飙升，出现僵尸进程但是连接数并不高，show processlist发现有大量的unauthenticated user。通过更改配置文件/etc/my.cnf里的在[mysqld]那一栏中添加skip-name-resolve，然后重启mysql即可解决。注意！ skip-name-resolve可以禁用dns解析，但是，这样不能在mysql的授权表中使用主机名了，只能使用IP。以前创建mysql用户是若用的是localhost现在则需要用127.0.0.1来代替在grant语句中执行一下添加该用户。当然CPU飙升还有其他情况：查询以及大批量的插入或者是网络状态突然断了,导致一个请求服务器只接受到一半…9.你们数据库是否支持emoji表情，如果不支持，如何操作？如果是utf8字符集的话，需要升级至utf8_mb4方可支持。10.mysqldump备份时，–master-data选项的作用是什么？还用过其他的参数么？--master-data选项的作用就是将二进制的信息写入到输出文件中，即写入备份的sql文件中。1. --master-data=2表示在dump过程中记录主库的binlog和pos点，并在dump文件中注释掉这一行；2. --master-data=1表示在dump过程中记录主库的binlog和pos点，并在dump文件中不注释掉这一行，即恢复时会执行；3. --dump-slave=2表示在dump过程中，在从库dump，mysqldump进程也要在从库执行，记录当时主库的binlog和pos点，并在dump文件中注释掉这一行；4. --dump-slave=1表示在dump过程中，在从库dump，mysqldump进程也要在从库执行，记录当时主库的binlog和pos点，并在dump文件中不注释掉这一行；注意!在从库上执行备份时，即–dump-slave=2，这时整个dump过程都是stop io_thread的状态加了--single-transaction就能保证innodb的数据是完全一致的，而myisam引擎无法保证（因为myisam压根就不支持事务），要保证myisam引擎数据一致必须加--lock-all-tables。11.什么是数据库事务，事务有哪些特性？一个数据库事务通常包含对数据库进行读或写的一个操作序列。它的存在包含有以下两个目的： 12为数据库操作提供了一个从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持一致性的方法。当多个应用程序在并发访问数据库时，可以在这些应用程序之间提供一个隔离方法，以防止彼此的操作互相干扰。它的特性如下： 1234原子性（Atomicity）：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。一致性（Consistency）：事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束。隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行。持久性（Durability）：一个事务一旦提交，他对数据库的修改应该永久保存在数据库中。事务的原子性与一致性缺一不可。 12.数据表student有id,name,score,city字段，其中name中的名字可有重复，需要消除重复行,请写sql语句语句如下： 1select distinct name from student 注意！单独的distinct只能放在开头，否则就报语法错误。 参考资料https://www.cnblogs.com/wajika/p/6718552.htmlhttps://www.hollischuang.com/archives/898https://zhuanlan.zhihu.com/p/50597960https://segmentfault.com/a/1190000008663001https://segmentfault.com/a/1190000000616820http://seanlook.com/2014/12/05/mysql_mysqldump_options_examples/]]></content>
      <categories>
        <category>大牛之路</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ES对应Kafka的topic生成不同的Index]]></title>
    <url>%2F2019%2F01%2F30%2FES%E5%AF%B9%E5%BA%94kafka%E7%9A%84topic%E7%94%9F%E6%88%90index%2F</url>
    <content type="text"><![CDATA[假设有两个模块分别叫shopauth和shoporder，日志文件也对应分别是shopauth.log和shoporder.log，现在需要把日志对应放到同个kafka里不同的topic里。 shopauth的filebeat.yml内容如下： 12345678910111213141516171819filebeat.prospectors:- type: log enabled: true paths: - /mnt/shopauth/logs/shopauth.log #日志路径 tags: ["logmessages"] encoding: utf-8 scan_frequency: 10s harvester_buffer_size: 15000 tail_files: true fields: alilogtype: app_log serverip: 172.16.0.201 #本地IP地址 log_topics: ecnode-logoutput.kafka: enabled: true hosts: ["172.31.0.84:9092"] #指定kafka的地址信息 topic: '%&#123;[fields][log_topics]&#125;' #自动识别topic 如果只有一个log源输入日志（不是指paths只有一个路径，paths可以同时指定多个路径），那么output.kafka的topic当然可以写死。如果是多个log源写入日志，而且又要对应输入到kafka的topic里，可以使用&#39;%{[fields][log_topics]}&#39;，达到自动识别的目的。 但是要注意！如果加上了fields_under_root: true，那么&#39;%{[fields][log_topics]}&#39;是错误的，要改成topic: &quot;%{[log_topic]}&quot;才可以。 shoporder的filebeat.yml内容如下： 123456789101112131415161718filebeat.prospectors:- type: log enabled: true paths: - /mnt/shoporder/logs/shoporder.log #指定路径 tags: ["logmessages"] encoding: utf-8 scan_frequency: 10s harvester_buffer_size: 15000 tail_files: true fields: alilogtype: app_log serverip: 172.16.0.207 #本地IP地址output.kafka: enabled: true hosts: ["172.31.0.84:9092"] #指定kafka的地址信息 topic: 'shoporder-log' #指定topic 启动filebeat和kafka，kafka的配置这里略过不表。在kafka里查看，发现已经生成对应的topic： 而logstash.yml内容如下： 123456789101112131415161718192021222324252627input &#123; kafka&#123; bootstrap_servers=&gt;"172.31.0.84:9092" #指定kafka的IP和端口 topics=&gt;["shoporder-log","shopauth-log"] #说明从这两个topic里消费 decorate_events=&gt;"true" #这个很重要，等会细说 codec=&gt;plain &#125;&#125;filter &#123; #利用kafka域的内容构建自定义的域 if [@metadata][kafka][topic] == "shopauth-log" &#123; mutate &#123; add_field =&gt; &#123;"[@metadata][index]" =&gt; "shopauth-log-%&#123;+YYYY-MM&#125;"&#125; &#125; &#125; else if [@metadata][kafka][topic] == "shoporder-log" &#123; mutate &#123; add_field =&gt; &#123;"[@metadata][index]" =&gt; "shoporder-log-%&#123;+YYYY-MM&#125;"&#125; &#125; &#125;&#125;output &#123; elasticsearch &#123; hosts=&gt;["172.31.0.76:9200"] #指定es的IP和端口 index=&gt;"%&#123;[@metadata][index]&#125;" #对应生成各自的index &#125;&#125; 说一下decorate_events，如果只用了单个logstash，订阅了多个主题，你肯定希望在es中为不同主题创建不同的索引，那么decorate_events就是你想要的配置项。这个值默认是false，当指定这个选项为true时，会附加kafka的一些信息到logstash event的一个名为kafka的域（Metadata fields）中，然后再通过filter进行判断，如果是从shopauth-log这个topic得到信息，就把index设定成shopauth-log-%{+YYYY-MM}&quot;。 启动logstash，待其正常之后，在es的控制台查看日志，发现index索引已经成功生成： 现在在kibana里就可以创建索引然后查找了！]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>elk</tag>
        <tag>logstash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决html里单引号转义的问题]]></title>
    <url>%2F2019%2F01%2F23%2F%E8%A7%A3%E5%86%B3html%E9%87%8C%E5%8D%95%E5%BC%95%E5%8F%B7%E8%BD%AC%E4%B9%89%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[正文在使用Django展现页面的时候，会出现这样的一个需求： 我们在views.py里获取到的一个数组，比如叫name，内容是：[&#39;james&#39;,&#39;wade&#39;,&#39;bosh&#39;,&#39;yaoming&#39;]，然后return render_to_response(&#39;a.html&#39;,{&#39;names&#39;:name,})，让a.html可以使用到这个name数组。若在a.html里需要对这个name数组进行for循环展示，正常思路的话，js如下： 123456function test() &#123; var name="&#123;&#123;names&#125;&#125;".split(",") alert(name) 进行for循环，略过不表 &#125; 那么得到的会是如下效果： 可见虽然name在views.py里是list，但是传入到html是一个字符串，对于字符串使用split按照逗号分隔。而html里会把单引号转义成了&amp;#39;，而&amp;#39;这个玩意儿比较恶心，它不能被JSON.parse加工成一个数组，进而不能被for循环。 那么遇到这种问题怎么办?改成这样： 1234567function test() &#123; var str="&#123;&#123;names&#125;&#125;".replace(/&amp;#39;/g,'"') var name=JSON.parse(str) alert(name) 进行for循环，略过不表 &#125; 执行效果如下：上面代码首先先把所有的单引号replace成双引号，Html是不会转义双引号的，所以就可以正常使用了。 当然如果views.py里提供的name直接是双引号的话，就不用这么折腾了。 数组如何使用双引号而不是单引号python默认生成数组是单引号的，也就是说是[&#39;apple&#39;,&#39;banana&#39;,&#39;candy&#39;]的样子，而不会自动生成[&quot;apple&quot;,&quot;banana&quot;,&quot;candy&quot;]，这一点是不能改变的。那么要获得到双引号的数组，比较好的办法是json： 12345&gt;&gt;&gt; names = ['james','wade','bosh','yaoming']&gt;&gt;&gt; import json&gt;&gt;&gt; print(json.dumps(names))["james", "wade", "bosh","yaoming"] 如果元素是中文的话，那么就要用(json.dumps(names,ensure_ascii=False))。 与正文内容无关的补充Centos 7修改中文字符集的方法： 123localedef -c -f UTF-8 -i zh_CN zh_CN.UTF-8export LC_ALL=zh_CN.UTF-8echo 'LANG="zh_CN.UTF-8"' &gt; /etc/locale.conf]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>html</tag>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将本地时间转化成UTC时间]]></title>
    <url>%2F2019%2F01%2F22%2F%E5%B0%86%E6%9C%AC%E5%9C%B0%E6%97%B6%E9%97%B4%E8%BD%AC%E5%8C%96%E6%88%90UTC%E6%97%B6%E9%97%B4%2F</url>
    <content type="text"><![CDATA[实际代码在日常工作中，有些时候需要把本地时间转换成UTC时间，通常来说，最直接的方法就是把北京时间（CST时间）减去8小时，但是如果考虑到夏令时，那么这样简单的数学计算就会得到错误的结果。要解决这种涉及时区的问题，就要使用特殊的模块pytz。 1234567891011121314151617181920212223Python 3.6.4 (default, Sep 3 2018, 10:11:51) [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)] on linuxType "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; import datetime,time,pytz #引入模块&gt;&gt;&gt; now = time.strftime("%Y-%m-%d %H:%M:%S") #得到当前时间&gt;&gt;&gt; now'2019-01-22 14:03:03'&gt;&gt;&gt; type(now)&lt;class 'str'&gt; #此时类型是字符串&gt;&gt;&gt; now = datetime.datetime.now()&gt;&gt;&gt; nowdatetime.datetime(2019, 1, 22, 14, 4, 49, 707859) #转换成datetime模式&gt;&gt;&gt; type(now)&lt;class 'datetime.datetime'&gt;&gt;&gt;&gt; utc_time = now.astimezone(pytz.utc) #转换成了UTC时间就不要用担心夏令时等等麻烦事了&gt;&gt;&gt; print(utc_time)2019-01-22 06:04:49.707859+00:00&gt;&gt;&gt; type(utc_time)&lt;class 'datetime.datetime'&gt; #还需要将datetime格式转换成str&gt;&gt;&gt; utc_now = utc_time.strftime('%Y-%m-%d %H:%M:00')'2019-01-22 13:57:00'&gt;&gt;&gt; type(utc_now)&lt;class 'str'&gt; #此时返回了字符串 上面的代码说明了过程，以及得到的东西的类型，其实精简下来只有三行： 123456&gt;&gt;&gt; import datetime,time,pytz&gt;&gt;&gt; now = datetime.datetime.now()&gt;&gt;&gt; utc_time = now.astimezone(pytz.utc)&gt;&gt;&gt; utc_now = utc_time.strftime('%Y-%m-%dT%H:%M:00Z')&gt;&gt;&gt; print (utc_now)2019-01-22T06:46:00Z 如果要查时区名称，可以使用pytz.country_timezones，如下： 12345&gt;&gt;&gt; from pytz import timezone &gt;&gt;&gt; pytz.country_timezones['CN']['Asia/Shanghai', 'Asia/Urumqi']&gt;&gt;&gt; pytz.country_timezones['US']['America/New_York', 'America/Detroit', 'America/Kentucky/Louisville', 'America/Kentucky/Monticello', 'America/Indiana/Indianapolis', 'America/Indiana/Vincennes', 'America/Indiana/Winamac', 'America/Indiana/Marengo', 'America/Indiana/Petersburg', 'America/Indiana/Vevay', 'America/Chicago', 'America/Indiana/Tell_City', 'America/Indiana/Knox', 'America/Menominee', 'America/North_Dakota/Center', 'America/North_Dakota/New_Salem', 'America/North_Dakota/Beulah', 'America/Denver', 'America/Boise', 'America/Phoenix', 'America/Los_Angeles', 'America/Anchorage', 'America/Juneau', 'America/Sitka', 'America/Metlakatla', 'America/Yakutat', 'America/Nome', 'America/Adak', 'Pacific/Honolulu'] 参考资料https://www.cnblogs.com/cathouse/archive/2012/11/19/2777678.htmlhttps://blog.csdn.net/junli_chen/article/details/52999448《Python cookbook》字符串如何转化成日期《Python cookbook》处理设计到市区的日期问题]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python3</tag>
        <tag>UTC时间</tag>
        <tag>时区转换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[较深入解析filebeat.yml各字段功能]]></title>
    <url>%2F2019%2F01%2F21%2F%E8%BE%83%E6%B7%B1%E5%85%A5%E8%A7%A3%E6%9E%90filebeat-yml%E5%90%84%E5%AD%97%E6%AE%B5%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[首先，6.0之后的版本的filebeat，已经不再支持document_type这个选项了。因为ES6不再支持自己在同一个index下定义多个type。 常见的几个参数以下面这个filebeat.yml为例： 1234567891011121314151617181920212223242526filebeat.prospectors:- type: log #这个值可以是stdin(读入标准)、udp（通过udp读取事件） enabled: true paths: - /var/log/messages #指定文件，可以使用通配符 tags: ["logmessages"] #lostash能区分不同目录发过来的日志，用tag区分 encoding: utf-8 #设置字符编码 scan_frequency: 10s #每 10 秒钟扫描一次 harvester_buffer_size: 15000 #实际读取文件时，每次读取15000字节 tail_files: true #是否从文件末尾开始读取 fields: alilogtype: usercenter_serverlog serverip: 172.16.0.207 fields_under_root: true #field 字段会放在根索引下，否则会放在 fields 字段下#这里添加第二个日志路径 - type: log enabled: true paths: - /tmp/test.log tags: ["test"]output.kafka: enabled: true hosts: ["172.31.0.84:9092"] topic: 'system-secure' #支持 topic: '%&#123;[fields][alilogtype]&#125;' 这种写法 在kibana上看到的效果如图： exclude和include而如果是这样： 123456789101112- type: log enabled: true paths: - /tmp/test.log exclude_lines: ['^JAMES'] #排除掉JAMES开头的行 include_lines: ['^HARDEN', '^CURRY'] #保留HARDEN或者CURRY开头的行 tags: ["test"]output.kafka: enabled: true hosts: ["172.31.0.84:9092"] topic: 'system-secure' 效果如图： 注意！如果同时定义了include_lines和exclude_lines，则Filebeat首先执行include_lines，然后执行exclude_lines。 这两个选项的定义顺序无关紧要。 即使exclude_lines出现在配置文件中的include_lines之前，include_lines选项也会始终在exclude_lines选项之前执行。 参考资料http://www.xiaot123.com/post/elk_filebeat1https://blog.csdn.net/u013613428/article/details/78665081http://www.51niux.com/?id=204https://github.com/wangriyu/docker-elk/wiki/Filebeat-Kafka-ELK]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>elk</tag>
        <tag>filebeat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将kafka加入到Elk集群]]></title>
    <url>%2F2019%2F01%2F21%2F%E5%B0%86kafka%E5%8A%A0%E5%85%A5%E5%88%B0Elk%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[环境交代架构如图： 1（目标模块 ---&gt;filebeat） ---&gt;（kafka ---&gt;logstash） ---&gt;（es ---&gt;kibana） 具体服务器信息如下： 1234172.16.0.207 工作模块+filebeat CentOS 7.4 64位 阿里云1核2G172.31.0.84 kafka+logstash CentOS 7.4 64位 阿里云2核4G172.31.0.76 es+es-head+kibana CentOS 7.4 64位 阿里云2核16G安全组已经开放了elk相应的端口 首先先执行yum update -y &amp;&amp; yum install java-1.8.0-openjdk* -y，在更新的时候不要闲着，在https://www.elastic.co/downloads网站下载所有的elk模块，然后上传到对应的服务器里。 filebeat的部署、配置和启动filebeat与目标机器安装在一起，它是用6.5.4版本，先从官网上下载rpm包，然后上传到服务器里。 1234#假设已经下载好了filebeat-6.5.4-x86_64.rpmrpm -ivh filebeat-6.5.4-x86_64.rpmcd /etc/filebeatcp filebeat.yml filebeat.yml-default #备份模板配置文件 修改filebeat.yml如下： 12345678910filebeat.prospectors:- type: log enabled: true paths: - /var/log/messages #设定日志输入源output.kafka: enabled: true hosts: ["172.31.0.84:9092"] #这里填入kafka的地址和端口 topic: 'system-secure' #指定一个topic 配置文件说明了数据的来源和目的地，使用/etc/init.d/filebeat start -e -c /etc/filebeat/filebeat.yml启动filebeat，然后ps -aux|grep filebeat查看一下进程。而filebeat的日志地址是在/var/log/filebeat目录下。 logstash的部署、配置和启动logstash是跟kafka在一台服务器里，首先是下载包并且解压缩： 123wget https://artifacts.elastic.co/downloads/logstash/logstash-6.5.4.tar.gztar -zxvf logstash-6.5.4.tar.gz -C /opt/cd /opt/logstash-6.5.4/config 新建一个配置文件，叫logstash_kafka2ES.conf： 12345678910111213input &#123; kafka&#123; bootstrap_servers=&gt;"172.31.0.84:9092" #kafka的地址和端口 topics=&gt;"system-secure" #topic要一致 codec=&gt;plain &#125;&#125;output &#123; elasticsearch &#123; hosts=&gt;["172.31.0.76:9200"] #es的地址和端口 index=&gt;"system-secure-%&#123;+YYYY-MM&#125;" #规定es使用的索引，按月份分类 &#125;&#125; 配置文件里规定数据来源是kafka的system-secure这个topic，再修改同目录下的jvm.options： 12-Xms512m #根据自己实际情况来-Xmx512m #根据自己实际情况来 保存退出，./bin/logstash -f ./config/logstash_kafka2ES.conf &amp;启动之，日志是logstash目录/logs/logstash-plain.log。 kafka的配置和启动已经在https://rorschachchan.github.io/2019/01/16/%E6%90%AD%E5%BB%BAKakfa2-11%E4%B8%BAELK%E6%9C%8D%E5%8A%A1/ 里说过了，这里略过。 elasticsearch-6.5.4的部署、配置和启动登录到es的服务器上，首先先下载安装包并且解压缩： 12345wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.5.4.tar.gztar -zxvf elasticsearch-6.5.4.tar.gz -C /opt/cd elasticsearch-6.5.4/useradd elk #es不能用root启动，需要新建一个用户chown -R elk:elk elasticsearch-6.5.4/ #整个文件夹都给elk了 修改一下elasticsearch.yml： 123456789#cluster.name: my-application #由于实验环境是一个es，就没写集群名称node.name: lcshopelkpath.data: /opt/elasticsearch-6.5.4/data/ #存数据的地方path.logs: /data/tmp/elklog #存日志的路径bootstrap.memory_lock: true #为了防止swapping，官方建议设定为true，阿里云的云服务器是没有swap，可以不写network.host: 0.0.0.0http.port: 9200http.cors.enabled: true #准许es-headhttp.cors.allow-origin: "*" 保存之后修改同目录的jvm.options： 12-Xms2g #根据自己实际情况来-Xmx2g #根据自己实际情况来 这里的配置，官网标准的建议是把50％的可用内存作为Elasticsearch的堆内存，保留剩下的50％。当然它也不会被浪费，Lucene会很乐意利用起余下的内存。查看node下是否开启了Mem_lock的语句是：curl &#39;localhost:9200/_nodes?filter_path=**.mlockall&#39;。 保存完毕，还没完,vim /etc/security/limits.conf，最后两行改成如下: 12345* soft nofile 65536* hard nofile 65536# allow user 'elk' mlockallelk soft memlock unlimitedelk hard memlock unlimited 然后切换成elk用户，执行./elasticsearch -d就是后台启动了。 简单的几句es命令： 1234curl -XGET http://127.0.0.1:9200/_cat/allocation?v #查看本机node磁盘容量curl -XGET http://127.0.0.1:9200/_cat/nodes?v #能查看node的CPU和负载情况curl -XGET http://127.0.0.1:9200/_aliases #查看所有的索引curl 'http://localhost:9200/_search?pretty' #查看索引一些细节 kibana和es-head的部署、配置和启动es-head是用docker部署的，语句如下： 12#假设docker已经安装好了docker run --name es-head -p 9100:9100 tobias74/elasticsearch-head:6 #这里必须安装6版本，不然的话，数据不会显示 运行完之后，要进入到容器里修改一下对应的配置文件Gruntfile.js，修改一下connect段落： 12345678910connect: &#123; server: &#123; options: &#123; port: 9100, base: '.', keepalive: true, hostname: '*' #新增加这样一句话 &#125; &#125; &#125; 保存文件，docker restart es-head即可。在浏览器里访问外网ip地址:9100，如图： Kibana也是用docker部署的，语句如下： 12#假设docker已经安装好了docker run --name kibana -p 5601:5601 docker.elastic.co/kibana/kibana:6.5.4 运行完之后，要进入到容器里修改一下对应的配置文件kibana.yml： 123456789101112---# Default Kibana configuration from kibana-docker.server.name: kibanaserver.host: "0.0.0.0" #准许所有人访问elasticsearch.url: http://es外网IP:9200xpack.monitoring.ui.container.elasticsearch.enabled: false# SSL for outgoing requests from the Kibana Server (PEM formatted)server.ssl.enabled: trueserver.ssl.key: /usr/share/kibana/config/mykey.key #这里是https证书server.ssl.certificate: /usr/share/kibana/config/mycert.crt #这里是https证书 修改完事之后，docker restart kibana，然后在浏览器里访问外网ip地址:9100就可以查看kibana了，然后先去menagement —&gt;index pattern填入刚刚生成的index，然后在discover页面里选择刚刚生成的index就能看到日志内容了： X-pack目前还不支持6.2以上的版本，故此先略。因为没有X-pack，所以再kibana.yml里的elasticsearch.url我们还是写http，有了X-pack就要改成elasticsearch.url: &quot;https://&lt;your_elasticsearch_host&gt;.com:9200&quot;的样子，让es与kibana之间的传输是加密的。 参考资料https://dzone.com/articles/just-say-no-swappinghttps://www.elastic.co/guide/cn/elasticsearch/guide/cn/heap-sizing.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>elk</tag>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建Kakfa2.11为ELK服务]]></title>
    <url>%2F2019%2F01%2F16%2F%E6%90%AD%E5%BB%BAKakfa2-11%E4%B8%BAELK%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[准备工作试验机器：阿里云centos 7.5，IP地址是172.31.0.84。 本文是单台kafka+zookeeper架构，如果土豪可以尝试3台zookeeper+3台kafka。 12345yum install java-1.8.0-openjdk* -ywget http://apache.website-solution.net/kafka/2.1.0/kafka_2.11-2.1.0.tgztar -zxvf kafka_2.11-2.1.0.tgz -C /optwget http://apache.website-solution.net/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gztar -zxvf zookeeper-3.4.10.tar.gz -C /usr/local 其实最新的kafka里面已经包括zookeeper了，不过我习惯了单独启动zookeeper，还是单独下载单独配置单独启动。 启动zookeeper首先先去zookeeper下的conf文件夹里编写配置文件： 12/usr/local/zookeeper-3.4.10/confcp zoo_sample.cfg zoo.cfg 然后编辑zoo.cfg，把最下面几行改成这样： 12345autopurge.snapRetainCount=3 #保留3个文件# Purge task interval in hours# Set to "0" to disable auto purge featureautopurge.purgeInterval=1 #保留一小时以内的日志server.1=172.31.0.84:2888:3888 #本机IP地址 2888端口：表示的是这个服务器与集群中的Leader服务器交换信息的端口；3888端口：表示的是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。 然后回到/usr/local/zookeeper-3.4.10/bin里，执行./zkServer.sh start，执行完毕之后，再用./zkServer.sh status检查一下状态，由于是单台，所以状态应该是standalone。 启动kafka同zookeeper一样，先去kafka的conf文件夹/opt/kafka_2.11-2.1.0/config里，在配置文件zookeeper.properties最下面加上如下几句话: 1234tickTime=2000initLimit=20syncLimit=10server.1=172.31.0.84:2888:3888 #zookeeper的地址，也就是本机地址 tickTime:这个时间是作为Zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个tickTime时间就会发送一个心跳。 修改好了zookeeper.properties之后，才是正式的kafka配置文件server.properties： 12345678broker.id=1port=9092 #broker监听的端口host.name=172.31.0.84 #填服务器 IPlog.dir = / data / kafka - logs # 该目录可以不用提前创建，在启动时自己会创建zookeeper.connect = 172.31.0.84:2181 # 这个就是zookeeper的ip及端口num.partitions = 16 # 需要配置较大 分片影响读写速度log.dirs = /data/kafka-logs # 数据目录也要单独配置磁盘较大的地方log.retention.hours = 168 # 时间按需求保留过期时间,避免磁盘满 确认zookeeper状态是启动之后，./bin/kafka-server-start.sh ./config/server.properties &amp;来启动Kafka服务，然后检查一下端口9092是否正常打开 kafka简单操作语句一些常用的操作语句如下： 12345678#创建topic./kafka-topics.sh --create --zookeeper 172.31.0.84:2181 --replication-factor 1 --partitions 1 --topic chenshuotest #factor大小不能超过broker的个数#查看topic./kafka-topics.sh --list --zookeeper 172.31.0.84:2181#在topic里增加信息./kafka-console-producer.sh --broker-list 172.31.0.84:9092 --topic chenshuotest#消费掉topic里的信息，需要在另外一个xshell窗口界面操作./kafka-console-consumer.sh --bootstrap-server 172.31.0.84:9092 --topic chenshuotest --from-beginning 参考文档http://www.cnblogs.com/JetpropelledSnake/p/10057545.html （zookeeper+kafka集群的配置，请看这里）]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>kafka</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Django里添加Celery让脚本异步在后台运行]]></title>
    <url>%2F2019%2F01%2F16%2F%E5%9C%A8Django%E9%87%8C%E6%B7%BB%E5%8A%A0Celery%E5%81%9A%E5%BC%82%E6%AD%A5%E4%BB%BB%E5%8A%A1%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[前言当使用Django执行脚本的时候，经常遇到一种情况：跳转到某个url，结果是先在后台执行一个时间较长的脚本，然后才能打开这个url页面，这样用户体验就很不好。 比如说像这样的views.py配置： 12345678910111213141516171819202122232425#使用ansible执行远程命令@csrf_exemptdef run_command(request): command = "ansible all -i /root/.ssh/hosts -m shell -a 'echo 'worinixianren' &gt;&gt; /tmp/xianren.txt'" #设定ansible远程命令 if request.method == 'POST': id = request.POST.getlist("ecs") #通过html来获取id num = [] num.append(len(id)) #传递参数，给下一个页面用的 name = [] #传递参数，给下一个页面用的 db = pymysql.connect("阿里云数据库","数据库账号","数据库密码","databases名") #根据上面获得的id去数据库里得到对应的内网IP cursor = db.cursor() with open('/root/.ssh/hosts','w') as f: for i in id: sql = 'select * from createyaml_ecs where name = "'+ i + '";' cursor.execute(sql) ip = cursor.fetchall()[0][3] cursor.execute(sql) name.append(cursor.fetchall()[0][1]) f.write(ip+" ansible_ssh_user=root"+"\n") #将得到的内网IP写入到一个文件里 db.close() #关闭数据库 child = subprocess.Popen(command,stdout=subprocess.PIPE, stderr=subprocess.PIPE,shell=True) #执行ansible命令 stdout, stderr = child.communicate() return render(request,'run_command.html',&#123;'data':num[0],'name':name&#125;) #将内容反馈到html页面里 else: return render(request,'homepage.html') 像上面这段代码，要看到run_command.html页面就要先把整个ansible部署的脚本全跑完，如果是几百台机器批量操作的脚本，那就要等到海枯石烂水倒流。那遇到这样的情况怎么解决呢？根据不同的请求，有不同的对策： 单纯的后台跑一个脚本，那么就可以使用Celery； 在后台跑脚本的同时，还需要不断的向后台发送请求（比如微信上的茶叶妹聊天机器人），那么就要使用Channels； Celery原理部分和配置定时任务就不多说了，文末的参考资料里有网站，这里主要说的是如何配置Celery。 环境交代存储后端:阿里云redis(需要支持evalsha命令，如果不支持，去控制台升级小版本即可)Python:3.6.5Django:2.1.1django-celery:3.2.2，安装方法：pip install django-celerycelery-with-redis：3.0，安装方法pip install celery-with-rediscelery:3.1.26.post2 具体配置首先配置setting.py，全文最后添加这样几句话： 1234567891011121314#celery配置信息#celery中间人 redis://:redis密码@redis服务所在的ip地址:端口/数据库号，我用的是254号#channels配置redis也是这样配置，如果没有密码，就可以把':redis密码@'省略BROKER_URL = 'redis://:redis密码@阿里云redis地址:6379/254'#celery结果返回，可用于跟踪结果CELERY_RESULT_BACKEND = 'redis://:redis密码@阿里云redis地址:6379/254'#celery内容等消息的格式设置CELERY_ACCEPT_CONTENT = ['application/json',]CELERY_TASK_SERIALIZER = 'json'CELERY_RESULT_SERIALIZER = 'json'#celery时区设置，使用settings中TIME_ZONE同样的时区CELERY_TIMEZONE = TIME_ZONE 在setting.py同级的文件夹里创建celery.py，内容如下： 12345678910111213141516171819202122#coding:utf-8from __future__ import absolute_import, unicode_literals from celery import Celeryfrom django.conf import settingsimport os #获取当前文件夹名，即为该Django的项目名project_name = os.path.split(os.path.abspath('.'))[-1]project_settings = '%s.settings' % project_name #设置环境变量os.environ.setdefault('DJANGO_SETTINGS_MODULE', project_settings) #实例化Celeryapp = Celery(project_name) #使用django的settings文件配置celeryapp.config_from_object('django.conf:settings') #Celery加载所有注册的应用app.autodiscover_tasks(lambda: settings.INSTALLED_APPS) 还是在同样的文件夹里，编辑__init__.py： 12345#coding:utf-8from __future__ import absolute_import, unicode_literals #引入celery实例对象from .celery import app as celery_app 然后在app（具体应用的文件夹里），创建一个叫tasks.py，这里面就是需要在后台执行的具体脚本： 1234567891011#coding:utf-8from celery.decorators import taskimport subprocess@task #在原有的方法上加上celery装饰器task#ansible批量部署命令def run_ansible(): command = "ansible all -i /root/.ssh/hosts -m shell -a 'echo 'worinixianren' &gt;&gt; /tmp/xianren.txt'" #设定命令 child = subprocess.Popen(command,stdout=subprocess.PIPE, stderr=subprocess.PIPE,shell=True) stdout, stderr = child.communicate() print ("success!!!") #执行成功！ 保存退出之后，修改原有的views.py，把原来涉及脚本的字段删除，改成: 12345678910111213141516171819202122@csrf_exemptdef run_command(request): if request.method == 'POST': id = request.POST.getlist("ecs") num = [] num.append(len(id)) #传递参数，给下一个页面用的 name = [] db = pymysql.connect("阿里云数据库","数据库账号","数据库密码","databases名") cursor = db.cursor() with open('/root/.ssh/hosts','w') as f: for i in id: sql = 'select * from createyaml_ecs where name = "'+ i + '";' cursor.execute(sql) ip = cursor.fetchall()[0][3] cursor.execute(sql) name.append(cursor.fetchall()[0][1]) f.write(ip+" ansible_ssh_user=root"+"\n") db.close() run_ansible.delay() #celery异步执行后台ansible程序，使用delay函数 return render(request,'run_command.html',&#123;'data':num[0],'name':name&#125;) else: return render(request,'homepage.html') 返回到manage.py所在的目录，先正常启动django，然后再/usr/local/python3/bin/celery -A project名称 worker -l info启动celery，如图： 看到tasks.py已经成功被celery使用了，然后在页面上去执行原本的命令，就会看到celery页面有刷新： 此时再去redis里查看一下存储的效果： 可见tasks执行的状态已经被保存到了redis里。但是上面我们是在前台页面启动celery，如果想把celery作为一个后台守护进程，那么命令语句如下： 1/usr/local/python3/bin/celery multi start worker -A project名称 -l info 效果如图： 停止或重启将上面的start换为stop或restart即可。 补充如果tasks.py内容变化了，需要重启celery才能生效。 如果在启动celery的时候，日志有写UserWarning: Using settings.DEBUG leads to a memory leak, never use this setting in production environments! warnings.warn(&#39;Using settings.DEBUG leads to a memory leak, never &#39;，那么就在settings.py里把DEBUG = True改成DEBUG = False即可。 查看redis有几个库的命令：config get databases。 参考资料http://yshblog.com/blog/163 （对照代码做一遍就更有体会了）https://www.cnblogs.com/wdliu/p/9517535.html (原理以及如何配置定时任务)https://www.cnblogs.com/wdliu/p/9530219.htmlhttp://docs.celeryproject.org/en/latest/getting-started/brokers/redis.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>celery</tag>
        <tag>异步任务</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[大量任务冲击下的activeMQ报错"GC overhead limit exceeded"]]></title>
    <url>%2F2019%2F01%2F14%2F%E5%A4%A7%E9%87%8F%E4%BB%BB%E5%8A%A1%E5%86%B2%E5%87%BB%E4%B8%8B%E7%9A%84activeMQ%E6%8A%A5%E9%94%99GC-overhead-limit-exceeded%2F</url>
    <content type="text"><![CDATA[半夜阿里云的杭州可用B区出现了机房抖动，几乎所有的B区服务全部掉线。阿里云的技术人员捅咕了半个小时左右，在大约11点40左右恢复了正常。此时几百万的设备开始同时恢复上线，然而经过了1个小时左右，依旧有几十万设备无法上线，有的甚至上线后又掉线。 我们的架构是设备要先去“注册中心”注册，注册成功之后才会正常的工作。如果多次注册不成功，就会释放连接，把连接让给其他需要注册的设备。但是发现设备上线的速度很慢，扩容了几台“注册中心”模块，效果依旧不见好转。发现注册模块的CPU全部都达到了100%： 登录到服务器里一看，日志不断的刷新这样的内容： 模块与activemq的延迟特别大，此时activemq又有几百万的消息没有消费堆积在队列里。大约十分钟左右，就开始抛出java.lang.OutOfMemoryError: GC overhead limit exceeded的错误，如图： 但是同一时间段里的activemq并没有出现内存吃紧的情况： 没有办法，就先赌一下的重启了activemq，没想到问题就解决了… 奇怪，明明activemq没有内存的明显消耗，却报内存耗尽。先把结果记录下来，等下一次再有类似的情况，好好观察一下（也但愿不要再在放假的时候出现故障了…）]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Zabbix的Python api去获取当前监控值]]></title>
    <url>%2F2019%2F01%2F09%2F%E4%BD%BF%E7%94%A8Zabbix%E7%9A%84python-api%E5%8E%BB%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E7%9B%91%E6%8E%A7%E5%80%BC%2F</url>
    <content type="text"><![CDATA[事前准备有些时候我们需要在非zabbix的web界面里得到zabbix-server对某台服务器的实时监控值。但是有些值是zabbix-server加工过的，比如eth0入网流量，zabbix-server加工的方法如下： 可见是每秒的变量并且还乘了8，那么如果要得到这样加工过的值，想通过shell得到linux的指标无疑是十分麻烦的。那么对于这种需求，我们想到的第一个办法就是使用zabbix的api，通过api去获取值比爬网页要方便许多（而且zabbix-server的web页面不是那么好爬的）。 Zabbix 3.0的API官方文档：https://www.zabbix.com/documentation/3.0/manual/apiZabbix 3.0的python版API官方文档：https://github.com/gescheit/scripts/tree/master/zabbix这里我更推荐用python版的api，因为使用zabbix-api这个python第三方库让开发变得更为简洁。 安装zabbix-api安装zabbix-api最方便的方法就是pip安装。本文的python版本2.7.15，使用源码安装的，安装包并不带pip，那么安装pip的方法如下： 123456789101112yum install -y zlib-devel zlib openssl openssl-develmv /usr/bin/pip /usr/bin/pip-bak #备份原有的pipwget --no-check-certificate https://pypi.python.org/packages/source/s/setuptools/setuptools-12.0.3.tar.gz#md5=f07e4b0f4c1c9368fcd980d888b29a65tar -zxvf setuptools-12.0.3.tar.gzcd setuptools-12.0.3python setup.py install #这一步需要上面刚安装的zlibwget https://files.pythonhosted.org/packages/d0/92/1e8406c15d9372084a5bf79d96da3a0acc4e7fcf0b80020a4820897d2a5c/pip-7.1.2.tar.gz#或者去https://pypi.org/project/pip/7.1.2/#files页面下载pip-7.1.2.tar.gz tar -zxcf pip-7.1.2.tar.gzcd pip-7.1.2sudo python setup.py installln -s /usr/local/python27/bin/pip2.7 /usr/bin/pip #做一个新的快捷方式 有了pip之后，就可以安装zabbix-api，命令是：pip install zabbix-api 。在python的命令行里输入from zabbix_api import ZabbixAPI不报错就代表安装成功。 链接zabbix通过zabbix-server鉴权的代码如下： 123456#coding:utf-8#这个脚本是用来获取zabbix 定时流量值from zabbix_api import ZabbixAPIzapi = ZabbixAPI(server="http://网页地址/zabbix/api_jsonrpc.php") zapi.login("网页的用户名", "网页的密码") #鉴权 如果没报错，就证明已经成功连接到zabbix-server了。 获取监控项还是以eth0入网流量为例，获取它的代码如下： 123456789101112#coding:utf-8#这个脚本是用来获取zabbix 定时流量值from zabbix_api import ZabbixAPIzapi = ZabbixAPI(server="http://网页地址/zabbix/api_jsonrpc.php") zapi.login("网页的用户名", "网页的密码") #鉴权hostname = ["服务器1名称","服务器2名称","服务器3名称","服务器4名称"] for name in hostname: list_item = zapi.item.get(&#123;"output": "extend","filter":&#123;'host':name&#125;,"search":&#123;'key_':'net.if.in[eth0]'&#125;&#125;) eth0_value = list_item[0]["lastvalue"] print "Incoming traffic bandwidth is:"+(eth0_value) 可见多么简单！ 上面代码里的hostname就是zabbix网页里的Host name，如图： 然后使用zapi.item.get方法通过filter来过滤，最后得到对应的key值。zapi下面还有很多方法，比如zapi.hostgroup.get、zapi.host.get、zapi.application.get等等等等，可以对于自己的需要，灵活运用。 参考文档https://blog.csdn.net/LYJ_viviani/article/details/70568434https://segmentfault.com/a/1190000014241994http://blog.51cto.com/xiaofengfeng/1907573]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>zabbix</tag>
        <tag>api</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Html制作progress进度条]]></title>
    <url>%2F2019%2F01%2F07%2FHtml%E5%88%B6%E4%BD%9Cprogress%E8%BF%9B%E5%BA%A6%E6%9D%A1%2F</url>
    <content type="text"><![CDATA[简单介绍无论是下载还是上传，亦或者是执行脚本。进度条都是必不可少的环节，它能让人清晰直观的看到事情发展的进度。现在生成进度条有很多种方法，我选择的是progress，它的用法很简单： 1&lt;progress value='70' max='100'&gt;&lt;/progress&gt; value属性表示进度条已经完成的进度值，范围为0~max之间。如果没有设置max属性，那么value属性值的范围要在0~1之间。如果没有value值，那么完成进度是不确定的。那么整个进度条就是一个动态效果，就像一个加载中loading，中间的进度块来回游荡。如下图： 动态进度条有些时候，我们无法正常获取到后台脚本运行的进度，因为某些脚本无法反馈给前端一个值来衡量目前运行到什么阶段，于是这种情况我们只能预估一下这个脚本大约用多少时间，做一个假的进度条来展示进度。如果想做一个逐渐进行的进度条，比如2秒钟跑满的进度条，那么代码如下： 12345678910111213141516171819&lt;body&gt;&lt;p&gt;进度条：&lt;progress value="0" max="100"&gt;&lt;/progress&gt;&lt;/p&gt;&lt;input type="button" value="开始" onclick="goprogress()"/&gt;&lt;/body&gt;&lt;script&gt; function goprogress()&#123; var pro=document.getElementsByTagName("progress")[0]; //获取progress的第一行 gotoend(pro,0); &#125; function gotoend(pro,value)&#123; var value=value+1; pro.value=value; if(value&lt;100) &#123; setTimeout(function()&#123;gotoend(pro, value);&#125;,20) //这里是时间，20的意思是2秒完成 &#125;else&#123; setTimeout(function()&#123;alert("任务完成")&#125;,20); &#125; &#125;&lt;/script&gt; 整个动态效果如下： 如何页面自动执行函数上面的例子，需要手动点击button，如果不想把函数绑定点击按钮事件上，而是要页面加载出来后自动执行函数就出现此效果，那么有两种办法： 直接把函数写到html的body标签里面 123&lt;body onload="myfunction()"&gt; //具体函数&lt;/body&gt; 在JS语句里调用 12345678&lt;script type="text/javascript"&gt; function myfun() &#123; alert("this window.onload"); &#125; /*用window.onload调用myfun()*/ window.onload = myfun; //不要括号&lt;/script&gt; 或者在JS语句里按以下方法调用： 1234567&lt;script type="text/javascript"&gt; window.onload=function()&#123; func1(); func2(); func3(); &#125;&lt;/script&gt; a href页面不刷新方法使用&lt;a href=&quot;#&quot;&gt;页面是会原地刷新的，那么如何不让页面刷新呢？使用&lt;a href=&#39;javascript:&#39;&gt; 。 参考资料https://blog.csdn.net/qq965194745/article/details/80034993https://frontenddev.org/article/how-to-use-javascript-to-do-a-high-force-the-progress-bar.htmlhttp://www.voidcn.com/article/p-crqmibur-a.htmlhttps://blog.csdn.net/Zhaky/article/details/50922613http://www.webfront-js.com/articaldetail/47.htmlhttps://www.cnblogs.com/witchgogogo/p/5547258.html （这个用bootstrap做的进度条更牛逼）]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>html</tag>
        <tag>前端</tag>
        <tag>进度条</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Nginx+Uwsgi将Django部署上线]]></title>
    <url>%2F2019%2F01%2F05%2F%E4%BD%BF%E7%94%A8Nginx-Uwsgi%E5%B0%86Django%E9%83%A8%E7%BD%B2%E4%B8%8A%E7%BA%BF%2F</url>
    <content type="text"><![CDATA[Uwsgi与Nginx搭配Django的原理请移步去看https://rorschachchan.github.io/2018/02/02/Uwsgi%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/ 。 配置uwsgi安装Uwsgi的方法很简单，pip install uwsgi即可，一般来说会直接下载到python路径下的bin目录夹里。 首先，如果启动了django的进程，请先关闭。 然后我们要在django根目录同级里，新增一个文件夹，比如叫chensite_uwsgi，里面手动编写一个配置文件chensite.ini，内容如下： 1234567891011121314[uwsgi]chdir = /chendjango/Kubernetes #这里指定django根目录地址module = Kubernetes.wsgi:application #这里指定django默认自带的wsgi文件路径，前面是文件夹名，后面带上:applicationmaster = True #指定启动主进程processes = 4 #指定进程数harakiri = 60 #当客户端请求uWSGI接口超过60s时，uWSGI会强制关闭客户端连接，然后重启响应客户端的workermax-requests = 5000 #最多5000请求socket = 127.0.0.1:8000 #使用本地的8000端口启动Django，效果等于python manage.py runserver 0.0.0.0:8000uid = www #使用www的用户去启动uwsgi，这里注意，如果非root用户可能会出现权限不足的情况，但是使用root用户会危险gid = wwwpidfile = /chendjango/chensite_uwsgi/chendjango.pid #指定pid文件daemonize = /chendjango/chensite_uwsgi/chendjango.log #指定log文件，同时要求进程在后台运行vacuum = True #当服务器退出时自动删除socket文件和pid文件logfile-chmod=644 #指定日志文件的权限 配置文件搞定之后，就可以使用/usr/local/python3/bin/uwsgi --ini chensite.ini来启动uwsgi了，启动完毕之后，ps -aux|grep uwsgi看一下进程是否正常，正常的话Django的进程就应该被uwsgi拉起来了，如果不正常可以通过我们刚刚指定的log文件来调试问题。 配置nginxNginx在这里的用途就是监听uwsgi，由于uwsgi已经把django进程开启，所以也达到了nginx“控制”django的效果。Nginx的安装方法就不多说了，这里主要说具体配置。 在nginx的conf/vhosts文件夹里，新建一个叫django.conf的文件来搭配uwsgi。文件内容如下： 123456789101112131415161718192021server &#123; listen 80; #指定外人对应访问端口 server_name django.lechange.com; #指定域名 charset utf-8; client_max_body_size 75M; location /static &#123; #这里如实填写静态资源路径 alias /chendjango/Kubernetes/static; &#125; location /media &#123; #同上 alias /chendjango/Kubernetes/media; &#125; location / &#123; #如果非静态资源，那么就跳转访问去8000端口 uwsgi_pass 127.0.0.1:8000; include /usr/local/nginx/conf/uwsgi_params; #这里填写uwsgi_params文件的地址 &#125;&#125; 保存退出之后，直接启动nginx，确认进程和端口号都正常的话，在浏览器里上登录对应的django页面就OK了！ 给网页title添加ico图标首先先找到一个喜欢的图片，然后去google一下“ico图标转换”，这种转换网站一搜一大把。登录到网站将这个喜欢的图片制作成16X16的ico图标文件，然后上传到服务器，放到django的静态文件目录里的任何地方。比如我只做好了一个batman.ico文件，然后把它放到static/pic文件夹下： 然后就是在html文件的title字段里添加如下两句话： 1234&lt;!--网页标题左侧显示--&gt;&lt;link rel="icon" href="/static/pic/batman.ico" type="image/x-icon"&gt;&lt;!--收藏夹显示图标--&gt;&lt;link rel="shortcut icon" href="/static/pic/batman.ico" type="image/x-icon"&gt; 保存之后，刷新一下页面，就看到效果了： 参考资料https://uwsgi-docs-zh.readthedocs.io/zh_CN/latest/tutorials/Django_and_nginx.htmlhttps://segmentfault.com/a/1190000014361352http://www.runoob.com/django/django-nginx-uwsgi.htmlhttps://segmentfault.com/a/1190000007952589]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>Django</tag>
        <tag>Uwsgi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql语句导出成excel时解决科学计数法的情况]]></title>
    <url>%2F2019%2F01%2F04%2FMysql%E8%AF%AD%E5%8F%A5%E5%AF%BC%E5%87%BA%E6%88%90excel%E6%97%B6%E8%A7%A3%E5%86%B3%E7%A7%91%E5%AD%A6%E8%AE%A1%E6%95%B0%E6%B3%95%E7%9A%84%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[普通情况导出excel将结果直接导出到/tmp/result.xls： 1mysql -h127.0.0.1 -u用户名 -p密码 -e "具体SQL命令" database名 &gt; /tmp/result.xls #请注意单引号双引号 解决科学计数法有时候数据库里会有比较长的数字，比如订单号或者身份证号，但是由于excel的操蛋设定，长数字在导出后在Excel中打开后却是用科学计数法显示的，过长的话，后面几位数字全都转换为0了，解决这样问题的方法就是引入CONCAT： 比如我要从sdb_b2c_delivery这个tables里查询两个时间戳之间的情况，将结果导出到/tmp/result.xls： 1mysql -h127.0.0.1 -u用户名 -p密码 -e 'SELECT CONCAT("",对应的列名1),CONCAT("",对应的列名2) FROM sdb_b2c_delivery WHERE t_begin &gt;= 1543593600 AND t_begin &lt;= 1546271999;' database名 &gt; /tmp/result.xls #请注意单引号双引号 但是这样导出来的结果还是科学计数法，不过可以修改单元格格式，改成“数值”，然后把小数位数改成0即可。 解决中文乱码的问题有时候数据库里会有中文，但是导出的时候发现excel看到的中文全是乱码，解决这样问题的方法需要加上--default-character-set=utf8，比如： 1mysql -h127.0.0.1 -u用户名 -p密码 --default-character-set=utf8 -e 'SELECT CONCAT("",对应的列名1),CONCAT("",对应的列名2) FROM sdb_b2c_delivery WHERE t_begin &gt;= 1543593600 AND t_begin &lt;= 1546271999;' database名 &gt; /tmp/result.xls #请注意单引号双引号 将result.xls直接使用notepad++打开，然后将excel列的格式设置为文本，再粘贴就能得到正确的表格了。 参考资料https://www.jianshu.com/p/2c8bfbfcd288https://qianrong.me/sql/2.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>excel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3写文件的几个例子]]></title>
    <url>%2F2019%2F01%2F04%2FPython3%E5%86%99%E6%96%87%E4%BB%B6%E7%9A%84%E5%87%A0%E4%B8%AA%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[拷贝一个文件的全部内容到另一个文件复制aaa.txt内容到另一个bbb.txt 12345fp = open('aaa.txt','r') for line in fp: fq = open('bbb.txt','a') #这里用追加模式，这里不能用w fq.write(line) fp.close() 在文件头部插入数据读出原有文件内容aaa.txt，移动索引到开始，写入新的数据data，然后再写入旧的数据。 12345with open('aaa.txt', "r+") as f: old = f.read() #将原来的内容取出 f.seek(0) #索引移动到头 f.write(data) f.write(old) 清空文件的内容当已存在一个文件对象，且这个文件对象可以对文件进行写write操作(注意不是追加append操作),则可以通过如下语句来清空一个文件的内容: 12&gt;&gt;&gt; f = open('file.txt','r+')&gt;&gt;&gt; f.truncate() #使用文件对象的成员函数truncate()来清空一个文件 如何让html文件识别换行符？如果使用替换方法把\r\n替换成&lt;br&gt;的话太蠢了，其实这种需求可以一句话解决：头尾加&lt;pre&gt;&lt;/pre&gt;。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>文件读写</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[伦敦八日游记]]></title>
    <url>%2F2019%2F01%2F02%2F%E8%8B%B1%E4%BC%A610%E6%97%A5%E6%B8%B8%2F</url>
    <content type="text"><![CDATA[这次的伦敦八日行其实是我的蜜月假期，原本打算跟媳妇去一趟巴塞罗那，但是网上攻略查了查发现巴塞罗那的小偷太多，甚至还有拦路抢包的事情发生。毕竟出门旅游，不想遇到什么添堵的事情，于是想来想去就选择了治安情况更好的伦敦作为本次的落脚点。 前期工作办理英国签证还是比较麻烦的，虽然在杭州可以直接办理，但是需要提交很多的证件—收入证明、公司营业执照复印件等等，然后要等待一个月左右再去照相按手印。若心急的话，可以走付费的加速通道。机票我媳妇选择了国航，路线是“杭州–&gt;北京–&gt;伦敦”，选择国航的主要原因是“行李在转机的时候可以直挂”。至于住宿，伦敦毕竟也是寸土寸金的地方，住宿还是蛮贵的，100磅一晚是正常价格，我媳妇选择了Airbnb，地址很不错，是靠近牧羊丛地铁站的Richman街道，交通很便利，周围也很安静。 出门游玩得需要现金吧，于是乎去中国银行兑换英镑，兑换汇率是8.9，我媳妇兑换了1000磅，兑换完了才知道原来市场上流通的英镑最大面值才50…最后就是在淘宝上购买英国电话卡，我俩八天里使劲用才用了6G左右，所以其实10G完全够用了，20G流量纯粹浪费。 具体行程这10天的具体行程如下：22日 从杭州出发，中午北京转机，晚上抵达伦敦希斯罗机场，办理oyster card，入住Airbnb23日 大英博物馆 + 考文特花园 + 海德公园嘉年华24日 杜莎夫人蜡像馆 + 贝克街散步 + 伦敦眼 + 去媳妇的朋友家圣诞聚餐25日 圣诞节全城休息，步行去摄政街看灯，在唐人街吃饭26日 WestField购物 + 温布利看球 + 哈罗德百货购物27日 西敏寺 + 伦敦塔桥 + 大本钟 + 泰晤士河游船28日 温莎城堡 + 碎片大厦观景29日 由于前几天太累了，原定的去剑桥大学参观取消，改成了牛津街购物30日 WestField购物 + 返程到北京31日 抵达杭州 伦敦的人伦敦是一个特别国际化的都市，出飞机场坐上地铁的那一刻，我发现车厢里有好多的印度人，让我一度怀疑飞机是不是飞到了新德里。伦敦大街上也是各种肤色，既有黑人白人也有头戴面纱的穆斯林，各路人马聚齐于此。伦敦人给人感觉是很友好的—只要人看到你拿着手机在路上一副不知所措的神情，就会上前主动问你“Are you lost?”记得我跟我媳妇第一天晚上9点多拖着行李找Airbnb的时候，就是一个黑人胖大姐帮我们联系了房东，而且还与我们一起找房东留下的钥匙。 我所住的Airbnb是提供有线电视的，总共有700个频道（另外还有100个电台），其中收费频道大约是400个，剩下300个频道里只有一个中文频道—凤凰卫视。但是我个人更感兴趣的是那些印度频道、巴基斯坦频道和穆斯林频道，因为第一次能接触到他们的电视节目觉得很新奇好玩。为什么能收到这些频道？我猜可能是英国政府为了照顾当地的印度人和中东人，让他们可以在千里之外看到自己家乡的节目。每天早上，穆斯林频道每天早上都有念经（古兰经？）的环节，屏幕上一盏烛火，背景是巨大的清真寺，然后飘过一行又一行的阿拉伯字，一个浑厚的男声在咿咿呀呀的念经…这个节目基本陪我度过了两个早上煮方便面的时间。 伦敦街头的卖艺人随处可见，多数是自弹自唱的音乐艺人，也有杂技艺人和幽默剧艺人。英国人很喜欢唱歌，尤其是喝酒的时候大家一起大合唱更是壮观。而每到周五周六的晚上，酒吧一条街人满为患，甚至有人在店外喝酒，同时马路上也会有临时的简易厕所供男士们方便。 英国不愧是腐国，本身洋人就比较高大，所以“彩虹小哥”在马路上就更有视觉冲击力，部分街道甚至会出售男同用品，而他们对这种现象也是司空见惯、习以为常。 英国男人最有名的，除了腐之外，那就是秃了。上到威廉、哈里两个王子下到地铁里的普通上班族，秃头的概率的确很高，我经常感叹那些白人们有着帅气的面庞和隐隐看到头皮的后脑勺。为什么英国是秃头的重灾区？有人说是因为英国的水质硬，所以毛孔不通畅，也有人说英国雨水多，而且当地人还不喜撑伞，频繁的冷水对头发也有伤害。但是我看到的几个印度和中东的店员却都不秃，那么英国白人秃头的真实原因不得而知，不过秃头的杀伤力的确对他们造成了很大的伤害，所以他们戴帽子的人不在少数。 说完了男人说女人，英国的女人不秃，头发茂密的很，而且他们还特别抗冷！零度左右的天气，我看到很多穿着破洞牛仔裤的女性，甚至还有穿短袖的，在大街上走来走去。至于什么“发热御寒丝袜”在英国都没得卖。这种抗冷属性应该算是他们的种族天赋。 顺便插一句题外话，伦敦街头的抗议行动我们看到了三处，第一处是大英博物馆门口有法轮功的静坐和散发传单；第二处是在摄政街的动物保护组织抗议“加拿大鹅”店残杀郊狼扒毛；第三处也是摄政街，有5个左右的伊斯兰人手持经书控诉美国政府。这里面让我印象比较深的是动物保护组织，他们堵着加拿大鹅的门店喊口号，但是抗议归抗议，并没有进去打砸，而且店里依旧有客人在购买，可以说除了闹一点之外都比较和谐。 伦敦的吃有人说伦敦的美食很少，因为英国人本身对于吃的想象力特别匮乏；也有人说伦敦的美食很多，因为它是地球上米其林餐厅最多的城市。其实这两个对立的说法都对，英国人自身对吃仅仅定义为“填饱肚子的行为”而已，所以纵然电视里的美食节目不少，但是英国本土并没有什么饮食文化而言。如果肯舍得钱下馆子的话，那么伦敦还是有很多上佳口味的饭店供人选择。 我在这几天在伦敦吃到了如下几种菜：牛排（网红店Flat Iron Steak和Bill’s）、龙虾（网红店Burger &amp; Lobster）、披萨（网红店Pane Cunzato）、中国菜（唐人街的金龙轩）、麦当劳、烤鸡（网红店Nando’s）、日料（超赞而且实惠的Eat Tokyo），反倒是鼎鼎大名的“炸鱼薯条”却只是看而没有吃。总体上来说，原味的欧洲菜跟亚洲口味的确有很大的不同，首先是每餐必有薯条（我个人喜欢薯条搭配蛋黄酱吃），其次各种酱汁种类很多，味道七七八八，再其次就是肉蛮好吃的，但是水果基本没有。当然我去的店相对平民，如果去米其林餐厅肯定会吃到高档的菜肴。 上面说了那么多饭里，我个人最喜欢的还是中国菜—-金龙轩的福建炒饭，蟹肉芡勾的很棒，而且分量十足！ 伦敦的买从行程规划里可以看到，我跟我媳妇准备了大量买买买的时间，因为圣诞节之后，就是会持续十天左右的Boxing Day。在此期间，几乎所有的商品都会让利，新品可能折扣少一点，部分老款甚至会打五折乃至更低！ 作为二次元的拥趸，Forbidden Planet是绝对不能错过的书店！它在大英博物馆附近，一楼是各种周边，地下室是书籍出售。在里面我买了两个蝙蝠侠周边。那里的日漫也很多，《暗杀教室》两本只需要三磅，划算的很！ 若要正经购物的话，伦敦也有很多去处。我跟媳妇先去了考文特花园，那里能买到很多好玩又精美的小玩意，比如银制的勺子和挂链，甚至还有潘海立根。摄政街跟哈罗德百货更是购物的火拼集中地，附近的商铺应该有100家，消费群体主要是中东人和亚洲人。白人和黑人更多的是聚集在像JD那种体育用品专卖店买鞋。至于为什么高端店被外国人包围，我想因为英国本身福利比较给力，所以土著平民都没有攒钱的意识，过着“今朝有酒今朝醉”的月光生活，自然也不会拿出那么多钱来买奢侈品。 大名鼎鼎比斯特小镇我俩没有去，因为那个地方在这种打折季肯定人满为患，事实也印证了我俩的预测。 不过英国的退税跟日本的不同，日本是在商家处直接退税，而英国是要在指定地点退税或者机场退税。机场退税有两条路，一条是去直接退英镑，但是排队非常夸张，大约要排4小时左右；还有一条就是直接退本国的货币，需要收取不俗的手续费而且兑换的汇率也很低，所以英国的退税政策其实并不友好。 伦敦文化几天接触下来，只管感觉到伦敦是一个“传统与现代”并存的城市。说它现代，就是各种高大上的各路品牌、宝马奔驰在马路上驰骋、超市基本都实现了无人结账而且几乎各处都配有免费wifi（最良心的是注册wifi只填写电子邮件，而根本不需要填写手机号，这一点跟国内众多注册很不一样！）；说它传统呢，就是普通居民建筑还保留传统英式风格，大大小小的教堂无论年代目前都在服务，特殊地方还有骑马巡警。景点里那些百年以上的软文化都妥善保存，景点外伦敦人喜欢看戏剧的习惯流传至今。这种“新与旧”和谐共存最明显的体现就是在温莎城堡，女王家虽然面积远不如故宫那么大，但是论奢华一点不虚我们。 不过，伦敦公共设施维护的普遍都不咋地，最让人吐槽的就是以下几点：垃圾箱很少导致街边烟头满地，非居民区垃圾袋随处可见，喝剩的纸杯也随意放在路边橱窗上，地铁没信号不说而且椅套看上去都旧旧的。据我媳妇在伦敦的朋友说，伦敦居民区的环卫工人每周三才会出来清理一次街道的垃圾袋，所以平时都是把垃圾袋放在家里，到了周三才一并拿出去扔掉，如果平时乱扔会被罚很重的款。 伦敦看球到了伦敦怎能不现场观看英超比赛？伦敦是著名的“足球之城”，当地就有6支英超联赛球队（切尔西、热刺、阿森纳、西汉姆、富勒姆、水晶宫），但是圣诞节期间主场作战的只有热刺一家，于是我在StubHub上买了两张热刺VS伯恩茅斯的门票。不过我真的不推荐各位去StubHub上买票，手续费高不说，而且出票速度奇慢，我是11月30日下单，12月21号才通知可以下载球票电子档，中途还不能退票。主要是StubHub毕竟是卖2手票的，只有有人卖才会出单通知你，所以还是在官网买票是最省心最效率的，但是要提前注册会员。 到了温布利下车一出门就能看到温布利球场，路上都是卖热刺队围巾的小贩，5磅一条。到了球场，首先对背包大小有要求，包不能大于4A纸的面积，否则就是要花10磅寄存。进场的时候要求安检并且把饮料瓶盖扔掉，在机器上扫描电子票的二维码入场，不检查实名制。 进了球场就是要狂躁起来，那场比赛热刺队也很给力，5：0痛击伯恩茅斯，孙球王梅开二度，我身后手持太极旗的韩国妹子们兴奋不已。热刺的球迷很热情，每个球员有了上佳表现，球迷都会唱歌，从穆萨登贝莱唱到哈里凯恩。出场之后，意犹未尽的我还跟温布利球场的雕像们一一合影。如果将来有一次能去巴塞罗那，肯定也会去诺坎普朝圣一下。 其他轶事倒时差的小秘诀：静下心来或者把自己弄疲惫，该睡觉的时候一定要正常睡觉，哪怕只有几个小时。 都说英国不准许肉类入境，但是我媳妇带的鸭脖子、鸡爪子在行李箱里就大摇大摆的登陆了。 伦敦地铁没有安检，Paddington火车车厢里也压根没有检票。 伦敦的热水非常方便，而且他们的自来水是可以直接饮用的，如果不能饮用的话会有提示。 伦敦普通居民区的门锁完全不是国内常见的“防盗门+防盗锁”，而是很老式的“木门+插钥匙锁”，所以那些特工电影里一脚破门的镜头果然不是在骗人… 伦敦市区电子屏幕上铺天盖地的是“抖音”海外版app的广告，而华为的广告只有商场里才有，但是我并没有发现卖华为手机的地方… 这八天里唯一看到的中国公众人物是杨幂，在杜莎夫人蜡像馆里(其实还有达赖喇嘛的蜡像，但是他毕竟自建流亡政府，就不能算中国人了)。她周围很冷清，跟布拉德皮特、约翰尼德普、乔治克鲁尼等人气大户完全没法比。 伦敦黑人很多，我看见不少的黑人喜欢把裤裆穿的很低，然后漏出来半截内裤甚至是屁股（囧），不知道这是不是他们的什么衣着文化… 其他小tips 大英博物馆的语音向导是有数的，请提早去拿； 杜莎夫人蜡像馆和伦敦眼可以买连票，价钱优惠而且都有快速通行权限； 圣诞期间碎片大厦晚上10点才关门，所以如果看不到日落那就干脆不用急了； London Pass卡的游船晚上5点05就停业了； London Pass卡支持两种大巴车，我个人推荐Golden Tours，虽然它的APP可能做得不太好，但是营业时间长，至少晚上9点我还看到车在马路上跑，而BIG BUS六点多就休息了； 准备的APP：航旅纵横+CityMapper+TripAdvisor； 一定要带伞！虽然伦敦各个小店都有卖伞，但是基本10磅一把，价格还是蛮贵的； 自带拖鞋、牙刷、毛巾等用品，还有插销转换头； 伦敦行李寄存地点不多，而且价格不菲，8磅一个箱子，当然啦，土豪可以无视此条；]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>旅游</tag>
        <tag>伦敦</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django实现文件上传功能]]></title>
    <url>%2F2018%2F12%2F19%2FDjango%E5%AE%9E%E7%8E%B0%E5%9B%BE%E7%89%87%E4%B8%8A%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[准备工作python：3.6.5Django：2.1.1执行pip install pillow，安装python图片处理库pillow 图片单张上传首先先修改一下setting.py，添加如下两行代码： 12MEDIA_URL = '/media/'MEDIA_ROOT = os.path.join(BASE_DIR, 'media').replace('\\', '/') #media即为图片上传的根路径 保存之后，在项目根目录即manage.py同级目录里创建media这个文件夹。然后编辑models.py，内容如下： 1234from django.db import modelsclass Img(models.Model): img_url = models.ImageField(upload_to='photos/',blank=True,null=True) #指定图片上传路径，即media/photos/ 保存之后执行一下python manage.py makemigrations和python manage.py migrate，建立项目与数据库之间的关系。 增加urls.py的内容如下： 123456from django.urls import pathfrom . import viewsurlpatterns = [ path(r'uploadImg/',views.uploadImg,name='uploadImg'),] 增加views.py的内容如下： 123456789其他内容略from .models import Img#图片上传def uploadImg(request): if request.method == 'POST': img = Img(img_url=request.FILES.get('img')) img.save() return render(request, 'imgUpload.html') 最后就是写一个前端页面imgUpload.html: 1234567891011121314 &lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;图片上传&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=&quot;&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; &#123;% csrf_token %&#125; &lt;input type=&quot;file&quot; name=&quot;img&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;上传&quot;&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 启动django，打开imgUpload.html就可以看到界面，并且上传图片了，效果如图（我这个前端是加工过的，不是上面的代码）： 然后在django项目目录里的media/photos路径里找到我们刚刚上传的test333.png，而且在数据库里也能看到这条记录，如下： 图片批量上传不过在现实工作中，图片批量上传的应用场景更为普遍，如果是批量上传的话，我们尝试一个全新而且更简单粗暴的方法。 首先先修改前端页面imgUpload.html，把&lt;input type=&quot;file&quot; name=&quot;img&quot;&gt;改成&lt;input type=&quot;file&quot; name=&quot;img&quot; multiple=&quot;&quot;&gt;，就这一处而已，其他都不动。 然后就是修改views.py，如下： 123456789 #图片上传def uploadImg(request): files = request.FILES.getlist('img') for f in files: destination = open('/tmp/' + f.name,'wb+') #上传的文件都放到/tmp文件夹里 for chunk in f.chunks(): destination.write(chunk) destination.close() return render(request, 'imgUpload.html') 可以看出，这次views.py在执行uploadImg已经完全脱离img数据库和media路径了，就是一个非常单纯的图片上传功能。效果如图： 此时去/tmp里检查文件是否成功传上来： 可见已经成功的一次性传上来三个文件到目标文件夹了。 使用阿里云云存储的API上传文件阿里云云存储上传文件的脚本如下： 1234567891011121314# -*- coding: utf-8 -*-#需要先执行pip install oss2import oss2,ospath = "图片所在文件夹的绝对路径"files = os.listdir(path) #得到文件夹下的所有文件名称#鉴权auth = oss2.Auth('这里是AK', '这里是SK')bucket = oss2.Bucket(auth, 'http://oss-cn-hangzhou.aliyuncs.com', '目标BUCKET名称')for i in files: bucket.put_object_from_file('路径/'+i, path+i) print ("上传成功！"+i+"的url地址是：https://lechangebbs.oss-cn-hangzhou.aliyuncs.com/jjfjj/"+i) print ("\n" * 2) #空两行 执行效果如下： 通过搭配这个脚本写到views.py里就可以把上传上来的图片转到阿里云云存储里去了！ PS，阿里云OSS有官方支持django的模块：django-aliyun-oss2-storage（果然够牛逼！），直接pip安装即可，如何使用待我研究一番先。 参考资料https://jinfagang.gitlab.io/2017/11/27/Django%E5%90%8C%E6%97%B6%E4%B8%8A%E4%BC%A0%E5%A4%9A%E5%BC%A0%E5%9B%BE%E7%89%87%E6%88%96%E6%96%87%E4%BB%B6/https://blog.csdn.net/c_beautiful/article/details/79755368https://www.jianshu.com/p/3c79b19849f5https://blog.csdn.net/u014633966/article/details/78727034https://abersheeran.com/articles/Django-MutliImageFormSet/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用ZABBIX自带模板去监控Mysql]]></title>
    <url>%2F2018%2F12%2F18%2F%E4%BD%BF%E7%94%A8ZABBIX%E8%87%AA%E5%B8%A6%E6%A8%A1%E6%9D%BF%E5%8E%BB%E7%9B%91%E6%8E%A7Mysql%2F</url>
    <content type="text"><![CDATA[事前准备Zabbix-agent:3.0.8，安装路径是/etc/zabbix/Mysql:5.7.10，安装路径是/opt/mysql/配置/etc/sudoers让zabbix用户可以使用sudo，如下： 1234## Allow root to run any commands anywhereroot ALL=(ALL) ALLzabbix ALL=(ALL) NOPASSWD:ALLDefaults:zabbix !requiretty 配置.my.cnf众所周知，Zabbix官方提供了自带监控Mysql的模板，但是这个模板并不能直接使用。所以我们需要有如下的改动： 首先，先在mysql目录下的etc文件夹里先创建一个.my.cnf文件，全路径是/opt/mysql/etc/.my.cnf，这个文件是zabbix要求的用于存放连接mysql数据库的账户信息的隐藏文件，这样可以避免在命令行里输入密码。整个.my.cnf文件内容如下： 1234567891011[mysql] #mysql程序要使用的账户信息host=localhostuser=用户名password=&quot;密码&quot; #此处的密码强烈建议加上引号socket=/tmp/mysql.sock #确认mysql的sock文件路径[mysqladmin] #mysqladmin程序要使用的账户信息host=localhostuser=用户名password=&quot;密码&quot;socket=/tmp/mysql.sock 这里建议在mysql里插入一个叫zabbix的用户，密码自己设定，然后在.my.cnf里就是用这个用户即可。此时，在命令行直接输入HOME=/opt/mysql/etc/ mysql和HOME=/opt/mysql/etc/ mysqladmin ping都应该是直接出结果，而不是用输入账号和密码，如图： 注意!这个.my.cnf的权限是644，用户和用户组是root，如果权限过大，那么启动mysql时就会报错：Warning: World-writable config file &#39;/opt/mysql/etc/.my.cnf&#39; is ignored。 修改userparameter_mysql.conf然后在zabbix-agent配置文件的文件夹/etc/zabbix/zabbix_agentd.d/里，会发现一个叫userparameter_mysql.conf的文件，把里面的内容改成如下样子: 1234567# For all the following commands HOME should be set to the directory that has .my.cnf file with password information.# Flexible parameter to grab global variables. On the frontend side, use keys like mysql.status[Com_insert].# Key syntax is mysql.status[variable].UserParameter=mysql.status[*],echo "show global status where Variable_name='$1';" | sudo HOME=/opt/mysql/etc /opt/mysql/bin/mysql -N | awk '&#123;print $$2&#125;'UserParameter=mysql.ping,sudo HOME=/opt/mysql/etc/ /opt/mysql/bin/mysqladmin ping | grep -c aliveUserParameter=mysql.version,/opt/mysql/bin/mysql -V 这个文件第一行注释的内容就是说明HOME路径就是.my.cnf文件所在的路径，后面的mysql和mysqladmin都要用绝对路径，同时加上sudo，这样zabbix才能正确的调用它。 来到zabbix-server端使用zabbix-get去试试结果： 然后就是在zabbix网页端将目标机器添加Template DB MySQL，至此，使用zabbix自带的mysql监控模板监控mysql数据库就结束了，效果如下： 监控连接数上面那个模板是不带有监控连接数的，要是单纯的去使用netstat获取当前链接值可能会反应较慢，那么就是用mysql自带的查连接数的命令：show status like &#39;%connect%&#39;;，执行效果如下： 简单说下这几个值的含义： Connections：试图连接到（不管是否成功）MYSQL服务器的连接总数 Locked_connects：锁住的链接数 Max_used_connections：服务器启动后已经同时使用过的连接最大数量（并发） Max_used_connections_time：出现Max_used_connections时的时间 Aborted_connects：尝试连接到MySQL服务器失败的次数 Threads_connected：当前的连接数 那么知道了含义，我们就可以对症下药了，这里我们监控两个数值Locked_connects和Threads_connected，那么就把下面的语句添加到userparameter_mysql.conf里： 123UserParameter=mysql.connections,echo "show status like '%Threads_connected%';" | sudo HOME=/opt/mysql/etc /opt/mysql/bin/mysql -N | awk '&#123;print $2&#125;'UserParameter=mysql.lockconnections,echo "show status like '%Locked_connects%';" | sudo HOME=/opt/mysql/etc /opt/mysql/bin/mysql -N | awk '&#123;print $2&#125;'UserParameter=mysql.rowofalarm,echo "select count(*) from alarm.adm_log_alarm;" | sudo HOME=/opt/mysql/etc /opt/mysql/bin/mysql -N | awk '&#123;print $1&#125;' #这个是检测alarm.adm_log_alarm的数据行数 重启zabbix-agent，配置对应的items和trigger即可。 额外补充一下，查看mysql数据库对应每个IP的详细链接情况的语句是： 1select substring_index(host,':',1) as ip , count(*) from information_schema.processlist group by ip; 效果如下： 参考资料https://github.com/erasin/notes/blob/master/linux/mysql/monitor.md （其他mysql状态监控语句）http://www.cnblogs.com/kerrycode/p/9206787.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将list重新排列后获取原来的索引]]></title>
    <url>%2F2018%2F12%2F14%2F%E5%B0%86list%E9%87%8D%E6%96%B0%E6%8E%92%E5%88%97%E5%90%8E%E8%8E%B7%E5%8F%96%E5%8E%9F%E6%9D%A5%E7%9A%84%E7%B4%A2%E5%BC%95%2F</url>
    <content type="text"><![CDATA[具体需求与解决方案假设我们有一个列表，现在要对列表里进行从大到小排序，然后再获取列表里原来各位元素的索引，怎么办？ 12#Python2.7new_list = sorted(enumerate(old_list),key=lambda x: x[1],reverse=True) #old_list就是原列表 举一个详细一点的例子： 可见原来aaa这个列表的元素虽然经过了大小排序，但是各元素的索引下标没有丢，而且通过zip（）方法能拆出来供我们继续使用。 enumerate() 函数这个enumerate()函数可以将一个可遍历的数据对象组合一个索引序列，同时列出数据和数据下标，默认情况下标是从0开始的，也可以手动更改，比如： 12345&gt;&gt;&gt;seasons = ['Spring', 'Summer', 'Fall', 'Winter']&gt;&gt;&gt; list(enumerate(seasons))[(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')]&gt;&gt;&gt; list(enumerate(seasons, start=1)) # 下标从 1 开始[(1, 'Spring'), (2, 'Summer'), (3, 'Fall'), (4, 'Winter')] 有了它，我们就可以轻松获取索引下标值了。 sorted(key=lambda)sorted（）是用来排列列表的函数，默认情况下是从小到大排列。如果列表里是每一个元素并不是单纯的一个数字，而是多字段，那么就要规定以哪一个字段作为标准来排列，这个这顶标准就是key。 举个例子： 123456&gt;&gt;&gt; listA = [3, 6, 1, 0, 10, 8, 9] #这个列表就是单字段，排序就是单纯按照数字大小排序&gt;&gt;&gt; print(sorted(listA))[0, 1, 3, 6, 8, 9, 10]&gt;&gt;&gt; listC=[('e', 4), ('o', 2), ('!', 5), ('v', 3), ('l', 1)] #这个列表是多字段&gt;&gt;&gt; print(sorted(listC, key=lambda x: x[1])) #指定按照多字段里第二个元素，即数字的大小进行排序[('l', 1), ('o', 2), ('v', 3), ('e', 4), ('!', 5)] x:x[]字母可以随意修改，排序方式按照中括号[]里面的维度进行排序，[0]按照第一维排序，[2]按照第三维排序 参考资料https://stackoverflow.com/questions/7851077/how-to-return-index-of-a-sorted-listhttps://stackoverflow.com/questions/16310015/what-does-this-mean-key-lambda-x-x1https://blog.csdn.net/u010758410/article/details/79737498]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>enumerate</tag>
        <tag>列表加工</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django前端输入变量通过内部脚本加工返回前端展示之八]]></title>
    <url>%2F2018%2F12%2F10%2F%E4%BB%8Echeckbox%E9%87%8C%E5%BE%97%E5%88%B0%E4%BC%A0%E5%85%A5%E5%80%BC%2F</url>
    <content type="text"><![CDATA[背景说明python：3.6.5Django：2.1.1Project：Kubernetes，文件夹路径就是/django/Kubernetes/App：createyaml，文件夹路径就是/django/Kubernetes/createyaml前文地址：https://rorschachchan.github.io/2018/12/04/Django%E5%88%B6%E4%BD%9C%E4%B8%80%E4%B8%AA%E5%AF%86%E7%A0%81%E7%94%9F%E6%88%90%E5%99%A8/ 需求说明以及实现思路之前在Django实现了输入文本然后通过ajax传递参数到后端执行脚本并且返回结果的效果。这一次要实现的是“多选框选中对应的选项然后提示确认，最后给后台执行命令”。 多选框在实际的页面里很常见，这一次要实现的效果如图： 要想在django的views.py里获取到checkbox的选择项，如果用表单方法很简单，只要request.POST.getlist就好，我尝试去用ajax去获取，但是得到的data是空值。可能是我道行不够，不过从代码简洁的角度来说还是更推荐用django的方法。 为了用户体验友好，我们一般都会在页面提交的时候加上提示的对话框，让用户再三确认。这样就要把form表单和confirm()对话框一起用，但是有一个现象要注意：如果把&lt;form&gt;标签写到&lt;button type=&quot;submit&quot;&gt;下面的话，comfirm()时点击了“取消”，return false是会生效的，即停留在本页，但是form表单是无法正常传递到目的地；如果把&lt;form&gt;标签写到&lt;button type=&quot;submit&quot;&gt;上面，现在表单可以正常传递了，但是“取消”功能又不生效了—即使点击取消依旧会跳转到表单的目标地。 这种现象产生的原因是：如果函数是包含在form的submit中的话，当点击按钮的时候，在弹出confirm()对话框之前，有很多的js需要执行的，而大家都知道在点击按钮的时候，表单会自动提交的；所以就没有等到用户点击“取消”按钮，form表单已经提交了，自然就不会管你有没有点击”取消”了。 解决方法：只要在按钮的onclick()事件的方法前面加一个return就ok了，这样肯定会先等返回结果在提交表单了，例如： 1&lt;input type="button" value="请点击我！" onclick="return method()"&gt; 具体代码ecs_list.html的body部分: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;h1 style="text-align:center;"&gt;数据库里的ECS数据展示&lt;/h1&gt; &lt;script&gt; function ecs_deploy() &#123; var name=prompt("请输入要执行的命令：1&gt;测试连通；2&gt;部署模块并启动；","1"); //添加一个输入框 var userids = []; //配置一个空集 $("input:checkbox[name = ecs]:checked").each(function(i)&#123; //使用循环遍历迭代的方式得到所有被选中的checkbox复选框 console.log($(this).val()); userids.push( $(this).val() ); //当前被选中checkbox背后对应的值 &#125;) if(confirm("你确定要对"+userids+"进行"+name+"操作？")) //让用户再次确认 &#123; location.href="&#123;% url "run_command" %&#125;"; &#125; else &#123; return false; //停留在本页，没有操作 &#125; &#125; &lt;/script&gt; &lt;div align="left" style="float:left"&gt; &lt;a href="&#123;% url "create_ecs" %&#125;"&gt;&lt;button type="button" class="btn btn-default"&gt;返回录入界面&lt;/button&gt;&lt;/a&gt; &lt;/div&gt; &lt;form action="/k8s/run_command/" method="POST"&gt; &lt;div align="right" style="float:left"&gt; &lt;button type="submit" class="btn btn-default" onclick="return ecs_deploy()" /&gt;选择服务器&lt;/button&gt; //这里添加了return &lt;/div&gt; &lt;table width="100%" border="1"&gt; &lt;thead&gt; &lt;br&gt; &lt;form&gt; &lt;tr&gt; &lt;td align="center"&gt;序号&lt;/td&gt; &lt;td align="center"&gt;云服务器名称&lt;/td&gt; &lt;td align="center"&gt;云服务器ID&lt;/td&gt; &lt;td align="center"&gt;内网地址&lt;/td&gt; &lt;td align="center"&gt;外网地址&lt;/td&gt; &lt;td align="center"&gt;操作系统&lt;/td&gt; &lt;td align="center"&gt;网络类型&lt;/td&gt; &lt;td align="center"&gt;CPU&lt;/td&gt; &lt;td align="center"&gt;内存&lt;/td&gt; &lt;td align="center"&gt;外网带宽&lt;/td&gt; &lt;td align="center"&gt;备注&lt;/td&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &#123;% for ecs in ecss %&#125; &lt;tr&gt; &lt;td&gt;&lt;input type="checkbox" value=&#123;&#123;ecs.name&#125;&#125; name="ecs"/&gt;&#123;&#123; ecs.id &#125;&#125; &lt;/td&gt; &lt;td align="center"&gt;&#123;&#123; ecs.name &#125;&#125; &lt;/td&gt; &lt;td align="center"&gt;&#123;&#123; ecs.ecsid &#125;&#125;&lt;/td&gt; &lt;td align="center"&gt;&#123;&#123; ecs.inIP &#125;&#125;&lt;/td&gt; &lt;td align="center"&gt;&#123;&#123; ecs.outIP &#125;&#125;&lt;/td&gt; &lt;td align="center"&gt;&#123;&#123; ecs.osname &#125;&#125;&lt;/td&gt; &lt;td align="center"&gt;&#123;&#123; ecs.networktype &#125;&#125;&lt;/td&gt; &lt;td align="center"&gt;&#123;&#123; ecs.CPU &#125;&#125;&lt;/td&gt; &lt;td align="center"&gt;&#123;&#123; ecs.memory &#125;&#125;&lt;/td&gt; &lt;td align="center"&gt;&#123;&#123; ecs.netwidth &#125;&#125;&lt;/td&gt; &lt;td align="center"&gt;&#123;&#123; ecs.remark &#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;% endfor %&#125; &lt;/tbody&gt; &lt;/table&gt; &lt;/form&gt; views.py相关部分如下: 1234567@csrf_exemptdef run_command(request): if request.method == 'POST': id = request.POST.getlist("ecs") return HttpResponse(id) else: pass urls.py相关部分如下： 1path(r'run_command/',views.run_command), 启动django后，在ecs_list.html页面如动图点击要操作的选项提交即可看到效果，再配上后台数据库查询+ansible的辅助，我们就可以完成一个运维平台的部署功能啦！ 点击页面直接选取上面说的是复选框选取，如果需要直接点击就能得到值的话，那么就要用click函数搭配this来实现该效果，举个例子： 1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;body&gt; &lt;script src="https://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js"&gt;&lt;/script&gt; &lt;script type="text/javascript"&gt; $(document).ready(function()&#123; $("p").click(function()&#123; //触发一个点击的函数，点击标签范围是p alert($(this).html()); //this的用途就是获取当前的元素 &#125;); &#125;); &lt;/script&gt; &lt;body&gt; &lt;p&gt;这是第一个段落。&lt;/p&gt; &lt;p&gt;这是第二个段落。&lt;/p&gt; &lt;p&gt;这是第三个段落。&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 页面效果如图： 参考资料https://stackoverflow.com/questions/4359238/how-do-i-get-multiple-values-from-checkboxes-in-djangohttps://stackoverflow.com/questions/14460421/get-the-contents-of-a-table-row-with-a-button-clickhttps://blog.csdn.net/stpeace/article/details/50816128http://www.runoob.com/js/js-popup.htmlhttps://blog.csdn.net/qq_36769100/article/details/79173476https://blog.csdn.net/qq_24018243/article/details/52316949https://bbs.csdn.net/topics/320062312]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Django</tag>
        <tag>checkbox</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Github如何删除掉一个commit]]></title>
    <url>%2F2018%2F12%2F06%2FGithub%E5%A6%82%E4%BD%95%E5%88%A0%E9%99%A4%E6%8E%89%E4%B8%80%E4%B8%AAcommit%2F</url>
    <content type="text"><![CDATA[写完了一个脚本，里面使用了阿里云的api，那自然也有公司的阿里云ak\sk，在调试的时候发现没问题，于是就上传到github上。传完之后一看，发现脚本里忘了删除敏感字段，连通公司的ak\sk一起被提交上去了… 卧槽，这还得了？要是这个commit被人发现并且拷贝走了，岂不是得到了公司的ak\sk，后果不堪设想啊。但是如何在github远端删除掉一个commit呢？ 先记录下这次commit之前一次正常的版本号，查询版本号也可以通过命令git log -5（查询最近5次提交历史）： 得到上一次的版本号是051ebceaedd6b64801aada354f921d6ea7ef0622，然后git reset --hard 051ebceaedd6b64801aada354f921d6ea7ef0622。 然后再git push origin HEAD --force即可。整个过程如下： 此时再去github上刷新commit的历史页面，发现记录已经回滚到051ebce（版本号前面7位）了，如图： 但是要注意！如果你的代码是两个地方在上传github，比如含敏感词汇的文件是通过windows客户端上传的，但是你在某个linux服务器上进行了删除commit的操作，那么如果windows继续commit的话，是会再次提交所有的commit的(含带有机密字段的commit)，所以要把源头也就是windows里的commit也要用这个方法干掉，这样才算彻底删除。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django前端输入变量通过内部脚本加工返回前端展示之七]]></title>
    <url>%2F2018%2F12%2F04%2FDjango%E5%88%B6%E4%BD%9C%E4%B8%80%E4%B8%AA%E5%AF%86%E7%A0%81%E7%94%9F%E6%88%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[背景说明python：3.6.5Django：2.1.1Project：Kubernetes，文件夹路径就是/django/Kubernetes/App：createyaml，文件夹路径就是/django/Kubernetes/createyaml前文地址：https://rorschachchan.github.io/2018/12/03/%E9%A1%B5%E9%9D%A2%E5%B1%80%E9%83%A8%E5%88%B7%E6%96%B0%E5%BE%97%E5%88%B0AES%E5%8A%A0%E5%AF%86%E5%80%BC/ secrets模块这个secrets模块是Python 3.6才有的模块，在说它之前，先看一下string.ascii_letters和string.digits，其中ascii_letters是生成所有字母，即a-z和A-Z,而digits是生成所有数字，即0-9,如下： 那么他俩搭配secrets模块就可以生成密码，代码如下： 12345678&gt;&gt;&gt; import secrets,string&gt;&gt;&gt; characters = string.ascii_letters + string.digits + "!@#$%^&amp;*()&#123;&#125;[]~" #加入特殊符号&gt;&gt;&gt; password = ''.join(secrets.choice(characters) for i in range(20)) #生成一个20位的随机字符串&gt;&gt;&gt; password'a%45BW5bxFlN3ylr!!IE'&gt;&gt;&gt; password = ''.join(secrets.choice(characters) for i in range(10)) #生成一个10位的随机字符串&gt;&gt;&gt; password')vqRWYxgxs' 看上去secrets.choice和random.choice的效果差不多，但是还是有差别的。因为random模块的官方文档清楚的写着该模块完全不适合用作数据加密，而secrets模块不但可以生成安全随机数还可以生成一个笃定长度的随机字符串—-可用作令牌和安全URL。 所以与random模块中的默认伪随机数生成器相比，我们应该优先使用secrets模块！ 后台检验输入值合法之前的文章，曾经写过在django的views.py里判断输入值是否为空的方法，地址是https://rorschachchan.github.io/2018/09/26/Django%E4%BD%BF%E7%94%A8form%E8%A1%A8%E5%8D%95%E5%88%A4%E6%96%AD%E8%BE%93%E5%85%A5%E5%80%BC%E6%98%AF%E5%90%A6%E5%90%88%E6%B3%95/ ，但是那套方法毕竟还太粗糙。这一次我们可以通过jQuery+Ajax获取到值，然后进行一个具体的判断，看一下这个值是否是数字，如果不是数字就直接在页面提示“输入非法”，如果是数字，就不会提示。 思路就是先获取到前端传来的值，然后在views.py里增加一个定义，如果值满足定义，就不会有动静，如果值不满足，那么就局部刷新一个页面。 具体代码路由文件urls.py部分如下： 123开头略 path(r'mkpasswd/',views.make_passwd,name='mkpasswd'), path(r'get_mkpasswd/',views.get_passwd,name='get_passwd'), 配置文件views.py相关部分如下： 12345678910111213141516171819开头略from django.views.decorators.csrf import csrf_exemptimport secrets,stringdef make_passwd(request): return render(request,'mkpasswd.html')@csrf_exemptdef get_passwd(request): characters = string.ascii_letters + string.digits + "!@#$%^&amp;*()~[]&#123;&#125;=+" if request.method == 'POST': num = request.POST.get('number',20) #这里得到的是str格式 if str.isdigit(num) is False: #判断是否是数字 return HttpResponse("输入值不合法！必须是数字！") else: result = ''.join(secrets.choice(characters) for i in range(int(num))) return HttpResponse(result) else: pass 前端页面mkpasswd.html如下： 1234567891011121314151617181920212223242526&#123;% extends 'base.html' %&#125;&#123;% block title %&#125; 创建密码&#123;% endblock %&#125;&#123;% block content %&#125; &#123;% csrf_token %&#125; &lt;h2&gt;创建密码&lt;/h2&gt; &lt;h3&gt;默认密码是20位，并且带有特殊符号&lt;/h3&gt; 密码长度：&lt;input type="text" id="number" /&gt;&lt;br /&gt; &lt;button&gt;生成密码&lt;/button&gt; &lt;div id="ask"&gt;&lt;h2&gt;&lt;/h2&gt;&lt;/div&gt; &lt;script&gt; $(document).ready(function()&#123; $("button").click(function()&#123; var word=document.getElementById('number').value //获取输入框的值 $.ajax(&#123; type:"POST", url:"&#123;% url "get_passwd" %&#125;", data:&#123;number:word&#125;, //传递参数 success:function(result)&#123;$("#ask").html(result);&#125; &#125;); &#125;); &#125;); &lt;/script&gt;&#123;% endblock %&#125; 最后整个的过程执行效果如下： 前端检验输入值合法俗话说得好，人生不折腾不舒服斯基。为了更好的体验，现在改一下方略：在用户输入的时候，页面要随时的判断输入值，有错误就直接提醒，这样就不用在提交的时候才告诉用户“输入值非法”了，但是这样的需求就需要更改判断逻辑—-把判断的任务交给jQuery而不是后台，jQuery判断成功了，再把值提交到后台。 要在输入的时候随时判断，那么就要使用jQuery的keydown功能，然后再配上each功能进行遍历。each的用法是$(selector).each(function(index,element))，这里index是选择器的index位置,而element是当前的元素，这两个元素都是必须的！ 那么只需要更改的是mkpasswd.html，内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041&#123;% block content %&#125; &#123;% csrf_token %&#125; &lt;h2 style="text-align:center;"&gt;创建密码&lt;/h2&gt;&#123;% endblock %&#125;&#123;% block content %&#125; &#123;% csrf_token %&#125; &lt;div style="text-align:center;"&gt; &lt;h2&gt;创建密码&lt;/h2&gt; //增加了居中效果 &lt;h3&gt;默认密码是20位，并且带有特殊符号&lt;/h3&gt; &lt;div&gt;密码长度：&lt;input style="margin: 5px; padding: 10px;" type="text" id="number" /&gt;&lt;br /&gt; //调整输入框的长宽 &lt;p style="color: red" id="error"&gt;&lt;/p&gt; //这里是警告出现的位置 &lt;button &gt;生成密码&lt;/button&gt; &lt;div id="ask"&gt;&lt;h2&gt;&lt;/h2&gt;&lt;/div&gt; //这里是结果出现的位置 &lt;/div&gt; &lt;script&gt; $(document).ready(function()&#123; $("#number").bind('keydown',function()&#123; //输入就开始检查 $('input').each(function(i,n)&#123; //进行遍历 var isnum = n.value.match(/^\d+$/g); //匹配正则表达式，是否是数字 if(null != isnum)&#123; $(n).css('border','2px solid green'); //是数字，边框变为绿色 document.getElementById("error").innerText=""; &#125;else&#123; $(n).css('border','2px solid red'); //不是数字，边框变为红色作为警告 document.getElementById("error").innerText="输入值必须是数字！"; &#125; &#125;); &#125;); $("button").click(function()&#123; //配置点击动作 var word=document.getElementById('number').value //获取输入框的值 $.ajax(&#123; type:"POST", url:"&#123;% url "get_passwd" %&#125;", data:&#123;number:word&#125;, //传递参数！！！！ success:function(result)&#123;$("#ask").html(result);&#125; &#125;); &#125;); &#125;); &lt;/script&gt;&#123;% endblock %&#125; 整改之后的效果如下： 参考资料http://www.blog.pythonlibrary.org/2017/02/16/pythons-new-secrets-module/https://www.cnblogs.com/yyds/p/7072492.htmlhttp://qindongliang.iteye.com/blog/2147336https://segmentfault.com/q/1010000002760528]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>Jquery</tag>
        <tag>Ajax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django前端输入变量通过内部脚本加工返回前端展示之六]]></title>
    <url>%2F2018%2F12%2F03%2F%E9%A1%B5%E9%9D%A2%E5%B1%80%E9%83%A8%E5%88%B7%E6%96%B0%E5%BE%97%E5%88%B0AES%E5%8A%A0%E5%AF%86%E5%80%BC%2F</url>
    <content type="text"><![CDATA[背景说明python：3.6.5Django：2.1.1Project：Kubernetes，文件夹路径就是/django/Kubernetes/App：createyaml，文件夹路径就是/django/Kubernetes/createyaml前文地址：https://rorschachchan.github.io/2018/11/29/Django%E4%B8%8EJquery%E3%80%81Ajax%E7%9A%84%E8%81%94%E5%90%88%E8%BF%90%E7%94%A8/ 需求说明以及实现思路原来通过前端输入值到后台脚本执行结果再反回页面是这样的： 现在接触了jQuery+ajax，那么就可以使用局部刷新来让界面变的更加友好。 我们在页面里配置了ajax，也要在views.py里配置request.POST.get，但是要注意，执行顺序是先执行ajax后执行request.POST.get，也就是说request.POST.get得到的是ajax加工过的值。如果是json字符串，就加一个dataType:&#39;json&#39;说明一下。 如果是一般的form表单形式，那么ajax的data部分可以这么写： 12345678$.ajax(&#123; url: url, data: &#123; limit: 10 &#125;, type: 'post', dataType: 'json'&#125;), 如果是直接发送一个json字符串到服务器，那么就要这么写： 123456789$.ajax(&#123; url: url, data: JSON.stringify(&#123; limit: 10 &#125;), type: 'post', dataType: 'json', contentType: 'text/plain'&#125;), 更多的使用方法可以去https://www.haorooms.com/post/jquery_ajax_wg 观摩一番。 具体代码前端文件encrypt.html内容如下： 12345678910111213141516171819202122232425&#123;% extends 'base.html' %&#125; &#123;% block title %&#125; AES加密&#123;% endblock %&#125;&#123;% block content %&#125; &#123;% csrf_token %&#125; &lt;h2&gt;AES加密&lt;/h2&gt; //将原来的form都取消了 要加密的字段：&lt;input type="text" id='word'&gt;&lt;br /&gt; &lt;button&gt;查询加密结果&lt;/button&gt; &lt;div id="ask"&gt;&lt;h2&gt;这里是结果&lt;/h2&gt;&lt;/div&gt; //设定id=ask，那么下面也要说明ask的div是要被局部刷新的 &lt;script&gt; $(document).ready(function()&#123; $("button").click(function()&#123; var keyword=document.getElementById('word').value //获取输入框的值，即name $.ajax(&#123; type:"POST", //指定方法是POST，如果不说明就是GET url:"&#123;% url "get_encrypt" %&#125;", //目标url就是get_encrypt函数结果 data:&#123;word:keyword&#125;, //规定name等于上面那个id，然后传递参数给django的views.py success:function(result)&#123;$("#ask").html(result);&#125; //返回get_encrypt函数结果 &#125;); &#125;); &#125;); &lt;/script&gt;&#123;% endblock %&#125; urls.py对应的部分如下： 12path(r'encrypt/',views.encrypt,name='encrypt'),path(r'get_encrypt/',views.get_encrypt,name='get_encrypt'), #这个是展示结果对应的函数 views.py对应的部分如下： 123456789101112131415默认部分略from django.views.decorators.csrf import csrf_exemptimport subprocessdef encrypt(request): return render(request,'encrypt.html') #请求encrypt就是展示encrypt.html页面@csrf_exempt #POST不检查csrf，正式环境不要这么用def get_encrypt(request): if request.method == 'POST': word = request.POST.get('word') #获取到name值，这个name是ajax加工过的 result = ("加密的结果是："+list(subprocess.getstatusoutput("java -jar /yunwei/AES/aesEncrpt.jar "+ word))[1].split("=")[1]) #这里执行java的命令得到结果 return HttpResponse(result) else: pass 启动django之后，打开对应的页面，效果如下： 而Request Headers部分如下： input标签id与name的区别最简单的说明：id就像是一个人的身份证号码，而name就像是他的名字，id显然是唯一的，而name是可以重复的，checkbox和radio都可以用name。id要符合标识的要求，比如大小写敏感，最好不要包含下划线（因为不兼容CSS）。而name基本上没有什么要求，甚至可以用数字。 如果在reset便签里这么写的话，重置功能将不会生效，因为id=&quot;reset&quot; name=&quot;reset&quot;，所以请极力避免用reset作为关键词。 1&lt;input type="reset" id="reset" name="reset" value="Reset" /&gt; 更多的区别可以看https://stackoverflow.com/questions/7470268/html-input-name-vs-id 。 参考资料https://blog.csdn.net/mingliangniwo/article/details/45533201https://thief.one/2017/09/14/3/https://www.haorooms.com/post/jquery_ajax_wghttp://www.cnblogs.com/birdshome/archive/2005/01/31/99562.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>Jquery</tag>
        <tag>Ajax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django前端输入变量通过内部脚本加工返回前端展示之五]]></title>
    <url>%2F2018%2F11%2F29%2FDjango%E4%B8%8EJquery%E3%80%81Ajax%E7%9A%84%E8%81%94%E5%90%88%E8%BF%90%E7%94%A8%2F</url>
    <content type="text"><![CDATA[背景说明python：3.6.5Django：2.1.1Project：Kubernetes，文件夹路径就是/django/Kubernetes/App：createyaml，文件夹路径就是/django/Kubernetes/createyaml前文地址：https://rorschachchan.github.io/2018/11/24/Django%E5%90%8E%E5%8F%B0%E6%89%A7%E8%A1%8C%E8%84%9A%E6%9C%AC%E5%8F%8D%E9%A6%88%E5%88%B0%E5%89%8D%E7%AB%AF%E8%BE%93%E5%87%BA/ 需求说明以及实现思路之前Django已经实现了点击按钮把值传入到后台脚本，同时把结果反馈到页面的效果了。但是那个逻辑太挫了:得把前端的变量存到本地去，然后后台的python脚本要去读取本地文件取的变量值执行任务。如果想用更加优雅的方法实现我们的目的那就要用jQuery+Ajax技术—-把目标反馈值包装成function调用，修改内置参数的方法，更容易上手，适合新手入门。 jQuery和Ajax的定义这里就不多说了，说直白点它们的作用就是不用离开当前的页面，而是在当前的页面加载出我们想要的结果，这就叫做异步刷新，这种刷新方法比较友好，而且可以少写一些html。 本次试验的目的就是在test111.html里随机输入内容，然后把数字“666”在当前页展示。效果如图： 这里我先使用POST方法，因为它无论是安全还是输入字符长度都要比GET方法优秀。但是要注意！如果代码中没有指明方法，那么默认就是GET方法。 具体代码前端页面test111.html的内容如下： 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset="utf-8"&gt; &lt;title&gt;TEST PAGE&lt;/title&gt; &lt;script src="https://cdn.staticfile.org/jquery/1.10.2/jquery.min.js"&gt;&lt;/script&gt; // 这里引用jquery.min.js &lt;script&gt; $(document).ready(function()&#123; //元素加载完成之后，绑定事件 $("#AJAX_post").click(function()&#123; //这里的AJAX_post与按钮的id一致，并且配置了点击click动作 var someth = $("#someth").val(); // 获取输入框的值 var data = &#123;"someth": someth&#125;; // 打包成get请求发送的数据 alert_text = '666即将出现！'; alert(alert_text); $.post( // post 方法请求服务器 '&#123;% url 'test111' %&#125;', // 请求的url data, // 这个data就是上面打包的数据 function(ret)&#123; // 回调函数，其中ret是返回的JSON var someth = ret['someth']; var num = ret['num']; // 这里把得到的两个值ret成查询结果 $("#result").text(num); // result就是输出到网页上的值，格式是text，如果是text(someth)，那么就会出现的是你随机输入的那段字符 &#125;) &#125;) &#125;); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;请随便输入：&lt;input type="text" id="someth" value=""&gt;&lt;/p&gt; &lt;p&gt;这里出现666：&lt;span id="result"&gt;&lt;/span&gt;&lt;/p&gt;&lt;/p&gt; &lt;button id="AJAX_post" type="button"&gt;ajax post&lt;/button&gt; &lt;/body&gt;&lt;/html&gt; ajax那部分虽然有注释，但是还是要多说一点： $(document).ready(function(){}:等待{}中涉及到的元素全部加载完，就按照function具体内容给它们绑定特殊事件; $(&quot;button&quot;).click(function(){}:$(&quot;AJAX_post&quot;)是Jquery的选择器，表示页面的“按钮”，.click(function(){}为前面选中的元素，绑定一个鼠标点击的事件，具体事件是function()里面； $.post：表示调用了post方法，里面有三个元素，用逗号隔开，分别是URL,data（可省略）和callback（可省略，其中URL可以就是要局部刷新后展示的那个页面； 如果想把变量以字符串的形式输入，那么就是var id=document.getElementById(&#39;name&#39;).value，如果单独使用request.GET.get，得到的数据类型是&#39;NoneType&#39;; 而对应的views.py那部分函数的内容如下： 1234567891011121314from django.views.decorators.csrf import csrf_exempt@csrf_exempt #取消CSRF保护，线上环境请不要这样def test(request): if request.method == 'POST': someth = request.POST.get('someth') #从前端获取name值 num = "666" #已经定义好了666，然后会被ret得到 data = &#123;&#125; data['someth'] = someth data['num'] = num print (data) return JsonResponse(data) else: return render(request,'test111.html') 对应的urls.py内容如下： 1path(r'test111',views.test,name='test111'), 保存之后，启动django，在test111.html页面即可达到效果。 参考资料http://www.runoob.com/jquery/jquery-ajax-get-post.htmlhttps://zhuanlan.zhihu.com/p/27665172https://my.oschina.net/esdn/blog/814094https://www.jianshu.com/p/26cd9f442a13https://segmentfault.com/a/1190000009938183 （rel=noopener的问题）]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>Jquery</tag>
        <tag>Ajax</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[服务器被入侵了]]></title>
    <url>%2F2018%2F11%2F27%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%A2%AB%E5%85%A5%E4%BE%B5%E4%BA%86%2F</url>
    <content type="text"><![CDATA[情况描述今天上班，甲方爸爸在微信里叫“设备直播无法播放”，登录到zabbix发现，播放模块的服务器的zabbix-agent已经脱落，而且这个服务器可以ping通但是不能ssh通。 让机房的人去重启了一下服务器，登录之后发现里面有一个很奇怪的进程watchbog： 这个进程不应该出现的，同时查看crontab -l的内容也已经变了： 我登录了一下https://pastebin.com，发现这个是一个提供类似便签记事的网站，黑客应该就是现在这个网站里输入了远程的脚本，然后让这台肉鸡去curl这个网站的网页达到下载脚本然后启动了watchbog进程的目的。 于是我就find / -name \* -type f -print | xargs grep &quot;pastebin&quot;，看一下系统里都有哪些文件里含有pastebin这个关键词。于是乎先发现/usr/bin里有几个不应该存在的命令： 然后顺藤的发现几乎所有的crontab文件都已经被污染了： 把以上所有被污染的文件全部删光内容，将watchbog进程彻底杀死。观察了一会，貌似没有复现问题。 后续解决方案 在zabbix监控上添加对watchbog进程的监控，如果出现直接通知负责人； 将ssh的22端口更改成33664端口，规定只有堡垒机可以登录； 与开发商议，确认此服务器的外网权限可以撤掉，于是撤掉外网IP； PS. http://www.4usky.com/ https://www.shutterstock.com/zh/ 这俩是很不错的壁纸网站~]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>centos 6.5</tag>
        <tag>后门软件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django前端输入变量通过内部脚本加工返回前端展示之四]]></title>
    <url>%2F2018%2F11%2F24%2FDjango%E5%90%8E%E5%8F%B0%E6%89%A7%E8%A1%8C%E8%84%9A%E6%9C%AC%E5%8F%8D%E9%A6%88%E5%88%B0%E5%89%8D%E7%AB%AF%E8%BE%93%E5%87%BA%2F</url>
    <content type="text"><![CDATA[背景说明python：3.6.5Django：2.1.1Project：Kubernetes，文件夹路径就是/django/Kubernetes/App：createyaml，文件夹路径就是/django/Kubernetes/createyaml前文地址：https://rorschachchan.github.io/2018/09/26/Django%E4%BD%BF%E7%94%A8form%E8%A1%A8%E5%8D%95%E5%88%A4%E6%96%AD%E8%BE%93%E5%85%A5%E5%80%BC%E6%98%AF%E5%90%A6%E5%90%88%E6%B3%95/ 需求说明之前我们已经达到了“页面判断输入值是否合法”，“页面输入值录入数据库”这两个目的，现在就到了重头戏–网页上点击按钮，然后调用后台python脚本，并且把脚本的结果反馈到网页端。 我们本次使用一个加密的python脚本encrypt.py，它主要得作用是输入某个字段，然后进行AES256加密，然后把加密结果返回给界面，整个脚本内容如下： 1234567#!/usr/bin/env python#coding=utf-8import subprocessAESWord = input("输入字段：")result = list(subprocess.getstatusoutput("java -jar /yunwei/AES/aesEncrpt.jar "+AESWord))[1].split("=")[1]print (AESWord+ "的加密结果是："+(result)) 脚本执行效果如下： 笨方法解决前端的页面内容如下： 12345678910111213&#123;% extends &apos;base.html&apos; %&#125; #这部分是引入base.html这个模板&#123;% block title %&#125; AES加密&#123;% endblock %&#125;&#123;% block content %&#125; &lt;form action=&quot;/k8s/encrypt/&quot; method=&quot;post&quot; name=&apos;encrypt&apos;&gt; &#123;% csrf_token %&#125; 要加密的字段：&lt;input type=&quot;text&quot; name=&quot;AESWord&quot; /&gt;&lt;br /&gt; &lt;input type=&quot;reset&quot; value=&quot;清除所有&quot; /&gt; &lt;input type=&quot;submit&quot; value=&quot;查询解析&quot; /&gt; &lt;/form&gt;&#123;% endblock %&#125; 目前已知views.py里使用request.POST.get()方法是可以捕获到前端输入值，但是这个输入值怎么传递给encrypt.py呢？这一点非常的复杂。 可能这个时候很多人会想使用“外部脚本引入django系统”的方法，但是那个方法可以引用到数据库，但是无法引用views.py里的函数的变量。于是只能用一个笨招：先把前端输入值记录到本地某个文件里，然后encrypt.py去读取这个文件，这样达到获取变量的方法。 于是views.py里的相关部分就是这样： 123456789101112前面略def encrypt(request): if request.method == 'POST': AESWord = request.POST.get('AESWord') with open('/yunwei/AES/AESWord.txt','w') as f: #把前端获取到的值记录到本地的AESWord.txt文件里 f.write(AESWord+"\n") child = subprocess.Popen('python /yunwei/AES/Encrypt.py',stdout=subprocess.PIPE, stderr=subprocess.PIPE,shell=True) stdout, stderr = child.communicate() result = str(stdout,encoding='utf-8') #将脚本反馈的结果输入result return HttpResponse(result) #页面展示result else: return render(request,'encrypt.html') 而encrypt.py内容改成如下： 1234567#!/usr/bin/env python#coding=utf-8import linecache,subprocessAESWord = linecache.getline(&apos;/yunwei/AES/AESWord.txt&apos;,1).strip(&apos;\n&apos;) #在这里读取前端的变量result = list(subprocess.getstatusoutput(&quot;java -jar /yunwei/AES/aesEncrpt.jar &quot;+AESWord))[1].split(&quot;=&quot;)[1]print (AESWord+ &quot;的加密结果是：&quot;+(result)) 执行效果如下： 这样的操作达到了目的！后期就是把result使用render加工映射到某个网页，页面就好看很多了。 js+ajax方法解决上面的方法虽然可以达到我们想要的目的，但是其实是十分不推荐的：一是因为网页调用本地程序的权限正在被取消，二是因为真不如JS写直接，三是只能在自己本地调用。 所以还是用前端来解决更专业更优雅，那么就要使用js+ajax。 具体内容下次补充… 补充在外部脚本引入django系统的方法就是在外部脚本的开头加上下面的内容： 12345678#!/usr/bin/env python#coding=utf-8import os,sys,djangosys.path.append('/django/Kubernetes/') # 将项目路径添加到系统搜寻路径当中os.environ['DJANGO_SETTINGS_MODULE'] = 'Kubernetes.settings' # 设置项目的配置文件django.setup()from createyaml.models import parameter #这样就可以引入models.py文件里的parameter这个类 但是上面说过，这个方法可以引入数据库models.py文件，并不能引入views.py文件。 参考资料https://stackoverflow.com/questions/15151133/execute-a-python-script-on-button-clickhttps://blog.csdn.net/yzy_1996/article/details/80223053https://simpleisbetterthancomplex.com/tutorial/2016/08/29/how-to-work-with-ajax-request-with-django.htmlhttps://www.candypapi.com/2017/11/02/Python-external-script-calls-the-Django-project-model-table/https://segmentfault.com/q/1010000005096919]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git clone的几个错误]]></title>
    <url>%2F2018%2F11%2F12%2FGit-clone%E7%9A%84%E5%87%A0%E4%B8%AA%E5%B0%8F%E6%95%85%E9%9A%9C%2F</url>
    <content type="text"><![CDATA[Git clone的时候可能会出现fatal: HTTP request failed的错误，如图： 一般来说这样的情况多半就是git版本太低，&lt;=1.7的版本经常出现这样的错误，解决问题的办法就是使用最新的git，安装git 1.9的方法在这里：https://rorschachchan.github.io/2018/06/13/Centos6%E5%AE%89%E8%A3%85git1-9%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/ 。 更新到1.9之后重新去git clone，这一次换成了SSL connect error错误： 此时就需要执行一下yum update -y nss curl libcurl，这样才能顺利的git clone。 如果出现了easy_install command not found，可以使用wget https://bootstrap.pypa.io/ez_setup.py -O - | python 解决，有了easy_install就可以安装pip了。 以上的操作是在python2.7下进行的。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>Python 2.7</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过调整Css让界面美观一点]]></title>
    <url>%2F2018%2F11%2F05%2F%E9%80%9A%E8%BF%87%E8%B0%83%E6%95%B4Css%E8%AE%A9%E7%95%8C%E9%9D%A2%E7%BE%8E%E8%A7%82%E4%B8%80%E7%82%B9%2F</url>
    <content type="text"><![CDATA[数据可视化肯定需要前端知识，同时也要美化前端，让用户的体验更好，这时候就需要接触到css技术。 css简单来说就是先给你需要修饰的部分设定变量，然后针对不同的变量做不同的声明，达到修改界面的目的。css规则由两个主要的部分构成：选择器，以及一条或多条声明，格式是：selector {declaration1; declaration2; ... declarationN }。 在html文本里添加一个style标签，比如：&lt;style type=&quot;test/css&quot;&gt; &lt;/style&gt;。这个标签可以放到&lt;body&gt;最尾处也可以放到&lt;head&gt;最尾处。不过一般来说都是放到&lt;body&gt;里。 在调整css的时候，可以搭配chrome的F12键直接修改，然后将修改的内容拷贝粘贴到html文件里。 比如我现在的页面是如下这个样子的： 这个结构可以看出使用最直白的html语言编写，为了美观大方，我们需要把它改成如下的样子： 原来的代码如下： 12345678910111213&lt;body&gt; &lt;div&gt; &lt;a href="&#123;% url 'home' %&#125;"&gt; &lt;h2&gt;Homepage&lt;/h2&gt; &lt;/a&gt; &lt;a href="&#123;% url 'blog_list' %&#125;"&gt;List&lt;/a&gt; &lt;a href="http://www.baidu.com"&gt;跳往百度&lt;/a&gt; &lt;a href="http://www.lechange.com"&gt;跳往乐橙&lt;/a&gt; &lt;/div&gt; &lt;hr&gt; &#123;% block content %&#125; &#123;% endblock %&#125;&lt;/body&gt;&lt;/html&gt; 更改后的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;body&gt; &lt;div class="nav"&gt; &lt;!-- 给这个div标签添加一个class叫nav --&gt; &lt;a class="logo" href="&#123;% url 'home' %&#125;"&gt; &lt;!-- 给这个div下的这个a标签添加一个class叫logo --&gt; &lt;h2&gt;Homepage&lt;/h2&gt; &lt;/a&gt; &lt;a href="&#123;% url 'blog_list' %&#125;"&gt;List&lt;/a&gt; &lt;a href="http://www.baidu.com"&gt;跳往百度&lt;/a&gt; &lt;a href="http://www.lechange.com"&gt;跳往乐橙&lt;/a&gt; &lt;/div&gt; &lt;hr&gt; &#123;% block content %&#125; &#123;% endblock %&#125; &lt;style type='text/css'&gt; body&#123; margin: 0; padding: 0; &lt;!-- 这是对整个body标签进行声明，外边距和内边距都是0 --&gt; &#125; div.nav&#123; background-color: #eee; border-bottom: 2px solid blue; padding: 5px 10px; &lt;!-- 这是对整个nav的div标签进行声明：颜色灰色 --&gt; &lt;!-- 增加一条底线取代&lt;hr&gt;，设定宽是2px，实线，颜色是蓝色 --&gt; &lt;!-- 设定上下边距5px,左右边距10px --&gt; &#125; div.nav a&#123; text-decoration: none; color: #000; &lt;!-- 这是对整个nav的div标签里的所有a标签说明：取消下划线，并且规定为黑色 --&gt; &#125; div.nav a.logo &#123; display: inline-block; color: green; font-size:120%; &lt;!-- 在这里对nav的div标签里那个叫logo的a标签进行单独的说明：缩进，并且规定为绿色 --&gt; &lt;!-- 字体大小是原来的120% --&gt; &#125; &lt;/style&gt;&lt;/body&gt;&lt;/html&gt; 调整css是一个很繁琐很麻烦的事情，需要耐心。至于如何整合css样式到一个文件然后统一配置的内容，请去看：https://rorschachchan.github.io/2018/05/12/%E5%8A%A0%E8%BD%BDcss%E6%A0%B7%E5%BC%8F%E7%9A%84%E4%B8%A4%E4%B8%AA%E6%96%B9%E6%B3%95/ 。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>html</tag>
        <tag>css</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用模板嵌套来精简html代码]]></title>
    <url>%2F2018%2F11%2F02%2F%E4%BD%BF%E7%94%A8%E6%A8%A1%E6%9D%BF%E6%A0%87%E7%AD%BE%E6%9D%A5%E7%B2%BE%E7%AE%80html%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[在编写django的时候，前端html文件里经常会遇到很多有大量重复代码的情况出现，为了代码精简好看以及后期维护的方便，就需要把那些重复的代码统一放到一个文件里去，不重复的部分自然保留，文件到时直接调用重复模板就好，不同的部分对应填充。 举个例子，有一个代码是templates/aaa.html： 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&apos;UTF-8&apos;&gt; &lt;title&gt;&#123;&#123; blog.title &#125;&#125;&lt;/title&gt; &lt;!-- blog.title就是文章标题，从数据库中提取，使用vender映射出来 --&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; &lt;a href=&quot;&#123;% url &apos;home&apos; %&#125;&quot;&gt; &lt;h2&gt;BACK TO HOMEPAGE&lt;/h2&gt; &lt;!-- 这部分是重复的 --&gt; &lt;/a&gt; &lt;/div&gt; &lt;h3&gt;&#123;&#123; blog.title &#125;&#125;&lt;/h3&gt; &lt;!-- 这一部分也是同样用vender映射，展现每一篇文章对应的作者和内容 --&gt; &lt;p&gt;作者：&#123;&#123; blog.author &#125;&#125;&lt;/p&gt; &lt;p&gt;分类： &lt;a href=&quot;&#123;% url &apos;blogs_with_type&apos; blog.blog_type.pk %&#125;&quot;&gt; &#123;&#123; blog.blog_type &#125;&#125; &lt;/a&gt; &lt;/p&gt; &lt;p&gt; &#123;&#123; blog.blog_type.pk &#125;&#125;&lt;/p&gt; &lt;p&gt;发表时间：&#123;&#123; blog.created_time|date:&quot;Y-m-d H:i:s&quot;&#125;&#125;&lt;/p&gt; &lt;!-- 这里规定了时间格式 --&gt; &lt;hr&gt; &lt;p&gt;&#123;&#123; blog.content &#125;&#125;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 假设aaa.html里”BACK TO HOMEPAGE”这个部分是重复的，即每一个页面都有返回主页的点击。既然都有这个功能，那么就单独做一个base.html文件当框架，把重复的部分写进去： 12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&apos;UTF-8&apos;&gt; &lt;title&gt;&#123;% block title %&#125;&#123;% endblock %&#125;&lt;/title&gt; &lt;!--这里加入了一个block(块），块的名字叫title--&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; &lt;a href=&quot;&#123;% url &apos;home&apos; %&#125;&quot;&gt; &lt;h2&gt;BACK TO HOMEPAGE&lt;/h2&gt; &lt;/a&gt; &lt;/div&gt; &lt;hr&gt; &#123;% block content%&#125; &#123;% endblock %&#125; &lt;!--这里又加入了一个block，块的名字叫content--&gt;&lt;/body&gt;&lt;/html&gt; 现在的base.html就是一个框架，里面有了两个block，这两个块有各自的名称，因为这两个块的内容是变化的。再把aaa.html里需要对应配置的部分定义成对应的变量，并且引入这个base.html即可。重新修理后的aaa.html就长这个样子了： 12345678910111213141516171819&#123;% extends &apos;base.html&apos; %&#125; &lt;!--首先引入同目录下的base.html--&gt;&#123;% block title%&#125; &#123;&#123; blog.title &#125;&#125; &lt;!--这部分就是title块的内容--&gt;&#123;% endblock%&#125;&#123;% block content %&#125; &lt;!--这一段就是content块的内容--&gt; &lt;h3&gt;&#123;&#123; blog.title &#125;&#125;&lt;/h3&gt; &lt;p&gt;作者：&#123;&#123; blog.author &#125;&#125;&lt;/p&gt; &lt;p&gt;分类： &lt;a href=&quot;&#123;% url &apos;blogs_with_type&apos; blog.blog_type.pk %&#125;&quot;&gt; &#123;&#123; blog.blog_type &#125;&#125; &lt;/a&gt; &lt;/p&gt; &lt;p&gt; &#123;&#123; blog.blog_type.pk &#125;&#125;&lt;/p&gt; &lt;p&gt;发表时间：&#123;&#123; blog.created_time|date:&quot;Y-m-d H:i:s&quot;&#125;&#125;&lt;/p&gt; &lt;hr&gt; &lt;p&gt;&#123;&#123; blog.content &#125;&#125;&lt;/p&gt;&#123;% endblock %&#125; 将aaa.html保存之后，刷新对应的页面，会发现依旧可以成功读取而且界面没有任何的变化。 可是在实际操作中也会出现这样的需求：多个不同的django APP可能会要访问同一个模板文件（即base.html），那么就要每一个app都复制一遍base.html吗？其实大可不必。这里可以修改一下setting.py，在里面设置一下公共的模板文件路径。 首先我们现在project根目录下建立一个base文件夹，把base.html复制进去，然后修改一下setting.py如下的字段： 1234567891011121314151617TEMPLATES = [ &#123; &apos;BACKEND&apos;: &apos;django.template.backends.django.DjangoTemplates&apos;, &apos;DIRS&apos;: [ os.path.join(BASE_DIR，&apos;base&apos;), #BASE_DIR是在文件最开始定义的，即project的根目录 ], &apos;APP_DIRS&apos;: True, #这句话的意思是templates文件夹里所有的文件都可以访问 &apos;OPTIONS&apos;: &#123; &apos;context_processors&apos;: [ &apos;django.template.context_processors.debug&apos;, &apos;django.template.context_processors.request&apos;, &apos;django.contrib.auth.context_processors.auth&apos;, &apos;django.contrib.messages.context_processors.messages&apos;, ], &#125;, &#125;,] 保存之后，再次刷新界面，发现界面没变化。这里django在寻找页面的时候，就会去project的路径/base下先找对应的文件，如果没有，会再去自己应用下的templates文件夹里找。如果两个都没有，那就会报错base.html is not exist。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>前端</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置IP白名单]]></title>
    <url>%2F2018%2F10%2F31%2FNginx%E9%85%8D%E7%BD%AEIP%E7%99%BD%E5%90%8D%E5%8D%95%2F</url>
    <content type="text"><![CDATA[环境交代Nginx配置IP白名单是非常基础的工作，这次试验就是配置某网页可以正常被部分IP访问，而其他网页访问将是403。目标网页地址是http://xxdtq.lechange.com/test/test.html，内容如下： 本机的外网IP地址是115.205.2.28，如图： 首先先nginx.conf里的日志配置格式如下： 123log_format access &apos;$http_x_forwarded_for - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; $remote_addr $request_time $upstream_response_time $http_host&apos;; Nginx的转发文件default.conf如下： 123456789101112131415server &#123; listen 80; server_name xxdtq.lechange.com; #如果浏览器输入的是xxdtq.lechange.com，那么就跳转到82端口 location / &#123; proxy_pass http://localhost:82; &#125;&#125;server &#123; listen 80; server_name xhssf.lechange.com; #如果浏览器输入的是xhssf.lechange.com，那么就跳转到82端口 location / &#123; proxy_pass http://localhost:83; &#125;&#125; 配置步骤现在配置xxdtq.conf文件内容如下： 123456789101112131415161718192021 server&#123; listen 82 default; #82端口 server_name xxdtq.lechange.com; root /mnt/xiuxiudetiequan/; #根目录是/mnet/xiuxiudetiequan/ index index.html index.htm index.php; add_header Set-Cookie &quot;HttpOnly&quot;; add_header Set-Cookie &quot;Secure&quot;; add_header X-Frame-Options &quot;SAMEORIGIN&quot;; add_header Strict-Transport-Security &quot;max-age=31536000; includeSubDomains&quot; always; location = /test/test.html &#123; #如果remote_addr是125.205.2.28来访问/test/test.html，那么就返回403 if ($remote_addr = 115.205.2.28) &#123; return 403; &#125; &#125; access_log /var/log/nginx/xxdtq/access.log access; error_log /var/log/nginx/xxdtq/error.log error;&#125; 执行了nginx -s reload后，刷新一下界面，却发现页面没变，并不是预期中的403，打开nginx的日志一看，发现获取到的$remote_addr是127.0.0.1！如下： 为什么是127.0.0.1？因为我们这个nginx做了一个80到82端口的转发呀，所以到80的地址是真实的外界IP，而80转发到82就是本机IP了。那这样的情况怎么办？就需要在default.conf里添加一句proxy_set_header x-forwarded-for $remote_addr;，如下： 12345678server &#123; listen 80; server_name xxdtq.lechange.com; location / &#123; proxy_pass http://localhost:82; proxy_set_header x-forwarded-for $remote_addr; &#125;&#125; 重启一波nginx，发现http_x_forwarded_for正是远程访问的IP地址115.205.2.28，于是将xxdtq.conf判断IP改成如下内容： 12345location = /test/test.html &#123; if ($http_x_forwarded_for = 115.205.2.28) &#123; #改用http_x_forwarded_for return 403; &#125; &#125; 重启nginx之后，果然页面是403，如图： 然后用其他的IP地址，比如用手机连接4G去打开http://xxdtq.lechange.com/test/test.html ，发现是正常读取的，试验成功！ 如果是要整个/test/目录都不让访问的话，就要改成如下内容： 12345location ^~ /test/ &#123; if ($http_x_forwarded_for = 115.205.2.28) &#123; # =是精确匹配 return 403; &#125; &#125; 如果要配置多个IP地址，就要改成如下内容： 12345location ~ ^/shopadmin &#123; if ($remote_addr ~* &quot;第一个IP|第二个IP|第三个IP&quot;) &#123; #这里改成~* return 403; &#125;&#125; elk里提取http_x_forwarded_fornginx日志中的http_x_forwarded_for字段会有多个IP。使用自定义的模板，grok常用表达式的IPORHOST匹配http_x_forwarded_for该字段，获取的IP值是最后一个，如何取第一个IP值？ 答案是： 1234mutate &#123; split =&gt; [&quot;http_x_forwarded_for&quot;,&quot;,&quot;] add_field =&gt; [&quot;real_remote_addr&quot;,&quot;%&#123;http_x_forwarded_for[0]&#125;&quot;] &#125; IPORHOST这些变量匹配不到所有IP，只能通过自定义正则来匹配到所有IP；再通过以上方法截取第一个IP值。正则表达式写法是：[\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}\,\s]* 参考资料http://seanlook.com/2015/05/17/nginx-location-rewrite/https://zhuanlan.zhihu.com/p/21354318http://blog.pengqi.me/2013/04/20/remote-addr-and-x-forwarded-for/http://gong1208.iteye.com/blog/1559835https://my.oschina.net/moooofly/blog/295853]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[两个Zabbix_get问题记录]]></title>
    <url>%2F2018%2F10%2F30%2FZabbix-get%E5%8F%8D%E9%A6%88%E7%9A%84%E7%BB%93%E6%9E%9C%E6%98%AFcontacting%2F</url>
    <content type="text"><![CDATA[Zabbix_get的结果是contacting在监控zookeeper的时候，我写了一个简单的脚本checkZKrole.sh来获取当前的角色，如下： 1234[root@zookeeper1 ~]# cat checkZKrole.sh #!/bin/bashrole=$(sh /usr/zookeeper/bin/zkServer.sh status| cut -d&quot; &quot; -f2)echo $role 执行效果如下： 本地执行没问题，然后在zabbix-agentd.conf里也把这个脚本添加到自定义监控项里： 重启了zabbix-agent后，发现一个很奇怪的现象，在zabbix-server里使用zabbix-get去拿值的时候拿到的是contacting，如图： 从上图可见，同样在127.1.1.28里取值，proc.num没问题，而且是秒取，但是这个自定义项就取不到。 我怀疑是脚本的问题，于是我改成一个单纯的echo，如下: 12345[root@zookeeper1 ~]# cat checkZKrole.sh #!/bin/bashrole=$(sh /usr/zookeeper/bin/zkServer.sh status| cut -d&quot; &quot; -f2)#echo $roleecho woshinibaba 这一次的返回值是正常的，可见不是脚本的问题： 那是他妈的什么问题，真是见了鬼了…后来想干脆写一个crontab，让crontab把角色写到本地，然后再用cut命令切开把结果当做zabbix_get的目标。但是在这里发现了问题所在，当我的crontab是* * * * * cd /usr/zookeeper/bin/; ./zkServer.sh status &gt; /tmp/role.txt &gt; /dev/null 2&gt;&amp;1，发现/tmp/role.txt里根本没有值，应该是crontab在执行有参数的命令的时候出现了问题。 后来发现了，原来是sudo搞得鬼，如果是由于zookeeper是root用户启动的，所以只有root用户能成功访问，如果是sudo的话，那么就会返回“Error contacting service. It is probably not running.”，所以截取出来的部分就是contacting，如图： zabbix_get执行脚本超时在监控mq队列时候，同样也需要到了自定义监控项，我写了几个简单的脚本如下： 1234567891011121314151617[root@dahuatech zabbix]# cat monitor_mq.sh #!/bin/ship=$1queuename=$2type=$3case $&#123;type&#125; in Pending) curl -s -u &apos;admin:admin&apos; &quot;http://$&#123;ip&#125;:8161/admin/queues.jsp&quot;|grep &quot;$&#123;queuename&#125;&lt;/a&gt;&lt;/td&gt;&quot; -A 5|sed -n &apos;2p&apos;|egrep -o &apos;[0-9]+&apos; ;; Enqueued) curl -s -u &apos;admin:admin&apos; &quot;http://$&#123;ip&#125;:8161/admin/queues.jsp&quot;|grep &quot;$&#123;queuename&#125;&lt;/a&gt;&lt;/td&gt;&quot; -A 5|sed -n &apos;4p&apos;|egrep -o &apos;[0-9]+&apos; ;; Dequeued) curl -s -u &apos;admin:admin&apos; &quot;http://$&#123;ip&#125;:8161/admin/queues.jsp&quot;|grep &quot;$&#123;queuename&#125;&lt;/a&gt;&lt;/td&gt;&quot; -A 5|sed -n &apos;5p&apos;|egrep -o &apos;[0-9]+&apos; ;;esac 配置了UserParameter=activemq.check[*],sh /etc/zabbix/monitor_mq.sh $1 $2 $3放到zabbix-agentd.conf里，重启了zabbix-agent。在zabbix-server配置了对应的item，如图： 然后在本地执行这个脚本，发现回值秒取，但是同样在zabbix-get里使用，就是timeout： 后来发现原来自己摆了一个乌龙，在zabbix-get的时候不能使用{HOST.IP}，因为zabbix-get不识别他，但是zabbix-server是识别的，所以在脚本里把ip=$1改成ip=真实的IP地址即可。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql主从同步的几个要点总结]]></title>
    <url>%2F2018%2F10%2F23%2FMysql%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E7%9A%84%E5%87%A0%E4%B8%AA%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[同步原理主从同步是Mysql非常常见的一个应用，也是非常重要的监控之处，这里简单总结在配置Mysql时候的几个要点，防止以后自己踩坑。 先说一下主从同步的原理，就是主数据库在数据库更新的时候会更新自己的binlog，同时也会向读数据库（一个或多个）传递这个binlog，此时从库开始一个io_thread这个线程用来接收这个binlog，然后把binlog写入到自己的relaylog，当relaylog发现有数据更新了，就开始一个sql_thread来按照主库更新自己的库，这样达到了“主库读库一致”的效果。图示如下： 上述过程：主从延迟：「步骤2」开始，到「步骤7」执行结束。步骤 2：存储引擎处理，时间极短步骤 3：文件更新通知，磁盘读取延迟步骤 4：Bin Log 文件更新的传输延迟，单线程步骤 5：磁盘写入延迟步骤 6：文件更新通知，磁盘读取延迟步骤 7：SQL 执行时长 要监控主从同步是否出现异常，可以通过show slave status\G里的Seconds_Behind_Master字段来查看，如图： 但是要注意！Seconds_Behind_Master是有前提的，那就是主库跟读库之间的网络情况要良好，因为这个字段是从属服务器SQL线程和从属服务器I/O线程之间的时间差距，（即比较binlog和relaylog执行sql的timestamp时间差），单位是秒。如果主服务器和从属服务器之间的网络连接较快，则从属服务器I/O线程会非常接近主服务器，所以本字段能够十分近似地指示，从属服务器SQL线程比主服务器落后多少。如果网络较慢，则这种指示不准确；从属SQL线程经常会赶上读取速度较慢地从属服务器I/O线程，因此，Seconds_Behind_Master经常显示值为0。即使I/O线程落后于主服务器时，也是如此。换句话说，本列只对速度快的网络有用。 要点总结 主库和读库的mysql版本保持一致，硬件情况也保持一致； binlog文件在生产系统中不易过大，建议小于500m，不然容易拖慢数据库性能； 设置slave前先检查一下设置的账号能不能远程登陆； 在设置多个库同步时，一个binlog-do-db参数对应一个库，不能一行写多个库； 如果出现了Slave_IO_Running: No这个状态，去主库上show master status\G，查看一下是否file跟从库的file是不是对不上； 代码里避免出现“查询读库后马上到主库操作”的字段，由于主从同步有延迟，这样很有可能会出现前端多次请求，而从库一致无法从主库得到最新的数据消息，所以sql被执行了好几次的错误，这样的情况可以考虑加入“可以用唯一索引限制”或者用insert … select … where not exist这种方式； 主库的慢sql太多的话，也会影响主从同步； 参考资料https://dba.stackexchange.com/questions/24793/mysql-replication-slave-is-continuously-lagging-behind-masterhttp://ningg.top/inside-mysql-master-slave-delay/http://database.51cto.com/art/201108/287653.htmhttps://zhuanlan.zhihu.com/p/28554242]]></content>
      <categories>
        <category>大牛之路</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Dockbix监控进程]]></title>
    <url>%2F2018%2F10%2F15%2F%E4%BD%BF%E7%94%A8dockbix%E7%9B%91%E6%8E%A7%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[之前在https://rorschachchan.github.io/2018/05/17/%E4%BD%BF%E7%94%A8zabbix%E5%8E%BB%E7%9B%91%E6%8E%A7docker%E5%AE%B9%E5%99%A8/ 介绍了如何使用dockbix去自动监控容器的cpu、mem和端口等值。而本文的内容就是讲述如何使用dockbix监控进程。 服务器情况如下：172.31.0.77，普通模式安装zabbix-server；172.16.0.194，服务器里有两个容器，一个是dockbix，另一个是具体的服务，里面是一个centos 7跑着nginx和php两个进程，如图： 如果你启动dockbix的语句是这样的话: 12345678910docker run \ --name=dockbix-agent-xxl \ --net=host \ --privileged \ -v /:/rootfs \ -v /var/run:/var/run \ --restart unless-stopped \ -e "ZA_Server=zabbix-server的IP地址" \ -e "ZA_ServerActive=zabbix-server的IP地址" \ -d monitoringartist/dockbix-agent-xxl-limited:latest 那么发现监控进程是失败的，如图： 原因就是dockbix和具体服务之间是两个独立的进程，所以dockbix无法访问到另一个容器的进程情况，这样就要干掉原有的dockbix，并且更改一下dockbix的启动语句： 1234567891011docker run \ --name=dockbix-agent-xxl \ --net=host \ --pid=host \ #增加这句话 --privileged \ -v /:/rootfs \ -v /var/run:/var/run \ --restart unless-stopped \ -e "ZA_Server=172.31.0.77" \ -e "ZA_ServerActive=172.31.0.77" \ -d monitoringartist/dockbix-agent-xxl-limited:latest 然后再去重新使用zabbix-get命令，就可以获取到进程了！ 默认下，所有的容器都启用了PID命名空间。PID命名空间提供了进程的分离。PID命名空间删除系统进程视图，允许进程ID可重用，包括pid 1。docker run的时候添加了--pid=host就是允许容器内的进程可以查看主机的所有进程。 如果是不要看所有主机的进程，而只是看某一个容器的进程，其他进程pid不看怎么设置呢？ 12docker run --name my-redis -d redis #假设你启动了一个名叫my-redis的容器docker run -it --pid=container:my-redis my_strace_docker_image bash #在建立一个my_strace_docker_imag容器，只与my-redis共享pid 如果zabbix-server发现容器内的某个服务死了，要进入容器里重启服务怎么办？答曰：docker exec 容器ID /bin/bash -c &quot;启动服务命令&quot; 参考资料https://github.com/monitoringartist/dockbix-agent-xxl/issues/42https://www.zabbix.com/documentation/3.4/zh/manual/appendix/items/proc_mem_num_noteshttps://docs.docker.com/engine/reference/run/#imagetag]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql.sock没了怎么办？]]></title>
    <url>%2F2018%2F10%2F15%2FMysql-sock%E6%B2%A1%E4%BA%86%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[今天在调整jumpserver堡垒机资产用户的时候，在点击“更新”的时候，爆出127.0.0.1:3306无法被访问，于是登录到服务器里一看，发现mysql进程挂了。先检查服务器存储空间，发现还很富裕，于是就启动mysql，爆出来如下错误： 12[root@lcshop-jumpserver ~]# mysqlERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (111) 然后来到/var/lib/mysql/里，瞅着这个紫了吧唧的mysql.sock，脑子一抽，把它删了… 删了… 这尼玛，再次启动mysql，错误码从111变成2： 12[root@lcshop-jumpserver mysql]# mysqlERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2) 这一下就尴尬了，mysql.sock没了怎么生成？有人说“重启服务器可以生成”，事实证明这就是纯粹的扯淡。真实的方法是：mysqld_safe &amp;。 如果mysqld_safe &amp;命令失败了，就要去查看一下mysql的日志，多半是某个文件权限不对，要改成mysql用户。 补充一句其他的问题：ImportError: libxslt.so.0: cannot open shared object file: No such file or directory，遇到这个问题怎么办？ yum install libxslt-devel -y]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>jumpserver堡垒机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker部署的几个tips]]></title>
    <url>%2F2018%2F10%2F10%2FDocker%E9%83%A8%E7%BD%B2%E7%9A%84%E5%87%A0%E4%B8%AAtips%2F</url>
    <content type="text"><![CDATA[公司的电商平台使用的是阿里云VPC网络，整个交换机和云服务器都是部署在D区。今天在部署测试环境的时候，发现无法购买服务器，在钉钉上与阿里云售后交涉后，接到噩耗—D区已经不再出售服务器了，如图： 没办法，只能把现有的服务器调高配置，在里面安装docker，尽可能的让各进程的环境彼此之间不受干扰。由于事发仓促，整个架构都要重新调整，镜像就先选用centos：latest，生成容器后在里面装环境以及git pull代码，把容器当做虚拟机来用了。 几个小提示 如果要pecl install swoole的话，要先yum install -y glibc-headers gcc-c++ kernel-headers gcc openssl pcre-devel和yum install -y openssl-devel； centos:latest镜像目前是7.5版本，如果要查看的话需要先安装lsb命令：yum install redhat-lsb -y； 如果容器里使用yum下载爆’Operation too slow. Less than 1000 bytes/sec transferred the last 30 seconds’，用yum -y install wget解决； 容器需要php7.2的环境的话，就要用最新的源： 12yum install epel-release -yrpm -Uvh https://mirror.webtatic.com/yum/el7/webtatic-release.rpm 别忘了开机自启动docker进程：systemctl enable docker； yum install node npm之前要 123yum install -y epel-releasecurl --silent --location https://rpm.nodesource.com/setup_8.x | bash -yum install -y nodejs #这样版本是8.12,npm的版本是6.4.1 在容器里查看端口情况就要安装netstat命令：yum install -y net-tools； 将一个运行中的容器做成镜像的命令：docker commit 容器ID号 镜像名称； 进入容器最好不要用docker attach 容器ID的方式，而是用docker exec -it 容器ID /bin/bash，离开容器的时候也不要用exit或者ctrl + D，这样会将容器停止，而是用ctrl + P、ctrl + Q 或者ctrl + Q + P组合键退出，这样就不会终止容器运行； 容器默认的时间与宿主机的时间相差8个小时，可以在docker run的时候使用-v挂载的方法挂载宿主机的时间文件，比如：docker run --name 容器名 -v /etc/localtime:/etc/localtime:ro ...，或者在dockerfile里添加“设定时区”的语句： 123#设置时区RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \ &amp;&amp; echo 'Asia/Shanghai' &gt;/etc/timezone \ 容器映射默认情况下是tcp6的，这是正常的现象，如果telnet不通，请先去检查容器内的服务是否正常，比如在容器里curl 127.0.0.1 端口号； 使用docker top 容器id命令能获取的PID是容器内进程在宿主机上的pid，ppid是容器内进程在宿主机上的父进程pid； 如果多个容器要挂载一样的数据就是用-volumes-from，比如docker run --volume-from 容器ID号； 在容器外启动容器内部进程的方法是：docker exec 容器ID /bin/bash -c &quot;对应的命令&quot;，在zabbix监控docker发现进程死了后，就可以用这个方法拉起来； 接上一条的说，docker跟虚拟机不同，它启动的时候是不会运行/etc/rc.d/rc.local的，如果想要Docker在启动后就自动运行/etc/rc.d/rc.local，请看https://github.com/johnnian/Blog/issues/13 里面说的方法； 容器内的进程是会映射到宿主机上的，举个例子，比如容器里运行了swoole，如图： 在宿主机上看也是能看到这个进程的： 参考资料http://blog.sina.com.cn/s/blog_5ff8e0a00102wmti.htmlhttps://outmanzzq.github.io/2018/01/11/docker-exit-without-stop/http://dockone.io/article/128https://blog.csdn.net/halcyonbaby/article/details/46884605https://stackoverflow.com/questions/30960686/difference-between-docker-attach-and-docker-exechttps://www.binss.me/blog/learn-docker-with-me-about-volume/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[容器报错：rpc error: code = 14 desc = grpc: the connection is unavailable]]></title>
    <url>%2F2018%2F09%2F29%2F%E5%AE%B9%E5%99%A8%E6%8A%A5%E9%94%99%EF%BC%9Arpc-error-code-14-desc-grpc-the-connection-is-unavailable%2F</url>
    <content type="text"><![CDATA[开发同学反馈某一个开发环境的机器卡的要命，我登录一看，内存已经被耗的差不多，但是一看top又看不出来哪个进程占用了很多的内存，如图： 换ps -e -o &#39;pid,comm,args,pcpu,rsz,vsz,stime,user,uid&#39; | sort -nrk5看也没看出来个之乎者也。 发现这个服务器里有两个容器，但是很奇怪，用docker stats却无法获得他们的基础值： 明明容器都是up状态啊，于是我就尝试链接到其中一台，发现报错：rpc error: code = 14 desc = grpc: the connection is unavailable，而且不能restart和kill,如图： 使用docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --shim docker-containerd-shim --runtime docker-runc --debug，发现里面是这样： 后来在https://github.com/moby/moby/issues/30984 这个文章下面找到了一个跟我情况差不多的哥们，也是docker stats命令失效。解决方法是重启docker进程：systemctl restart docker.service，果然，重启之后在手动启动上面两个容器，容器就可以正常访问了： 服务器的内存情况也得到了一定的缓解： 后来跟开发复盘，原来是这个机器上一次死机了，没法关闭容器，只能直接在阿里云控制台重启，而正常的流程应该是先关闭容器再重启的。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django前端输入变量通过内部脚本加工返回前端展示之三]]></title>
    <url>%2F2018%2F09%2F26%2FDjango%E4%BD%BF%E7%94%A8form%E8%A1%A8%E5%8D%95%E5%88%A4%E6%96%AD%E8%BE%93%E5%85%A5%E5%80%BC%E6%98%AF%E5%90%A6%E5%90%88%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景说明python：3.6.5Django：2.1.1Project：Kubernetes，文件夹路径就是/django/Kubernetes/App：createyaml，文件夹路径就是/django/Kubernetes/createyaml前文地址：https://rorschachchan.github.io/2018/09/18/Django%E9%80%9A%E8%BF%87%E5%94%AF%E4%B8%80%E6%A0%87%E8%AF%86%E7%AC%A6%E5%B0%86%E5%90%8E%E5%8F%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E5%BA%94%E8%BE%93%E5%87%BA/ 需求与解决思路对于表单而言，检查用户输入的信息是否合法是必然项。检查合法一般来说都是用JavaScript或JQuery。不过我是一个前端白痴，JavaScript对我来说就是天书。但是Django非常的贴心，在form表单里就准备了“验证输入内容”这个功能。 如果使用这个功能，首先先在app的views.py里导入form模块：from django import forms。 导入模块之后，设定一个类，这个类就是要在前端html页面中生成form表单中的input标签的，比如： 123456class YamlInfo(forms.Form): #定义的django表单 name = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;,) #自定义错误信息 replicas = forms.DecimalField(max_digits=2,error_messages=&#123;&apos;required&apos;: u&apos;副本个数不能大于100&apos;&#125;) #最大只有2位数 labels_app = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;) containers_name = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;) containers_image = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;) 表单上输入的东西可能会有很多，根据实际情况哪些字段不能为空就把那些字段写到这个class里，在上面那个YamlInfo里把这五项配置对应的Django表单字段，比如replicas，这个字节代表的是容器副本个数，所以它只能是数字，而且我们不要求它大于100，就设定max为2。 创建完类之后，需要在html页面里根据类的对象创建html标签，然后再提交的时候，需要后台views.py把前端页面提交的数据封装到一个对象里：obj = YamlInfo(request.POST)。由于每个Django表单的实例都有一个内置的is_valid()方法，用来验证接收的数据是否合法。如果所有数据都合法，那么该方法将返回True，并将所有的表单数据转存到它的一个叫做cleaned_data的属性中，该属性是以个字典类型数据，然后对这组数据进行展示或者保存到数据库就随你便了；如果有一个数据是非法的，就可以return一个别的结果。 实际代码理论到此结束，先看views.py: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667from django.shortcuts import render,render_to_responsefrom django.http import HttpResponsefrom .models import parameter #引入数据库里的类from django import forms #引入模块class YamlInfo(forms.Form): #定义的django表单 name = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;,) replicas = forms.DecimalField(max_digits=2,error_messages=&#123;&apos;required&apos;: u&apos;副本个数不能大于100&apos;&#125;) #最大只有2位数 labels_app = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;) containers_name = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;) containers_image = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;)#create_yaml就是用来展示输入的页面而已def create_yaml(request): obj = YamlInfo() #创建form的对象 return render(request,&apos;create_yaml.html&apos;,&#123;&apos;obj&apos;:obj&#125;) #返回create_yaml这个模板，模板里的内容其实都是空的#yaml_list就是展示所有的输入情况def yaml_list(request): obj = YamlInfo() #创建form的对象 if request.method == &apos;POST&apos;: input_obj = YamlInfo(request.POST) #request.POST为提交过来的所有数据 if input_obj.is_valid(): data = input_obj.clean() #用clean()函数获取提交的数据 apiVersion = request.POST.get(&apos;apiVersion&apos;,&apos;v1&apos;) #POST.get方法获取到非form的对象 kind = request.POST.get(&apos;kind&apos;,&apos;RC&apos;) name = data[&apos;name&apos;] #用data字典来获取form的对象 replicas = data[&apos;replicas&apos;] labels_app = data[&apos;labels_app&apos;] containers_name = data[&apos;containers_name&apos;] containers_image = data[&apos;containers_image&apos;] containerPort1 = request.POST.get(&apos;containerPort1&apos;,None) containerPort2 = request.POST.get(&apos;containerPort2&apos;,None) containers_name2 = request.POST.get(&apos;containers_name2&apos;,None) containers_image2 = request.POST.get(&apos;containers_image2&apos;,None) containerPort2_1 = request.POST.get(&apos;containerPort2_1&apos;,None) containerPort2_2 = request.POST.get(&apos;containerPort2_2&apos;,None) print (data) #可以在后台看到整个data的内容 else: #如果输入不合法，返回错误信息 error_msg = input_obj.errors #errors为错误信息 return render(request,&apos;create_yaml.html&apos;,&#123;&apos;obj&apos;:input_obj,&apos;errors&apos;:error_msg&#125;) #将错误信息直接返回到前端页面去展示,刚刚输入的非法字段也保留 else: #如果不是post提交，那么就是展示数据里的情况 yamls = parameter.objects.all().order_by(&apos;-id&apos;) #以倒数展示，即新加的在上面 context = &#123;&#125; context[&apos;yamls&apos;] = yamls return render_to_response(&apos;yaml_list.html&apos;,context) #返回yaml_list.html，里面有数据库的所有数据 Parameter = parameter() #将数据库的类实例化 Parameter.apiVersion = apiVersion Parameter.kind = kind Parameter.name = name Parameter.replicas = replicas Parameter.labels_app = labels_app Parameter.containers_name = containers_name Parameter.containers_image = containers_image Parameter.containerPort1 = containerPort1 Parameter.containerPort2 = containerPort2 Parameter.containers_name2 = containers_name2 Parameter.containers_image2 = containers_image2 Parameter.containerPort2_1 = containerPort2_1 Parameter.containerPort2_2 = containerPort2_2 Parameter.save() #保存这些到数据库里 yamls = parameter.objects.all().order_by(&apos;-id&apos;) context = &#123;&#125; context[&apos;yamls&apos;] = yamls return render_to_response(&apos;yaml_list.html&apos;,context) 配置一下urls.py: 123456789from django.contrib import adminfrom django.urls import pathfrom createyaml import views #将app的views.py文件引入urlpatterns = [ path(&apos;admin/&apos;, admin.site.urls), #每个页面对应各自在views.py里的函数 path(r&apos;create_yaml/&apos;, views.create_yaml), path(r&apos;yaml_list/&apos;, views.yaml_list),] 配置一下用户输入的界面—create_yaml.html： 123456789101112131415161718192021222324252627282930313233343536373839&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;生成K8S所用的YAML文件&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;用户输入&lt;/h1&gt; &lt;h2&gt;请注意！大小写敏感！！！&lt;/h2&gt; &lt;form action=&quot;/yaml_list/&quot; method=&quot;post&quot; name=&apos;yamllist&apos;&gt; &#123;% csrf_token %&#125; API版本： &lt;select name=&apos;apiVersion&apos;&gt; &lt;option value=&quot;v1&quot; selected&gt;v1&lt;/option&gt; &lt;option value=&quot;extensions/v1beta1&quot;&gt;beta1&lt;/option&gt; &lt;/select&gt;&lt;br /&gt; 任务类型： &lt;select name=&apos;kind&apos;&gt; &lt;option value=&quot;Pod&quot; selected&gt;Pod&lt;/option&gt; &lt;option value=&quot;Service&quot;&gt;Service&lt;/option&gt; &lt;option value=&quot;Deployment&quot;&gt;Deployment&lt;/option&gt; &lt;option value=&quot;ReplicationController&quot;&gt;ReplicationController&lt;/option&gt; &lt;/select&gt;&lt;br /&gt; &lt;p&gt;任务名称：&#123;&#123; obj.name &#125;&#125; &lt;span&gt;&#123;&#123; errors.name &#125;&#125;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;任务数量：&#123;&#123; obj.replicas &#125;&#125; &lt;span&gt;&#123;&#123; errors.replicas &#125;&#125;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;APP名称：&#123;&#123; obj.labels_app &#125;&#125; &lt;span&gt;&#123;&#123; errors.labels_app &#125;&#125;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;容器1名称：&#123;&#123; obj.containers_name &#125;&#125; &lt;span&gt;&#123;&#123; errors.containers_name &#125;&#125;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;容器1镜像：&#123;&#123; obj.containers_image &#125;&#125; &lt;span&gt;&#123;&#123; errors.containers_image &#125;&#125;&lt;/span&gt;&lt;/p&gt; 容器1开放端口1：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort1&quot; /&gt;&lt;br /&gt; 容器1开放端口2：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort2&quot; /&gt;&lt;br /&gt; 容器2名称：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containers_name2&quot; /&gt;&lt;br /&gt; 容器2镜像：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containers_image2&quot; /&gt;&lt;br /&gt; 容器2开放端口1：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort2_1&quot; /&gt;&lt;br /&gt; 容器2开放端口2：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort2_2&quot; /&gt;&lt;br /&gt; &lt;input type=&quot;reset&quot; value=&quot;清除所有&quot; /&gt; &lt;input type=&quot;submit&quot; value=&quot;生成yaml文件&quot; /&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 而跳转后的yaml_list.html就是这样： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;yaml文件展示&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;数据库里的yaml数据展示&lt;/h1&gt; &lt;table width=&quot;100%&quot; border=&quot;1&quot;&gt; &lt;thead&gt; &lt;a href=&quot;http://121.41.37.251:33664/create_yaml/&quot;&gt;&lt;button&gt;返回&lt;/button&gt;&lt;/a&gt; &lt;!--插入按钮 开始--&gt; &lt;input type=&quot;button&quot; value=&quot;执行&quot; onclick=&quot;MsgBox()&quot; /&gt; &lt;!--插入按钮 结束--&gt; &lt;!--引用JS代码以达到弹出对话框目的 开始--&gt; &lt;script language=&quot;javascript&quot;&gt; function MsgBox() //声明标识符 &#123; confirm(&quot;确定要执行后台脚本么？&quot;); //弹出对话框 &#125; &lt;/script&gt; &lt;!--引用JS代码以达到弹出对话框目的 结束--&gt; &lt;br&gt; &lt;form&gt; &lt;tr&gt; &lt;td align=&quot;center&quot;&gt;任务序号&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;yaml名称&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;api版本&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;任务类型&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;任务数量&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;对应应用&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;使用的第一个镜像名称&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;镜像1的第一个端口&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;镜像1的第二个端口&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;使用的第二个镜像名称&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;镜像2的第一个端口&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;镜像2的第二个端口&lt;/td&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &#123;% for yaml in yamls %&#125; &lt;tr&gt; &lt;td&gt;&lt;input type=&quot;radio&quot; name=&quot;id&quot; checked=&quot;checked&quot;/&gt;&#123;&#123; yaml.id &#125;&#125; &lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.name &#125;&#125; &lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.apiVersion &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.kind &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.replicas &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.labels_app &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.containers_image &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.containerPort1 &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.containerPort2 &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.containers_image2 &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.containerPort2_1 &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.containerPort2_2 &#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;% endfor %&#125; &lt;/tbody&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; 启动django，我们来看一下效果！ 不过说实话，对于用户来说，肯定选择题的感觉要比填空题好。所以到时候我们可以把阿里云容器仓库里的所有的镜像做成一个数据库，到时候映射到这个页面，让用户去在里面做选择而不是填空。而且django的form检查相比较JavaScript而言还是很粗糙的，如果是处女座的话，还是要搞JavaScript，而且两者也并不冲突，一个是对前端用户而言，一个是后台检查录入数据库的。 参考资料https://docs.djangoproject.com/en/2.1/topics/forms/ （官方文档）http://www.liujiangblog.com/course/django/152https://www.cnblogs.com/chenchao1990/p/5284237.htmlhttp://dokelung-blog.logdown.com/posts/221431-django-notes-8-form-validation-and-modelinghttps://www.jb51.net/article/103135.htm]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django将某个数据库字段给多个app使用]]></title>
    <url>%2F2018%2F09%2F25%2FDjango%E5%B0%86%E6%9F%90%E4%B8%AA%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AD%97%E6%AE%B5%E7%BB%99%E5%A4%9A%E4%B8%AAapp%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[前言Django里经常会有这样的一个需求—-同样的一组数据要给很多个app使用。比如一个运维系统，运维人员的名单就既要给“项目部署”这个APP用又要给“责任负责人”这个APP用。如果每次都要去跨应用去from XXX.models import xxx的话，代码感觉很不友好。那么要解决这个问题，就要用到django自带的ContentTypes框架。以下是所用软件版本：Django:2.1.1Python:3.6.4old app:Articlesnew app:read_stats 原始状态与前期配置目前在django的控制台页面的情况是这样的： 可见里面就一个叫Articles的app，点开之后，发现对应的项目也很简单，只有id和title这两个字段而已： 本次试验的目的就是新建立一个文章统计计数的app，在里面配置数据库，然后让原来的blog这个app能够使用得到新app的数据项。 首先先建立一个专门用来计数的app，比如就叫read_stat。那么就在django项目路径下python manage.py startapp read_stats，再把这个新的app名称添加到settings.py里： 12345678910INSTALLED_APPS = [ &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;, &apos;article&apos;, #先加载django自身的app，然后是第三方app，最后是自己开发的app &apos;read_stats&apos;,] 编辑一下read_stats里的models.py，创建模型先： 12345678910from django.db import modelsfrom django.contrib.contenttypes.fields import GenericForeignKey #这句话是固定的，引用类型from django.contrib.contenttypes.models import ContentType #这句话是固定的，引用类型# Create your models here.class ReadNum(models.Model): read_num = models.IntegerField(default=0) #设定read_num就是一个普通的数字 content_type = models.ForeignKey(ContentType,on_delete=models.DO_NOTHING) #说明这是一个外键，即关联的模型，加上后面的话的意思是：即使删除了这个字段也不会影响其他数据 object_id = models.PositiveIntegerField() #这里是一个主键，即pk content_object = GenericForeignKey(&quot;content_type&quot;,&quot;object_id&quot;) #通过上面两个变量，配置成一个通用的外键 通过使用一个content_type属性代替了实际的model（如Post，Picture），而object_id则代表了实际model中的一个实例的主键，其中，content_type和object_id的字段命名都是作为字符串参数传进content_object的。 配置了数据库，肯定需要python manage.py makemigrations和python manage.py migrate： 数据更新完毕之后，修改一下负责后台展示的admin.py： 1234567from django.contrib import adminfrom .models import ReadNum #引用ReadNum这个模型# Register your models here.@admin.register(ReadNum) #装饰器class ReadNumAdmin(admin.ModelAdmin): list_display = (&apos;read_num&apos;,&apos;content_object&apos;) 此时刷新一下django页面就看到read_stats这个app已经注册成功了： 由于是新的，所以里面空空如也，点击一下ADD，就可以输入值了：Read num就是设定的“阅读次数”，Content type这个数据是一个选择项，选择需要对应的数据库模型，即Article这个app里的models.py的类—Article，而Object id就Articles对应的文章编号： 这样达到了后台配置“将Article应用里的第2篇文章的阅读次数上调到了99次”。 数据库的跨app配置刚才手动在后台配置完毕，但是目前这个read_num数据只能是在read_stats这个app里自嗨。要给让Article能够得到这个read_num的话，就需要通过模型获取到具体数值，这里要用到ContentType.objects.get_for_model方法。首先要配置Article下的models.py： 123456789101112131415161718from django.db import modelsfrom django.db.models.fields import exceptions #引入错误给try...except使用from django.contrib.contenttypes.models import ContentType #引入ContentTypefrom read_stats.models import ReadNum #从另一个app里引入类# Create your models here.class Article(models.Model): title = models.CharField(max_length=30) content = models.TextField() #这是它原来的数据库内容 #添加一个方法给admin.py使用，如果有就直接返回值（字符串），如果没有object就返回一个0 def get_read_num(self): try: ct = ContentType.objects.get_for_model(self) #确定ContentType readnum = ReadNum.objects.get(content_type=ct,object_id=self.pk) #每个readnum都是content_type和object_id对应的QuerySet return readnum.read_num #这样返回就是一个具体的值，不然只是一个数据 except exceptions.ObjectDoesNotExist: return 0 再修改Article下的admin.py，让后台可以体现出来read_num： 1234567from django.contrib import adminfrom .models import Article# Register your models here.@admin.register(Article)class Article(admin.ModelAdmin): list_display = (&apos;id&apos;,&apos;title&apos;,&apos;get_read_num&apos;) #这里新加上刚才的那个方法 由于admin.py里返回的必须是字段，所以我们才在models.py里添加了一个方法去生成字段。 刷新一下Django后台页面，就看到效果了： 至此，这个read_num数据就同时被两个APP关联分享了。至于再把read_num通过一定的处理方法之后映射到html前端就很简单了。 参考资料https://docs.djangoproject.com/en/2.1/ref/contrib/contenttypes/ （官方文档）]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django前端输入变量通过内部脚本加工返回前端展示之二]]></title>
    <url>%2F2018%2F09%2F18%2FDjango%E9%80%9A%E8%BF%87%E5%94%AF%E4%B8%80%E6%A0%87%E8%AF%86%E7%AC%A6%E5%B0%86%E5%90%8E%E5%8F%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E5%BA%94%E8%BE%93%E5%87%BA%2F</url>
    <content type="text"><![CDATA[背景说明python：3.6.5Django：2.1.1Project：Kubernetes，文件夹路径就是/django/Kubernetes/App：createyaml，文件夹路径就是/django/Kubernetes/createyaml前文地址：https://rorschachchan.github.io/2018/09/13/Django%E5%88%B6%E4%BD%9C%E5%89%8D%E7%AB%AF%E9%A1%B5%E9%9D%A2%E7%94%9F%E6%88%90yaml%E6%96%87%E4%BB%B6%E4%B9%8B%E6%94%B9%E8%BF%9B%E7%89%88/ sqlite3的用法sqlite是django默认的数据库，如果只是存一点简单的数据，那么它是足够胜任的。如果在django的APP文件夹里配置了models.py而且执行了python manage.py makemigrations和python manage.py migrate的话，那么在project的文件夹里是会生成db.sqlite3这个文件的。至于如何命令行操作sqlite和python调用sqlite，请去看：http://blog.51cto.com/zengestudy/1904680 ，里面说的已经很清楚了。 不过要注意的是execute方法得到的是一个对象，是看不到具体的sql结果。还需要fetchall方法进一步的解析，这样得到的是一个列表，然后取其中的具体元素，如图： 使用唯一标识符由于yaml的参数是从前端传入的，如果同时有多个人传入数据，那么后端脚本在取参数就会出现错误：多个人在传入不同的数据之后得到的结果却是一样的，即服务器接收到的最后那个数据返回的结果。为了不出现这样的混乱，所以我们就要引入唯一标识符保证每个人得到都是他们的结果。 在数据库里是有一个主键的也就是id，它是django生成数据库的时候自带的private key，每一个id都是唯一的，既然唯一那肯定就是我们选做唯一标识符的首选。至于怎么用它，其实就是在原有的views.py上做一点小手脚。如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344from django.shortcuts import renderfrom django.http import HttpResponsefrom .models import parameter #引入同级的modes.py里的parameter类def create_yaml(request): return render(request,'create_yaml.html') #这个页面是用来输入各值def get_yaml(request): if request.method == 'POST': #如果是post传参，那么就记录下来 apiVersion = request.POST.get('apiVersion','v1') kind = request.POST.get('kind','RC') name = request.POST.get('name') replicas = request.POST.get('replicas','1') labels_app = request.POST.get('labels_app',None) containers_name = request.POST.get('containers_name',None) containers_image = request.POST.get('containers_image',None) containerPort1 = request.POST.get('containerPort1',None) containerPort2 = request.POST.get('containerPort2',None) containers_name2 = request.POST.get('containers_name2',None) containers_image2 = request.POST.get('containers_image2',None) containerPort2_1 = request.POST.get('containerPort2_1',None) containerPort2_2 = request.POST.get('containerPort2_2',None) signer = request.POST.get('signer', 'Micheal Jackson') else: return HttpResponse('404') Parameter = parameter() #将parameter实例化 Parameter.apiVersion = apiVersion #把刚刚从前端得到的值对应赋值 Parameter.kind = kind Parameter.name = name Parameter.replicas = replicas Parameter.labels_app = labels_app Parameter.containers_name = containers_name Parameter.containers_image = containers_image Parameter.containerPort1 = containerPort1 Parameter.containerPort2 = containerPort2 Parameter.containers_name2 = containers_name2 Parameter.containers_image2 = containers_image2 Parameter.containerPort2_1 = containerPort2_1 Parameter.containerPort2_2 = containerPort2_2 Parameter.save() #保存修改 yaml = parameter.objects.get(id=Parameter.id) #通过object.get方法是得到保存的所有值，但是我们只要本次的值，也就是id与private key一致的 return HttpResponse('api版本:%s yaml类型:%s yaml名称:%s 副本数量:%s yaml所属APP:%s 容器名称:%s 容器镜像名:%s' % (yaml.apiVersion,yaml.kind,yaml.name,yaml.replicas,yaml.labels_app,yaml.containers_name,yaml.containers_image))) #输出部分刚输入的值到页面，检查一下是否正确 urls.py如下： 123456789from django.contrib import adminfrom django.urls import pathfrom createyaml import viewsurlpatterns = [ path('admin/', admin.site.urls), path(r'create_yaml/', views.create_yaml), path(r'get_yaml/', views.get_yaml),] 启动django，在前端页面测试一下看看是否得到的结果就是本次输入的结果，如图： 可以看到，返回的页面正确的输出了本次各个参数！剩下还有三部分： 做一个python脚本，把脚本加工的结果返回到前端； 用css/js把界面加工一下； 加入javascript，在前端输入的时候判断输入值是否合法； 参考资料http://blog.51cto.com/lannyma/1735751http://www.liujiangblog.com/course/django/152https://www.jianshu.com/p/46188b39eae5]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
        <tag>html</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[调用阿里云api去修改域名对应IP]]></title>
    <url>%2F2018%2F09%2F17%2F%E8%B0%83%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91api%E5%8E%BB%E4%BF%AE%E6%94%B9%E5%9F%9F%E5%90%8D%2F</url>
    <content type="text"><![CDATA[问题简述以阿里云厂家为例，假设我们有一个网站，它的服务器、数据库、负载均衡都部署在杭州区可用区B,将IP A绑定到某个域名上，启动了系统之后为客户提供服务。那么如果现在要对这套系统进行灾备，应该怎么做？ 第一个方法：在可用区D复制一模一样的环境，然后以“主备服务器组”的方式配置一下负载均衡：如果端口监听不正常就会切换到备用服务器上，监听正常了再切回来。但是这个方式有一个问题，就是当前模式阿里云的主备切换是不支持HTTPS/HTTP的，如图： 可见，这种方式是有很大的局限性的。 那既然同是花钱，干脆就做一个异地容灾，整套系统在其他的地理区域比如上海区也复制一遍，把上海区的B IP也绑定到这个网站域名上，阿里云的域名解析是支持多IP绑定同一个域名的。平时的时候，上海区的IP被域名解析的权重是0，一旦杭州区出现了某些线路方面的硬件问题，那么就将杭州区的权重降成0，同时提高上海区的权重，这样用户就会直接访问到上海区的系统。 理想是丰满的，但是现实是骨感的，因为阿里云的权重配置区域是1~100，而不是0~100，如下图： 也就是说这个云解析的负载均衡是不能当做主备切换使用的，如果想要通过阿里云解析来达到主备切换的目的，方法只能是升级VIP DNS，配置网站监控，具体操作是https://help.aliyun.com/document_detail/59372.html?spm=5176.215331.1147916.23.65de614dac85Sw 。但是这个VIP升级是需要钱的，如果监控的网站越多，花费越大，如果老板不肯掏这份钱，那就只能换条路走。 脚本内容想来想去，还是老办法—-调用阿里云API修改云解析记录达到切换IP的目的。脚本如下，这里我采取了命令行交互的形式，实际上都是将域名IP写死的： 1234567891011121314151617181920212223242526272829303132333435363738#!/usr/bin/env python#coding=utf-8#此脚本版本是2.7，用来修改阿里云云解析IP地址，使用之前请先安装sdk:pip install aliyun-python-sdk-domainimport jsonfrom aliyunsdkcore.client import AcsClientfrom aliyunsdkcore.request import CommonRequestprint "请注意！本脚本只会修改lechange.com域名下的A记录！！！"RRKeyWord = raw_input("请输入您要修改的域名：")Value = raw_input("请输入新的IP：")client = AcsClient('这里是AK', '这里是SK','cn-hangzhou')request = CommonRequest()request.set_accept_format('json')request.set_domain('alidns.aliyuncs.com')request.set_method('POST')request.set_version('2015-01-09')def getRecordId(RRKeyWord): global RecordId request.set_action_name('DescribeDomainRecords') request.add_query_param('DomainName', 'lechange.com') #这里写死了lechange.com域名 request.add_query_param('RRKeyWord', RRKeyWord) request.add_query_param('TypeKeyWord', 'A') response = client.do_action_with_exception(request) encode_json = json.loads(response) RecordId = encode_json['DomainRecords']['Record'][0]['RecordId'] #需要获取这个RecordId def UpdateDomainRecord(RRKeyWord,Value): request.set_action_name('UpdateDomainRecord') request.add_query_param('RecordId', RecordId) request.add_query_param('RR', RRKeyWord) request.add_query_param('Type', 'A') request.add_query_param('Value', Value) response = client.do_action_with_exception(request)if __name__ == "__main__": getRecordId(RRKeyWord) UpdateDomainRecord(RRKeyWord,Value) 这个脚本比较粗糙，可以改进的地方如下： 判断输入的域名和IP是否符合格式的规范； 判断输入的域名是否存在； 如果添加错误，对应的报错； 搭配爬虫页面脚本使用，如果爬虫页面脚本出现了异常，那么直接启动这个脚本，并且发送微信/邮件通知！ 效果展示整个脚本启动后效果如下： 参考资料https://help.aliyun.com/document_detail/29776.html?spm=a2c4g.11186623.2.37.d31b31dfNqojPThttps://help.aliyun.com/document_detail/44657.html?spm=a2c4g.11186623.6.579.4d1d7cd208aSgl]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django前端输入变量通过内部脚本加工返回前端展示之一]]></title>
    <url>%2F2018%2F09%2F13%2FDjango%E5%88%B6%E4%BD%9C%E5%89%8D%E7%AB%AF%E9%A1%B5%E9%9D%A2%E7%94%9F%E6%88%90yaml%E6%96%87%E4%BB%B6%E4%B9%8B%E6%94%B9%E8%BF%9B%E7%89%88%2F</url>
    <content type="text"><![CDATA[前言之前搞了一个简易版的“通过前端页面生成yaml”的方法，地址在此：https://rorschachchan.github.io/2018/09/03/制作前端页面生成yaml文件/ 。但是这个方法实际上有很多的不足，比如说每一次生成记录就消失了，无法追溯，所以要引入数据库，把每一次的数据保存到数据库里。 整体的流程设计还是跟以前的一样： 制作一个create_yaml.html网页让用户输入相关数值，并且有两个按钮，一个是重置，一个是生成yaml供K8s使用； 数值保存到django的数据库里； 做一个脚本，脚本从django数据库里取值然后执行； 脚本的结果返回到get_yaml网页，它也有两个按钮，一个是返回，一个是执行此yaml； 本篇文章的内容是第一步和第二步，Django的project名是Kubernetes，app名是createyaml。 配置数据库由于这个小系统保存的数据量不多，所以我就直接使用django默认的db.sqlite3数据库。跑到Kubernetes/createyaml的models.py里，根据yaml的实际情况编写一下数据库各字段： 123456789101112131415161718192021222324252627282930313233from django.db import models # Create your models here.class parameter(models.Model): type = ( (U'Pod','Pod'), (U'Service','Service'), (U'Deployment','Deployment'), (U'ReplicationController','ReplicationController'), ) api_type = ( (U'v1','v1'), (U'extensions/v1beta1','beta1'), ) apiVersion = models.CharField(verbose_name='API版本',max_length=20,choices=api_type) kind = models.CharField(verbose_name='任务类型',max_length=50,choices=type) name = models.CharField(verbose_name='任务名称',max_length=100) replicas = models.CharField(verbose_name='任务数量',max_length=50,default='1') #默认情况下副本数是1 labels_app = models.CharField(verbose_name='APP名称',max_length=100) containers_name = models.CharField(verbose_name='容器1名称',max_length=100) containers_image = models.CharField(verbose_name='容器1镜像',max_length=100) containerPort1 = models.CharField(verbose_name='容器1开放端口1',max_length=25,blank=True) #可以为空，下同 containerPort2 = models.CharField(verbose_name='容器1开放端口2',max_length=25,blank=True) containers_name2 = models.CharField(verbose_name='容器2名称',max_length=100,blank=True) containers_image2 = models.CharField(verbose_name='容器2镜像',max_length=100,blank=True) containerPort2_1 = models.CharField(verbose_name='容器2开放端口1',max_length=25,blank=True) containerPort2_2 = models.CharField(verbose_name='容器2开放端口2',max_length=25,blank=True) signer = models.CharField(verbose_name='登记人',max_length=50, default='system') signtime = models.DateField(auto_now_add= True) #默认添加当前时间#返回相应的值def __unicode__(self): return self.name 保存之后，python manage.py makemigrations和python manage.py migrate，就会看到db.sqlite3文件在Kubernetes这个project文件夹里诞生了。 配置URL路由根据整体的流程设计所说，url.py就新增了如下几个路由： 12345urlpatterns = [ path(r'create_yaml/', views.create_yaml), #create_yaml网页里的内容就是views.py里的create_yaml函数，下同 path(r'get_yaml/', views.get_yaml), path(r'addok/', views.addok),] 在admin后台界面也要体现出每一次数据输入，于是就配置一下Kubernetes/createyaml/admin.py: 123456789101112from django.contrib import adminfrom .models import parameter #把parameter这个class引入# Register your models here.class parameterAdmin(admin.ModelAdmin): list_display = ('name','apiVersion','kind','replicas','labels_app','containers_name','containers_image','containerPort1','containers_name2','containers_image2','containerPort2_1','signer','signtime') #把models.py里的字段都添加进去 exclude = ['signer'] #signer字段不要添加 def save_model(self, request, obj, form, change): obj.signer = str(request.user) obj.save()admin.site.register(parameter,parameterAdmin) 准备工作完事，开始搞前端页面。 配置前端在createyaml文件夹下建立一个template文件夹，里面先写一个create_yaml.html： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;生成K8S所用的YAML文件&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;用户输入：&lt;/h1&gt; &lt;h2&gt;请注意！大小写敏感！！！&lt;/h2&gt; &lt;form action=&quot;/get_yaml/&quot; method=&quot;post&quot; name=&apos;addyaml&apos;&gt; &lt;!-- form action的意思就是，submit的指向就是/get_yaml/，以post形式传递 --&gt; &#123;% csrf_token %&#125; API版本： &lt;select name=&apos;apiVersion&apos;&gt; &lt;option value=&quot;v1&quot; selected&gt;v1&lt;/option&gt; &lt;option value=&quot;extensions/v1beta1&quot;&gt;beta1&lt;/option&gt; &lt;/select&gt;&lt;br /&gt; 任务类型： &lt;select name=&apos;kind&apos;&gt; &lt;option value=&quot;Pod&quot; selected&gt;Pod&lt;/option&gt; &lt;option value=&quot;Service&quot;&gt;Service&lt;/option&gt; &lt;option value=&quot;Deployment&quot;&gt;Deployment&lt;/option&gt; &lt;option value=&quot;ReplicationController&quot;&gt;ReplicationController&lt;/option&gt; &lt;/select&gt;&lt;br /&gt; 任务名称：&lt;input type=&quot;text&quot; name=&quot;name&quot; /&gt;&lt;br /&gt; 任务数量：&lt;input type=&quot;text&quot; placeholder=&quot;请输入阿拉伯数字&quot; name=&quot;replicas&quot; /&gt;&lt;br /&gt; APP名称：&lt;input type=&quot;text&quot; placeholder=&quot;对应的APP&quot; name=&quot;labels_app&quot; /&gt;&lt;br /&gt; 容器1名称：&lt;input type=&quot;text&quot; name=&quot;containers_name&quot; /&gt;&lt;br /&gt; 容器1镜像：&lt;input type=&quot;text&quot; name=&quot;containers_image&quot; /&gt;&lt;br /&gt; 容器1开放端口1：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort1&quot; /&gt;&lt;br /&gt; 容器1开放端口2：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort2&quot; /&gt;&lt;br /&gt; 容器2名称：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containers_name2&quot; /&gt;&lt;br /&gt; 容器2镜像：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containers_image2&quot; /&gt;&lt;br /&gt; 容器2开放端口1：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort2_1&quot; /&gt;&lt;br /&gt; 容器2开放端口2：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort2_2&quot; /&gt;&lt;br /&gt; &lt;input type=&quot;reset&quot; value=&quot;清除所有&quot; /&gt; &lt;input type=&quot;submit&quot; value=&quot;生成yaml文件&quot; /&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 写完了之后，再来一个addok.html： 123456789101112131415161718192021&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;添加成功&lt;/title&gt; &lt;style&gt; * &#123; margin: 0; padding: 0; &#125; a&#123; text-decoration:none; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; &lt;p&gt;添加成功&lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 前端准备完毕。 配置views.pyviews.py里的具体函数是整个django的主心骨，内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647from django.shortcuts import renderfrom django.http import HttpResponse,HttpResponseRedirectdef create_yaml(request): return render(request,'create_yaml.html') #只是展现一个页面而已def get_yaml(request): if request.method == 'POST': #如果是POST就获取前端传入的值 apiVersion = request.POST.get('apiVersion','v1') kind = request.POST.get('kind','RC') name = request.POST.get('name') replicas = request.POST.get('replicas','1') labels_app = request.POST.get('labels_app',None) containers_name = request.POST.get('containers_name',None) containers_image = request.POST.get('containers_image',None) containerPort1 = request.POST.get('containerPort1',None) containerPort2 = request.POST.get('containerPort2',None) containers_name2 = request.POST.get('containers_name2',None) containers_image2 = request.POST.get('containers_image2',None) containerPort2_1 = request.POST.get('containerPort2_1',None) containerPort2_2 = request.POST.get('containerPort2_2',None) signer = request.POST.get('signer', 'Micheal Jackson') else: return HttpResponse('404') from createyaml.models import parameter #数据库对应项进行赋值 Parameter = parameter() Parameter.apiVersion = apiVersion Parameter.kind = kind Parameter.name = name Parameter.replicas = replicas Parameter.labels_app = labels_app Parameter.containers_name = containers_name Parameter.containers_image = containers_image Parameter.containerPort1 = containerPort1 Parameter.containerPort2 = containerPort2 Parameter.containers_name2 = containers_name2 Parameter.containers_image2 = containers_image2 Parameter.containerPort2_1 = containerPort2_1 Parameter.containerPort2_2 = containerPort2_2 Parameter.save() #保存到数据库里 # 重定向到添加成功页面 return HttpResponseRedirect('/addok/')def addok(request): return render(request,'addok.html') 效果验证启动django之后，首先先去admin后台看一下当前的情况，如图： 可以看到里面是有几个记录的，那么我们现在登录外网地址:端口/create_yaml，输入一些字段看一下效果： 再返回到admin后台刷新，发现刚才新加的任务已经体现出来了： 至此，就达到了“前端html传入数据，后端数据库记录”的效果。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一篇旧文----《当今中国会不会发生革命》]]></title>
    <url>%2F2018%2F09%2F06%2F%E4%B8%80%E7%89%87%E6%97%A7%E6%96%87-%E5%BD%93%E4%BB%8A%E4%B8%AD%E5%9B%BD%E4%BC%9A%E4%B8%8D%E4%BC%9A%E5%8F%91%E7%94%9F%E9%9D%A9%E5%91%BD%2F</url>
    <content type="text"><![CDATA[苏振华对本文的初稿提出了中肯的批评和建议，在此致以感谢。 二十世纪中国是一个革命的世纪。二十世纪上半叶，中国经历的主要革命运动有辛亥革命、二次革命、五四运动、北伐战争和共产主义革命。1949年中国共产党取得政权后，又搞了许多具有社会革命性质的社会运动，其中最为著名的有土地改革、人民公社运动、大跃进和文化大革命。改革开放后，中国共产党逐渐从一个革命党转变为执政党，但是中国的一些知识分子、学生和民众却从共产党手中接过“革命的旗帜”，于是就有了1989年的学生运动以及最近的“零八宪章运动”和所谓“茉莉花运动”等集体行动的事件。当然也有知识分子提出中国应该“告别革命”，应该反对激进主义。这是一种应然性吁求，但问题在于：中国是否会再发生（或者能避免）一场革命性的社会动荡？ 这一问题甚至引发中国政治精英的广泛关注。最近网上有文章说中共高层有不少人在阅读托克维尔（Alexis de Tocqueville）的《旧制度与大革命》（L’Ancien regime et la Revolution），幷说王岐山看完此书后曾担忧地表示：中国的现代化转型不会那么顺利；中国人自己的代价也没有付够。当然，革命一旦发生，人民将付出的代价在一定程度上是由革命性质决定。一般来说，政治革命（一场只改变政权的性质，而不改变社会经济结构的革命）给社会带来的震荡要远远低于社会革命（一场既改变政权的性质，又改变社会经济结构的革命），非暴力革命给社会带来的震荡要远远低于暴力革命。王岐山也许是在担心中国会发生一场暴力革命，甚至是暴力性的社会革命。 不管上述中共高层读书的传说可信度如何，有一点十分明确：虽然近年来中国政府在维护稳定上花了很大的力气，中国的经济在近三十年来取得了举世瞩目的发展，民众的生活水平在近年来也有了很大的提高，但中共高层丝毫没有减轻对在中国再发生一次革命的可能性的焦虑。中共高层为甚么会如此忧虑？当前中国与政权稳定相关的根本问题是甚么？本文试图在理论的指导下对当前中国面临的困境作出分析。 一 革命为甚么会发生：理论简述早期的西方理论都把现代化过程中所发生的巨大社会变迁看作是一个国家发生革命的主要诱导因子。这一理论的逻辑很简单：现代化带来了传统的生活方式和价值观的变化，给身处其中的人们带来很大的不适应和不确定性；同时，现代化过程也削弱了传统社会组织对于人们的控制，给革命造就了机会1。的确，世界上的革命无一不发生在正在发生巨大变化的社会之中，而巨大的社会变迁确实会给身处其境的人们带来多方面的不确定性。从这个意义上说，这种理论自有它的道理。但是，世界上每一个国家在现代化过程中都经历过巨大的社会变迁，却不是每个国家都发生了剧烈的革命。社会变迁充其量只能是引发革命的一个必要条件。 在过去的大多数时间，有些学者也常用阶级或者是利益集团的视角来解释一个国家革命的成功与否2。他们的逻辑也很简单：如果一个国家中的一个主要阶级拥护和加入了革命，那么革命就会成功；反之革命就不会发生，就是发生了也会失败。当今中国的不少学者也仍然会自觉或者不自觉地运用这一视角来分析中国社会的危机所在。依笔者所见，这类分析方法表现出了左派知识分子的天真，而反映出来的则是这些知识分子看待问题时的教条性。 这并不是说人们在现代社会中不会产生阶级认同。问题在于：每一个人在社会上都会同时拥有许多身份（比如一个人同时可具有如下的身份：工人、浙江人、男人、某些圈子中的一员、某个俱乐部的成员等），并且具有某一身份的人们之间又存在着巨大的差别（比如工人之间就有蓝领工和白领工、技术工和非技术工、熟练工和非熟练工、临时工和正式职工之间的差别等）。因此，除非存在巨大无比的外力，比如国家对社会上的一个主要人群的利益完全漠视，幷且对这一人群的抗争进行严厉的和系统性的镇压，否则那些被天真的知识分子所认定的“阶级”就很难形成强烈的认同感，去完成知识分子所赋予他们的“历史使命”。 当今世界只有两类大型群体会有着较为“天然的”强大认同感，那就是族群和宗教群体。他们所发起的抗争和革命也因此往往有较大的威力。在很大的程度上，当今所流行的各种“社会分层研究”都是过去知识分子的研究误区的某种产物。不同的社会分层方法除了对了解社会流动和指导政府的公共政策制订有一定的应用性意义外，从社会行动或革命的角度来看，其价值却十分有限。这当然是题外话。 1970年代后，西方学者开始强调国家的性质和结构性行为对革命产生乃至成功的影响3。这类理论背后的一个核心逻辑是：在当代交通和通讯技术的支持下，现代国家获得了古代国家完全没有的渗透社会的能力。与古代国家相比，现代国家的管治领域不但十分宽泛，而且它的政令更能严重影响到社会上绝大多数成员的利益。现代国家的这一性质导致了如下三个后果：第一，国家的错误政策非常容易触发民众大规模的针对国家的怨恨情绪；第二，国家的强势刺激了人们组织起来进行抗争，要求国家颁布和施行对自己群体有利的法律和社会政策；第三，部分人就会想到通过夺取国家的权力（即革命）来彻底改变国家的性质，通过掌握国家权力来推行他们的理想。在这种所谓“国家中心论”的视角下，西方学者做了大量的研究，幷逐渐产生了以下三点共识（即衡量一个国家发生革命可能性的三个维度）：第一，革命不容易发生在一个有着效率较高的官僚集团的国家（官僚集团内的程序政治会增强国家精英的团结、国家决策的合理性和国家镇压机器的有效性）；第二，革命不容易发生在一个对社会精英有着很强吸纳能力的国家；第三，革命不容易发生在一个对社会有着很强渗透力（不仅仅指由国家所控制的交通和通讯工具，而且指警察机构对社会的监控能力）的国家4。 以上的三个维度有很强的解释力。的确，早期的革命，包括法国革命（1789）、俄国革命（1917）、中国革命（1949）和伊朗革命（1979），都发生在用以上三个维度来衡量处境都不太妙的国家。其实，官僚集团的效率、国家对社会精英的吸纳能力，以及国家对社会的渗透能力，是任何国家进行有效统治的关键要素。一个没有这些能力或者是这三方面能力不足的现代国家，无论是民主国家还是威权国家，都会在其运行过程中遇到大量的困难。但问题是，长期以来在分析革命的可能性时，西方学者过于借重了这三个因素，因此直到1980年代他们还在强调苏联和东欧国家具有很大的政治稳定性（因为这些国家都有着比较有效率的官僚集团、对社会精英的吸纳能力和对社会的渗透力）5，而完全没有料想到革命竟然马上就在这些国家发生了，而且其中不少国家的革命都取得了成功。 笔者认为，在分析苏联和东欧国家爆发革命的可能性时，西方学者都忽略了国家权力的合法性基础和国家政权稳定性之间的关系这一维度的重要性。具体来说，一个国家的权力愈是建立在较为稳定的合法性基础之上，这一国家就愈不可能发生革命。苏联和东欧之所以发生革命，不仅仅是因为它们的经济没搞好、它们的军事落后、它们在民族问题上走入误区、它们的领导人采取了错误的政策等（这些因素都很重要），而且更在于这些国家没有把政权建立在一个比较稳定的合法性基础之上。笔者多年来对中外各国革命作出分析时不断强调国家的合法性基础与政权稳定性之间的紧密关系6。笔者认为，西方学者所着重的三个维度都是国家统治手段中偏“硬件”性质的成份，而国家的合法性基础和政权稳定性则构成了国家统治的关键性“软件”，它们缺一不可。 二 合法性和政权的稳定性国家虽然掌握着强大的官僚组织以及军队与警察等武装力量，但是其统治的有效性仍必须依赖于国家政权在大众（包括国家官员）心目中的合法性。考察古今中外的统治史，我们会发觉国家在寻求统治合法性时只能采取以下三种方式：通过一种价值性的承诺、通过提供公共服务、通过一个普遍被接受的国家领导选拔程序。相应地，我们可以界定三种理想状态的国家合法性基础：意识形态型、绩效型和程序型7。如果一个国家统治的正当性是基于一个被民众广为信仰的价值体系，我们可以说这个国家的统治是基于意识形态合法性；如果一个国家统治的正当性来源于国家向社会提供公共物品的能力时，这个国家的统治则基于绩效合法性；如果一个国家的领导人是通过一个被大多数人所认可的程序而产生，这一国家的统治则基于程序合法性。 需要强调的是，以上定义的是国家合法性来源的三个理想类型（ideal types）。现实中，任何国家都不会把合法性完全建立在某一理想类型之上；或者说，任何国家的合法性来源都是这些理想类型的一个混合体。但是，在某一历史时期内，某一理想类型往往会成为一个国家统治最为重要的基础，幷在很大程度上定义了一个国家的性质。 现在让我们来讨论不同的国家合法性基础和政权稳定性之间的关系。 （一）意识形态合法性意识形态是国家统治的一个最为根本的合法性基础。一个国家如果把执政基础完全建立在某一意识形态之上，那是不行的；但是，一个国家的执政如果没有意识形态作为基础，则是万万不行的。当大多数的民众都认同国家所推崇的某一意识形态时，这种意识形态不仅仅为国家的统治提供了道德性依据，而且为社会提供了一个“核心价值观”。如果一个国家有一个被广为接受的核心价值观，统治成本就会大大降低。 需要强调的是，核心价值观不能是“八荣八耻”，也不能是“雷锋精神”，因为这些都只能是一个国家的从属性价值观，只有核心价值观才有助于建立国家的合法性基础。国家的核心价值观必须是一种宏大的给予历史以某种道德意义的叙事（即西方后现代学者所说的“宏大叙事”[grand narrative]）。美国中学教科书上所描述的美国建国历史以及那些由建国时期政治家所确定的建国原则和理念，就是核心价值观的一个例子；西周初期所形成的“天命论”以及在西周历史中逐渐得以完善的“宗法制度”是有周一代的核心价值观，幷对古代中国的政治哲学和政治文化产生过重大的影响；当代中国学生在学校里学过的围绕着历史唯物主义和“只有共产党才能救中国”而展开的中国近代史叙事，也是核心价值观的一个例子。当然，美国的宏大叙事在其社会中仍然可以获得广泛的认同，而中国教科书中的叙事方式和内容在国内已经没有多少人真正认同了，幷且中国政府至今也没有创造出一套能被广泛认同的宏大叙事。这一意识形态的缺失所导致的后果就是核心价值观的缺乏，幷给当下中国政府的执政带来了很大的困扰。此是后话。 不同的意识形态有着不同的性质，幷对国家政权的稳定性有着不同的影响。意识形态合法性有三个主要类型：领袖魅力型、世俗意识形态型、宗教意识形态型。在这三个类型中，领袖的魅力（近似于韦伯所说的“克里斯玛合法性”）最不能给予政权一个稳定的合法性基础，因为领袖的寿命有限。 一般来说，世俗意识形态对大众所作的承诺比较容易被验证。一旦当国家不能兑现那些承诺，就会产生合法性危机。从这个意义上来说，世俗意识形态也不是一个稳定的合法性基础。但是如果我们把世俗意识形态进一步细分，就会发觉不同的意识形态对人性有不同的要求和对民众有不同的许诺。一般来说，要是一种意识形态对人性的要求愈接近于人的本性幷且其许诺愈不容易被证伪，这一意识形态就愈能为国家的合法性提供一个可靠的基础。比如美国建立在个人主义基础上的“机会之地”（Land of Opportunity）这一意识形态，不但与人的竞争和趋利本性十分接近，而且很难被证伪。这一意识形态有着人们所说的“钱币落在正面我赢，落在反面你输”（heads I win, tails you lose）的性质：你的成功证明了这意识形态的正确性，而你没有成功很容易被解释为是你没有付出足够或恰当的努力。与之相比较，“共产主义”这一意识形态就很难为一个政权提供稳定的合法性基础。共产主义意识形态不但建立在一个过于理想的人性的基础之上，幷且承诺提供一个比其他社会制度更为完美的世俗世界，例如“各尽所能、按需分配”之类。如果一个国家把共产主义意识形态作为合法性基础，一旦国家不能兑现相应的承诺，民众马上就会产生“信仰危机”，从而给国家带来合法性危机。 但是从理论上来说，即使一个国家把合法性建立在像共产主义这样很不牢靠的意识形态之上，这一国家也是有可能取得较为长久的政权稳定的。这里的诀窍是：当大多数民众还相信这一意识形态时，国家就应该采用选举（程序合法性）来补充共产主义意识形态的内禀不稳定性。因为一旦有了选举，幷且在社会上的大多数民众都认可共产主义意识形态的情况下，当政府搞得不好时，候选人就可以攻击政府没有带领人民在共产主义的“康庄大道”上正确地前进，民众就会去怪罪当朝政府的施政，而不是从意识形态本身的误区来检讨国家中所存在的根本问题。读者可以假设，如果中国在毛泽东时代能搞出一个共产党领导下的民主社会的话，今天的中国也许就不会面临如此严重的意识形态合法性危机。 以上的逻辑还支持了以下的推论：宗教意识形态要比任何世俗意识形态更能为一个国家提供稳定的合法性基础。宗教源自于人的可怜的本性──因为害怕失去和死亡而无限放大生命的意义。宗教的承诺也不具有可验证性──“来世”、“净土”或者“天堂”这样的宗教承诺既十分动人又无法验证，而对于宗教来说，最具权威的克里斯玛都是不存在于世俗世界的“神”、“佛”或者是“圣人”。宗教意识形态与人性的贴近和承诺的无法验证性，赋予那些把国家合法性建基于宗教意识形态之上的国家很大的政权稳定性。 不过，在现代社会，宗教意识形态合法性的最大弱点来自宗教力量和国家政权之间的紧张。现代社会极其复杂且变化极快。为了适应新的变化，国家政权就必须以务实的态度来处理日益复杂的世俗性事物，但是国家的务实态度及其所带来的社会后果势必会招来具有强烈保守倾向的宗教力量的反对。由政教斗争所导致的政权不稳定性，对于那些把宗教意识形态作为合法性基础的国家来说，是必定要面临的一个难题。当今伊朗的政治就在较大程度上受到这一因素的困扰。 （二）绩效合法性任何一个政府都需要为治下的民众提供必要的公共服务，例如仲裁、维持公共秩序、保证人身安全、保卫国家等。这个层面上的绩效是绝不可少的。如果一个政府没有能力提供这些最为基本的公共物品，相应的国家就不会存在，即便存在也会很快垮台。这里所说的“绩效合法性”，指的是国家领导集团在一个更为进取的层面上积极创造绩效以获取合法性。 获取这一合法性的手段可分为三种亚类型：领导经济发展、官员作为民众的道德表率和炒作民族主义情绪。但是，这三种手段都不能为国家提供一个稳定的合法性基础。首先，没有一个国家能保证经济的永久高增长。其次，把官员的道德表率作为国家合法性基础就会将贪污这样在法律层面上能解决的问题提升为政治问题，从而从根本上削弱了国家的合法性。最后，如果在和平时期政府经常以炒作国际危机来提高其统治合法性的话，这一国家的国际环境就会日趋险恶，幷且大量的极端民族主义者就会在这一国家中产生。这将推动一个国家朝着战争的方向发展，后果不堪设想。 总之，当一个国家的合法性系于绩效承诺时，这一国家的政府就必须设法来兑现这些承诺。如果这些绩效承诺得到了兑现，民众的欲望就会提高，幷对政府提出更高的要求，而政府则不得不把民众不断提高的要求作为新的、更新的，甚至是即时的工作目标。但是，一旦政府不能够兑现其承诺时，这一国家马上就会出现合法性危机。 （三）程序合法性现代社会到来之前，除了古希腊之外，程序始终不是世界各国权力合法性的一个重要基础。这幷不是说在古代政府首脑产生的背后没有程序可言，而是说这些程序只在一小部分精英之间才有意义，幷且这些程序在国家政治中不占有像今天的选举政治般重要的地位。笔者认为，以下三个原因使得程序合法性在现代政治中的地位不断上升： 第一，现代国家绝大多数都采取了政教分离原则，宗教意识形态不再是国家的主要合法性来源，或者说现代国家失去了古代国家所拥有的一个十分稳定的合法性基础；第二，现代国家的政府管理的事情愈来愈多，这就使得绩效在现代国家合法性中的地位大大增强，幷给现代国家的政治带来很大的不稳定性；第三，在现代技术的支持下，政府的统治能力不断加强，民众生活受到国家政策愈来愈严重的影响。在这一背景下，怎么控制政府的权力，幷使之不滥用权力，对广大民众来说就变得十分迫切。 我们可以从多种视角来解释为甚么民主政治会在现代国家中兴起。就本文的角度而言，民主兴起的一个重要原因就是现代国家意识形态合法性不足幷且严重倚重于绩效合法性，这就使得国家不得不依靠程序合法性来获得政权的稳定性。 由于以下原因，现代意义上的程序合法性（即民主选举）会给国家政权带来很大的稳定性8： 第一，一旦国家首脑是由民选产生，只要选举被认为是公正的，执政者即使在上台后表现很差，也不会影响政府执政的合法性。用通俗的话说，在绩效合法性的统治基础上，当官如果不为民作主，就有被赶回家卖红薯的危险；而在程序合法性的统治基础上，当官即使不为民作主，也至少得当完一届才回家卖红薯。从这个意义上说，程序合法性大大减低了民众对政府执政的压力。 第二，当一个国家有了程序合法性后，即使有执政者被赶下台也不是甚么大事。这是因为程序合法性在很大程度上把政府和政体分开了。政府即使垮台（比如水门事件[Watergate Scandal]后的尼克松[Richard M. Nixon]政府），政体也不会受到根本性的动摇。 第三，当一个国家有了程序合法性后，民众的不满在相当程度上可以通过选举或其他常规程序的政府更迭而得到缓解。一旦民众有了选择，他们就难以联合起来进行革命，这也给国家政权带来了稳定性。 第四，一旦当官的不为民作主也没有马上就被赶回家卖红薯的危险的时候，公开批评国家领导就不是甚么大事了，这就给言论和结社自由提供了基础。但这自由同时也约束了人民的行为，缓解了社会矛盾，从而构成了政权稳定的一个重要机制。这是因为言论和结社自由让社会上各种思想及利益的交流和竞争，使人们对社会其他群体的利益有了更深的理解，对社会现状有了现实感。同样重要的是，一旦有了言论和结社自由，现代社会的多样性势必会导致社会组织在利益和观点上的分化，这些组织互相牵制使得任何全民性的革命运动变得不大可能。 但就稳定国家政权而言，程序合法性也有着很多弱点，其中最为重要的是它背后必须有一个核心价值观支撑，或者说只有在竞选各方都服从同一意识形态（即“忠诚反对”）时，程序合法性才能为国家提供政权稳定性。如第二次世界大战前的德国，共产党、纳粹党和社会民主党各自有着完全不同的意识形态，幷且共产党和纳粹党都想利用选举来夺取政权，把国家彻底引向对自己有利的方面，形成赢者通吃的格局，选举在这种情形下就不可能成为国家政权稳定的基础。从这个意义上说，一个政治上最为稳定的国家（或者说最不可能发生革命的国家）应该是一个同时拥有意识形态合法性和程序合法性的国家：程序合法性需要强有力的意识形态合法性的支持，幷且程序合法性又是维持国家的意识形态合法性的关键。 三 有关中国政府合法性的经验研究在“世界价值观调查”（World Values Survey）和“亚洲民主动态调查”（Asian Barometer Survey）等调查数据基础上，一些学者对中国的国家合法性进行了研究。他们的一个重要发现是：中国民众对政府的认可度要远远高于许多西方民众对他们政府的认可度。他们于是就得出中国政局稳定、国家具有很高的合法性这一结论9。一般来说，我们都会相信这些研究的结论是成立的。这些学者都受过严格的西方学术训练，他们的材料所展示的也是全国民众的普遍看法，而不是少数人的极端观点。同时，中国政府近年来加强了吏治，采取了一系列的“亲民政策”，这些政策应该说是取得一定效果的。笔者近年来在全国范围内与农村和城市的各界民众进行了不少交流，感到中国百姓的生活水平在近年来有了普遍的和显著的提高，或者说大多数百姓确实从国家的政策中获得了实惠。这些学者的研究结果所反映的正是民众对于当今政府的绩效在一定程度上的认可。 但问题是，从“百姓对当下政府的绩效是肯定的”这一现象中，我们是不能推论出“这个国家的政局是稳定的”这样一个结论的。遍览世界各国，民众对政府绩效的评价，可以说是说变就变的。在西方，民众对政府的认可度数月内就可以波动许多个百分点（他们对政府的认可度有时甚至低至百分之十几）。在西方国家，民众对政府绩效的认可度与国家政局的稳定性之间没有很大的关系，因为西方国家合法性的根本基础不是政府的绩效，而是被主流精英和人民所认可的核心价值观和具有程序公正的选举。但是在中国，百姓对政府执政绩效的认可度与政局的稳定却有着密切的关系：如果中国百姓对政府绩效的认可显著下跌的话，的确是有可能引发一场大规模的政治波动甚至革命的。这背后的原因很简单：共产主义意识形态在中国已经式微，但是国家又拿不出其他有效的价值观取而代之；同时，中国领导人也不是通过一种被大多数人所认可的程序而产生的。中国因此非常缺乏意识形态和程序层面上的合法性，于是绩效就成了国家合法性的最为重要、甚至是唯一的基础。 四 当前中国的问题所在──合法性问题中国经济发展举世瞩目，百姓的生活水平近年来有了很大的提高。但是，中国维稳的成本却愈来愈高。2011年，中国一些人受到突尼斯“茉莉花革命”的影响，促动“茉莉花运动”，但国内几乎没有人响应。尽管如此，不少市政府还是如临大敌，弄得马路上的警察人数不知超过了寥寥无几的闹事人群多少倍。显然，繁荣的经济和大多数百姓对当下政府在不少方面的表现还算满意这些事实，完全不能减轻中共高层领导的焦虑。到底甚么是当前中国政局的关键性不稳定因素？或者问：中共高层领导到底在忧虑甚么？说到这一点，国内的绝大多数知识分子和百姓都会把诸如贫富差距过大、官员贪污腐败等放在首列，但这些因素的重要性或许幷不是想象般大。当前中国的贫富差距的确很大，而官员贪污腐败（特别是在那些吏治较差的省份）无疑也十分严重。相比之下，印度的贫富差距和官员腐败也十分厉害，甚至在不少方面明显超过了中国，可是印度却不是人们认为很可能发生革命的国家。显然，仅仅是贫富差距和官员贪污腐败是不足以引发革命的。 中国的知识分子和百姓都对贫富差距和官员腐败深恶痛绝，但是中国却完全不存在这方面的高质量研究。于是，在考虑这些问题时，中国的知识分子和民众就不得不凭借想象：你对政府有多大程度上的不信任，你就会把中国的贫富差距和官员腐败问题想象得有多严重。笔者认为，当前中国的问题归根到底是政治问题，或者说国家的合法性问题，而不是诸如贫富差距和官员腐败这类社会问题。而中共政权合法性问题的关键在于：第一，国家在共产主义意识形态式微后再也拿不出一个能被广泛认可的主流价值体系；第二，国家不敢（或者不愿意）把合法性的重心转移到程序合法性的层面上来；第三，国家对于绩效合法性产生了过度的依赖。 当下中国的领导人似乎仍然不了解绩效合法性的内禀不稳定这一特质，因为在他们的各种发言中不断流露出人民自然会拥护一个绩效优良的政府这样一种天真的论点，幷且他们也正在努力地通过加强政府绩效来获取国家的合法性。他们的做法与百姓情绪的耦合就给中国带来了如下的悖论：中国的经济和民众的生活水平在近年来都取得了举世羡慕的发展，但是社会却有朝着革命方向发展的倾向。 当社会上的大多数精英和百姓都认同于国家建构的意识形态时，这一意识形态就会成为一个社会的核心价值观或者说核心意识形态。在有着主流意识形态的国家中，社会就会显得非常平和甚至是保守。比如媒体：如果一个记者经常在某一媒体上发表与主流意识形态不符的言论，百姓就会不喜欢这个媒体，其订阅量或收视率就会下降，媒体老板也因此会不喜欢这一记者。可以说，当国家建构的主流意识形态被广为接受时，百姓就会更相信那些平和甚至是保守的报导，而发表偏激言论的媒体就会没有出路。个体也一样：如果一个人经常在公开场合（和网络上）发表与主流意识形态不符的言论，他的言论就会被忽视，他的朋友也不会喜欢他，他也不会有任何社会影响。但是，如果社会上的精英和大多数百姓不认同国家建构的主流意识形态时，人们就会不相信主流媒体中的报导，特别是与政治有关的报导，与主流意识形态保持一致的媒体就会在民众的心目中被边缘化，幷且不再能建构民众的舆论，而敢于反对主流意识形态的媒体和个人就会被看作是“社会的良知”。 当国家建构的意识形态不再是社会上的主流价值观时，在面对以上的异议时国家也就失去有效的对策。如果国家对闹事者或者发表对国家不满观点的人士进行镇压的话，那么国家政权在民众心目中就会进一步失去道义，稍有良知的国家干部就会感觉愧疚，而闹事者和发表对国家不满观点的人士就会被大家看作是“英雄”。但是如果国家选择容忍的话，那么这些人的行动和言论就得不到约束。更有之，一旦形成了这样的“机会结构”，人们就会发觉“会闹的孩子多吃奶”这一妙诀，社会民风于是趋于民粹和暴戾。同时，一旦大众有着把闹事者和发表对国家强烈不满观点的人士看作是“英雄”的倾向，随着“英雄”形象而产生的种种利益就会刺激有些人带着寻租的心态去装扮“英雄”。社会道德就在围绕着反体制而产生的种种“高尚”话语下不断下降。 当国家建构的意识形态不再是社会上的主流价值观时，政府就会失去公信力。这时，如果国家对舆论不加控制，反政府的言论就会在社会上产生很大的影响力，从而引发政治危机。但是如果国家控制舆论的话，人们就会去追逐谣言；加上长期控制舆论而导致人们普遍的无知，天方夜谭式的谣言很容易不胫而走，比如“江泽民去世了，但是中共却秘不发葬”、“薄熙来手上有一百多条人命”、“被重庆警察击毙的不是周克华而是一个便衣警察”等，也会被大家（包括不少社会精英）津津乐道。这些传言不但会给中国的政局增加不确定因素，幷且使得中国本来就很糟糕的政治文化进一步走向糜烂。 当国家建构的意识形态不再是社会上的主流意识形态时，国家的当权者甚至不敢运用民主选举来增强其合法性。从当权者的私利角度看，在这样的情况下举行选举不但会使他们马上下台，而且整个共产党的统治也会结束；很少有当权者愿意在这样的条件下推动民主选举。而从国家利益来说，如果政治精英不能服从一个主流价值观，由选举而产生的“非忠诚反对派”就会撕裂社会，这给了当局拒绝搞民主选举以一定的道德依据。但接下来的问题是，不搞以选举为核心的程序政治只会使得社会矛盾不断积累，幷为中国从威权国家到民主国家的平稳过渡增加了难度。 一旦国家的合法性不能依托于意识形态和领导人的产生程序，绩效就成了国家唯一可依托的合法性基础。得益于中国的“强国家”传统，中国政府在加强执政绩效方面应该说还是可圈可点的。但是，即便可圈可点的绩效使得中国政府变得十分富有，其后果却是金钱使国家领导变得短视，以为金钱能解决一切问题，结果在解决一个问题的同时制造了几个问题。更令人担忧的是，围绕着金钱所产生的种种利益，使得大量的利益相关者带着工具理性围聚在政府周围。这些人对体制毫无忠诚可言，他们一方面死死地把住体制的大船，另一方面则随时准备另寻高就甚至搞狡兔三窟。当前中国出现了“裸官”现象，即不少国家干部的妻子和子女都在国外拥有永久居住权甚至是公民资格，大多数年轻人都向往公务员和国企的工作，其原因盖出于此。这带来的后果就是当前中国民众的强烈仇官心理以及由此生发出来的对任何成功者的仇恨心理，整个社会的道德维系（moral fabric）被大面积毁坏。 为了进一步加强绩效合法性，政府就必须加强吏治、采取悦民政策，幷且把社会上可能出现各种不安定因素的事情统统管了起来。但是，恶性循环不可避免地开始了：政府管得愈好，民众对政府的要求就会愈高；政府管得愈多，问题也就愈多，很多社会问题于是成了政治问题。社会问题的重新政治化是近十年来中国出现的一个令人担忧的发展方向。 五 中国的前途在国内，对国家前途不看好的还真是大有人在，其中既有国内语境下的“自由主义者”和比较极端的“左派”，也有难以计数的掌握着一定话语权的网民。最近，甚至连吴敬琏这样比较持重的学者，都在发表文章惊呼当前中国的“经济社会矛盾几乎到了临界点”10。本文认为，中国的确有再爆发一次革命的可能。与以上的观点不同是，笔者认为当这场动荡到来时，其引发的根本原因不应该是当今中国社会上存在着的各种“经济社会矛盾”，而是民众在主观层面上的不满情绪以及由此带来的大量的社会矛盾。而这些不满情绪和社会矛盾的根源，则是当今政府在国家的法律─选举合法性不足的情况下，过多地把绩效当作了国家合法性的根本基础。笔者同时认为，虽然当前的形势很严峻，但是由于以下原因，中国并没有马上就爆发一场革命的危险： 第一，尽管近年来中国经济发展的势头有所减缓，但是中国仍然是世界上经济发展最为迅速、百姓生活水平有着快速提高的国家。只要中国经济继续能保持目前的增长势头，绩效合法性就还能维持一定的效力，一场革命性的动荡在中国就暂时不会发生。 第二，在中国的不少地区（特别是藏区和新疆地区）有着很严重的民族问题，但中国少数民族人口与汉人相比比例实在太小；这就是说，与前苏联不同，少数民族地区的动乱在中国不会是引发革命的一个主要动因。 第三，由于美国经济的衰退和美国对外政策在世界上普遍不得人心，相当部分的中国知识分子不再简单地把美国政治和政治体制作为理想，或者说当前中国的“自由派”知识分子不再享有1980年代的道德高度，因此也失去了1980年代一呼百应的能力。 第四，中国知识分子在近年来生活水平有了很大的提高，幷且他们发表言论的渠道也大大增加。如果说前一个变化给了知识分子耐心，使他们不会急于鼓动革命，后一个变化则促进了知识群体的分化，从而降低了在中国产生一个人们广为接受的反体制意识形态的可能性。第五，国内外大多数的学者往往会把中国每天都在发生的群体性抗争事件（特别是一些重大事件）看作为革命性事件的可能促发因素。这种观点再一次反映了知识分子的天真。笔者认为，大量的群体性事件对中国政治的稳定实际上有着巨大的正面作用。当前不少地方的地方政府软弱，中国大规模爆发群体性抗争事件的阈值因此较低，社会矛盾也不容易有大规模的堆积。此外，当前中央政府对地方发生的群体性抗争事件采取的基本态度就是让地方政府自己去处理。只要地方政府能控制住局面，中央就保持袖手旁观的姿态；但是如果地方政府让事件失控，或者在处理过程中造成了流血事件，在国内外引起广泛关注，中央政府则会对地方政府官员进行处罚。中央政府的这一做法强化了群体性事件参加者“反贪官不反皇帝”的心态，同时也促使地方政府在处理群体性事件时表现出了极大的多样性和灵活性，从而大大缓解了中国群体性事件走向政治化的倾向。 第六，与一些领袖终身制的国家相比，中国已经形成了一套比较成型的国家领导每届五年，每任不超过两届的做法。虽然新的领导人不是由普选产生，幷且换届过程的不透明也给各种政治流言提供了温床，但是换届送走了人们已经厌烦了的领导（不在于干得好不好，而在于一个人在领导位置坐长了人们都会产生厌倦感），给了人们一种新的想象和希望，从而缓解了社会矛盾朝着革命的方向发展。 但是以上这些有利于缓解社会矛盾激化的因素，完全不可能改变以下的事实：在意识形态和程序合法性严重不足的情况下，执政绩效成了当前中国政府最为主要的合法性基础。因此，即便中国没有马上就发生革命性动荡的危险，只要国家的性质得不到根本性的改变，再发生一次革命的危险在中国始终存在。从这个意义上来说，“中国人自己的代价”的确“没有付够”。 注释1 Samuel P. Huntington, Political Order in Changing Societies (New Haven, CT: Yale University Press, 1968); William Kornhauser, The Politics of Mass Society (Glencoe, IL: Free Press, 1959); Eric R. Wolf, “Peasant Rebellion and Revolution”, in National Liberation: Revolution in the Third World, ed. Norman Miller and Roderick Aya (New York: Free Press, 1971), 48-67. 2 Barrington Moore, Social Origins of Dictatorship and Democracy: Lord and Peasant in the Making of the Modern World (Boston: Beacon Press, 1966); Jeffrey M. Paige, Agrarian Revolution: Social Movements and Export Agriculture in the Underdeveloped World (New York: Free Press, 1975). 3 Jeff Goodwin, No Other Way Out: States and Revolutionary Movements, 1945-1991 (New York: Cambridge University Press, 2001); Tim McDaniel, Autocracy, Capitalism, and Revolution in Russia (Berkeley, CA: University of California Press, 1988); Autocracy, Modernization, and Revolution in Russia and Iran (Princeton, NJ: Princeton University Press, 1991); Theda Skocpol, States and Social Revolutions: A Comparative Analysis of France, Russia, and China (New York: Cambridge University Press, 1979); Timothy P. Wickham-Crowley, Guerrillas and Revolution in Latin America: A Comparative Study of Insurgents and Regimes since 1956 (Princeton, NJ: Princeton University Press, 1992). 4、5 Jeff Goodwin and Theda Skocpol, “Explaining Revolutions in the Contemporary Third World”, Politics and Society 17, no. 4 (1989): 489-509. 6 Dingxin Zhao, “State Legitimacy, State Policy, and the Development of the 1989 Beijing Student Movement”, Asian Perspective 23, no. 2 (1999): 245-84; “State-Society Relations and the Discourses and Activities of the 1989 Beijing Student Movement”, American Journal of Sociology 105, no. 6 (2000): 1592-632. 7 Dingxin Zhao, The Power of Tiananmen: State-Society Relations and the 1989 Beijing Student Movement (Chicago: University of Chicago Press, 2001); “The Mandate of Heaven and Performance Legitimation in Historical and Contemporary China”, American Behavioral Scientist 53, no. 3 (2009): 416-33. 8 赵鼎新：〈民主的生命力、局限与中国的出路〉，《领导者》，2007年第18期，页76-86。 9 Jie Chen, Popular Political Support in Urban China (Washington, DC: Woodrow Wilson Center Press; Stanford, CA: Stanford University Press, 2004); Bruce Gilley, “Legitimacy and Institutional Change: The Case of China”, Comparative Political Studies 41, no. 3 (2008): 259-84; Lianjiang Li, “Political Trust in Rural China”, Modern China 30, no. 2 (2004): 228-58; Tianjian Shi, “Cultural Values and Political Trust: A Comparison of the People’s Republic of China and Taiwan”, Comparative Politics 33, no. 4 (2001): 401-19; Wenfang Tang, Public Opinion and Political Change in China (Stanford, CA: Stanford University Press, 2005). 10 参见吴敬琏的博客，http://wujinglianblog.i.sohu.com/blog/view/236115860.htm。]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>政治</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Django制作前端页面生成yaml文件]]></title>
    <url>%2F2018%2F09%2F03%2F%E5%88%B6%E4%BD%9C%E5%89%8D%E7%AB%AF%E9%A1%B5%E9%9D%A2%E7%94%9F%E6%88%90yaml%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[整体流程与环境说明整体流程如下图，请感受灵魂画师的功力： Django:2.1.1，阿里云服务器Python:3.6.4，安装方法见：https://rorschachchan.github.io/2018/07/31/获取网站title的脚本/ Django启动由于是python3，所以直接pip install django就安装最新的Django版本。 12345django-admin startproject Kubernetes #如果提示django-admin命令不存在可以做一个软连接到/usr/local/bin/目录下cd Kubernetespython manage.py startapp createyaml #创建APPpython manage.py migratepython manage.py createsuperuser app创建完毕之后，在Kubernetes/settings.py的INSTALLED_APPS字段添加createyaml，此时就创建好了项目和app。python manage.py runserver 0.0.0.0:8000启动django，然后浏览器地址栏输入外网IP：8000，就会看到django正常启动了，如图： Django准备首先我们先准备一个脚本111.sh，这个脚本很简单，就是接收到前端传入的数值然后加工成一个yaml文件，如下： 123456789101112131415161718192021222324#!/bin/bash#用来生成对应的yaml文件cat &lt;&lt; EOF================================ HERE IS YOUR YAML ================================EOFecho apiVersion: v1echo kind: $1echo metadata:echo name: $2echo labels:echo app: webecho spec:echo containers:echo -- name: front-endecho image: $5echo ports:echo -- containerPort: $3echo -- name: rss-readerecho image: nickchase/rss-php-nginx:v1echo ports:echo - containerPort: $4 可以看出上面这个生成yaml脚本太粗糙了，很多地方还有待改进，但是这仅仅是一个小例子而已。再去/django/Kubernetes/createyaml/templates里准备一个比较简单的前端页面脚本，内容如下： 12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;创建yaml文件&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;创建YAML文件用于K8s部署&lt;/h1&gt; &lt;h2&gt;请根据实际情况填写以下内容&lt;/h2&gt; &lt;form method="post" action="/create_yaml/"&gt; &lt;input type="text" name="kind" placeholder="类型"&gt;&lt;br&gt; &lt;input type="text" name="name" placeholder="名称"&gt;&lt;br&gt; &lt;input type="text" name="containerPort1" placeholder="容器端口1"&gt;&lt;br&gt; &lt;input type="text" name="containerPort2" placeholder="容器端口2"&gt;&lt;br&gt; &lt;input type="text" name="mirror" placeholder="镜像"&gt;&lt;br&gt; &#123;&#123; error &#125;&#125;&lt;br&gt; &lt;button id="btn" type="submit"&gt;生成yaml&lt;/button&gt; &#123;% csrf_token %&#125; &lt;!-- 标签添加CSRF令牌，这是因为django针对CSRF(跨站请求伪造)有保护措施，没有这句话就是403 --!&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 有了页面，还需要一个域名指向这个页面，修改一下/django/Kubernetes/Kubernetes/urls.py，改成如下： 12345678from django.contrib import adminfrom django.urls import pathfrom createyaml import views #将createyaml这个app的views引进urlpatterns = [ path('admin/', admin.site.urls), path(r'create_yaml/', views.create_yaml), #新版的这里不再是url了，把这个url指向views.py里的create_yaml函数] 再继续，写一下views.py里的create_yaml函数： 1234567891011121314import subprocess #引入这个库#创建yamldef create_yaml(request): if request.method == 'POST': kind = request.POST.get('kind', '') #后面的''是默认值的意思 name = request.POST.get('name', '') containerPort1 = request.POST.get('containerPort1', '') containerPort2 = request.POST.get('containerPort2', '') mirror = request.POST.get('mirror', '') result = subprocess.Popen(args=['bash','/docker/111.sh',name,mirror,containerPort1,containerPort2],stdout = subprocess.PIPE,shell = False).stdout.read() #在这里通过subprocess去启动111.sh这个脚本 return HttpResponse(result,content_type="text/plain") else: return render(request,'createyaml.html') 以上函数多说几句： 首先判断请求的方法是否是POST，不是的话返回该页面; request.POST.get方法获取前端传入的名称或者端口等值，此处的kind、name、mirror和containerPort就是html文件里form表单部分那两个input标签的name属性； 获取到了变量，然后就让subprocess来调用111.sh来用这些变量去运行脚本，执行的结果就是result，然后return这个result结果； 使用subprocess最好不打开shell = True，因为这样的话，要是不小心rm -rf /，你就gg了，但是如果shell = False的话，就会把刚才的命令看成rm和-rf /两部分，也就是不能成功，这样也免去了别人恶意注入的危险； 实际操作效果 参考资料https://blog.csdn.net/xiaoyaozizai017/article/details/72794469http://lipeilipei.top/2018/02/07/python+django%E5%AE%9E%E7%8E%B0%E7%99%BB%E9%99%86%E5%8A%9F%E8%83%BD%EF%BC%88%E4%B8%8B%E7%AF%87%EF%BC%89/https://blog.csdn.net/bjbz_cxy/article/details/79358718 (如果不想用django就可以看看这个cgi方法)http://blog.51cto.com/laomomo/2163399]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins自动构建镜像并且发送钉钉通知]]></title>
    <url>%2F2018%2F08%2F30%2FJenkins%E8%87%AA%E5%8A%A8%E6%9E%84%E5%BB%BA%E9%95%9C%E5%83%8F%E5%B9%B6%E4%B8%94%E5%8F%91%E9%80%81%E9%92%89%E9%92%89%E9%80%9A%E7%9F%A5%2F</url>
    <content type="text"><![CDATA[部署流程图把k8s引入到整个部署的自动化流程如下图： 上图已经说的很明白了，但是结合到我公司的内部情况，再加一点文字的解释： 运维做一个前端页面，上面提供一些关键词作为变量传入; 开发将代码上传到svn或者gitlab，进行jira通知，如果是svn的话，jenkins将新代码打包成zip文件，启动jenkins把windows的zip包上传到阿里云云存储上；如果是到gitlab，就不用打包成zip了，直接就把包传到云存储上； Gitlab/Svn通过webhook通知jenkins去挂载云存储bucket的文件夹里，并且根据对应的dockerfile进行build成镜像，然后再把镜像推送到云镜像仓库里，推送成功后，Jenkins发送一个钉钉成功的通知； Jinkens针对本次镜像和实际部署内容再搭配上之前传递进来的变量，构建一个yaml文件； 通过create这个yaml文件，启动对应的services来达到用户访问的目的，此时Jenkins再发一条钉钉通知，整个部署流程结束。 环境说明Jenkins:2.124,jenkins与docker在同一台云服务器上，并且确定这个机器上可以顺利login到阿里云的私有仓库云存储:阿里云OSSGitlab:10.7.3镜像仓库:阿里云容器镜像仓库钉钉:4.5.5 Jinkens安装钉钉插件既然要让jenkins调用钉钉发送成功消息，那么就需要把jenkins跟钉钉结合在一起。至于怎么配自定义钉钉机器人，请看钉钉的官方文档：https://open-doc.dingtalk.com/docs/doc.htm?spm=a219a.7629140.0.0.karFPe&amp;treeId=257&amp;articleId=105735&amp;docType=1 。而jenkins里也是有官方的钉钉插件，界面系统管理–管理插件，然后搜索“dingding”，安装即可，如图： 插件安装完毕之后，重启jenkins即可。 挂载阿里云存储阿里云官方挂载云存储的方法是ossfs，登陆到jenkins所在的服务器(centos 7.4)里，步骤如下： 123456wget https://github.com/aliyun/ossfs/releases/download/v1.80.5/ossfs_1.80.5_centos7.0_x86_64.rpmyum localinstall ossfs_1.80.5_centos7.0_x86_64.rpm #这一步安装可能会比较慢echo 需要挂载的bucket名:云存储对应ak:云存储对应sk &gt; /etc/passwd-ossfs #将云存储的ak,sk写入到文件里chmod 640 /etc/passwd-ossfsmkdir /tmp/ossfs #创建挂载文件ossfs 需要挂载的bucket名 /tmp/ossfs -ourl=http://oss-cn-hangzhou-internal.aliyuncs.com #如果不是阿里云就要用外网的endpoint 操作的效果如下，我挂载的bucket叫ligentest，毕竟代码是高度机密，bucket属性设置是私有，256T的容量爽爽的： 配置任务在jenkins里创建一个新的工程，取名叫“构建镜像并且上传到云仓库”。“gitlab更新就触发jenkins”的配置内容可以参考 https://rorschachchan.github.io/2018/05/25/Gitlab-Jenkins搭建持续集成系统/ 一文进行操作。 配置正确jenkins与gitlab各自的webhook，测试提交能返回200之后。就要配置构建和构建后操作。 构建选择执行shell，里面填写这样一个命令：sudo sh /docker/pushimage.sh，也就是运行一个脚本，脚本内容如下： 12345678#!/bin/bash#这个脚本用来推送最新的镜像去阿里云镜像仓库version=$(date +20%y%m%d) #用当前日期作为versiondocker build -f /docker/chenpyfile -t chentest/python:$version . #先本地构建镜像image_id=$(docker images | awk '&#123;print $3&#125;' | sed -n '2p') #获取image的id号docker tag $image_id registry.cn-hangzhou.aliyuncs.com/lechangetest/chentest:$version #给本地的镜像打一个tagdocker push registry.cn-hangzhou.aliyuncs.com/lechangetest/chentest:$version #推送到阿里云对应的仓库去 构建后操作选择钉钉通知器配置，jenkins URL一栏应该默认填好的，即jenkins的网址；钉钉access token这一栏就是直接填机器人的那个access token，然后选择根据什么情景机器人触发通知，如图： 触发验证首先要确认jenkins用户能否正常使用docker命令，方法就是修改一下/etc/sudoers添加jenkins这个用户即可。 这次测试，我们就不搞nginx那种静态页面了，换一个python在后台运行的例子。首先，准备一个叫time.py的脚本，这个脚本很简单，就是不断的输出当前时间的脚本： 123456789101112#!/usr/bin/env python#coding=utf-8import timedef get_time(): localtime = time.asctime( time.localtime(time.time()) ) print ("本地时间为 :", localtime) #python的dockerfile用的是latest，python3是要求有括号的if __name__ == '__main__': while True: get_time() time.sleep(1) 对应的dockerfile叫chenpyfile，如下： 123456789101112############################################################# Dockerfile to build A python container images ## Based on Python #############################################################FROM python:latestMAINTAINER ChrisChan "Chris@jjfjj.com"RUN apt-get update &amp;&amp; \ apt-get install -y vim &amp;&amp; \ apt-get install -y procpsRUN mkdir -p /root/appCOPY /script/ /root/script #把上面那个脚本拷贝到容器里，当然挂载也可以CMD ["python", "/root/script/time.py"] #这里不要写“python /root/script/time.py”，注意前后台问题 这个dockerfile在本地测试构建镜像是完全没问题的，然后触发一下git push，就会看到钉钉机器人启动了： 构建完毕之后，机器人也会给一个成功的标志，然后去阿里云的云仓库一看，嗯，果然已经推送过来了！如图： 再docker run -dit --name chen-pytest registry.cn-hangzhou.aliyuncs.com/lechangetest/chentest:20180831，也能看到新创建的镜像是可以启动的： 至此整个“Jenkins自动构建镜像并且发送钉钉通知”部分就结束了。 参考资料https://jimmysong.io/posts/kubernetes-jenkins-ci-cd/https://help.aliyun.com/document_detail/32196.htmlhttp://www.cnblogs.com/jianxuanbing/p/7211006.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
        <tag>钉钉</tag>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[K8s的基础操作]]></title>
    <url>%2F2018%2F08%2F27%2FK8s%E4%BB%8E%E9%83%A8%E7%BD%B2%E5%88%B0%E6%89%A9%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[环境说明kubenetes:阿里云服务，版本v1.10.4，三个master，一个node，我也不知道为啥阿里云设定master最少是3个，而node最少可以是1个…服务器:阿里云Centos 7.4 部署服务首先，我们先部署一个以dockhub最新nginx镜像为底的nginx。命令如下：kubectl run nginx-test --image=nginx:latest --port=80。同理，再部署一个最新版redis的话，就是找葫芦画瓢：kubectl run redis-test --image=redis:latest --port=6379。 两个命令敲完，这就给k8s下达了一个deployment（部署任务），可用kubectl get deployments和kubectl get pods命令查看： 可以看到现在已经生成了对应的pod，而pod里就是容器了，容器里就是对应的服务。如果想爬进这个容器看一下里面的文件等情况，命令是：kubectl exec -it nginx-test-bb95c4645-7qpbj bash。 这里插播一下kubectl get deployment里各参数的含义： 1234DESIRED：对应.spec.replicas，用户设定的期望副本数CURRENT：对应.status.replicas，目前运行的副本数UP-TO-DATE:对应.status.updatedReplicas，包含最新的pod template的副本数AVAILABLE：对应.status.availableReplicas，进入正常状态的副本数 但是现在这个服务是外网无法访问的，因为宿主机还没有一个端口与这个nginx容器的80端口相对应。所以要暴露一个端口给外部用于访问。命令是：kubectl expose deployment/kubernetes-bootcamp --type=&quot;NodePort&quot; --port 80，然后用kubectl get services查看一下效果： 然后在对应的master和node里就看到宿主机随机分配的那个30497端口已经启动了，如图： 在浏览器上访问一下30497端口，果然可以访问到nginx服务： 扩容服务服务嘛，总有高峰低谷。比如微博，突然爆出来哪个娱乐明星的新闻，肯定就会有大量的流量涌入，此时就需要扩容，那么k8s的扩容很简单，就是pod的复制，如果要把上面那个nginx-test的部署任务进行扩展，命令就是kubectl scale deployments/nginx-test --replicas=4，如图： 可见nginx-test又生成了三个pod，与原来的组成了4个pod，而另一个redis的部署任务是没有变化的。 用kubectl get pods -o wide可见，每一个pod分配到了不同的虚拟IP上，而且node都是阿里云的那台node服务器。 在阿里云控制台也能看到里面的情况： 此时进入到node节点，docker ps -a就会看到新的nginx景象生成，同时也生成了三个/pause的容器： kubernetes中的pause容器主要为每个业务容器提供以下功能： 在pod中担任Linux命名空间共享的基础； 启用pid命名空间，开启init进程。 注意！目前kubernetes似乎仅仅支持共享网络，还不支持进程体系、文件系统之间的共享。如果此时在访问，就会看到访问会相对均匀的落到这四个pod中的每一个，起到一个负载均衡的作用。如果高峰期过了，不需要那么多pod了，就kubectl scale deployments/nginx-test --replicas=1，pod就会恢复成1个，据我几次试验，每次都是保留最老的那一个pod。 yaml文件创建一个podK8s的yaml文件的文法和规矩，官方社区就有教程：https://www.kubernetes.org.cn/1414.html 。但是如果要搭配阿里云的私有镜像，需要先参考一下阿里云文档：https://help.aliyun.com/document_detail/86562.html 。注意，这个方法不能在命令行里使用，只能在yaml或者json里用。这里先写一个简单的nginx配置文件pod-nginx.yaml做例子，全文如下： 1234567891011121314151617181920---apiVersion: v1kind: Podmetadata: name: aliyun-nginx labels: app: webspec: restartPolicy: Always #表明该容器一直运行，默认k8s的策略，在此容器退出后，会立即创建一个相同的容器 nodeSelector: zone: node1 #节点选择 containers: - name: aliyun-test-nginx image: registry-vpc.cn-hangzhou.aliyuncs.com/lechangetest/chentest:1.1 imagePullPolicy: IfNotPresent #可选择Always、Never、IfNotPresent，即每次启动时检查和更新images的策略，IfNotPresent是节点上没有此nginx镜像时才执行pull操作 ports: - containerPort: 80 #容器开发对外的端口 hostPort: 33664 #映射到主机的端口/对外映射的端口（一般可以不写） imagePullSecrets: - name: regsecret #这句话为了通过阿里云似有仓库的鉴权 保存退出，再kubectl create -f pod-redis.yaml把这个文件执行一下。然后kubectl get pod看一下效果： 发现我们创建那个redis-pod状态是Pending（等待中），那就是不成功啊。于是就kubectl describe pod/pod-redis查看一下原因，反馈如下： 这个错误的意思是“如果指定的label在所有node上都无法匹配，则创建Pod失败”。原来是我没有配置kubectl label nodes，那先把pod-redis删除，再把nodeSelector那一段去掉，改成nodeName: cn-hangzhou.i-bp1978gmunq3oalfcqlx，去掉再重新create一下。kubectl get pod检查： 然后就是给这个pod增加一个对外的端口。kubectl expose pod/aliyun-nginx --type=&quot;NodePort&quot; --port 80，效果如下： 再去浏览器里，输入node的外网网址：31829看看效果： 配置成功，当然这整个过程也可以在阿里云的控制台操作，更简单更直观，而且阿里云还会自动把对外端口配置到SLB里，具体步骤可以看阿里云的官方文档。 升级与回滚假设我们把nginx-test这个deployment的镜像升级成阿里云私有仓库的1.1版本，那么命令是： 1kubectl set image deployments/nginx-test nginx-test=registry.cn-hangzhou.aliyuncs.com/lechangetest/chentest:1.1 升级之后，kubectl get pod发现有几个节点不正常，如图： 那么这种情况下需要紧急回滚，回滚命令： 1kubectl rollout undo deployment/nginx-test 一会就看到回滚成功了。如图： 参考资料https://jimmysong.io/posts/what-is-a-pause-container/https://blog.csdn.net/mailjoin/article/details/79686937http://pipul.org/2016/05/why-we-need-the-pod-and-service-of-kubernetes/https://www.imooc.com/article/30473]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>容器</tag>
        <tag>阿里云</tag>
        <tag>kubenetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos6.5升级最新内核4.18的坑]]></title>
    <url>%2F2018%2F08%2F25%2Fcentos6-5%E5%8D%87%E7%BA%A7%E6%9C%80%E6%96%B0%E5%86%85%E6%A0%B84-18%E7%9A%84%E5%9D%91%2F</url>
    <content type="text"><![CDATA[升级流程开发童鞋要搞BBR，然后让我在他的阿里云服务器上升级一下内核。我登进去一看，centos 6.5，内核还是2.6的。 之前我曾经搞过centos 7升级内核到最新版，文章在此：https://rorschachchan.github.io/2018/06/11/阿里云centos7升级内核过程/ 。centos6升级内核有几个地方不太一样，但是过程差不多。整个升级内核步骤如下： 12345先备份镜像，很重要！！！ 而且备份镜像成功之前，云服务器不可以重启。yum update -yrpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org #导入ELRepo GPG keyrpm -Uvh https://www.elrepo.org/elrepo-release-6-8.el6.elrepo.noarch.rpm #安装 6版本的ELRepoyum --enablerepo=elrepo-kernel install kernel-ml -y #截至本文，最新的是4.18，lt版本是4.4 如果yum的时候有提示Warning: RPMDB altered outside of yum，只需要删除一下yum的历史记录即可：rm -rf /var/lib/yum/history/*.sqlite 。 安装完毕之后，vim /etc/grub.conf，把default改成0，即指定使用第一个内核启动，如图： 然后在阿里云控制台重启一下这个服务器即可。 无法启动？可能有的人直接就启动成功了，因为网络上很多文章到此就结束了。但是我这台服务器，很不幸，出现了问题。在控制台上看服务器是“运行中”，但是无法ssh连接，而且ping也是失败。不一会，控制台的服务器就显示“已停止”，可见是内核出了问题。 联系了阿里的后台，他们反馈这个机器现在的状态是Module scsi_wait_scan not found，那知道了原因就对症下药吧，这个问题解决方法不止一个，我亲测以下的方法好使。 首先先用刚刚做的那个磁盘快照回滚到之前正常的状态，重新执行上面整个安装4.18的内核的所有操作，然后还要补充如下： 123echo 'add_drivers+="virtio_blk"' &gt;/etc/dracut.conf.d/force-vitio_blk-to-ensure-boot.confcp /boot/initramfs-4.18.5-1.el6.elrepo.x86_64.img /boot/initramfs-4.18.5-1.el6.elrepo.x86_64.img-bak #把新下载的4.18的img文件备份dracut -f initramfs-4.18.5-1.el6.elrepo.x86_64.img 4.18.5-1.el6.elrepo.x86_64 #编译生成新的img，4.18.5-1.el6.elrepo.x86_64这个文件在/lib/modules/下 重新在阿里云控制台重启一下这个服务器，这一次就OK了。 发生异常的原因是：更新内核后,在写dracut程序时无法检测KVM&#39;s virtual disk driver &quot;virtio_blk&quot;，此驱动被用于访问KVM虚拟磁盘,dracut没有正常添加新的initramfs module,导致系统没有磁盘访问驱动无法正常启动。 参考资料https://bugzilla.kernel.org/show_bug.cgi?id=60758https://opengers.github.io/linux/linux-source-code-compile-kernel-rpm/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>内核</tag>
        <tag>BBR</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Kubectl使用的简单举例]]></title>
    <url>%2F2018%2F08%2F22%2F%E5%AE%89%E8%A3%85%E5%B9%B6%E4%B8%94%E9%85%8D%E7%BD%AEkubectl%2F</url>
    <content type="text"><![CDATA[安装kubectl在阿里云的Kubernetes界面生成一个新的集群，如图： 但是这个集群是无法通过ssh登陆云服务器那样登录的，这个时候要操作k8s就有两个招数，第一个招数就是用kubectl这个工具去连接到集群。但是kubectl很难搞，因为它所在的storage.googleapis.com在大陆是无法访问的，如果效仿https://www.kubernetes.org.cn/installkubectl 里面的方式去下载kubectl是无法成功的，如图： 为了应付这个办法，就要去kubernete的github界面里下载代码包，然后手动上传到云服务器里安装。 首先到https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.11.md#v1112 里的Client Binaries下载1.11版本的kubectl的包，如图： 将这个包上传到云服务器之后解压缩，然后把kubernetes安装包里的/client/bin/kubectl做一个/usr/local/bin/kubectl的软连接，如图： 如果所在的网络也无法打开github，那么只好用国内的源https://mirrors.ustc.edu.cn/kubernetes/apt/pool/ ，下载相应的包之后手动上传到云服务器里也能达到一样的效果，缺点就是国内源没有github更新的那么快。 配置kubectl阿里云在生成kubernetes集群后，点击管理，最下面会有一个配置文件，将整个文件内容写入/root/.kube/config，然后再一次使用kubectl cluster-info就能看到配置成功了，如图： 再用kubectl config view能进一步看到细节： 这样就证明可以通过kubectl连接到kubenetes集群了。 kubectl基本操作 kubectl get nodes：查看master和worker的基本情况，如图： kubectl run ngx-test --image=nginx:latest --port=8080 --restart=Never：部署一个以nginx最新镜像为底的叫ngx-test的部署，并且开放下面容器的8080端口，每个部署的名称不能重复。部署会自动生成pod，如果加上了--restart=Never，那么pod生成一次失败就不再生成； kubectl delete deployment chen-test:删除一个叫chen-test的部署，注意，使用kubectl命令，要删除拥有该pod的Deployment。如果我们直接删除pod，Deployment将会重新创建该pod； kubectl get deployments：查看部署情况，如图： kubectl proxy: 每个pod在kuber集群里都是一个封闭的网络环境里，可以通过这个命令使API server监听在本地的8001端口上； kubectl get pods：获取每一个pods的基本情况，如图: kubectl describe pods:查看每一个pods的运行细节，可以出来为什么pods没有正常的运行，如果要特别制定具体的pod，那就是kubectl describe pods pod的名称； kubectl exec -it POD_NAME bash:连接到对应的pod里； kubectl get pods -n kube-system:查看NAMESPACE是kube-system的所有pod； 10.kubectl delete pods/kubernetes-dashboard-7b9c7bc8c9-q8425 -n kube-system:删除掉kube-system这个NAMESPACE里kubernetes-dashboard-7b9c7bc8c9-q8425这个pod； 参考资料https://help.aliyun.com/document_detail/64940.html?spm=a2c4g.11186623.4.1.2c4652f3qdpMed （这个是通过ssh访问k8s负载均衡的方法）https://kubernetes.io/cn/docs/tutorials/kubernetes-basics/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
        <tag>kubernetes</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用gitlab搭配阿里云容器镜像服务构建镜像]]></title>
    <url>%2F2018%2F08%2F15%2F%E4%BD%BF%E7%94%A8gitlab%E6%90%AD%E9%85%8D%E9%98%BF%E9%87%8C%E4%BA%91%E5%AE%B9%E5%99%A8%E9%95%9C%E5%83%8F%E6%9C%8D%E5%8A%A1%E6%9E%84%E5%BB%BA%E9%95%9C%E5%83%8F%2F</url>
    <content type="text"><![CDATA[工作思路本次北京AWS技术峰会里看到了很多公司在运维上使用容器部署和扩容的实例，一天下来感受良多。现在比较流行部署办法就是“云镜像”：即开发把新的代码提交到gitlab上，然后gitlab与云厂家的镜像服务相关联，然后每一次commit提交都会触发一次镜像的构建，然后再根据这个镜像部署到实际的服务器里，同时将此服务器作一个快照，同时再搭配上容器监控，如果服务吃紧，就用此快照购买实例扩容；如果服务闲余，那么也会自动将最老的服务器实例关机，进而释放退款。 用图像来说就是这个意思： 勾连gitlab与云镜像本文使用的镜像厂家是阿里云，gitlab版本是10.7.3。 进入阿里云的“容器镜像”页面，如果你是第一次使用这个产品需要先建立一个仓库密码，然后点击左侧的代码源，如图： 在gitlab地方选择“绑定账号”，就需要填写对应的栏目： 前两项很好写，最后一个token需要在gitlab里创建：在gitlab的页面，点击个人的头像，然后settings—Access Tokens，填写好名字（生产环境一般都是填运维的账号）然后在api处打勾，生成的那个东东就是token，直接复制填写到阿里云的页面即可。如图： 配置镜像仓库在阿里云容器镜像界面点击“创建镜像仓库”，填写好名字摘要仓库类型之后，在代码源里选择gitlab，由于刚刚填写了token所以是可以看得到gitlab用户下所有的project名的，如图： 然后点击新创建的那个仓库，在构建一栏默认已经选择好了“代码变更时自动构建镜像”，点击“添加规则”，如图： 这里我选择了master分支，然后指明了dockerfile文件名和路径，最后版本号就先写一个version，这个可以通过gitlab在commit时特殊指定。 右侧栏里的Webhook是用来发送提示的，可以在钉钉里创建一个机器人，在创建机器人时会生成webhook，然后把机器人的webhook添加到这个webhook即可。如果在添加的时候提示“当前请求失败，请重试”，这个情况是因为Webhook的名称里有中文，要全英文才可以。 编写dockerfile如果没有dockerfile是无法构建镜像的，于是就在上面“规则”的目录里创建对应的dockerfile文件，注意!“规则”里的根目录就是代码文件夹的顶目录，而不是整个服务器的根目录。写dockerfile的基础知识和语法这里不多说了，网络上有的是，我就随便写一个nginx dockerfile，内容如下： 123456789101112131415############################################################# Dockerfile to build Nginx container images# Based on Debian############################################################FROM debian:latestMAINTAINER ChrisChan "Chris@jjfjj.com"RUN apt-get updateRUN apt-get install -y nginx RUN apt-get install -y vim RUN apt-get install -y procps #安装ps命令RUN echo 'HI!WARRIOR is the champion!!!' &gt; /var/www/html/index.nginx-debian.htmlEXPOSE 8080 #开放8080端口COPY /file/kubernetes.tar.gz /mnt/#CMD service nginx start &amp;&amp; nginx -g "daemon off;"ENTRYPOINT [ "/usr/sbin/nginx", "-g", "daemon off;" ] 注意！使用上面注释的CMD语句作为结尾的话，那么这个镜像docker run的时候就会马上退出，这是因为把command做为容器内部命令，那么nginx程序将后台运行，这个时候nginx并不是pid为1的程序，而是执行的bash，这个bash执行了nginx指令后就挂了，所以容器也就退出了。简而言之，Docker容器后台运行,就必须有一个前台进程。因为Docker容器仅在它的1号进程（PID为1）运行时，会保持运行。如果1号进程退出了，Docker容器也就退出了。 在gitlab触发之后，阿里云就自动把这个dockerfile build成了镜像保存在阿里云的容器仓库里，如图： 想用这个镜像就可以直接去阿里云的仓库里下载并启动，这样就节省了本地的硬盘容量。最后就是把这个镜像部署到对应的kubernetes集群里，这样就完成了“gitlab代码提交触发阿里云构建镜像”的过程，而如何使用kubernetes的内容将在以后细说。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>持续集成</tag>
        <tag>阿里云</tag>
        <tag>gitlab</tag>
        <tag>docker镜像</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云Centos7开启swap虚拟内存]]></title>
    <url>%2F2018%2F08%2F13%2F%E9%98%BF%E9%87%8C%E4%BA%91Centos7%E5%BC%80%E5%90%AFswap%E8%99%9A%E6%8B%9F%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[出差归来，几个开发反馈说gitlab网页卡的不行，上传代码也非常吃力。我登入服务器一看，原来是内存已经耗尽了。 修改配置文件gitlab本身就是一个特别吃内存的软件，服务器还是2核4G的配置。于是我就登陆到gitlab容器里，修改一下/etc/gitlab/gitlab.rb，把unicorn[&#39;worker_processes&#39;]手动改成了3，也就是比CPU大一个，这样可以少开一点进程。但是注意，这个参数最小值是2，如果设置成1，那么gitlab就会崩坏。 保存文件之后，gitlab-ctl reconfigure，看一下内存的情况，嗯，比刚才好一点点。如图： 开启虚拟内存上面那个方法毕竟效果有限，时间长了还是会把内存一点点蚕食光，于是就要使用Swap分区，但是阿里云虚拟服务器默认是不带swap分区的，如何手动创建swap分区才是本文的要点。 这里我用了一个非生产环境的机器做实验。 创建swap分区主要的中心思想就是“创建一个文件，然后将这块文件格式化为swap格式”，首先先看一下当前的磁盘容量： 当前已用磁盘容量是16G，使用cat /proc/swaps看一下当前虚拟内存的情况： 这个情况说明没开启swap，于是就手动建立一个文件夹，比如叫/swaps，在/swaps这个路径下执行dd if=/dev/zero of=swaps bs=512 count=8388616，在这里创建swap大小为bs*count=4294971392(4G)，这个过程需要一点时间，稍等片刻： 通过mkswap swaps命令将上面新建出的swaps文件做成swap分区： 此时使用cat /proc/sys/vm/swappiness查看数值应该是0，需要sysctl -w vm.swappiness=60把它改成60，这里60的含义是：100%-60%=40%，即物理内存剩下40%的时候时启用虚拟内存。若想永久修改，则编辑/etc/sysctl.conf文件，改文件中有vm.swappiness变量配置。 再swapon /swaps/swaps： 最后就是添加开机自动挂载，即在/etc/fstab文件添加如下一句： 1/swaps/swaps swap swap defaults 0 0 再用cat /proc/swaps命令检查一下swap分区是否启动： 最后，重启一下服务器，看一下开机是否正常挂载上这个虚拟分区了： 可见原来使用了16G容量，现在用了20G，这中间差的4G就是拿来做了swap，于是内存就这样多了4个G…]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
        <tag>虚拟内存</tag>
        <tag>阿里云服务器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[爬取当前IP并且修改阿里云安全组的脚本]]></title>
    <url>%2F2018%2F08%2F07%2F%E7%88%AC%E5%8F%96%E5%BD%93%E5%89%8DIP%E5%B9%B6%E4%B8%94%E4%BF%AE%E6%94%B9%E9%98%BF%E9%87%8C%E4%BA%91%E5%AE%89%E5%85%A8%E7%BB%84%E7%9A%84%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[动机与脚本我工位所用的网络是公司特批的海外专线，速度OK还能翻墙出去看看，自从有了这条线爽的飞起，但缺陷就是每周IP地址都会变，IP一变很多的阿里云ecs安全组就要重新配置，因为有一些公网端口比如grafana或者跳板机是只能公司运维人员访问的。这样每周都要手动改一次IP地址太烦了，于是乎，写了下面这个脚本，一劳永逸的解决这个问题： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#coding=utf-8#这个脚本在python3.6下自验通过，用途是去爬当前的IP地址然后给阿里云安全组添加新的IP，并且删除掉老的IPfrom aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import AuthorizeSecurityGroupRequestfrom aliyunsdkecs.request.v20140526 import RevokeSecurityGroupRequestfrom aliyunsdkcore.profile import region_providerimport requests,sys,re,osfrom bs4 import BeautifulSoupclt = client.AcsClient('这里是AK', '这里是SK', 'cn-hangzhou') #鉴权file = "F:\\ip.txt"def checkDIR(): global file if os.path.exists(file) == True: #先判断文件是否存在 with open(file, "r") as f: old_ip = f.read() return (old_ip) #获取旧ip else: print("ip.txt文件不存在，请手动生成！") sys.exit() #文件不存在直接退出def getIP(): global file r = requests.get('http://www.ip111.cn/') #这里输入要爬的网站域名 soup = BeautifulSoup(r.text, "lxml") context = [] for link in soup.find_all('td'): #获取所有td标签内容 context.append(link.get_text()) #添加一个列里 str = context[4] ip = re.split(r'[\n\s]\s*', str)[1] #多符号分割字符串 with open(file, "w") as f: f.write(ip) return ipdef addnewRULE(func): global clt # 设置参数 for port in ['3000/3000', '34872/34872']: #这里是端口 request = AuthorizeSecurityGroupRequest.AuthorizeSecurityGroupRequest() request.set_accept_format('json') request.add_query_param('RegionId', 'cn-hangzhou') request.add_query_param('SecurityGroupId', '目标安全组ID') request.add_query_param('IpProtocol', 'tcp') request.add_query_param('PortRange', port) request.add_query_param('SourceCidrIp',func()) request.add_query_param('NicType', 'intranet') #如果不加这句话就是公网添加 if port == '3000/3000': request.add_query_param('Description', 'Grafana使用端口') else: request.add_query_param('Description', 'Zabbix和堡垒机使用端口') # 发起请求 response = clt.do_action(request) print (response)def deloldRULE(func): global clt # 设置参数 for port in ['3000/3000','34872/34872']: request = RevokeSecurityGroupRequest.RevokeSecurityGroupRequest() request.set_accept_format('json') request.add_query_param('RegionId', 'cn-hangzhou') request.add_query_param('SecurityGroupId', '目标安全组ID') request.add_query_param('IpProtocol', 'tcp') request.add_query_param('PortRange', port) request.add_query_param('SourceCidrIp', func()) request.add_query_param('NicType', 'intranet') #如果不加这句话就是公网删除 # 发起请求 response = clt.do_action(request) print (response)if __name__ == '__main__': checkDIR() deloldRULE(checkDIR) getIP() addnewRULE(getIP) 整个脚本的逻辑就是先在F盘下有ip.txt里面就保存当前IP地址，然后执行脚本的时候就会先在目标安全组里删除掉这个IP相关的3000端口和34872端口，然后去www.ip111.cn里爬取当前的网址，把新IP写入到ip.txt的同时，再去目标安全组里添加这个新IP相关的3000端口和34872端口。 新的知识点 把上一个函数结果当作参数在下一个函数里执行的方法： python的退出有两个：os._exit()和sys.exit()：os._exit()会直接将python程序终止，之后的所有代码都不会执行；sys.exit()会抛出一个异常: SystemExit，如果这个异常没有被捕获，那么python解释器将会退出。如果有捕获该异常的代码，那么这些代码还是会执行。使用sys.exit()来退出程序比较优雅，一般情况下也用这个，os._exit()可以在os.fork()产生的子进程里使用。 在windows里定时执行python脚本的方法：打开控制面板—&gt;系统和安全—&gt;计划任务。如图： 点击右侧的创建基本任务，输入任务名称和可选的描述。点击下一步，设置任务的开始时间，可以选择每日执行、每周执行或每月执行。点击下一步，操作选择启动程序，点击下一步输入参数。如图： 123程序或脚本：python.exe 添加参数：输入要执行的python脚本路径（包括文件名）起始于：输入python.exe的目录（不包括文件名） 最后点击下一步，整个过程搞定。 目前http://www.ip111.cn/网站已经更改了网页格式，上述的代码有一段已经不好使了，需要将getIP()这个函数改成如下的方法: 123456789101112def getIP(): global file r = requests.get('http://2018.ip138.com/ic.asp') #改用这个域名 soup = BeautifulSoup(r.text, "lxml") context = [] for link in soup.find_all('body'): #获取body内容 context.append(link.get_text()) #添加一个列里 str = context[0] ip = re.split(r'[\[\]]',str)[1] #进行分割 with open(file, "w") as f: f.write(ip) return ip]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
        <tag>python3.6</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[获取网站title的脚本]]></title>
    <url>%2F2018%2F07%2F31%2F%E8%8E%B7%E5%8F%96%E7%BD%91%E7%AB%99title%E7%9A%84%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[脚本在此公司的商城需要添加一个脚本，这个脚本就是观察首页页面是否正常，虽然已经配置了zabbix监控网站是否200，但是有一些特殊的情况，比如网页可以打开但是页面是“file not found”，类似这样就需要被运维第一时间监控到然后通知开发。 原本我打算直接爬取整个首页然后与服务器里的index.html对比一下，如果不符合就报警，但是跟前端同事说了这个思路之后，前端说服务器上是没有index.html的，因为这个index.html是结合其他的php拼接的。前端说“只要能检测title正常就OK，一般来说title能获取到就证明系统是OK的，如果titleOK但是html内容获取不到就是前段代码的问题，跟系统无关”。于是我就写了这么一个爬虫脚本来获取网站title，如下： 12345678910111213#!/usr/bin/env python#coding=utf-8#这个脚本的用途是用来爬取商城首页title，然后判断是否正常import requests,sysfrom bs4 import BeautifulSoupreload(sys)sys.setdefaultencoding('utf-8') #不然就会UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-4: ordinal not in range(128)r = requests.get('https://www.lechange.com') #这里输入要爬的网站域名r.encoding = requests.utils.get_encodings_from_content(r.content)[0]soup = BeautifulSoup(r.text,'lxml') #这一步需要事前pip install lxmlprint soup.title.string 说一下，如果在from bs4 import BeautifulSoup爆出ImportError: No module named &#39;bs4&#39;是因为安装的库装错了，应该是pip install beautifulsoup4而不是pip install beautifulsoup。启动脚本效果如下： 编码问题上面那个脚本里的soup.title.string的类型是bs4.element.NavigableString，如果不用print那么它的形式是unicode的，如图： 这种现象并不新鲜，比如list在python2里一直都不是正常输出中文的，如图： 可见只有for in的时候才会正常编码，那么这样的情况怎么办？ 最简单的方法，改用python3。不过上面那个脚本是可以直接把中文放到soup.title.string进行判断的。 安装python 3.6.4首先要先安装相关依赖包yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make，其中readline-devel这个很重要，他是管方向键的，如果python运行的时候方向键不好使，那么就要yum install readline-devel安装，安装完毕后重新configure和make。 然后过程如下： 1234567891011121314151617yum -y install epel-release #运行这个命令添加epel扩展源#安装pipyum install python-pippip install wgetwget https://www.python.org/ftp/python/3.6.4/Python-3.6.4.tar.xz#解压xz -d Python-3.6.4.tar.xztar -xf Python-3.6.4.tar#进入解压后的目录，依次执行下面命令进行手动编译./configure prefix=/usr/local/python3make &amp;&amp; make install#将原来的链接备份mv /usr/bin/python /usr/bin/python.bak#添加python3的软链接ln -s /usr/local/python3/bin/python3.6 /usr/bin/python#测试是否安装成功了python -V 更改yum配置，因为其要用到python2才能执行，否则会导致yum不能正常使用，需要分别修改/usr/bin/yum和/usr/libexec/urlgrabber-ext-down这两个文件，把他们的#! /usr/bin/python修改为#! /usr/bin/python2。 然后还要给python3的pip3做一个软连接: ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3。 注意！如果你用了python3那么上面那个脚本就会有很大的变动。 参考资料https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.htmlhttp://scrapy-chs.readthedocs.io/zh_CN/1.0/intro/tutorial.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[云服务器的内存竟然少了500M...]]></title>
    <url>%2F2018%2F07%2F27%2F%E7%AE%97%E7%AE%97%E5%86%85%E5%AD%98%E7%9A%84%E8%BF%99%E4%B8%80%E7%AC%94%E7%B3%8A%E6%B6%82%E5%B8%90%2F</url>
    <content type="text"><![CDATA[故障发现今天发现有一台阿里云线上环境的服务器内存在告急，使用free -m一看，果然剩余的内存不多了，而且buffers和cached也都不高，如图： 用top一看，里面的情况是这样的: 很奇怪，top里的res即物理内存加起来也就2200M多一点，但是free命令里显示已经用掉了几乎3.4个G，那这1.2G的空头内存去哪了？要知道，free命令会把Slab缓存统计到了used memory里，那就看看slab缓存有多少吧。 yum install -y nmon，使用nmon看一下，如图： 发现里面有几乎650MB的slab内存，这样还是少了大约550MB，那么使用slabtop查看细节，如图： 再用cat /proc/meminfo去查看一下内存详细情况，如图： https://blog.famzah.net/2014/09/22/know-your-linux-memory-usage/ 这里提到内存的计算公式： 1234MemTotal = MemFree + (Buffers + Cached + SwapCached) + AnonPages + (Slab + PageTables + KernelStack)MemTotal = MemFree + (Active + Inactive) + (Slab + PageTables + KernelStack)MemTotal = MemFree + (Buffers + Cached + SwapCached) + AnonPages + ((SReclaimable + SUnreclaim) + PageTables + KernelStack)MemTotal = MemFree + ((“Active(anon)” + “Active(file)”) + (“Inactive(anon)” + “Inactive(file)”)) + ((SReclaimable + SUnreclaim) + PageTables + KernelStack) 虽然作者说他测试的机器内核是3.2的，但是这几个公式对我这个服务器（内核2.6）都可以用，虽然肯定不能严丝合缝但是相差值并不大，我用前两个公式算了一下我这个机器的情况： 12MemTotal（3495620） = MemFree（251396） + Buffers（11456） + Cached（292324） + SwapCached（0） + AnonPages（2302484） + Slab（627068） + PageTables（8972） + KernelStack（1920） MemTotal（3495592） = MemFree（251396） + Active（2450960） + Inactive（155276） + Slab（627068） + PageTables（8972） + KernelStack（1920） 猜测一下我特么的法克，这个memtotal跟3921112差距很远啊！相差了412MB！为什么会少了这么多？会不会这412MB就是那used memory减去slap内存的那部分神秘内存？他为什么没有统计在/proc/meminfo里？ 于是果断给阿里云提工单，截图发锤，让他们给一个完美的解释。 等待阿里云回复的时间里，我又找了几个其他的机器，各种型号的都算了一下，发现一个现象：凡是装了这个模块的服务器都出现了MemTotal不相符的问题，大约误差值都是400M~500M，而除了这个模块，MemTotal的误差值基本就是50M以内。 呃…这好像不能怪阿里云了…不过的确MemTotal是有误差的啊！ 找开发了解了一下，这个服务器里用了大量的tcp长连接，而且是https的，使用netstat -na|grep ESTABLISHED|wc -l一看，有95000个左右。 而在开发环境的机器里查看，MemTotal的相差率很小，而tcp连接数则不到20个。那用排除法可以确定是TCP长连接的锅，于是我猜测TCP长连接占用掉了一部分内存，而这部分内存又没有在meminfo（SLAB）里体现出来，进而导致free命令与top命令相差过大。 小心求证未完待续… 参考资料http://farll.com/2016/10/high-memory-usage-alarm/#comment-9881http://lday.me/2017/09/02/0012_a_memory_leak_detection_procedure/ （虽然跟本文没啥关系，但是强力推荐）http://blog.yufeng.info/archives/2456http://lovestblog.cn/blog/2015/08/21/rssxmx/https://www.mawenbao.com/research/linux-ate-my-memory.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>内存泄漏</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用tqdm制作下载进度条]]></title>
    <url>%2F2018%2F07%2F24%2F%E4%BD%BF%E7%94%A8tqdm%E6%B7%BB%E5%8A%A0%E4%B8%8B%E8%BD%BD%E7%9A%84%E8%BF%9B%E5%BA%A6%E6%9D%A1%2F</url>
    <content type="text"><![CDATA[制作进度条既然接手了国内专有云，就要写一个“自动化部署脚本”。于是我就把整个部署的安装包放到阿里云的bucket，用脚本去wget这个部署包，然后进行脚本部署。但是由于这个安装包比较大，`于是就打算在脚本里添加一个“下载进度条”，这样就能了解到当前的下载情况。 google了一下，就发现了tqdm这个库，它声称比老版的progressbar库的单次响应时间提高了10倍以上，安装的方法很简单：pip install tqdm。 具体的用途和参数可以去看https://lorexxar.cn/2016/07/21/python-tqdm/ 这篇文章。 从tqdm的几个参数可见要使用tqdm做下载进度条首先需要整个文件的大小。整个文件的大小可以用requests.get方法获取，获取到header里就有目标的大小。在使用requests模块下载大文件/数据时，建议使用使用stream模式。如果是stream=False，它会立即开始下载文件并放到内存中，如果文件过大，有可能导致内存不足。然后就是把目标文件拆成一个一个的小块，逐步的写入一个文件，这样达到了下载文件的目的。整个脚本如下： 123456789101112131415161718192021#!/usr/bin/env python# -*- coding: utf-8 -*-import requestsfrom tqdm import tqdmdef downloadFILE(url,name): resp = requests.get(url=url,stream=True) #stream=True的作用是仅让响应头被下载，连接保持打开状态， content_size = int(resp.headers['Content-Length'])/1024 #确定整个安装包的大小 with open(name, "wb") as f: print "安装包整个大小是：",content_size,'k，开始下载...' for data in tqdm(iterable=resp.iter_content(1024),total=content_size,unit='k',desc=name): #调用iter_content，一块一块的遍历要下载的内容，搭配stream=True，此时才开始真正的下载 #iterable：可迭代的进度条 total：总的迭代次数 desc：进度条的前缀 f.write(data) print name + "已经下载完毕！"if __name__ == '__main__': url = "需要下载的文件的地址" name = url.split('/')[-1] #截取整个url最后一段即文件名 downloadFILE(url,name) 注意！下载文件所在的bucket要设置成“公有读”而不能是“私有”。 补充 解压缩的脚本： 12345import zipfilefilename = '要解压包的路径'fz = zipfile.ZipFile(filename, 'r')for file in fz.namelist(): fz.extract(file, path) 这个脚本即使没有unzip命令也可以执行的。 获取本地IP地址的脚本： 12345678def get_local_ip(ifname = 'eth0'): import socket, fcntl, struct s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) inet = fcntl.ioctl(s.fileno(), 0x8915, struct.pack('256s', ifname[:15])) ret = socket.inet_ntoa(inet[20:24]) return retprint get_local_ip() bpython，这是一个好东西，可以在linux环境下实现类似pycharm的提示功能,搭配tab键补全。安装方法就是pip install bpython，然后启动python的时候直接bpython即可。效果如图： 参考资料https://blog.csdn.net/qq_40666028/article/details/79335961http://blog.topspeedsnail.com/archives/9075https://www.168seo.cn/python/24286.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>可视化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将Redhat的yum更换成免费版本]]></title>
    <url>%2F2018%2F07%2F20%2F%E5%B0%86radhat%E7%9A%84yum%E6%9B%B4%E6%8D%A2%E6%88%90%E5%85%8D%E8%B4%B9%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[RedHat替换yum源这次给吉林移动做一个项目，他们的服务器必须要用IE浏览器登陆堡垒机进行环境部署。我登陆上去一看，是redhat，在使用yum的时候会有如下报错： 这句话的意思是“redhat自带的yum源是需要注册才是更新下载软件的，如果必须注册才能使用”，换而言之就是要收费。卧槽，怎么可能，我们向来是“要钱没有，要命一条”。于是就要用CentOS源来替代yum源，而CentOS源是免费的。 首先先删除掉redhat自带的yum：rpm -qa | grep yum | xargs rpm -e --nodeps。 然后用cat /etc/redhat-release命令去查看一下系统版本，我这个机器的版本是Red Hat Enterprise Linux Server release 6.5 (Santiago)，就去http://mirrors.163.com/centos/6/os/x86_64/Packages/ 下载如下几个文件： 123http://mirrors.163.com/centos/6/os/x86_64/Packages/yum-metadata-parser-1.1.2-16.el6.x86_64.rpmhttp://mirrors.163.com/centos/6/os/x86_64/Packages/yum-3.2.29-81.el6.centos.noarch.rpmhttp://mirrors.163.com/centos/6/os/x86_64/Packages/yum-plugin-fastestmirror-1.1.31-45.el7.noarch.rpm 如果想下载centos 7的就去http://mirrors.163.com/centos/7/os/x86_64/Packages/ 这个网站下，文件名字是一样的就是版本号不一样，需要自己找一下。 然后就是安装这几个包： 123456789rpm -ivh yum-metadata-parser-1.1.2-16.el6.x86_64.rpmrpm -ivh yum-3.2.29-81.el6.centos.noarch.rpmrpm -ivh yum-plugin-fastestmirror-1.1.31-45.el7.noarch.rpmcd /etc/yum.repos.d/wget http://mirrors.163.com/.help/CentOS6-Base-163.repo #最好先备份旧文件sed -i 's#$releasever#6#g' ./CentOS6-Base-163.repoyum clean all #清除原有的缓存yum makecache #重建缓存yum update -y #更新系统 大功告成！可以使用免费的yum去装装装了！ 修复Python-urlgrabber版本过低当执行到rpm -ivh yum-3.2.29-81.el6.centos.noarch.rpm这一步的时候，可能会出现一个python的错误： 1Python-urlgrabber &gt;= 3.9.1-10 is needed by yum-3.2.29-73.el6.centos.noarch 要求python-urlgrabber版本必须大于等于3.9.1-10，而用rpm -qa|grep python查看当前的版本是python-urlgrabber-3.9.1-9.el6.noarch，于是就rpm -e python-urlgrabber-3.9.1-9.el6.noarch卸载掉，wget http://mirrors.163.com/centos/6/os/x86_64/Packages/python-urlgrabber-3.9.1-11.el6.noarch.rpm之后，执行rpm -ivh python-urlgrabber-3.9.1-11.el6.noarch.rpm命令安装即可。 安装完毕，再用rpm -ivh --force yum-*安装后面的内容。如图: 无法解析yum源如果在yum makecache的时候出现了http://mirrors.163.com/centos/6/os/x86_64/repodata/repomd.xml: [Errno 14] PYCURL ERROR 6 - &quot;Couldn&#39;t resolve host &#39;mirrors.163.com&#39;&quot;的错误，如图： 就修改一下/etc/resolv.conf，然后在里面添加一句nameserver 8.8.8.8，保存即可。 NOKEY？？？如果出现Header V3 RSA/SHA1 Signature, key ID c105b9de: NOKEY，可以使用如下方法解决： 123cd /etc/pki/rpm-gpg/ wget http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-6 rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>redhat</tag>
        <tag>yum源</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7编码安装php7.2和node.js8.11]]></title>
    <url>%2F2018%2F07%2F17%2Fcentos7%E7%BC%96%E7%A0%81%E5%AE%89%E8%A3%85php7-2-7%2F</url>
    <content type="text"><![CDATA[安装php7.2首先先做准备工作： 123yum install -y libpng libpng-develyum install -y bzip2 bzip2-develyum install -y curl curl-devel 编译安装步骤在此： 12345678910111213141516171819cd /root/wget http://101.96.10.64/cn2.php.net/distributions/php-7.2.7.tar.gztar -zxvf php-7.2.7.tar.gzcd php-7.2.7sudo ./configure /--prefix=/usr/local/php727 / #PHP7安装的根目录--with-config-file-path=/usr/local/php727/etc / #PHP7的配置目录--with-apxs2=/usr/bin/apxs #如果用的是nginx就不要这句话--with-gd / #PHP gd模块--with-bz2 / #包含BZip2支持--with-zlib / #包含ZLIB支持--with-curl / #包含cURL支持--enable-mbstring / #启用多字节字符串支持--enable-zip / #包含Zip读写支持--enable-fpm / #启用PHP-FPM进程管理--enable-mysqlnd / #Enable mysqlnd explicitly--with-mysqli / #包含mysql支持--with-pdo-mysql/ #包含mysql支持make &amp;&amp; make install 如果出现了configure error xml2-config not found. please check your libxml2 installation错误，要执行如下两个： 12yum install libxml2yum install libxml2-devel -y 重新去执行./configure那步和make &amp;&amp; make install，整个编译完成之后，再把原带的php.ini拷贝到源码安装的文件夹里： 1cp /root/php-7.2.7/php.ini-development /usr/local/php727/lib/php.ini 设置环境变量，修改/etc/profile文件使其永久性生效，并对所有系统用户生效，在文件末尾加上如下两行代码： 123PATH=$PATH:/usr/local/php/binexport PATHsource /etc/profile 设置php-fpm开机自动启动 1234chmod +x /etc/init.d/php-fpmchkconfig php-fpm oncp /usr/local/php727/etc/php-fpm.conf.default /usr/local/php727/etc/php-fpm.confservice php-fpm start 安装gcc 8.1.0安装node.js需要先安装gcc，但是这个gcc不能用yum install gcc-c++装，因为centos7的gcc版本太低（4.8.5）不满足，在node.js编译的时候会报错：WARNING: C++ compiler too old, need g++ 4.9.4 or clang++ 3.4.2 (CXX=g++)。所以要去https://ftp.gnu.org/gnu/gcc/ 下载一个高版本的，我选择了目前最牛逼的8.1.0。 12345sudo yum install glibc-headers gcc-c++ #编译软件装上，少很多麻烦wget https://ftp.gnu.org/gnu/gcc/gcc-8.1.0/gcc-8.1.0.tar.gztar -zxvf gcc-8.1.0.tar.gzcd gcc-8.1.0./contrib/download_prerequisites #如果tar (child): lbzip2: Cannot exec: No such file or directory，就yum -y install bzip2 此时进入漫长的等待，一会就会出现如下的字样，代表成功安装了! 此时进行编译安装： 12./configure --enable-checking=release --enable-languages=c,c++ --disable-multilib #执行这一步之前系统是有gcc的，虽然版本很低make &amp;&amp; make install 又要进行漫长的等待…这一次非常非常漫长，我当时几乎用了大约2个小时… 然后使用gcc -v检查一下版本： 安装node.js 8.11先去https://nodejs.org/en/download/ 下载新的版本包: 直接下载到linux里解压缩，如下： 12345wget https://ftp.gnu.org/gnu/gcc/gcc-8.1.0/gcc-8.1.0.tar.gztar zxvf node-v8.11.3.tar.gzcd node-v8.11.3./configure --prefix=/usr/local/node/8.11.3make &amp;&amp; make install 此时在make这一步可能会有这样的错误： 这个原因是“升级gcc时，生成的动态库没有替换老版本gcc动态库”，所以要将gcc最新版本的动态库替换系统中老版本的动态库。 使用find / -name &quot;libstdc++.so*&quot;查找编译gcc时生成的最新动态库，发现最近的动态库是这个： 于是就进行替换并作一个软连接: 123456cp /root/gcc-8.1.0/stage1-x86_64-pc-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6.0.25 /usr/lib64cd /usr/lib64ll libstdc++.so.6lrwxrwxrwx 1 root root 19 Jul 17 09:59 libstdc++.so.6 -&gt; libstdc++.so.6.0.19 #把原来的记住，防止有回滚的现象rm -rf libstdc++.so.6ln -s libstdc++.so.6.0.25 libstdc++.so.6 然后重新返回到node-v8.11.3文件夹里去make就OK了！ 设定环境变量，vim /etc/profile，在export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL一行的上面添加如下内容： 123#set for nodejsexport NODE_HOME=/usr/local/node/8.11.3export PATH=$NODE_HOME/bin:$PATH 保存退出之后，source /etc/profile，再node --version看一下版本是v8.11.3就是OK了！]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>nodejs</tag>
        <tag>gc++</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[世界杯的一些感悟]]></title>
    <url>%2F2018%2F07%2F12%2F%E4%B8%96%E7%95%8C%E6%9D%AF%E7%9A%84%E4%B8%80%E4%BA%9B%E6%96%B0%E6%84%9F%E6%82%9F%2F</url>
    <content type="text"><![CDATA[传控已死？今早英格兰加时赛输给了克罗地亚，至此就剩下一名曼城球员还在本届世界杯继续前进了，那就是法国队的边后卫门迪。再加上之前小组出局的德国和1/8赛输球的西班牙，不得让人怀疑是否“传控已死”？ 传控被瓜迪奥拉发扬光大已经10年了，2008年的西班牙也是靠着传控和巴萨的班底拿下两次欧洲杯和一次世界杯。传控虽然在理论上是一个完美的战术，但是战术也需要人来执行，球员水平有高低状态有起伏，裁判的尺度也不一样，这都会影响传控的比赛结果。这几年的传控逐渐被各路教练针对性研究，他们用“高压迫，快速反击，大巴防守”的套路击败传控的经典战役已经屡见不鲜。所以这几年的传控可谓是磕磕绊绊，风光不再。 传控对中场球员要求很高，一旦球员失去了往前传球的机会，那么就成了无效控球，倒脚来倒脚去时间就走光了。而传统打法对球员的要求相对简单但是对球员身体素质和纪律要求很高，所以更多球队选择了传统打法，而他们也很有针对性的对强队进行了部署，或打高空球或者摆大巴打反击。 我个人通过今年的世界杯和以往的几次欧冠来得到这样的结论：传控没有死，但是传控在杯赛的统治力已经大幅下滑，仅但在联赛和小型杯赛还有一定的优势。原因很简单，联赛是三十多场比赛，容错率要远大于杯赛，这就是传控的好处—虐菜相对来说比较稳。但是最近的足坛趋势是世界杯/欧洲杯/欧冠最大，拿不到上面几个锦标，球员就很难得到金球奖。所以在成绩的压力下，足坛也会慢慢将传控降温，改走传统打法。 即使是442也要有能一脚长传功力的中场做炮台，合适的球员搭配合适的战术才会得到胜利。任何战术本身也要自我修复漏洞，现在的传控队伍也开始慢慢放弃无用的控制，讲究定位球破门和远射破门，但是如何破密集防守还是世界教练共同面对的难题。 决赛怎么看？世界杯决赛肯定是防守为主的低比分比赛。法国那边进攻肯定还是“吉鲁吸引炮火，格里兹曼见缝插针，有反击找姆巴佩，角球任意球上大个子”的常规进攻路线。而克罗地亚也是慢节奏抓定位球的方法。我觉得克罗地亚中场并不虚法国，但是莫德里奇这几年没有跟坎特交手过，可以通过这场决赛看看双方谁更技高一筹。法国这批球员相对年轻，虽然这场比赛他们输不起，但是他们已经有了2016年欧洲杯亚军的惨痛经验，而克罗地亚虽然有些球员没有决赛经验，但是他们心态更放松，比较明显的隐患就是克罗地亚的体能是否能支持他们再一次顶得住法国的炮火。 从2006年至今，三届世界杯都踢了延长赛，所以我个人推荐买常规时间法国赢或者平。 至于季军赛，我觉得凯恩会进球，但是比利时3：2赢下英超内战。 世界杯让足彩也跟着热闹起来。我也跟着潮流买了几场比赛，但是我发现凡是“我跟别人说自己没买的”比赛，结果真中了；凡是我“下注买”的比赛都输了，且不用说德国输墨西哥，日本赢哥伦比亚的冷门战，英格兰打哥伦比亚那场的常规时间最后一分钟，米纳进了一个头球，我直接损失100块… 由此我坚信了，我就不是一个特别有好运气的人，而且也比较害怕成为赌徒，完全符合毛主席对知识分子和小资产阶级的定义，一辈子就是老婆孩子热炕头的命。 中国足球怎么办？每到这种重大足球赛事，国足就要被当作反面典型来说嘴。前几天黄西发了微博调侃遭到国足及相关人士的狂喷，其实喷来喷去，主题就是一个“国足那些球员拿钱多，成绩却这么烂，如何能提高国足成绩？” 其实这个主题是老生常谈，每次都说改革但是也没什么进步，哪怕输给泰国1-5，全国上下一片骂，几天之后涛声依旧… 我个人认为中国足球在20年时间内是不可能强大的，因为这与中国国情有关。 第一，在中国传统教育里，中高阶级就没有那种“把孩子培养成运动员”的想法，毕竟丁俊晖父亲和张玉宁父亲才是少数，更多的父母希望孩子去当医生当公务员做生意，这不仅仅是大陆家庭，香港家庭和台湾家庭也是如此。只有贫苦家庭才会把孩子送去专门搞体育； 第二，为什么中产家庭不希望孩子只是把体育当作兴趣爱好而不是职业？首先现在独生子女太多，家长担心吃苦；其次，搞职业体育是从小开始的，万一踢不出来光阴就白白浪费了，而在发达国家，比如日本，贫富差距没有那么大，而且球员素养相对较高，即使不能大红大紫也不至于饿死，而比如南美部分贫困国家，家里不是独生子女，本来很穷上不起学，踢不出来就继续去搬砖，所以这两种国家的足球成绩不会太烂；再其次，足球青训部分教练素质不高，家长担心孩子跟着学坏； 第三，足球需要青训，而青训需要几代人的时间，但是足协更喜欢速成的方法，这与足球规律相悖，所以搞来搞去钱花了不少却始终原地转圈； 记得“诗人”贺炜在日本与比利时之战之后，发微博羡慕日本足球的同时也说“不多说了，说多了反动”。的确，如果潜规则少一点，贫富差距均衡一点，或许不止是足球，全中国体育的市场化就会有更加显著的改善了。]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>足球</tag>
        <tag>世界杯</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mycat读写分离测试]]></title>
    <url>%2F2018%2F07%2F10%2FMycat%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E7%AE%80%E5%8D%95%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[配置文件解析前文说了schema.xml文件的前两块内容，真正与读写分离有关的是第三块dataHost内容： 123456&lt;dataHost name="mycatTEST" maxCon="1000" minCon="10" balance="3" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host="hostM1" url="rm-bp1099x0552q92edr.mysql.rds.aliyuncs.com:3306" user="mycat" password="这里是密码"&gt; &lt;readHost host="hostS1" url="rr-bp1x35g0w6r767eu4.mysql.rds.aliyuncs.com:3306" user="mycat" password="这里是密码"&gt; &lt;/writeHost&gt; &lt;/dataHost&gt; 这里主要描述的就是逻辑库需要映射的后端真实数据库的情况。某些选项含义如下： maxCon:指定每个读写实例连接池的最大连接。也就是说，标签内嵌套的writeHost、readHost标签都会使用这个属性的值来实例化出连接池的最大连接数; minCon:指定每个读写实例连接池的最小连接，初始化连接池的大小; balance:负载均衡类型，目前的取值有4种： balance=“0”, 所有读操作都发送到当前可用的writeHost上。 balance=“1”，所有读操作都随机的发送到readHost。 balance=“2”，所有读操作都随机的在writeHost、readhost上分发。 balance=”3”，所有读请求随机的分发到wiriterHost对应的readhost执行，writerHost不负担读压力 writeType:负载均衡类型，目前的取值有3种： writeType=“0”, 所有满足规则的写操作轮询的发送到可用的writeHost上。 writeType=“1”，所有满足规则的写操作随机的发送到readHost。 writeType=“2”，所有满足规则的写操作随机的在writeHost、readhost分发。（这一点我很怀疑，写操作怎么在readhost上进行） dbType:指定后端连接的数据库类型，目前支持二进制的mysql协议，还有其他使用JDBC连接的数据库。例如：mongodb、oracle、 spark等; dbDriver:指定连接后端数据库使用的Driver，目前可选的值有native和JDBC，当使用JDBC时则可以这么写：jdbc:mysql://mycatTEST:3306/; switchType:主库切换算法，目前的取值有3种： switchType=”-1”,表示不自动切换 switchType=”1”, 默认值，自动切换 switchType=”2”, 基于MySQL主从同步的状态决定是否切换,心跳语句为show slave status switchType=”3”,基于MySQL galary cluster的切换机制（适合集群）（1.4.1），心跳语句为show status like &#39;wsrep%&#39; heartbeat:这个标签内指明用于和后端数据库进行心跳检查的语句; writeHost &amp; readHost:这两个标签都指定后端数据库的相关配置给mycat，用于实例化后端连接池。唯一不同的是，writeHost指定写实例、readHost指定读实例，组着这些读写实例来满足系统的要求。在一个dataHost内可以定义多个writeHost和readHost(我这里就配了一对，其实可以配很多对)。但是，如果writeHost指定的后端数据库宕机，那么这个writeHost绑定的所有readHost都将不可用。 Demo测试先登陆主库，然后show slave status \G;命令看一下状态，重点是Slave_IO_Running、Slave_SQL_Running和Seconds_Behind_Master这三个字段，如图： 关注这三个字段的原因是“Mycat心跳机制通过检测他们来确定当前主从同步的状态”，如果Seconds_Behind_Master的数值大于slaveThreshold，读写分离筛选器会过滤掉此Slave机器，防止读到很久之前的旧数据，而当主节点宕机后，切换逻辑会检查Slave上的Seconds_Behind_Master是否为0，为0时则表示主从同步，可以安全切换，否则不会切换。 确认完之后，再去log4j2.xml文件把日志级别改成debug。如下： 123456 &lt;Loggers&gt; &lt;asyncRoot level="debug" includeLocation="true"&gt; &lt;AppenderRef ref="Console" /&gt; &lt;AppenderRef ref="RollingFile"/&gt; &lt;/asyncRoot&gt;&lt;/Loggers&gt; 改完之后重启mycat。登陆到8066端口的mycat逻辑库，先创建一个库，再执行一个写的操作： 12345CREATE TABLE `travelrecord` ( `id` int(11) NOT NULL, `name` varchar(255) NOT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert into travelrecord (id,name) values(5000010,'bengbeng'); 在日志一看，发现这条记录已经被写入了dn2这个datanode里，如下： 日志的意思是：逻辑库收到了insert命令，然后与真实库连接成功并且执行同步命令，con need syn ,total syn cmd 1 commands，之后发送查询sql，因为插入的那个数据是5000000，按照auto-sharding-long的规则，只会记录到db2的分片里。执行完后，会释放mycat逻辑库与真实Mysql连接也就是release connection MySQLConnection和release channel MySQLConnection。 再执行一个读的操作，比如SELECT * FROM travelrecord;，日志是这样记录的： 与schema.xml里的readhost字段对比，的确是从hostS1上读取到的，由于balance=”3”，所以只会从读库读取，由于读的操作db1、db2、db3这3个分片都会操作（需要把他们的内容拼接在一起才是完整的内容），于是日志会打印三遍，实验结束。至于其他的更改参数情况，可以去看参考资料里的第二篇文章，说的很详尽了。 参考资料http://valleylord.github.io/post/201601-mycat-log-analysis/http://codingo.xyz/index.php/2018/03/08/mycat2/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>读写分离</tag>
        <tag>数据库中间件</tag>
        <tag>mycat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[博客评论改用来必力]]></title>
    <url>%2F2018%2F07%2F09%2F%E5%8D%9A%E5%AE%A2%E8%AF%84%E8%AE%BA%E6%94%B9%E7%94%A8%E6%9D%A5%E5%BF%85%E5%8A%9B%2F</url>
    <content type="text"><![CDATA[原来我的博客评论用的是hypercomments，但是这几天发现评论已经不能用了，变成了Close discussion，如图： 去https://www.hypercomments.com/en/pricing 发现已经没有免费版了，或者是我这个google邮箱里的免费版hypercomments到期了，于是就琢磨换成来必力吧。 首先先去https://livere.com 注册一个账号，这个来必力是韩国的软件，但是用google翻译就不用怕了，注册很简单，找回密码也很简单。 再去https://livere.com/insight/communite 里选择免费版，然后填写博客的地址和名称，选择个人网站。这个时候会得到一个data-uid，如图： 打开NexT主题的配置文件_config.yml中，搜索livere_uid，将livere_uid前面的#号去掉，将id填写到livere_uid：后面。再找到Hypercomments，把hypercomments_id这一行注释掉即可。]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>hexo</tag>
        <tag>博客搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mycat配置文件解析与分表存储测试]]></title>
    <url>%2F2018%2F07%2F06%2FMycat%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%A7%A3%E6%9E%90%E4%B8%8E%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[前文已经部署了mycat并且启动，此时登陆到mycat的8066端口，可以看到有一个database，这个database里有几个tables，如图： 这些库和表根本不是我数据库里的啊，那它是从哪里来的呢？前文说了，mycat有一个虚拟库（逻辑库），它会把逻辑库上的操作映射到真实库里，现在8066这个端口就是虚拟库，里面有几个逻辑表，但是这些表其实不是真正存在的。而mycat主要有三个配置文件，分别是schema.xml、rule.xml和server.xml，server.xml就是配置虚拟数据库的账号密码的地方，很简单没什么好说的，rule.xml是分片规则的配置文件，没事别动它。而schema.xml里是主要配置逻辑库和逻辑表的配置文件。 配置文件解析去除掉注释的schema.xml文件是这样的： 可以看到整个配置文件分为三大块，第一块是schema，第二块是dataNode，第三块是dataHost，其中第三块是跟读写分离相关的，所以这里就说前两个部分，先说第二块dataNode： 123&lt;dataNode name="dn1" dataHost="mycatTEST" database="db1" /&gt;&lt;dataNode name="dn2" dataHost="mycatTEST" database="db2" /&gt;&lt;dataNode name="dn3" dataHost="mycatTEST" database="db3" /&gt; 这一段表示该数据库有哪些数据节点，以及这些数据节点实际对应的数据服务器（这个节点跟dataHost的块有关）和数据库名，这里配置了3个节点dn1,dn2,dn3，都是在mycatTEST服务器上，也就是说我们需要在mycatTEST那个服务器，也就是下面writeHost的机器里先创建三个database，分别叫db1,db2,db3。我们在逻辑库上的操作都会分别下发到这三个db里，具体的下发算法在上面schema里有写。 再看第一块schema的内容： 12345678910111213&lt;schema name="TESTDB" checkSQLschema="false" sqlMaxLimit="100"&gt; &lt;table name="travelrecord" dataNode="dn1,dn2,dn3" rule="auto-sharding-long" /&gt; &lt;table name="company" primaryKey="ID" type="global" dataNode="dn1,dn2,dn3" /&gt; &lt;table name="goods" primaryKey="ID" type="global" dataNode="dn1,dn2" /&gt; &lt;table name="hotnews" primaryKey="ID" autoIncrement="true" dataNode="dn1,dn2,dn3" rule="mod-long" /&gt; &lt;table name="employee" primaryKey="ID" dataNode="dn1,dn2" rule="sharding-by-intfile" /&gt; &lt;table name="customer" primaryKey="ID" dataNode="dn1,dn2" rule="sharding-by-intfile"&gt; &lt;childTable name="orders" primaryKey="ID" joinKey="customer_id" parentKey="id"&gt; &lt;childTable name="order_items" joinKey="order_id" parentKey="id" /&gt; &lt;/childTable&gt; &lt;childTable name="customer_addr" primaryKey="ID" joinKey="customer_id" parentKey="id" /&gt; &lt;/table&gt;&lt;/schema&gt; 这一段主要描述了虚拟数据库的schema即TESTDB中有哪些表，以及每个表分布在哪些数据节点上、分布的方法采用哪种算法。其他的选项含义如下： checkSQLschema:当该值设置为true时，如果我们执行语句select * from TESTDB.travelrecord;则MyCat会把语句修改为select * from travelrecord;。即把表示schema的字符去掉，避免发送到后端数据库执行时报（ERROR 1146 (42S02): Table ‘testdb.travelrecord’ doesn’t exist）。这里最好是采用默认的false； sqlMaxLimit:当该值设置为某个数值时。每条执行的SQL语句，如果没有加上limit语句，MyCat也会自动的加上所对应的值。例如设置值为100，执行select fromTESTDB.travelrecord;的效果为和执行select from TESTDB.travelrecord limit 100;相同。需要注意的是，如果运行的schema为非拆分库的，那么该属性不会生效。需要手动添加limit语句； primaryKey:该逻辑表对应真实表的主键，例如：分片的规则是使用非主键进行分片的，那么在使用主键查询的时候，就会发送查询语句到所有配置的DN上，如果使用该属性配置真实表的主键； type:该属性定义了逻辑表的类型，目前逻辑表只有“全局表（global）”和”普通表”两种类型； autoIncrement:mysql对非自增长主键，使用last_insert_id()是不会返回结果的，只会返回0。所以，只有定义了自增长主键的表才可以用last_insert_id()返回主键值。使用autoIncrement=“true”指定这个表有使用自增长主键，这样mycat才会不抛出分片键找不到的异常。这里最好是采用默认的false； rule:该属性用于指定逻辑表要使用的规则名字，规则名字在rule.xml中定义，必须与tableRule标签中name属性属性值一一对应； joinKey:插入子表的时候会使用这个列的值查找父表存储的数据节点； parentKey: 属性指定的值一般为与父表建立关联关系的列名。程序首先获取joinkey的值，再通过parentKey属性指定的列名产生查询语句，通过执行该语句得到父表存储在哪个分片上。从而确定子表存储的位置； 举个例子方便理解，&lt;table name=&quot;employee&quot; primaryKey=&quot;ID&quot; dataNode=&quot;dn1,dn2&quot; rule=&quot;sharding-by-intfile&quot; /&gt;，意思就是“这个employee的表，主键是ID，只在dn1和dn2以sharding-by-intfile的规则存储”。 举个例子按照上面修改了配置文件之后，重启一波mycat，登陆mycat的9066管理端口，使用show @@datanode;和show @@datasource;可以查看到数据库源和datanode已经成功建立了，如图： 手动在阿里云的RDS的读库上创建db1、db2、db3这三个databases，如图： 由于阿里云读写同步，所以只读实例上也有了db1、db2、db3这三个databases。 此时再开一个窗口，登陆mycat的8066端口，看到里面有了TESTDB这个逻辑库以及里面的逻辑表，但是这些逻辑表实际是不存在的，如图： 这时创建employee表，插入数据： 12345create table employee (id int not null primary key,name varchar(100),sharding_id int not null);insert into employee(id,name,sharding_id) values(1,'leader us',10000);insert into employee(id,name,sharding_id) values(2, 'me',10010);insert into employee(id,name,sharding_id) values(3, 'mycat',10000);insert into employee(id,name,sharding_id) values(4, 'mydog',10010); 检查一下数据已经被成功插入，并且如果使用select * from查看的话，会从两个datanode上去查，而且都自动加上了limit 100的字样，这一点符合我们在schema.xml里配置的&lt;table name=&quot;employee&quot; primaryKey=&quot;ID&quot; dataNode=&quot;dn1,dn2&quot;/&gt;和sqlMaxLimit=&quot;100&quot;，如图： 再来到阿里云只读RDS数据库里，检查一下刚刚在虚拟数据库里操作的动作是否被正确映射过来。如图: 可见writeType=“0”已经成功，这就是分表存储。 参考资料https://blog.csdn.net/wangshuang1631/article/details/62898469https://sylvanassun.github.io/2016/07/09/2016-07-09-MyCat/http://codingo.xyz/index.php/2018/02/27/mycat1/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>读写分离</tag>
        <tag>数据库中间件</tag>
        <tag>mycat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mycat 1.6.5的部署与启动]]></title>
    <url>%2F2018%2F07%2F05%2FMycat%E7%9A%84%E9%83%A8%E7%BD%B2%E4%B8%8E%E7%AE%80%E5%8D%95%E6%B5%8B%E8%AF%95%2F</url>
    <content type="text"><![CDATA[准备工作先说一下硬件： mycat服务器:阿里云ECS,centos7.4,2核2G1M带宽,外网带宽主要是为了yum安装方便； 数据库主库:阿里云RDS; 数据库读库:阿里云RDS只读实例; 登陆阿里云ECS之后，首先先进行如下操作： 12345678wget http://dl.mycat.io/1.6.5/Mycat-server-1.6.5-release-20180122220033-linux.tar.gz #下载1.6.5版本yum install java-1.8.0-openjdk* -y #安装java 1.8yum install -y mysql #安装mysql客户端useradd mycat #创建mycat用户passwd mycat #更改这个用户的密码tar -zxvf Mycat-server-1.6.5-release-20180122220033-linux.tar.gz -C /usr/local #解压缩/usr/localcd /usr/local/chown -R mycat.mycat /usr/local/mycat/ #设置mycat目录的属主和属组 然后登陆到阿里云RDS读库和写库，看一下大小写是否是“不敏感”,否则可能会发生表找不到的问题，阿里云的RDS默认是不敏感的： 12345678MySQL [(none)]&gt; show global variables like '%lower_case%';+------------------------+-------+| Variable_name | Value |+------------------------+-------+| lower_case_file_system | OFF | #这个是“当前系统文件是否大小写敏感”，只读参数，无法修改| lower_case_table_names | 1 | #这个是“表名是否大小写敏感”，可以修改，改完了重启生效+------------------------+-------+2 rows in set (0.00 sec) Mycat原理和文件结构Mycat的原理跟Atlas查不多，都是用一个虚拟的数据库作为前端，后面是挂上真实的写库和读库。如图： mycat文件夹的文件结构很简单： conf：配置文件； lib：服务依赖的一些jar文件.； logs：日志存储文件夹； bin：可执行命令的地方： mycat的配置文件主要在/usr/local/mycat/conf文件夹里，里面有很多文件，但是主要的配置文件是如下几个： server.xml用来配置虚拟数据库的信息； schema.xml用来配置真实读库写库的信息； rule.xml是分片规则的配置文件，分片规则的具体一些参数信息单独存放为文件；注意！在这个目录下，配置文件修改，需要重启Mycat或者通过9066端口reload才会生效。 首先在打开server.xml，在如下的地方做修改: 123456789&lt;user name="root" defaultAccount="true"&gt; &lt;!-- 这里是给虚拟库设定一个账号叫root，并且作为默认账号 --&gt; &lt;property name="password"&gt;chenx1242&lt;/property&gt; &lt;!-- 账号root的密码 --&gt; &lt;property name="schemas"&gt;TESTDB&lt;/property&gt; &lt;!-- 账号root对应的虚拟库,这个库保持默认比较好 --&gt;&lt;/user&gt;&lt;user name="test"&gt; &lt;!-- 这里是给虚拟库设定一个账号叫test，并且作为默认账号 --&gt; &lt;property name="password"&gt;26e9p69r&lt;/property&gt; &lt;!-- 账号test的密码 --&gt; &lt;property name="schemas"&gt;TESTDB&lt;/property&gt; &lt;!-- 账号test对应的虚拟库,这个库保持默认比较好 --&gt; &lt;property name="readOnly"&gt;true&lt;/property&gt; &lt;!-- 说明这个账号是只读账号 --&gt;&lt;/user&gt; 然后打开schema.xml，编辑如下地方： 12345678910&lt;dataHost name="localhost1" maxCon="1000" minCon="10" balance="0" writeType="0" dbType="mysql" dbDriver="native" switchType="1" slaveThreshold="100"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;!-- can have multi write hosts --&gt; &lt;writeHost host="hostM1" url="阿里云RDS:3306" user="账号" password="对应密码"&gt; &lt;!-- can have multi read hosts --&gt; &lt;readHost host="hostS1" url="阿里云只读RDS:3306" user="账号" password="对应密码"/&gt; &lt;/writeHost&gt; &lt;!-- &lt;writeHost host="hostS2" url="localhost:3316" user="root" password="123456"/&gt; --&gt; &lt;!-- &lt;writeHost host="hostM2" url="localhost:3316" user="root" password="123456"/&gt; --&gt; &lt;/dataHost&gt; 检查好格式并保存之后，就到mycat目录下的/bin/里./mycat start就启动mycat了。启动成功之后，8066和9066都是被监听的，如图： 启动故障排错如果启动mycat失败，可以去logs文件夹里看日志，这里举例几个有代表性的错误： wrapper.log日志：Caused by: io.mycat.config.util.ConfigException: SelfCheck### schema mycat refered by user test is not exist!server.xml里schema最好选择默认的TESTDB，而不是错误里的自己起名的mycat。 wrapper.log日志：org.xml.sax.SAXParseException; lineNumber: 23; columnNumber: 3; The content of elements must consist of well-formed character data or markup去检查一下server.xml的第23行，看一下是不是多了一个’&lt;’或者’&gt;’。 wrapper.log日志：Caused by: io.mycat.config.util.ConfigException: user root duplicated!server.xml里普通账号root，只读账号也叫root，冲突了。 wrapper.log日志：Caused by: org.xml.sax.SAXParseException; lineNumber: 16; columnNumber: 101; Element type &quot;WriteHost&quot; must be declared.schema.xml配置中writeHost写成了WriteHost导致报错。 mycat.log日志如下： 12018-07-06 15:53:22.894 WARN [$_NIOREACTOR-8-RW] (io.mycat.backend.mysql.nio.MySQLConnectionAuthenticator.handle(MySQLConnectionAuthenticator.java:91)) - can't connect to mysql server ,errmsg:Access denied for user '数据库账号'@'本地IP' (using password: YES) MySQLConnection [id=8, lastTime=1530863602566, user=数据库账号, schema=db3, old shema=db3, borrowed=false, fromSlaveDB=false, threadId=4555911, charset=utf8, txIsolation=3, autocommit=true, attachment=null, respHandler=null, host=阿里云写库地址, port=3306, statusSync=null, writeQueue=0, modifiedSQLExecuted=false] schema.xml里把真实库的配置写错了。 mycat.log日志：(io.mycat.net.NIOConnector.finishConnect(NIOConnector.java:155)) - error: java.net.ConnectException: Connection refusedschema.xml的&lt;dataHost&gt;字段是否写入了多余的数据库。 参考资料http://valleylord.github.io/post/201601-mycat-install/https://www.jianshu.com/p/f15d64fcb2f3]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>读写分离</tag>
        <tag>数据库中间件</tag>
        <tag>mycat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[写在阿根廷出局之后]]></title>
    <url>%2F2018%2F07%2F03%2F%E5%86%99%E5%9C%A8%E9%98%BF%E6%A0%B9%E5%BB%B7%E5%87%BA%E5%B1%80%E4%B9%8B%E5%90%8E%2F</url>
    <content type="text"><![CDATA[桑保利的无奈阿根廷在俄罗斯世界杯的征程结束了，3:4输给法国看上去好像不那么糟糕，但是在姆巴佩下半场的2球时间里，阿根廷的后防线的的确确崩溃了。 一天之后的凌晨，俄罗斯靠点球大战送西班牙回家。很多阿根廷的球迷说阿根廷应该效仿俄罗斯，跟法国摆大巴，靠着偷鸡或者点球胜利。 我个人认为，此方法不可取。虽然阿根廷2014年是靠防守进了决赛，但是这支阿根廷老人更老，新人不牛，而且整支队伍缺乏磨合，纪律性也不够。桑保利深知阿根廷无法保持90分钟的高质量大巴，最多三十分钟。而且大巴阵需要一个高点去压迫对方的后卫，比如穆里尼奥的德罗巴、科斯塔、卢卡库，至少也得有一个能跳又壮的C罗在禁区里搅合，但是伊卡尔迪这次没来，所以桑保利无论是防守还是进攻都无法选择大巴。 所以说，“攻出去”是桑保利无奈的选择，至少这样能死的还壮烈一点。当然，桑保利换上法齐奥是一个败笔，但是最根本的原因还是阿根廷人才断档造成的阵容畸形。 梅西的困局梅西在国家队是不是过得不爽？这是必然的。因为他在巴萨得到的支持远大于他在国家队得到的支持，但是这种支持差以肉眼可见的速度缩小。而且阿根廷的媒体对梅西也是比较苛刻，这就吃了没有好公关团队的亏。 让梅西去踢中场是很暴殄天物的行为，但是现在中场式微，梅西不得不去后撤拿球，甚至还要在边路拿球。我曾经说过，梅西后撤拿球就是慢性自杀，首先他不靠近禁区就无法高质量的射门，其次后撤拿球会让对手更多的容错率去包夹他进而消耗他的体力。这样下来不仅场面不好看，梅西的数据更难看，难免被人黑。不过我还是不明白为什么迪巴拉与梅西无法共存，他俩是位置冲突没错，但是梅西可以踢边路，让迪巴拉去踢前腰/影锋，这个从理论上来说是可行的。 反正在俱乐部解决梅西的问题很简单，砸钱买人即可，但是在国家队，估计要费桑保利的脑细胞了（前提是他不下课），所以说足球是和平年代的战争，表面拼的是场上比分，实际拼的是场下准备。 很多球迷反应说梅西在世界杯上没什么笑容，这让我想起来中日甲午战争的时候，中国船上的洋水手回忆说“中国的海员战斗前摩拳擦掌跃跃欲试，但是中国的军官则是一脸忧虑、若有所思”。事实说明，其实军官是更了解敌我实力差距的，梅西也是如此。但是没有办法，他必须要做打一个很难打赢的战争。 梅罗之争可以说这两个人在俄罗斯的表现都是他们各自在俱乐部七层左右的功力（C罗要高一点），但是这两个人都踢飞了点球，而那个点球原本都可以把他们队伍带到下半区去面对较弱对队伍从而提高晋级的概率，可以说国家队过早出局跟他们有直接关系。 梅西在淘汰赛表现还可以但是在0:3输克罗地亚那一场太过失常，但是C罗这一边也是“高开低走”，不过同样四届世界杯，梅西世界杯6球3助攻，C罗是7球1助攻，大家都没有在淘汰赛进球，的确很巧合。 不过皇马三连冠外加葡萄牙拿到了欧洲杯冠军，让C罗的生涯看起来比梅西完美了很多。明年是巴西美洲杯，现在美洲杯的竞争完全不逊于欧洲杯，小马哥离开的阿根廷想夺冠并不乐观，梅西估计注定无法作为领袖为阿根廷带来一个洲际冠军了。 这两个人都是超级射手，而且不可否认的是他们都需要优秀的中场作为火力支持，以前梅西有“哈白布”大杀四方，而C罗现在有了“克卡莫”也逆转了金球奖总数，所以作为球迷，要认识到这一点：现代足球单打一场或许可以，连续独斗五场以上就是天神下凡了。 不过客观的说，除非内马尔等人能拿到世界杯，不然今年的金球奖还是C罗的，梅西和巴萨需要尽快加油，而加油最有效的方法就是补强中场，加强控制。]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>足球</tag>
        <tag>世界杯</tag>
        <tag>阿根廷</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用xshell做代理查看无公网服务器的WEB界面]]></title>
    <url>%2F2018%2F06%2F30%2F%E4%BD%BF%E7%94%A8xshell%E5%81%9A%E4%BB%A3%E7%90%86%E6%9F%A5%E7%9C%8B%E6%97%A0%E5%85%AC%E7%BD%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84WEB%E7%95%8C%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[在工作中经常有一些服务器是高机密的，那么这样的服务器就要与外网隔离。但是没有公网的服务器如果也没有连入到局域网的话，按常理来说是无法打开程序的Web界面。这里则分享一个黑科技—使用xshell做代理然后用浏览器去查看Web界面。 首先要在Xshell顶端菜单栏选择查看—隧道窗格。如图： 此时Xshell的底端就出来一个窗口，然后选择转移规则，如图： 在转移规则右键，选择添加，在添加的窗口里，类型(方向）选择Dynamic(SOCKS4/5)，端口就用默认的1080，备注爱写不写，如图： 来到windows桌面，点击我的电脑—控制面板—Internet选项，打开连接这个标签页，选择下面的局域网设置。如图： 在局域网（LAN）设置里，先在为LAN使用代理服务器前面打勾，然后点击高级，在套接字那里输入127.0.0.1，端口就是刚刚默认的1080，点击确定保存，如图： 此时在浏览器里输入内网的IP地址就能打开这个服务器里Web界面了，比如我公司内部的云存储界面： 不过此时你是完全属于LAN环境，公网是无法访问的。如果要恢复访问公网，那么就要返回到局域网（LAN）设置里，把为LAN使用代理服务器前面的勾点掉就OK。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>xshell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置防盗链]]></title>
    <url>%2F2018%2F06%2F27%2FNginx%E9%85%8D%E7%BD%AE%E9%98%B2%E7%9B%97%E9%93%BE%2F</url>
    <content type="text"><![CDATA[为什么网站们都要限制流量？无论是网站服务器亦或是游戏服务器还是邮件服务器，说穿了也是一台电脑，也有CPU和内存。只不过服务器的CPU功能比个人电脑的CPU功能强大，比如个人电脑的CPU一秒钟能算1亿个数，那么服务器的CPU一秒钟就能算十亿个数。毕竟个人电脑只针对个人，但是服务器是要“接客”的，有了强大的硬件做后盾，网页/游戏/邮箱才不会那么轻易的Down掉。 但是CPU不是人类大脑，人脑是越用越聪明，CPU是越用越磨损，毕竟始终在连电的环境下。于是乎，没有必要的运算能省就省，一个人省一次，十万个人就省十万次，一千万个人就省一千万次，这样达到积少成多的目的。 CPU计算的是各种数据，而这些数据也叫作流量。有用的流量、有价值的流量通过CPU计算无可厚非，但是出现了没有用的流量或者是别人盗用我们的资源，那么这种情况能避免都要避免。什么叫盗用我们的资源，比如自己网站（网站A）上的图片或者视频，被其他人直接复制网站然后粘贴到他们的主页（网站B）上，其他用户登录了B网站，然后点击了那个图片和视频，由于是网址重链接，里外里提供数据的还是我们的服务器。也就是说B网站就是一个中介，而真正提供服务的是网站A，但是广告费和点击率都要网站B赚走了，这事儿实在是叔可忍婶不可忍。 什么是盗链？如何发现被盗链？什么叫盗链，上面已经说的差不多了，如果上面的文字没有看懂的话，举个例子，如果您看到了这两个图片，证明这个网站就是在盗链。 这两个就是一个盗取的是QQ空间的图片，另一个就是百度的图片。用其他网站的图片这事儿本身是无所谓的，只要不涉及版权问题，都希望自己的作品能广泛传播，但是请不要直接通过网址重定向，厚道一点的行为应该是：“图片另存为”，然后到目标网站上去重新上传一下。 这里再多说一点网站的基础知识。 PV值：PV=page view，网站是有少则一个网页多则N多网页组成的一个整体，PV值就是统计用户访问网站的总页数。比如www.JQK.com这个网站，今天有100个用户登录，平均每个用户翻阅了里面5个网页。那么这个网站的PV值就是500。若一个IP地址，对一个页面刷新10000次，PV值也是1.要查询网站的PV值登陆http://www.alexa.cn就行。 Hit值：这个就是对网页里每个元素的点击量，一个网页里的图片就是一个元素，一个flv文件也是一个元素，一首歌曲也是一个元素。这些的总量就是hit值，hit值越高就证明这个网站被人查看的情况越高，那么也证明网站的高人气，那么自然广告也会卖出去很多钱。 因为建网站这事儿关心到了金钱利益，网站越被人关注，自然价值也越大。于是会有一个公式来评判网站的“每日贡献”：总流量=访问流量+下载流量= Page view值 x 页面大小+下载文件大小 x 下载次数。 作为管理者，每天观察一下自己一亩三分地儿的网站数据情况是本职工作。但是有时候也会遇到网站流量很惊人的情况，一般来说，网站流量过大（CPU运转很多）的原因如下： 网站是一个很大的网站：比如说淘宝，京东，网易，youtube，facebook那种大网站，里面成万上亿的网页，而且每天又有那么多人登陆，自然浏览量很大。虽然这些大集团的服务器也是少则几千，多则上万，甚至在不同地区也会有不少的服务器集群，但是这几万台服务器需要提供的数据会很多也是不争的事实。这种现象是正常的。 网页内容太大：可能本身网站是一个小网站，加起来也就十页二十页的内容，但是每一天的流量依旧很惊人，那么很有可能是单页或者某几页的字节太大。比如网页里有太多的图片，太多的视频，太多的其他链接，也有可能是前端码农们给这个网页的规划不合理。导致这个网页每一次被点击都要大费周折（hit值和PV值不高，但是日流量很高），长此以往不仅会耽误用户的整体体验，对服务器也是一个重大伤害。 搜索引擎产生了大量的数据流量：网站需要推广，于是就在各种搜索引擎上打广告，也有自己网站的很多图片用于外部调用。这样的结果就是本身来观摩网站的人很少，但是“借着引擎经过”的人很多，所以就会有PV值不高，但是Hit值和日流量很高的现象出现。 图片或者其他元素被盗链：第一部分就说过了，别人拿我们的图片去吸引别人关注，然后别人想要深入了解，还要来使用我们的服务器去提供详细数据。这种“用我们的牌子住我们的房，吃我们的饭却不给我们钱”的现象实在应该被弄死。这种现象的特征也是PV值不高（没人真正点击网站），但是Hit值和日流量很大（自己服务器的数据都给别的网站提供了）。 网站被DDos攻击了：被一些恶意的IP地址频繁登陆，来回的刷流量。这样迫使CPU做出运算的行为其实就是在远程的破坏服务器的硬件CPU，遇到这种现象，之前Nginx文章里有写，要么通过access.log找到这些IP封掉，要么就在配置文件里加上限制（limit-rate)。 服务器是如何知道图片是从站外而来的呢？在http协议里有一个重要的选项叫refer，这个选项的内容就是该元素的来源地址。如果这个元素是服务器自己提供的，那么头文件里是没有refer这个选项的。通过refer这个信息，我们也可以知道登陆网站的客户是从哪个网站点击链接而来的。这样方便进行一个统计和规划。 假如，我在QQ空间里面发现一个图，然后右键图片，选择在新标签栏里打开图片，这时候通过浏览器审查元素的功能，能查查看请求头信息和响应头信息，发现响应头信息里多了一个refer，里面的内容就是图片的源地址： 我在QQ空间里看腾讯的照片自然是可以的，但是如果我在别的网站里看腾讯的照片，加重了腾讯服务器的负担，自然腾讯公司会不满意。于是腾讯服务器发现当前要引用这个图片的地址与refer头信息不是一个来源之后，就不会把这个图片的数据传送过来，于是就看到那个此图片来自QQ空间，未经准许不可饮用的警告图片。 既然知道了服务器是如何判断文件是否盗链，那么只要伪装一个refer就可以欺骗服务器达到“反防盗链”的目的了。至于这部分，可以自己单独研究。 如何使用Nginx反盗链？同样的使用Nginx.conf，在http的大括号下面，新建一个location，加入如下信息： 12345678910111213141516location ~ .*\.(wma|wmv|asf|mp3|mmf|zip|rar|jpg|gif|png|swf|flv)$ &#123;#指定对以上几种类型的文件建立防盗链 valid_referers none blocked *.alala.com alala.com;#盗链的范围不包括alala.com和alala.com下的二级网站， if($invalid_referer) &#123; #rewrite ^/ http://www.alala.com/error.html; return403;#如果发现有引用以上文件的地址与refer头信息不符的情况，直接重定向成error.html这个网页，服务器返回403，forbidden。 &#125;&#125; 或者使用第三方模块ngx_http_accesskey_module实现Nginx防盗链。实现方法如下： 下载NginxHttpAccessKeyModule模块文件：http://wiki.nginx.org/File:Nginx-accesskey-2.0.3.tar.gz； 解压此文件后，找到nginx-accesskey-2.0.3下的config文件。编辑此文件：替换其中的$HTTP_ACCESSKEY_MODULE为ngx_http_accesskey_module； 用一下参数重新编译nginx：./configure --add-module=Nginx目录/to/nginx-accesskey,然后执行:make &amp;&amp; make install; 修改nginx.conf文件，添加以下几行： 123456location /download &#123; accesskey on; accesskey_hashmethod md5; accesskey_arg &quot;key&quot;; accesskey_signature &quot;mypass$remote_addr&quot;;&#125; 其中：accesskey为模块开关；accesskey_hashmethod为加密方式MD5或者SHA-1；accesskey_arg为url中的关键字参数；accesskey_signature为加密值，此处为mypass和访问IP构成的字符串。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>防盗链</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[给非root开放tcpdump命令权限]]></title>
    <url>%2F2018%2F06%2F22%2F%E7%BB%99%E9%9D%9Eroot%E5%BC%80%E6%94%BEtcpdump%E5%91%BD%E4%BB%A4%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[这周给开发们上了堡垒机，使用的是开源的jumpserver，官网是http://www.jumpserver.org/ 。 注册了账号下发给各位开发之后，开发反馈了一个问题：无法用tcpdump抓包。因为tcpdump默认是只能被root调用的，如果是非root用户使用就会报错：You don&#39;t have permission to capture on that device。 如果要让普通用户也能顺利用上tcpdump，方法很简单，就是对tcpdump这个文件修改成u+s即可。整个过程如下图： 在堡垒机的web界面试一下： 但是jstack这个命令不能按照上面的方法配置给非root用户，因为jstack命令只能是当前java进程的用户才能用。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos6安装git1.9安装过程]]></title>
    <url>%2F2018%2F06%2F13%2FCentos6%E5%AE%89%E8%A3%85git1-9%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[安装过程Centos 6.x用yum安装git的话，默认是1.7.1。它在执行git push的时候会报错:error: The requested URL returned error: 401 Unauthorized while accessing。这种情况升级git可破。 具体的升级方法如下： 123456789yum install -y curl-devel expat-devel gettext-devel openssl-devel zlib-devel perl-devel #先准备一下环境cd /rootwget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/git-core/git-1.9.0.tar.gz #下载1.9的包tar -zvxf git-1.9.0.tar.gzcd git-1.9.0make prefix=/usr/local/git all #安装到/usr/local里make prefix=/usr/local/git installln -s /usr/local/git/bin/* /usr/bin/ #建立软连接git --version 常用命令随便列举几个常用命令： 123456789git remote add origin http://xxxxxxx #将后面那个网址作为remote的源站git remote rm origin #将刚刚建立的那个源站删了 git pull origin master #把remote的master分支的内容down到本地git reset --hard HEAD #撤销未提交的文件git fetch -p #更新最新的远程分支，如果远程分支已删除，则删除本地对应标记的远程分支git branch -a #查看所有分支git checkout -b feature/test origin/feature/test #在本地新增对应的远程分支并切换到 新增的分支上git branch -D feature/test #删除本地feature/test分支 这个命令慎用，生产环境后期一般留个4,5个版本的release开头的分支,可以通过此命令删除一些早期版本的分支git branch checkout feature/test #通过此命令可以来回切换本地分支，当存在线上代码需要回滚的时候，可以进行次命令切换到之前的release分支 配置忽视文件每一个项目肯定都会有一些不会变的文件，比如日志等，那么这种“不想要加入版本库”的文件就要做一个忽视，这样每一次push或者pull都回节约一点时间。 要对这种“被忽视”文件进行配置，首先要先在git的文件夹里打开.gitignore，把要忽视的文件或者文件夹路径写进去，注意，这里的根目录是git文件夹而不是传统的根目录。然后git add .gitignore，此时git commit -m &#39;添加忽视文件&#39;和git push给远程gitlab提交一个版本，然后到目标文件夹去，git rm -r --cached 要忽视的文件名，然后git status看一下这个文件是否已经被gitlab上删除了，如果真的删除掉了同时本地文件也没有丢失，就可以再一次的git commit + git push，去gitlab网页检查时候这个文件应该就不会出现在网页里了，以后这个文件也不会参与任何的更改。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins搭配ansible部署]]></title>
    <url>%2F2018%2F06%2F12%2FJenkins%E6%90%AD%E9%85%8Dansible%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[架构流程现在运维组工具里加入了gitlab这个版本控制工具，再加上原有的jenkins和ansible，整个代码模块部署流程如下：1.在代码服务器上push更改的代码到gitlab；2.gitlab通过webhook推送事件到jenkins,触发构建任务；3.jenkins从gitlab将最新代码拉取下来；4.jenkins通过ansible将最新的代码部署到应用服务器；5.推送构建状态到gitlab； 安装ansiblejenkins虽然支持ansible，但是前提是jenkins所在的主机上要有ansible程序，安装ansible的方法如下： 123pip install --upgrade pippip install paramiko PyYAML Jinja2 httplib2 sixpip install ansible #安装的是2.5.4版本 然后需要jenkins服务器与代码服务器之间建立ssh免密码登陆的关系，这里就不说细节了，可以去看一下http://blog.51cto.com/chenx1242/1763978 这个文章。 再去/etc/ansible/hosts手动输入一下授信服务器的IP地址，启动一下ansible看效果： 如果在启动ansible的时候出现了如下的错误： 12/usr/lib/python2.7/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.21.1) or chardet (2.2.1) doesn&apos;t match a supported version! RequestsDependencyWarning) 那就是python库中urllib3 (1.21.1) or chardet (2.2.1)的版本不兼容，解决办法如下： 123pip uninstall urllib3pip uninstall chardetpip install requests 安装插件登陆jenkins的web页面，选择系统管理—&gt;管理插件，安装如下三个插件：Ansible plugin、Ansible Tower Plugin、AnsiColor。如图： 安装插件并且重启了ansible之后，还是系统管理-–&gt;全局工具配置，找到ansible安装，分别把ansible的路径根据实际情况填写进去，如图： 填写完毕之后保存即可。 配置工程打开某一个project，就用之前在https://rorschachchan.github.io/2018/05/25/Gitlab-Jenkins搭建持续集成系统/ 这个文章里用到的jicheng-test，因为它已经跟gitlab集成了，所以只要gitlab有commit变化，就会webhook到jenkins进行操作。 配置jicheng-test，选择构建这个标签页。在增加构建步骤选择Invoke Ansible Ad-Hoc Command，这里我为了做实验随便写了一点命令，如图： 上面的配置就是先让jenkins输出这个是来自jenkins机器的信息！！，然后启动ansible，对/etc/ansible/hosts里的所有ip机器执行hostname和cd /mnt ; echo &quot;我是你大爷！&quot; &gt;&gt; 321.txt这两个命令。 测试结果前文说了，这个jicheng-test已经做了gitlab+jenkins的配置，所以只要在代码服务器的git文件夹里，执行commit，代码被push到gitlab服务器上的同时也会触发jenkins打包。 于是操作如图： 在gitlab的网页端查看代码已经上传： 再去jenkins里确认是否被成功触发了： 这次操作显示蓝灯，就是OK，点击选择控制台输出，查看一下执行细节： 效果达到！试验成功！ 如果需要回滚，就在jenkins新建一个与gitlab相连的project，切换gitlab的分支，然后重新commit，触发jenkins打包并且ansible部署即可。 故障排错可能在jenkins集成的时候出现如下错误: 12345 代码服务器ip | UNREACHABLE! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;Failed to connect to the host via ssh: Host key verification failed.\r\n&quot;, &quot;unreachable&quot;: true&#125; 这是因为jenkins在执行ansible是通过jenkins用户去操作的，虽然我们在安装ansible那一步的时候已经构建了服务器之间的ssh关系，但是那只是root用户的，所以如果没配置jenkins用户的ssh免密码登录，那么sudo su -s /bin/bash jenkins切换到jenkins用户在ssh jenkins@目标IP这一步的时候，会出现如下的提示： 1234The authenticity of host &apos;目标IP(目标IP)&apos; can&apos;t be established.ECDSA key fingerprint is SHA256:Nerx/EZH+ul0/qeb21+ii5EctQ0mO8hijIDlAWEGje8.ECDSA key fingerprint is MD5:6e:d8:6d:17:ca:79:9c:5e:bc:7e:9e:e6:33:41:08:25.Are you sure you want to continue connecting (yes/no)? 因为ansible不会主动帮你输入yes，所以还需要在jenkins用户下把id_dsa.pub文件添加到代码服务器的authorized_keys里，制作一个ssh免密码登录。如果这时候你手动执行一下ssh jenkins@目标IP并且输入yes之后，再重新构建这个project就会发现错误变样了： 12345 代码服务器ip | UNREACHABLE! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\r\n&quot;, &quot;unreachable&quot;: true&#125; 原因还是上面的话，由于目标机器上是没有jenkins这个用户的，所以自然也不会存在登录密码，即使用了jenkins用户制作了authorized_keys也是没用，所以需要指定ssh到目标IP的用户，如果是ansible的命令就是ansible all -i /etc/ansible/hosts -u root -m shell -a &quot;具体的shell命令&quot;，但是jenkins里配置root的地方很难找，所以就可以在/etc/ansible/hosts里更改一下，改成如下的样子： 1目标ip地址 ansible_ssh_user=root #指定用root用户登录到目标IP， 这样执行命令就没有障碍了，不过root用户权限过大，实际生产环境还是建立一个更加保险的账号最佳。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>jenkins</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云centos7升级内核到4.17过程]]></title>
    <url>%2F2018%2F06%2F11%2F%E9%98%BF%E9%87%8C%E4%BA%91centos7%E5%8D%87%E7%BA%A7%E5%86%85%E6%A0%B8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[docker对内核的支持要求很高，详情可以看：https://www.szyhf.org/2017/01/07/%E9%98%BF%E9%87%8C%E4%BA%91%E4%B8%8Ecentos%E5%86%85%E6%A0%B8%E9%97%AE%E9%A2%98/#comment-54 。文中也有阿里云容器的工程师亲自回复的升级内核的方法，不过他那套是升级内核到4.4，现在已经是4.17了，这里写一下如何升级到最新内核的过程。 而阿里云默认的centos7的内核是3.10的，如图： 首先，安装elrepo的yum源，命令如下： 1234567[root@iZ23pg8sy5bZ ~]#rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org[root@iZ23pg8sy5bZ ~]#rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm Retrieving http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpmRetrieving http://elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpmPreparing... ################################# [100%]Updating / installing... 1:elrepo-release-7.0-3.el7.elrepo ################################# [100%] 其次是安装最新的内核，命令是yum -y --enablerepo=elrepo-kernel install kernel-ml，如果是要安装长期支持的内核，命令是yum –enablerepo=elrepo-kernel -y install kernel-lt，在一顿噼里啪啦之后，就会出现如下的字样，提示我们已经安装了4.17的kernel内核了： 123456789101112Downloading packages:kernel-ml-4.17.0-1.el7.elrepo.x86_64.rpm | 45 MB 00:00:03 Running transaction checkRunning transaction testTransaction test succeededRunning transactionWarning: RPMDB altered outside of yum. Installing : kernel-ml-4.17.0-1.el7.elrepo.x86_64 1/1 Verifying : kernel-ml-4.17.0-1.el7.elrepo.x86_64 1/1 Installed: kernel-ml.x86_64 0:4.17.0-1.el7.elrepo Complete! centos7内核升级完毕后，还需要我们修改内核的启动顺序，vim /etc/default/grub，修改一处地方： 12345678GRUB_TIMEOUT=5GRUB_DISTRIBUTOR=&quot;$(sed &apos;s, release .*$,,g&apos; /etc/system-release)&quot;GRUB_DEFAULT=saved #把这里的saved改成0GRUB_DISABLE_SUBMENU=trueGRUB_TERMINAL_OUTPUT=&quot;console&quot;GRUB_CMDLINE_LINUX=&quot;crashkernel=auto rhgb quiet net.ifnames=0&quot;GRUB_DISABLE_RECOVERY=&quot;true&quot;~ 接下来还需要运行grub2-mkconfig命令来重新创建内核配置，命令是grub2-mkconfig -o /boot/grub2/grub.cfg，如下： 12345678910Generating grub configuration file ...Found linux image: /boot/vmlinuz-4.17.0-1.el7.elrepo.x86_64Found initrd image: /boot/initramfs-4.17.0-1.el7.elrepo.x86_64.imgFound linux image: /boot/vmlinuz-3.10.0-693.2.2.el7.x86_64Found initrd image: /boot/initramfs-3.10.0-693.2.2.el7.x86_64.imgFound linux image: /boot/vmlinuz-3.10.0-693.el7.x86_64Found initrd image: /boot/initramfs-3.10.0-693.el7.x86_64.imgFound linux image: /boot/vmlinuz-0-rescue-f0f31005fb5a436d88e3c6cbf54e25aaFound initrd image: /boot/initramfs-0-rescue-f0f31005fb5a436d88e3c6cbf54e25aa.imgdone 执行完毕之后，回到阿里云控制台重启一下这个机器，然后查看一下内核情况： 12uname -r4.17.0-1.el7.elrepo.x86_64]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>内核</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Grafana配置smtp邮件]]></title>
    <url>%2F2018%2F06%2F06%2FGrafana%E9%85%8D%E7%BD%AEsmtp%E9%82%AE%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[配置smtp如果要通过grafana接收告警邮件，都需要配置邮箱。而相关配置文件就是grafana.ini，分别要修改如下几个地方： 1234567891011121314151617181920#################################### SMTP / Emailing ##########################[smtp]enabled = truehost = smtp.163.com:465user = 邮箱前缀@163.com# If the password contains # or ; you have to wrap it with trippel quotes. Ex """#password;"""password = 客户端授权密码;cert_file =;key_file =skip_verify = truefrom_address = 邮箱前缀@163.comfrom_name = Grafana # EHLO identity in SMTP dialog (defaults to instance_name);ehlo_identity = dashboard.example.com#################################### Alerting ############################[alerting]# Disable alerting engine &amp; UI features;enabled = true# Makes it possible to turn off alert rule execution but alerting UI is visibleexecute_alerts = true 我采用了网易邮箱，把文件保存退出之后，重启一下grafana-server。然后在页面的alatm页面里配置Notification channels，如图： 如果发送不成功，去查看一下日志，日志地址是/var/log/grafana/grafana.log。如果发送成功了，那么邮箱会收到这样的一个邮件： 邮箱密码问题问题这里要注意几个问题！ 阿里云的服务器出于安全考虑默认是不会开放25端口的，如果你非要用阿里云的服务器去打开25端口，请移步https://www.alibabacloud.com/help/zh/doc-detail/56130.htm ； 如果不想麻烦阿里云那么就要使用其他端口，比如我配置文件里面写的加密的465端口，这个端口不能使用登陆邮箱的普通密码，而是需要填写“授权码”； 以网易邮箱为例，首先先要打开POP3/SMTP服务，如图： 其次然后在客户端授权密码里设置一个新的密码，如图： 然后把这个授权码填写到grafana.ini里，填邮箱的登录密码是错误的。 参考资料http://www.kubiops.com/blog/2017/02/27/Grafana%E5%91%8A%E8%AD%A6%E9%85%8D%E7%BD%AE.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>grafana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab给分支设定权限]]></title>
    <url>%2F2018%2F06%2F06%2FGitlab%E7%BB%99%E5%88%86%E6%94%AF%E8%AE%BE%E5%AE%9A%E6%9D%83%E9%99%90%2F</url>
    <content type="text"><![CDATA[给gitlab的各位开发设置权限是很重要的，不然他们就可能会偷偷的把执行分支合并甚至git pull来破坏线上环境。 首先先确定在project下各位人员的身份，在设置（setting）–成员(members)里面，可以看到projects现有的用户和用户组，如图： 由于我这个gitlab已经是汉化版的了，这里做一个简单的中英对比：Master是“主程序员”、Developer是“开发人员”、Reporter是“报告者”，这个身份只有读权限可以创建代码片段，一般来说都给测试人员，而Guest就是“访客”了，它只能提交问题和评论。 然后再到版本库（Repository）里选择保护分支（Protected Branches），如图： Allowed to merge就是分支合并权限，Allowed to push就是推送权限，这两个可以根据不同人的身份进行控制。如果受保护，除了master权限的人员，其余人都不可以push、delete等操作。默认情况下master分支是处于被保护状态下的，developer角色的人是无法提交到master分支的。 如果是docker的话，那么gitlab权限问题修复会用到如下命令： 12docker exec -it gitlab update-permissionsdocker restart gitlab容器的ID]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Waiting(TTFB)过长的问题]]></title>
    <url>%2F2018%2F06%2F04%2F%E8%A7%A3%E5%86%B3Waiting-TTFB-%E8%BF%87%E9%95%BF%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[正文电商平台整套系统是从上海商派公司（ecshop）那里购买的整套代码，结合我们公司自己的二开功能的3.0版本在上周几经波折终於部署上去了，经过了一个周末之后，今天市场运营的人在微信群里叫：“官方网站打开速度好慢。”果然整个官网首页要5~6秒钟才打得开，这个显然是不能忍受的，使用F12查看细节，发现Waiting(TTFB)的时间非常长，如图： 正常来说TFFB时间通常建议在200ms以下，如果超过推荐值，会引起队列中其他资源下载都跟着变慢。TFFB高主要有两个原因：一是客户端和服务器之前网络情况比较差；二是服务器应用响应比较慢；第三：重定向太多，重定向跟TFFB时间成正比。 于是乎检查网络情况以及各应用负载情况，都是OK的，重定向也很少。那么就减少DNS查询，把所有能用IP的地方都替换了域名，比如nginx的localhost里使用对应服务器的域名而不是127.0.0.1，比如在配置文件里的阿里云的数据库和redis都用IP地址替代。然而收效甚微，该慢依旧是慢。 这个时候就返回到后台去查看，左翻翻右翻翻，最后找到了这个地方，如图： 启动全页缓存，一切就都好了… 补充故障前端妹子跑来问一个问题，界面上一个1.1k的js文件，为什么加载用248ms？如图： 可见大量时间都用在了Content Download上，但是这个文件明明已经很小了。况且旁边还有150K左右的文件也用了不到80ms，可见应该不全是网络传输慢那么简单。 看了一下这个js的细节，发现这个js需要去访问阿里云的OSS资源。如图： 是不是时间花费在访问资源上了呢，于是我单独访问一下这个png图片，发现单独访问的时间根本不长： 这个js已经没有压缩的余地了，那么究竟是什么这么消耗时间？这个我要慢慢查，先把问题记录一下… 参考资料https://www.oschina.net/question/244077_221319]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Centos7安装zabbix3.4全过程]]></title>
    <url>%2F2018%2F06%2F04%2FCentos7%E5%AE%89%E8%A3%85zabbix3-4%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[安装zabbix-server 3.4本文以centos 7为例。 123456789101112131415161718systemctl stop firewalld.service #关闭防火墙systemctl disable firewalld.service #开机不启动防火墙setenforce 0 #清空selinux的配置 yum install mariadb-server mariadb –ysystemctl enable mariadb #设置开机启动systemctl start mariadb #启动MariaDBrpm -Uvh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-agent-3.4.5-1.el7.x86_64.rpmyum install zabbix-server-mysql zabbix-web-mysql -yzcat /usr/share/doc/zabbix-server-mysql-3.4.9/create.sql.gz |mysql -uzabbix -pzabbix zabbix #这里是设定zabbix数据库账号密码和database的地方，create.sql.gz这个文件位置要根据实际情况来vim /etc/httpd/conf.d/zabbix.conf #这里要修改文件里的时区，改成Asia/Shanghaisystemctl start zabbix-serversystemctl enable zabbix-server setsebool -P httpd_can_connect_zabbix onsetsebool -P httpd_can_cetwork_connect_db onsystemctl start httpd systemctl enable httpdchkconfig zabbix_agent onsystemctl start zabbix-agent 然后就是在浏览器输入外网IP/zabbix/进行页面安装了，剩下的就不多写了。 如果打开WEB网页是如下的样子： 请检查php-fpm的版本。 安装zabbix-agent 3.4如果是centos 6: 123rpm -Uvh http://repo.zabbix.com/zabbix/3.4/rhel/6/x86_64/zabbix-release-3.4-1.el6.noarch.rpmyum install -y zabbix-agentchkconfig zabbix-agent on;service zabbix-agent start #如果不对就使使zabbix_agent 如果是centos 7: 123rpm -Uvh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-agent-3.4.5-1.el7.x86_64.rpmyum install -y zabbix-agentchkconfig zabbix-agent on;service zabbix-agent start #如果不对就使使zabbix_agent 安装Graphtree虽然官方说Graphtree只维护到3.2版本，但是经过我测试3.4依旧可用。安装方法如下： 12345首先进入到zabbix的html页面的文件夹yum install patch -ywget https://raw.githubusercontent.com/OneOaaS/graphtrees/master/graphtree3.0.4.patchpatch -Np0 &lt;graphtree3.0.4.patchchown -R apache.apache oneoaas #如果是nginx，那就是www.www 刷新一下zabbix-server即可发现Monitoring下面多了一个Graphtree，如图： 点击即可查看。 其他资料https://www.kaijia.me/2014/11/zabbix-report-lack-of-free-swap-space-issue-on-server-without-swap-solved/https://blog.csdn.net/sinat_15955423/article/details/76685878 (centos6.x安装php5.6+gd库+bcmath库)https://www.sundayle.com/zabbix-monitor/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次阿里云负载均衡端口监听不正确的过程]]></title>
    <url>%2F2018%2F05%2F31%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E9%98%BF%E9%87%8C%E4%BA%91%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E7%AB%AF%E5%8F%A3%E7%9B%91%E5%90%AC%E4%B8%8D%E6%AD%A3%E7%A1%AE%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[在阿里云上新配置了一个负载均衡，后面挂载的服务器上安装了一个nginx，分别开启了80端口和8080端口，其中80端口是给http访问的，8080端口是给https访问的，同时在8080端口上做了http跳转https的配置。 但是在负载均衡配置完毕之后，发现tcp的80转8080是OK的，但是https的443转80却始终不OK，网页也自然打不开，但是在nginx上看80端口的确是在stand by： 而且安全组都做了配置，telnet端口也是完全没有问题的，如图： 执行了一下time curl -I -X HEAD SLB的域名 -x http://本机IP地址:80看一下效果，如图： 可见命令执行OK，但是耗时需要7秒，而默认的阿里云SLB在https监听的超时时间设定是5秒，怀疑是后端ECS上对head头响应慢导致的健康检查失败。然后在网页上使用“检查”功能，发现有几个js、css文件耗时很长，于是就叫前端的码农们配合查一下，在几位前端吭哧吭哧解决了这个问题之后，https访问恢复正常。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[苹果手机无信用卡注册区美国apple store的办法]]></title>
    <url>%2F2018%2F05%2F30%2F%E8%8B%B9%E6%9E%9C%E6%89%8B%E6%9C%BA%E6%97%A0%E4%BF%A1%E7%94%A8%E5%8D%A1%E6%B3%A8%E5%86%8C%E5%8C%BA%E7%BE%8E%E5%9B%BDapple-store%E7%9A%84%E5%8A%9E%E6%B3%95%2F</url>
    <content type="text"><![CDATA[这次去霓虹国在心斋桥Apple体验店买了一个256G的iphone X，由于政府政策的原因，中国区的apple store有很多应用是没有的，于是乎我就打算注册一个美国版的账号，从而登录美国版的apple store去下载那些“你懂得”的app。 首先先登录https://www.apple.com/ ，在网页最下面先确定国家是United States，然后点击Manage Your Apple ID，如图： 在https://appleid.apple.com/#!&amp;page=signin页面里，点击Create your Apple ID建立一个新的apple账号，名称正常写，国家还是United States不要动，生日如实填写，但是如果是未成年人的话，有些成人的app是不可以被下载的。然后就是写好自己的登陆问题，这个问题已经要记住，每次登陆都要输入，忘记的话就麻烦了。注册账号这里其他部分我就不多说了。 账号注册完毕之后，就直接在苹果网站上登录，登录之后，就会看到账号的详细信息，在Payment &amp; Shipping的地方点击Add Payment Method…，如图： 这里有一个PAYMENT METHOD的地方，要填写none，如果你用apple手机上登录这个账号的话，这里是不能选none的，无论是Dr.还是Mr.都没有none这个选项，所以说一定要在网页登录账号。然后就是需要你填写一些用户地址、邮编等信息，由于是账号注册时候选择的是美国，那么也需要填写美国的地址，可以在http://www.haoweichi.com/Index/random里生成一个身份信息填写。如图： 下面那个SHIPPING ADDRESS就是账单邮寄的地址，想填就填，不想填就放那。填写好了之后点击save，但是目前这个账号还是不能通过的，如果你在apple手机登录了这个账号然后登录apple store的话，会有一个提示：该账号没有被使用过，请填写细节。 这里如果你还手机上操作填写细节，发现你刚刚在电脑上填写的地址和邮编已经同步到手机的账号了，但是支付卡那一栏还是没有none，也就是说依旧要一个信用卡。此时请在电脑上下载itunes，然后在电脑的itunes里登录这个美国区账号，由于电脑itunes里的支付渠道依旧可以选择none，所以我们可以在这里绕一个弯，使用itunes这个渠道来完成这个美国区账号的彻底注册。 在itunes把整个账号完整过程都注册完毕之后，再登录到手机端，就可以在美国的apple store里尽情的下载app了！]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>apple</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[超赞的京都大阪五日游]]></title>
    <url>%2F2018%2F05%2F25%2F%E8%B6%85%E8%B5%9E%E7%9A%84%E4%BA%AC%E9%83%BD%E5%A4%A7%E9%98%AA%E4%BA%94%E6%97%A5%E6%B8%B8%2F</url>
    <content type="text"><![CDATA[说来惭愧，活了30年了这是我第一次出国旅行，借着公司有一次旅游的机会就跟女朋友一起到京都和大阪玩5天。 搞定了签证，在网上买好了USJ的快速通行票，又预定了随身WIFI，简单在穷游、知乎和马蜂窝上做了做自由行的攻略，18号晚上6点半从杭州萧山机场出发，两个小时后到达关西机场。之前在《miss pilot》里看到过ANA的航空，这一次亲自乘坐感觉还是不错，飞机场有吃有玩还有葡萄酒喝。 到关西机场之后，又按指纹又照相的通过了一连串的海关检查，就跟公司其他小伙伴兵分两路，他们去奈良看鹿，我跟女票直接去京都。凭借女票的三脚猫日语功力和她以前来过大阪的经验，我俩先办理了地铁卡，又购买了一日游行卡，最后坐上了从大阪出发到京都的新干线。 从大阪到京都大约花了一个半小时左右，抵达京都已经是晚上11点了。路上下着细细小雨，再加上两人拖着箱子有点肚饿，就在路边的seven-eleven里简单买了一点水和东西，买东西之余发现在超市里有成人书籍出售。从便利店出来顺着google地图找之前在爱彼迎上预订的民宿，那是一个公寓型民宿，凭借店主之前在邮件里写的密码，我们从信箱里拿到房间钥匙，顺利入住。 日本的庙京都是一个充满寺庙和神社的地方，京都的旅行也就是“从这个庙出来，到下一个庙去”，而清水寺正是京都众多庙里人气很旺的景点之一，日本的庙和神社有一个习惯，入寺前先用竹勺洗手，如果要入室参拜的话还要脱鞋。在京都穿和服是一个很常见的事情，而且我觉得一群人穿和服是一个蛮cool的风景，不过女票没有租，但是在寺里买了很多的御守。 昨晚到京都太晚，无法注意天空，到了白天才发现京都的天真的很蓝，看见远方的山轻而易举。从清水寺出来下一站是八坂神社，巧的是遇到了一对新婚夫妇在这里结婚拍照，不得不说日本新郎传统的黑和服加扇子的形象还是很帅的。 日本的玩水族馆是我非常喜欢的地方，而大阪海游馆也是这次游玩里安排的重要环节之一，但是比较让我失望的是它的海底隧道很短，大约也就杭州水族馆的一半长度。我俩没有看到喂食节目，而且海游馆也没有海豹顶球，海豚跳舞这样的节目。不过海游馆的鱼种类还是很多的，有些品种还可以亲手去摸一摸它们。出了海游馆就是一个蛮大的摩天轮，用一日通票的话可以免费上去坐一圈。 大阪的USJ是我们这次日本之行的最后一站也是最高潮的部分，去年圣诞节我跟女票在上海的迪士尼度过的。从迪士尼回来她就一直碎碎念大阪的环球影城，我俩还特意挑选了一个工作日去玩就是为了尽可能的少排队，但是那天依旧很多很多人，真的超火爆。 环球影城的运营模式跟迪士尼差不多，通过IP分主题区，可以购物也有花车游行。但是整个乐园的玩法相对单一—-都是过山车：哈利波特是过山车、蜘蛛侠是过山车、小黄人是原地晃晃过山车、侏罗纪公园是水上过山车，至于翼龙飞行和好莱坞美梦更是超刺激的过山车… 这一次环球影城的特殊项目有四个：怪物猎人、美少女战士（看动画片）、柯南（密室逃脱）和最终幻想。我跟女票还有公司同事都选择了柯南，虽然通篇日语对白，不过还是能猜出来一个大概剧情，所以一个半小时玩下来感觉就像看了一遍柯南的剧场版，里面的解密就不剧透了，机关真的很难，想要在一个小时内完全逃脱几乎是一个不可能的任务。 上面把正经的娱乐说完了，下面来说一点不正经的娱乐。我和女票在大阪住在日本桥地铁站附近，那里距离道顿堀走路也就10分钟的路程，而道顿堀附近有一个街叫宗右卫门町，那里就是大阪有名的牛郎街，一路走过去各种牛郎宣传大海报和在路边搭讪的小哥，甚至那附近的小吃店里还有牛郎哥的宣传单。除了铺天盖地的牛郎哥哥外还有站街的妹妹，大多数都是黄发浓妆，但是仔细看脸都不算太好看的。这些人会跟过往的单身男女搭讪，邀请他们去店里坐坐喝点酒说说话，至于有没有更进一步的皮肉关系，那就不好说了。而且据说他们是不做不懂日语人的生意的，所以如果他们真的纠缠你了，就直接说我是外国人就好。 日本的购物到了日本，买东西是必然的。不过当地的大商场关门很早，基本晚上八点半左右就开始关门。在伏见稻荷大社甚至有的商铺五点半就打烊了，我很好奇，商场这么早关门，那日本人晚上的娱乐是什么呢？他们除了去居酒屋喝酒和广场溜达再加上回家看电视难道就没有其他的娱乐了吗？ 不过，各大药妆店的营业时间很晚，甚至唐吉坷德是24小时营业。这种地方里充满了大陆人、香港人、台湾人、韩国人还有泰国人，在人群和背包中穿梭，拎着篮子买买买，买到5000就可以退税。我女票这次买了很多的卸妆水乳液面膜眼霜口红还有零食，作为一个在旁边无事可做的男人，深深地觉得陪女人逛街是一个很遭罪的事情。 日本的吃我是看过《深夜食堂》和《孤独的美食家》的，所以对日本的食物有一点好感，而且在杭州吃到日本料理也不是一个难事。不过这次到了日本，连续吃了五天当地的饭，发现日本的菜其实很单一。 日本普通的餐就是“米饭+猪肉\牛肉\鸡肉+沙拉+味增汤”，日本的米饭是很好吃的，但是他们的肉做法基本就是炸，炒是很少的。如果不是米饭的话就是炒面、拉面、寿司或者是煎饺。期间我跟女票吃了一次烤肉，里面有“最强牛里脊和牛肠”给我留下了很深的印象。此外在海游馆还吃到了我梦寐已久的大阪烧，插播一句话，吃大阪烧的时候还看到足球运动员郑大世，我女票一眼就认出他来了… 日本的消费能力不低，五天下来，基本上每一顿饭都大约花费了3000多日元，在吉野家吃算比较便宜的，2000不到就能搞定。在烤肉店要了套餐，每人是5000日元。这次在日本，觉得最好吃的是牛里脊，然后就是烤蟹壳。 说完了吃再说说喝，大阪和京都随处可见自动售卖机，售卖机里面基本就是五样饮品—水、绿茶、优酸乳、可乐和咖啡，价钱还都差不多。日本的水果很贵，一个不到6斤重的西瓜就要2200日元左右，橘子大约五块钱一个，但是他们的酒却相比较便宜。在日本我可没少喝梅子酒、气泡果酒和啤酒。 日本的电视我俩住的民宿有一个小电视，里面有12个频道，其中三个是购物频道…我想可能日本的免费电视就这么点，大多数都是收费频道。这九个电视台白天有新闻，有韩剧，有街头采访；晚上有芭蕾舞片段、有综艺节目、还有打着圣光的肉番！说到综艺节目，里面有一个片段就是把秃头用毛巾擦的锃亮，然后用遥控板去对着秃头摁键，结果信号经过秃头的折射，竟然能顺利的操纵电视。再后来叫来两个秃头，尝试多次折射，依旧可以准确遥控电视…就这么一个环节把我之前从来不看日本综艺节目的同事笑翻了，回国后就开始恶补这种日本综艺。 游玩的tips1.日本路边的垃圾箱很少，据说是因为他们没有边走路边吃喝东西的习惯，所以随处带一个塑料袋来装垃圾；2.USJ的快速通行证只有日语区的页面才有，请准备好visa和master卡；3.办理的地铁充值卡不要扔，下一次再来日本，直接储值依旧可以使用；4.到了USJ别上来先买东西，要先排队玩，东西可以放到最后出院的时候再买；5.不会日语在一般情况下没问题，但是如果看不懂车站的话，就难免要问路了，这样会比较头疼，准备一个google翻译。6.champion在日本的地摊也有卖，人民币大约100多，所以淘宝上那些200左右的champion完全不需要考虑… 这次的遗憾这次玩的蛮爽的，但是大阪仅仅只有三天只能玩一个皮毛，比如本次出游的遗憾如下： 1.据说大阪有一个棒球场，20日元一个球，然后通过发球机器发射，游客可以轮棒尝试一下本垒打的快感，但是由于时间太紧没有打上棒球…2.没有去游戏机厅，以前常在漫画里看到日本有那种弹子机，如果赢的多，可以用塑料筐装满小弹子去换钱，这种游戏机厅在大阪的商场很常见，而且门口都有大广告，上面写“新品到店，欢迎畅玩”；3.在龟梨和也和山下智久主演的《我命中注定的人》里，龟梨和也手工雕刻了一个王将的木牌，这次到了大阪逛了很多店，都没有发现这款木雕，不仅没有这个木雕，连战国时期各大将的头盔纺织品也没有看到，这一点很遗憾；4.USJ里的变形金刚和终结者2都暂时停业，不过我后来在B战上看了视频，还是过山车… 等下一次如果有机会能去东京的话，就尝试把上面几个弥补上，再顺便去一趟秋叶原。]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>日本</tag>
        <tag>旅游</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab+Jenkins搭建持续集成系统]]></title>
    <url>%2F2018%2F05%2F25%2FGitlab-Jenkins%E6%90%AD%E5%BB%BA%E6%8C%81%E7%BB%AD%E9%9B%86%E6%88%90%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[前言gitlab是一个应用很广泛的版本控制工具，他也有自带的持续集成工具—gitlab cli，但是这个工具不如jenkins那么好用。本文的目的要把gitlab和jenkins进行结合，当我们更新了代码并且把代码push到gitlab的时候，gitlab会把代码的变化通知到jenkins，然后jenkins就会自动构建project。 说一下实验环境：Jenkins所在服务器IP：121.41.37.251(10.168.173.181)，版本是2.124(查看jenkins的版本语句java -jar /usr/lib/jenkins/jenkins.war --version);Gitlab所在服务器IP：114.55.224.158(10.25.85.175)，使用容器安装，版本是10.7.3; jenkins添加gitlab插件通过浏览器登陆jenkins界面，然后在系统管理里面选择管理插件，如图： 然后在可选择插件里搜索gitlab hook插件，但是没想到我这个版本提示”目前的1.4.2版本的gitlab hook目前存在安全隐患”，如图： 具体的安全隐患细节是这样的： 这个风险请自己把握，然后我选择了继续安装，如图： 安装完了gitlab hook插件后，还要安装GitLab Plugin和Gitlab Authentication plugin这两个插件，方法跟上面的一样。 创建测试工程在jenkins上建立一个新的任务，比如叫jicheng-test，这是一个自由风格的软件项目： 然后在源码管理里面选择git，然后输入gitlab里面仓库的地址，比如我在gitlab上新建了一个project叫jenkinstest，那么就复制这个仓库的地址填到jenkins的Repositories里，如图： 还要在Credentials这里面写上gitlab的用户和密码，然后保存即可： 配置 GitLab 用户浏览器切换到gitlab界面，在用户头像点击，User settings —&gt; Access Tokens，这里的Personal Access Tokens写入一个账号，这个账号是用来让Jenkins和GitLab API交互。这个用户将需要是全局的管理员或添加进每个组／工程，并作为成员。需要开发者权限来报告构建状态。如图： 输入账号和账号有效时期之后，会生成一个Private token，如图： 拷贝它，稍后在配置Jenkins服务器时会用到。 配置 Jenkins 服务器需要配置 Jenkins 服务器来与 GitLab 服务器通信。 在 Jenkins 中，选择系统管理 -&gt;系统设置，在系统设置中找到GitLab的部分： 在Connection name后的输入框中输入连接名称，在Gitlab host URL后的输入框中输入GitLab服务器的URL地址。点击Credentials行最后面的Add -&gt; Jenkins按钮，弹出如下对话框，在Kind 后的下拉列表中选择GitLab API token，并把上一步拷贝的Private token粘贴到API token后面的输入框中。 随后在Credentials的下拉框中选择GitLab API token。 配置 Jenkins 工程来到刚刚建立的那个工程jicheng-test，点击构建触发器，先勾选Build when a change is pushed to GitLab，点击高级，然后再点击一下Generate就会生成一个Secret Token，如下： 点击左下角的保存按钮，保存前面所做的配置。这个时候要记录两个东西，一个是Build when a change is pushed to GitLab那一行中，GitLab CI Service URL:后面的 URL；还有一个就是刚刚生成的Secret Token，这俩在后面配置GitLab工程时需要用到。 配置 GitLab 工程在gitlab进入那个叫jenkinstest的project，然后在settings---&gt;Integrations，在URL里填写刚刚记下来的URL，在Secret Token里填写刚刚记下来的Secret Token，如图： 然后点击下面绿色的add webhook，就会生成一个Webhooks，如图： 去代码服务器上提交一个commit，然后push到gitlab里，再返回到Integrations，对刚刚生成的webhooks点击test，选择push events，如图： 然后就会出现200的成功字样，如图： 如果你再点击一下test上面的edit，就会看到webhook最近调用情况，再点击view details的话，就会看到具体的调用细节，如图： 验证测试此时我在代码服务器上做了一些简单的改动，然后重新把代码push到gitlab服务器上，在jenkins里的相关project里，就会看到已经自动开始build了，如图： 再在具体的某次build里选择控制台输出，就会看到构建的详细过程，如图： 横向扩展如果是多个gitlab的project去对应同一个jenkins，那么需要在jenkins创建任务的时候就选择是根据一个已经存在的任务创建，如图： 在这里写上作为模板的任务的名称，然后在新生成的任务配置的源码管理里添加一个新的Repositories，如图： 如果想要限制分支的话，就要更改Branches to build，现在默认是“只要master分支有push就会触发jenkins构建”。然后再回到gitlab的新project里，进入Integrations，输入配置 Jenkins 工程那个环节里的URL就OK了，Secret Token不用单独填写，因为在复制任务那一步的时候直接把Secret Token全部拷贝过来了。 参考资料http://www.cnblogs.com/bugsbunny/p/7919993.htmlhttps://www.wolfcstech.com/2018/03/26/gitlab_trigger_jenkins_build/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用yum安装软件爆No such file or directory]]></title>
    <url>%2F2018%2F05%2F17%2F%E4%BD%BF%E7%94%A8yum%E5%AE%89%E8%A3%85%E8%BD%AF%E4%BB%B6%E7%88%86No-such-file-or-directory%2F</url>
    <content type="text"><![CDATA[今天开发反馈说yum install redis报错-bash: /usr/bin/yum: /usr/bin/python: bad interpreter: No such file or directory，于是我就登上服务器，使用python一看，反馈-bash: python: command not found，原来这个机器的python被人改动了，用whereis python查了一下，原来python的地址被人改成了/usr/bin/python2.7，于是就手动更改了一下/usr/bin/yum，把#!/usr/bin/python改成了#!/usr/bin/python2.7。但是使用yum install -y redis发现虽然可以连接到库但是会报No such file or directory，如图： 原来光改了/usr/bin/yum还没用，还要改/usr/libexec/urlgrabber-ext-down这个文件，同样也是把python改成/usr/bin/python2.7说明python的路径才可以。 改了上面两个文件之后，又加上了yum clean all和yum makecache，清除一下缓存，一切恢复了正常。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用zabbix去监控docker容器]]></title>
    <url>%2F2018%2F05%2F17%2F%E4%BD%BF%E7%94%A8zabbix%E5%8E%BB%E7%9B%91%E6%8E%A7docker%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[前言现在容器技术越来越普遍，那么搭建了容器肯定要监控起来，监控方法有两种，一种是做一个zabbix-agent容器去监控容器，还有一个是升级原有的zabbix-agent，这里说第一种。 这里先交代一下环境：zabbix-server的ip是10.244.48.42，要监控的机器ip是10.244.34.79，这个机器里面装了一个容器在运行gitlab，如图： 事前检查两台服务器是否互通，而且10050和10051端口是否standby。还要在zabbix-server端做好auto-discovery，等等等等准备工作。 使用Zabbix Agent Docker进行监控在10.244.34.79这个机器上先安装zabbix-agent容器： 12345678910docker run \ --name=dockbix \ #这个是容器的名称 --net=host \ #容器可以直接访问主机上所有的网络信息 --privileged \ #容器内的root拥有真正的root权限 -v /:/rootfs \ #这个是对应宿主机的映射盘 -v /var/run:/var/run \ --restart unless-stopped \ #不管退出状态码是什么始终重启容器，不过当daemon启动时，如果容器之前已经为停止状态，不要尝试启动它。 -e &quot;ZA_Server=10.244.48.42&quot; \ #这里就填写zabbix-server的ip地址 -e &quot;ZA_ServerActive=10.244.48.42&quot; \ -d hub.c.163.com/canghai809/dockbix-agent-xxl-limited:latest #这里使用了网易蜂巢镜像 但是反馈给我docker: invalid restart policy unless-stopped.这样的错误信息，原来这个gitlab这台服务器的docker版本较老，而unless-stopped这个是在1.9.0版本才加入的，所以对于旧版的docker环境需要改成always。 更改docker run的命令之后重新执行效果如下： 可见容器启动成功，docker logs -f 容器ID号看一下日志是否正常。如果正常的话，应该在zabbix-server端是可以看到这个10.244.34.79已经被添加到控制台里了，如图： 导入监控docker的模版在zabbix server上导入监控docker的模版，一共2个模版,下载后解压。模版下载地址: https://dl.cactifans.com/zabbix/Zabbix-Template-App-Docker.tar.gz 。 我使用主动模式，因此导入Zabbix-Template-App-Docker-active.xml这个模版，如图： 此时可以去zabbix-server这个机器上验证一下是否监控成功，在zabbix-server上执行zabbix_get -s 10.244.34.79 -k docker.discovery，效果如下： 可见已经成功获取到了那两个容器的名称，这就代表zabbix-server已经监控到位了。 验证数据首先现在10.244.34.79里执行docker stats 容器1的ID 容器2的ID...，看一下当前运行的所有容器的状态，如下： 与zabbix-server的latest data做一下对比，由于被监控机的docker版本较老，docker stats结果不是那么的精准，不过用来监控参考还是OK的…如果docker是最新版的，那么监控值是很准的。 剩下的就是慢慢添加triggers了… 补充一句，zabbix-agent 3.2的rpm安装方法： 1234rpm -ivh http://repo.zabbix.com/zabbix/3.2/rhel/7/x86_64/zabbix-release-3.2-1.el7.noarch.rpm yum -y install zabbix-agent zabbix-senderservice zabbix-agent startchkconfig zabbix-agent on 参考资料https://github.com/monitoringartist/zabbix-docker-monitoring （墙裂推荐！）https://blog.codeship.com/ensuring-containers-are-always-running-with-dockers-restart-policy/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab的配置备份]]></title>
    <url>%2F2018%2F05%2F16%2FGitlab%E9%85%8D%E7%BD%AE%E5%A4%87%E4%BB%BD%2F</url>
    <content type="text"><![CDATA[备份正文我这个gitlab是容器安装的，直接使用最新的gitlab镜像，gitlab版本是10.7.3。 要备份数据的话，就要进入容器里，执行gitlab-rake gitlab:backup:create，效果如下： 执行完毕之后，在/var/opt/gitlab/backups文件夹里就会生成一个备份文件，我这里生成的文件叫：1526454102_2018_05_16_10.7.3_gitlab_backup.tar，这个就是备份的文件。 如果要还原的话，命令如下： 1234567891011# 先关闭连接数据库的进程sudo gitlab-ctl stop# 通过指定时间戳来执行restore操作，这个操作会复写gitlab的数据库sudo gitlab-rake gitlab:backup:restore BACKUP=1526454102 #BACKUP后面的是备份文件开头的那串数字# 再次启动gitlabsudo gitlab-ctl start# 通过下面命令检查gitlabsudo gitlab-rake gitlab:check SANITIZE=true 注意！利用backup机制进行备份的话，对gitlab的版本是要求严格一致的。例如用8.6版的gitlab生成的备份文件，拿到8.7版的gitlab上进行恢复，是会报错的。 同时除了要导入备份文件之外，还要备份以下几个文件： 123/etc/gitlab/gitlab.rb 配置文件须备份/var/opt/gitlab/nginx/conf nginx配置文件/etc/postfix/main.cfpostfix 邮件配置备份 如果要设置这个备份文件的生命周期和备份文件存储的位置，编辑/etc/gitlab/gitlab.rb，修改如下的地方： 1234gitlab_rails[&apos;backup_path&apos;] = &quot;/var/opt/gitlab/backups&quot; #这里改新路径gitlab_rails[&apos;backup_archive_permissions&apos;] = 0644 #这里可以设定文件的权限# limit backup lifetime to 7 days - 604800 secondsgitlab_rails[&apos;backup_keep_time&apos;] = 604800 #文件存储时间一周 然后重启一下gitlab即可。 参考资料http://eimsteim.github.io/2017/12/12/%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%9D%91%E7%88%B9%E7%9A%84Gitlab%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%E4%B9%8B%E6%97%85/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab的简单应用]]></title>
    <url>%2F2018%2F05%2F16%2FGitlab%E7%9A%84%E7%AE%80%E5%8D%95%E5%AE%9E%E7%94%A8%2F</url>
    <content type="text"><![CDATA[gitlab跟svn的区别我就不多说了，这里直接说具体应用。 建立一个project先登陆到gitlab的网页，我这里使用了root用户，选择create a project，然后就是填写project的名称以及它所属的用户，这里由于只有root用户，所以这个叫jjfjj的project就是root自己的，如果建立了一个组的话，那么这里就填写那个组，如下： 下面这个Visibility Level ，就是权限等级，它分三种： Private：私有的，只有你自己或者组内的成员能访问 Internal：所有登录的用户 Public：公开的，所有人都可以访问 这个东西和project的名称都是可以后期更改的。 然后就是create project，就创建了这个jjfjj。如图: 将本地代码上传建立好了gitlab，就要把开发的代码传进去，我在另外一个机器里，创建一个目录code，这个目录就是专门用来放置代码的，假设现在里面有一个文件叫testcode.py，如图： 具体操作如下： 如果在两个不同的文件夹里执行上面的过程，会传输到两个不同的project里。说明一下上面几个命令的意思：git init：初始化git仓库git add .：添加整个目录里的所有文件到仓库git rm --cached 某个文件名：将某个文件从gitlab上撤除，如果想当前文件夹恢复成一个普通的文件夹，那就把文件夹路径下的.git文件删除掉即可git commit -m &#39;这里是要写的注释&#39;：提交代码到仓库git remote add origin +gitlab的地址(上上图里红色框的内容)：链接到gitlab服务器git push origin master：push代码到服务器git remote -v：查看当前文件夹的目标project 此时刷新一下gitlab的project页面，就看到刚刚的那个testcode.py已经传上来了。如图： 如果代码有所更改或者出现Everything up-to-date，那么就按顺序执行git add .，git commit -m &#39;这里是要写的注释&#39;，git push origin master即可。 免密码push代码在上面的git push origin master的时候需要输入gitlab的用户密码，如要需要免密码push，有两种方法。 第一种方法是ssh，请看 https://blog.whsir.com/post-1749.html/comment-page-1#comment-3425 。 第二种方法是用http的方式传送，先打开.git/config这个配置文件，修改url = http://账号:密码@以.git结尾的项目地址,保存之后重新去执行git add .，git commit -m &#39;这里是注释&#39;，git push origin master，就不再需要输入密码了。 从gitlab上垃取代码在要部署的机器上找到要部署的文件夹，我这里用/gitlab为例，操作如下： 12345678910[root@pass-mixnumbus-001 /GITLAB] # git init #将这个文件夹进行初始化 Initialized empty Git repository in /GITLAB/.git/ #提示现在已经安装了.git文件[root@pass-mixnumbus-001 /GITLAB(master)] # git remote add origin http://114.55.224.158/root/JJFJJ.git #确定库[root@pass-mixnumbus-001 /GITLAB(master)] # git pull origin master #制定要把master分支的代码全拉取到这个文件夹里Username for 'http://114.55.224.158': root #输入账号和密码Password for 'http://root@114.55.224.158': From http://114.55.224.158/root/JJFJJ * branch master -&gt; FETCH_HEAD[root@pass-mixnumbus-001 /GITLAB(master)] # ls #看一下效果admin.py looksql.py models.py syncECS.py testsyncECS.py 再与gitlab界面的代码比较一下，果然都过来了！如图： 在gitlab上建立分支gitlab上有很多个分支，主要的分支是master，它也是默认的分支，但是实际工作中是需要其他的开发去新建一些测试的分支，到时候可以先把这些测试的分支拿来部署，如果有问题就回滚回master分支。 分支相关的语句如下： 123456git branch #查看本地分支git branch -r #查看远程分支git branch -a #查看所有分支git branch develop #本地创建新的分支，此时刷新gitlab的页面的话就会有这个叫develop的分支建立了git checkout develop #切换到新的develop分支git checkout -b develop #上面两步可以合成一个命令，这个的意思就是：创建+切换分支 这个时候在代码机上新增或者改变文件，然后执行git add .，git commit -m &#39;这里是要写的注释&#39;，git push origin develop，就把新增的变化上传到了develop分支，如图： 1234567891011[root@iZ23pg8sy5bZ ~/GITLAB(develop)] # git push origin developCounting objects: 4, done.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 325 bytes | 0 bytes/s, done.Total 3 (delta 1), reused 0 (delta 0)remote: remote: To create a merge request for develop, visit:remote: http://114.55.224.158/root/JJFJJ/merge_requests/new?merge_request%5Bsource_branch%5D=developremote: To http://114.55.224.158/root/JJFJJ.git fc8d456..8a97b58 develop -&gt; develop 而在部署的机器上，直接执行git pull origin develop，输入账号密码之后，就会把develop分支的内容全部垃取下来了。 如果不想要这个develop分支了，就git branch -d develop，如果要删除远程的分支，就是git push origin :develop，注意这个冒号。 如果gitlab的地址发生了改变，那么在git pull之前需要git remote set-url origin 新的git地址，不过设定完毕之后，免输账号密码的效果会消失。 参考资料https://blog.cnbluebox.com/blog/2014/04/15/gitlabde-shi-yong/https://zhang759740844.github.io/2016/08/27/git%E6%8A%80%E5%B7%A7/https://www.restran.net/2016/02/23/git-and-gitlab-guide/https://www.jianshu.com/p/f54053afecf2]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gitlab的汉化过程]]></title>
    <url>%2F2018%2F05%2F15%2FGitlab%E7%9A%84%E6%B1%89%E5%8C%96%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[gitlab的容器安装方法部署前的第一句话，gitlab是不支持32位系统的！ gitlab用容器部署的话非常的简单，首先docker pull gitlab/gitlab-ce:latest下载镜像，然后docker run --detach --hostname 本机外网IP --publish 443:443 --publish 80:80 --publish 2222:22 --name gitlab --restart always gitlab/gitlab-ce:latest建立一个容器，如图： 然后在浏览器的地址栏里输入服务器的外网IP地址，就到了一个更换密码的页面，这个密码就是root的密码，如图： 设定密码之后，就可以通过root账号登陆gitlab了，如图： 至于“使用ldsp方式登录”、“配置域名”和“关闭注册功能”请移步去看：https://rorschachchan.github.io/2018/05/10/在已经运行的docker容器里面使用中文/ 。 gitlab的汉化方法汉化之前，要确定gitlab的版本，先docker exec -it 容器ID env LANG=C.UTF-8 /bin/bash登陆到容器里，执行cat /opt/gitlab/embedded/service/gitlab-rails/VERSION，由于当时镜像是最新的，所以gitlab的版本是10.7.3。 还是在容器里，执行git clone https://gitlab.com/xhang/gitlab.git，克隆获取汉化版本库(这里要感谢辛苦的汉化工作者，向你们致敬！)，默认是获取最新的。如果需要下载老版本的汉化包，则要加上老版本的分支，如：git clone https://gitlab.com/xhang/gitlab.git -b v10.2.5-zh。 然后gitlab-ctl stop先停止gitlab服务，cd gitlab/进入到刚刚下载的那个git包里，执行如下代码： 123456root@10 gitlab]# git fetchroot@10 gitlab]# git diff v10.7.3 v10.7.3-zh &gt; ../10.7.3-zh.diffroot@10 gitlab]# cd ..root@10 ~]# patch -d /opt/gitlab/embedded/service/gitlab-rails -p1 &lt; 10.7.3-zh.diffroot@10 ~]# #如果提示没有patch，请执行apt-get update &amp;&amp; apt-get install patchroot@10 ~]# gitlab-ctl start 重新返回到浏览器里，就能看到汉化后的gitlab了，大功告成！ 参考资料https://xuanwo.org/2016/04/13/gitlab-install-intro/https://www.jianshu.com/p/6606aed59a56http://adairjun.github.io/2016/12/20/gitlab/https://github.com/marbleqi/gitlab-ce-zh/blob/v10.5.1-zh-patch/Nginx.md]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>gitlab</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅析django里models.py、views.py与网页之间的爱恨纠葛]]></title>
    <url>%2F2018%2F05%2F14%2F%E6%B5%85%E6%9E%90django%E9%87%8Cmodels-py%E3%80%81views-py%E3%80%81page%E4%B9%8B%E9%97%B4%E7%9A%84%E7%BA%A0%E8%91%9B%2F</url>
    <content type="text"><![CDATA[前言Django + Boostrap现在是运维开发的必备技能，因为他俩是运维可视化的关键技术，而本文就是简单说一下整个Django的数据库---后台---前端的工作原理。其实所谓Django开发，就是熟悉了 Django的规则之后，按照它的规则去填空，填你自己想要展现的东西。 环境：django 2.0 + python 3.6 + pycharm 2018 django建立一个app之后就会有models.py、views.py、admin.py这几个文件，他们三个分别的用途如下： models.py主要是用来设置数据在数据库的存储格式（比如默认值，字段类型和字段长度等等）; admin.py是用来设置在/admin/后台里面的显示样式; views.py是用来设置在前台网页里的显示样式； urls.py是用来编辑域名规则； 上面4个文件里，重中之重的就是views.py，说它是整个django的灵魂都不为过！所以要是掌握了它，基本就明白了大半个django了。 举个例子假设有一个models.py，内容如下： 1234567from django.db import models from django.contrib.auth.models import User class BlogType(models.Model): type_name = models.CharField(max_length=15) #规定type_name是一个最大为15字节的charfield def __str__(self): return &apos;&lt;BlogType:%s&gt;&apos; % self.type_name 然后随便加入一些内容，如图： 而在views.py里，要求在前端网页里如此的显示： 1234567from django.shortcuts import render_to_response,get_object_or_404 from .models import BlogType #这里引用了models.py里的那个class def blog_list(request): context = &#123;&#125; context[&apos;blog_types&apos;] = BlogType.objects.all() return render_to_response(&apos;pageblog/blog_list.html&apos;,context) 在views.py里规定，如果有访问域名是/blog_list/的网页，就返回pageblog/blog_list.html这个页面，而这个blog_list.html只是一个框架，里面的内容是context。context本身是一个字典，里面的key对应的value是用ojbects这个函数获得的，objects.all()就是获取全部的意思。用来填充blog_list.html的context里面有blog_types这个key。 那么现在就可以在blog_list.html里使用blog_types这个key了，如下： 1234&lt;!-- 前面略 --&gt; &lt;h4&gt;博客分类&lt;/h4&gt; &lt;h3&gt; &#123;&#123; blog_types &#125;&#125; &lt;/h3&gt; &lt;!-- html文件要用views.py里的变量要加上&#123;&#123;&#125;&#125; --&gt;&lt;!-- 后面略 --&gt; 这样的效果如下： 返回的是QuerySet类型，QuerySet是Django的查询集，可以通过QuerySet条件查询得到对应模型的对象集合。由此看出blog_types已经成功的引入到了blog_list.html里。 至于拆成每一个“博客类型”就很简单了，html部分如下： 12345678910&lt;h4&gt;博客分类&lt;/h4&gt; &lt;!-- ul是无项目的标签 --&gt; &lt;ul&gt; &#123;% for blog_type in blog_types%&#125; #开始一个for循环 &lt;li&gt;&lt;a href=&quot;&#123;% url &apos;blogs_with_type&apos; blog_type.pk %&#125;&quot;&gt;&#123;&#123; blog_type.type_name &#125;&#125; &lt;/a&gt;&lt;/li&gt; #对每一个类型加上一个a链接 &#123;% empty %&#125; #如果为空就说“暂无分类” &lt;!-- li是具体的项目 --&gt; &lt;li&gt; 暂无分类 &lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt; 再说urls.py上面说过了，urls.py是配置域名路由规则的。它的格式比较简单，就是path(&#39;域名&#39;，views.py里的函数，name=&#39;自定义名称&#39;)。比如下面这个urls.py： 123456789from django.contrib import adminfrom django.urls import include,pathfrom article.views import blog_list #article是django项目里自己创建的一个appurlpatterns = [ path('',blog_list,name='home'), #这里的name可写可不写，如果写的话，在href跳转的时候就可以直接用 path('admin/', admin.site.urls), path('blog/',include('article.urls')), #引用的的include方法用在这里] 上面这个是总的路由文件，当然可以把所有的app的路由都写到里面去，也可以在各自的app下写各自的路由，这样方便管理。比如我就在article这个app文件夹下面又单独了一个urls.py，这里面所有的域名就会自动添加blog/这个路径，而整个urls.py内容如下： 1234567from django.urls import pathfrom . import viewsurlpatterns = [ path('&lt;int:blog_pk&gt;',views.blog_detail,name='blog_detail'), path('type/&lt;int:blog_type_pk&gt;',views.blogs_with_type,name='blogs_with_type'),] 在上面的第一个path里，目的就是传入一个值blog_pk，而这个blog_pk就是在views.py里的blog_detail函数需要传入的参数，跟request一样。上面也说过了，这个两个path都会自动在前面加上/blog/路径。 views.py与前端如何把数据库里的内容映射到前端页面呢？就是用views.py里的render_to_response，它是负责渲染的。render_to_response的用法是后面要加上对应的html页面和要映射的内容，比如下面这个views.py: 1234567from django.shortcuts import render_to_response,get_object_or_404from .models import Blog #这里引用了models.py里面的类：Blogdef blog_detail(request,blog_pk): #每一次使用这个函数都要传入一个参数：blog_pk context = &#123;&#125; context['blog'] = get_object_or_404(Blog,pk=blog_pk) #通过get_object_or_404这个方法生成一个字典 return render_to_response('blog_detail.html',context) #这个blog_detail.html就是对应的前端页面 从上面可以看到，views.py先引入了数据库文件models.py里的Blog这个class，然后设定一个空字典，将这个字典按照对应数据库默认的主键pk与浏览器输入的pk一一对应填满，最后就是按照blog_detail.html为前端框架，里面赋予整个填满值的context字典。 而对应的前端页面blog_detail.html如下： 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset='UTF-8'&gt; &lt;title&gt;&#123;&#123; blog.title &#125;&#125;&lt;/title&gt; &lt;!-- 这里的blog就是views.py里context['blog']里的blog --&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; &lt;a href="&#123;% url 'home' %&#125;"&gt; &lt;!-- 这里就是返回首页，home是在urls.py里设定的 --&gt; &lt;h2&gt;BACK TO HOMEPAGE&lt;/h2&gt; &lt;/a&gt; &lt;/div&gt; &lt;h3&gt;&#123;&#123; blog.title &#125;&#125;&lt;/h3&gt; &lt;p&gt;作者：&#123;&#123; blog.author &#125;&#125;&lt;/p&gt; &lt;p&gt;分类： &lt;a href="&#123;% url 'blogs_with_type' blog.blog_type.pk %&#125;"&gt; &lt;!-- 就是将blog.blog_type.pk作为views.py里blog_detail函数的传入值 --&gt; &#123;&#123; blog.blog_type &#125;&#125; &lt;/a&gt; &lt;/p&gt; &lt;p&gt; &#123;&#123; blog.blog_type.pk &#125;&#125;&lt;/p&gt; &lt;p&gt;发表时间：&#123;&#123; blog.created_time|date:"Y-m-d H:i:s"&#125;&#125;&lt;/p&gt; &lt;!-- 这里将输出时间做了规范化 --&gt; &lt;hr&gt; &lt;p&gt;&#123;&#123; blog.content &#125;&#125;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[加载css样式的两个方法]]></title>
    <url>%2F2018%2F05%2F12%2F%E5%8A%A0%E8%BD%BDcss%E6%A0%B7%E5%BC%8F%E7%9A%84%E4%B8%A4%E4%B8%AA%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[背景说明环境： django 2.0+python 3.6+pycharm 2018project名称: blog 普通的网页加载css网页使用了css才会更好看更炫酷，一般情况下的网页是这样的： 上面这个html文件里用到了模板，而且又对div和 a标签做了class定义，最后分别对各自的class进行了css说明。整个文档看下来比较直观。 但是这样就会有一个问题，就是把html内容和css内容写到了一起，一般来说为了后期维护，都会把css单独写到一个文件夹里，然后让这个html来引用这个css文件夹的具体某个css文件。 于是，我们就在blog这个project目录下建立一个叫static的文件夹，用它来专门装css\js这样的静态文件。 首先，建立了这个static文件，肯定就涉及到引用的问题，而如何让django可以识别static呢？ 打开blog/settings.py这个文件，这个文件是整个project的配置文件，在文件末尾加上这样的话，如下： 1234 #将项目根目录里的static制定成项目的静态文件夹,这样django就可以识别 #注意，static前面没有'/' STATICFILES_DIRS = [os.path.join(BASE_DIR, 'static'),]​ 这样blog这个根目录就可以识别了static文件夹了。 然后在pycharm里新建一个css文件叫base.css，如果是专业版的pycharm是可以直接建立css类型文件的，免费社区版是没有这个功能。再将原文里面的所有关于css的内容拷贝到这个base.css里，如下： 1234567891011121314151617181920*&#123;margin: 5px;padding: 10px;&#125; div.nav &#123;background-color: gold;border-bottom: 2px solid #ccc;&#125; div.nav a&#123;text-decoration:none;color: blue;padding: 5px 10px;&#125; div.nav a.logo&#123;display: inline-block;font-size: 120%;&#125; 保存之后，为了验证django是否成功的识别此文件，可以在浏览器里输入外网IP：端口号/static/base.css查看是否返回就是上面内容，如果是就代表识别成功，如果是404就要重新检查settings.py了。 在原有的html里删除掉&lt;style&gt;标签内css内容，还要在head里添加一句话：&lt;link rel=&quot;stylesheet&quot; href=&quot;/static/base.css&quot;&gt;,如下： 这样就达到了引用css所在的static文件夹的目的。 Django内部的加载css方法上面说的是普通html加载css的方法，而django内部也有自己的一套方法，再次打开settings.py里看到有如下的内容： 123456789INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'blog',] 上面的django.contrib.staticfiles就是django的css加载方法，使用这个方法也很简单。 首先要在html文件最上面先声明要调用这个方法: 12&#123;% load staticfiles %&#125;&#123;# 这个staticfiles是django自带的，可以在settings文件里看到 #&#125; 然后把link标签改成如下： 1&lt;link rel=&quot;stylesheet&quot; href=&quot;&#123;% static &apos;base.css&apos; %&#125;&quot;&gt; 保存文件刷新即可，而且用了这种方法，在chrome浏览器里F12 查看，会解析成普通模式的方法，如图： 在django项目里，还是更推荐用django的方法。 额外补充如果html文件开头声明引用了某个模板，比如： 12&#123;% extends &apos;base.html&apos; %&#125; #声明引用了base.html这个模板&#123;% load staticfiles %&#125; 那么extends语句必须在最上面，不然就会报错：TemplateSyntaxError at /&lt;ExtendsNode: extends &#39;base.html&#39;&gt; must be the first tag in the template.]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>django</tag>
        <tag>前端技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[创建Mysql容器过程]]></title>
    <url>%2F2018%2F05%2F12%2F%E5%88%9B%E5%BB%BAMysql%E5%AE%B9%E5%99%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[过程记录先docker pull mysql，当前最近的版本是8.0，然后docker images查看一下效果。 然后就是启动一个容器，命令是：docker run --name test-mysql -p 3306:3306 -e MYSQL\_ROOT\_PASSWORD=123456 -d mysql,这句话的意思是：启动一个叫test-mysql的容器， 端口影射是3306到宿主机的3306，同时设置root的密码是123456，然后以守护进程的形式启动。 但是如果在宿主机上使用mysql -h127.0.0.1 -uroot -p123456可能会报错，报错内容是：Authentication plugin ‘caching_sha2_password’ cannot be loaded: 那么就docker exec -it 容器ID号 env LANG=C.UTF-8 /bin/bash进入到容器里，使用mysql -uroot -p123456，看一下在容器里是否可以正常登录，如果可以的话，那么就在mysql的命令行里执行ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;;。 退出容器在宿主机上重新连接，这样就OK了。至于原因就是，mysql的客户端是yum安装的，虽然是centos 7，但是安装的版本也是5.5版本的，所以8.0的客户端有一个新的密码加密方式：caching_sha2_password，客户端不支持，所以需要手动到命令行里更改一下。 mysql存储的坑先思考一个问题：假如某mysql容器里存储了100G的数据，那么这个容器关闭了，这100G的数据还在么？从宿主机是可以找到这100G的数据么？ docker inspect mysql-container-id，找到里面的volume字段，这里也显示挂载的host路径，可以通过这个路径来备份数据。或者使用docker cp mysql-container-id:/path/to/db-backup-file ./，把容器内数据放到当前目录下。如果是生产环境，必须使用Volume或数据容器。 参考资料http://binary-space.iteye.com/blog/2412769http://dockone.io/question/108]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>docker容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[python报错：importError: No module named bz2]]></title>
    <url>%2F2018%2F05%2F12%2Fpython%E6%8A%A5%E9%94%99%EF%BC%9A'importError-No-module-named-bz2'%2F</url>
    <content type="text"><![CDATA[每日统计阿里云同步延迟的邮件早就编写完毕了，现在要放到专门跑脚本的服务器里，进去到这个服务器里发现这个机器已经被人装了两个python，分别是python 2.7.5（默认路径）和python 2.7.13（路径是/usr/local/python/bin/python），说实话我个人不太明白这么做的原因何在。 但是既然已经被人搞成这样了，那就适应环境吧，把脚本拷贝过来，把依赖库都安装好，但是在执行matplotlib的库的时候，爆了一个错误：ImportError: No module named bz2。 这就是因为两个python，但是启动的那个python文件夹里面是没有bz2.so这个文件的，于是就需要把系统里默认的2.7.5的bz2.so拷贝到2.7.13的lib路径里。 首先find / -name bz2.so找一下文件，如下： 1234[root@dvl-stun-002 GETDTS]# find / -name bz2.so/usr/local/aegis/PythonLoader/lib/python2.7/lib-dynload/bz2.so/usr/local/aegis/SecureCheck/lib/python2.7/lib-dynload/bz2.so/usr/lib64/python2.7/lib-dynload/bz2.so 然后cd /usr/local/python/lib/python2.7/，把/usr/lib64/python2.7/lib-dynload/bz2.so复制到这个文件夹里即可。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在已经运行的docker容器里面使用中文]]></title>
    <url>%2F2018%2F05%2F10%2F%E5%9C%A8%E5%B7%B2%E7%BB%8F%E8%BF%90%E8%A1%8C%E7%9A%84docker%E5%AE%B9%E5%99%A8%E9%87%8C%E9%9D%A2%E4%BD%BF%E7%94%A8%E4%B8%AD%E6%96%87%2F</url>
    <content type="text"><![CDATA[配置ldap公司搭建的gitlab现在需要开启ldap服务，也就是这样就可以用公司的域账号登陆gitlab，而不用开发一个一个去注册账号了。 开启ldap登陆的任务光荣的落到了我身上，于是我就登陆到gitlab服务器一看，嚯，这还是在容器下启动的，如图： 于是我就docker exec -it 容器ID号 /bin/bash登陆到这个容器里，编辑/opt/gitlab/embedded/service/gitlab-rails/config/gitlab.yml，如下： 1234567891011121314ldap: enabled: true sync_time: host: '公司域账号服务器IP地址' port: 389 uid: 'sAMAccountName' method: 'plain' # "tls" or "ssl" or "plain" bind_dn: 'dahuatech\Ldap_System' password: '对应的密码' active_directory: allow_username_or_email_login: lowercase_usernames: base: user_filter: 但是在填写到base的时候发现了一个问题，公司的base是中文的，是&#39;OU=大数据研究院,OU=研发中心,OU=大华技术,DC=dahuatech,DC=com&#39;，但是在文件里输入中文却是乱码，如图： 容器默认是不支持中文的，在容器里的命令行输入中文也是空白。那么面对一个已经运行的容器，如何正常的输入中文呢？ 答案是：使用docker exec -it 容器ID号 env LANG=C.UTF-8 /bin/bash登陆，这样就能正常使用中文了，如图： gitlab-ctl restart之后，登陆到gitlab页面一看，已经添加ldap访问方式： 取消“注册”功能修改好配置文件gitlab.yml之后，现在就要把“注册”功能去掉，这样以后都统一用公司的域账号登陆，避免一些乱七八糟的用户来注册乱七八糟的账号。 首先用root账号登陆到gitlab里，在网页里进入到admin area，如图： 然后再点击最下面的settings，选择Sign-up restrictions，然后把Sign-up enabled前面的勾点掉，如图： 保存改变之后，退出root账号，重新看一下，gitlab的注册功能就暂时被取消了，需要的时候再开即可。 配置域名为了方便记忆，给gitlab服务配置一个域名，在阿里云的域名解析控制台给gitlab配置了域名之后，还要在gitlab.yml手动更改hostname，把hostname改成域名的样子，如图： 这样没有结束，因为网页里的url还是显示外网IP而非域名,如下： 此时需要重启，重启的命令是gitlab-ctl restart，重启完了之后url也会发生变化。这样才算完整的配置了域名：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过阿里云服务器ID添加服务器资料到django的脚本]]></title>
    <url>%2F2018%2F05%2F07%2F%E9%80%9A%E8%BF%87%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8ID%E6%B7%BB%E5%8A%A0%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%B5%84%E6%96%99%E5%88%B0django%E7%9A%84%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[本文的环境是：centos 7 + django 2.0 + python 3.6 先给django里的project创建了models.py，里面内容如下： 123456789101112131415from django.db import models# Create your models here.class ecs(models.Model): name = models.CharField(verbose_name='云服务器名称',max_length=30) ecsid = models.CharField(verbose_name='云服务器ID',max_length=30,default='') inIP = models.GenericIPAddressField(verbose_name='云服务器内网地址') outIP = models.GenericIPAddressField(verbose_name='云服务器外网地址') osname = models.CharField(verbose_name='操作系统',max_length=50,default='') networktype = models.CharField(verbose_name='网络类型',max_length=20) CPU = models.IntegerField(verbose_name='云服务器CPU',default='2') memory = models.IntegerField(verbose_name='云服务器内存',default='2048') netwidth = models.IntegerField(verbose_name='云服务器外网带宽',default='0M') signtime = models.DateField(auto_now_add=True) remark = models.CharField(verbose_name='备注',max_length=255,blank=True) 可以看出这个就是一个很简单的云服务器的配置统计，但是要录入的阿里云服务器很多，一个一个手动输入实在太累，于是就要写一个脚本来达到django同步的效果！ 脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#!/usr/bin/env python#coding=utf-8#这个脚本通过查询阿里云服务器ID来达到同步django的目的import json,pymysqlfrom aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import DescribeInstancesRequestclt = client.AcsClient('这里是ak','这里是sk','这里是地域名')# 设置参数request = DescribeInstancesRequest.DescribeInstancesRequest()request.set_accept_format('json')request.add_query_param('RegionId', 'cn-hangzhou')request.add_query_param('InstanceIds', ['这里是服务器ID']) #如果是多个服务器ID，可以继续往下写# 发起请求response = clt.do_action(request)#print(response) #这里可以看一下返回的response，但是它是byte格式的data=str(response, encoding = "utf-8")ecs = json.loads(data) #转换成str格式name = str(ecs['Instances']['Instance'][0]['InstanceName'])ecsid = str(ecs['Instances']['Instance'][0]['InstanceId'])inIP = str(ecs['Instances']['Instance'][0]['VpcAttributes']['PrivateIpAddress']['IpAddress'])[1:-1] #如果不加[1:-1]的话，得到的是一个IP外面还有中括号outIP = str(ecs['Instances']['Instance'][0]['PublicIpAddress']['IpAddress'])[1:-1]networktype = str(ecs['Instances']['Instance'][0]['InstanceNetworkType'])CPU = int(ecs['Instances']['Instance'][0]['Cpu'])memory = int(ecs['Instances']['Instance'][0]['Memory'])osname = str(ecs['Instances']['Instance'][0]['OSName'])#创建数据库连接，注意这里我加入了charset和cursorclass参数conn = pymysql.connect( host = "127.0.0.1", user = "数据库账号", password = "数据库密码", database = "数据库名称", charset = 'utf8', cursorclass = pymysql.cursors.DictCursor)#获取游标cursor = conn.cursor()#三个引号里如何加入变量sql = """INSERT INTO ecs_ecs (name,ecsid,inIP,outIP,networktype,CPU,memory,netwidth,signtime,osname) VALUES (%(name)s,%(ecsid)s,%(inIP)s,%(outIP)s,%(networktype)s,%(CPU)d,%(memory)d,%(netwidth)d,NOW(),%(osname)s);""" % dict(name='\''+name+'\'',ecsid= '\''+ecsid+'\'',inIP=inIP,outIP=outIP,networktype='\''+networktype+'\'',CPU=CPU,memory=memory,netwidth=1,osname='\''+osname+'\'')#print (sql) #在这里可以先看看sql输出的是否正确cursor.execute(sql)# 关闭数据库连接conn.close() 正常来说应该是先建立一个def来获取阿里云服务器配置，再来一个def来将各配置录入到数据库里，同时让阿里云服务器的id作为变量，而且还要加上如果sql执行失败就回滚的语句。而我由于是临时使用，所以这个脚本按照流水式写下来的，不过不影响阅读。 ps.进化之后的脚本在我的github里，地址是： https://github.com/RorschachChan/chenWORK/blob/master/通过阿里云ID号将服务器信息同步到django.py 比如现在要添加一个服务器，这个服务器的id是：i-bp12ego6x9srzsytxeqo，如图： 那么对应填写好脚本里的ak/sk之后，就把i-bp12ego6x9srzsytxeqo填写到“服务器ID”的位置 ，执行这个脚本，结果如下： 不过这个脚本有两个缺点：第一：如果阿里云服务器是中文名称，那么使用api查询出现的是十六进制的符号；第二：如果服务器里没有外网IP或者是后开的临时带宽，那么在outIP的地方得到的值是空，sql语句会因为少一项而报错；第三：这个api没有查询服务器带宽值的功能，还需要另外写一个脚本搭配。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python3</tag>
        <tag>django2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次nginx负载均衡配置问题]]></title>
    <url>%2F2018%2F04%2F28%2F%E8%AE%B0%E4%B8%80%E6%AC%A1nginx%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[故障背景公司有三个实体服务器，内网IP分别是10.1.82.83、10.1.82.84、10.1.82.113，这三个作为源站使用专线连接到了阿里云的一台nginx服务器上，并且通过这个nginx做负载均衡展示这三个服务器里面的网页。负载均衡使用的是nginx 1.12版本，最外面在上一个CDN起到静态页面加速的作用。整个架构如图： CDN的配置界面如下： 但是现在很奇怪的是，所有节点启动之后，外网用户通过负载后访问均指向了10.1.82.84这一台服务器，nginx.conf配置是最小连接数的配置，如下： 123456789101112131415161718192021222324252627upstream eln.dahuatech.com &#123; #ip_hash; #hash $http_x_forwarded_for; #sticky; least_conn; server 10.1.82.83 max_fails=2 fail_timeout=30s; server 10.1.82.84 max_fails=2 fail_timeout=30s; server 10.1.82.113 max_fails=2 fail_timeout=30s;&#125;server &#123; server_name eln.dahuatech.com; listen 80; listen 443 ssl; access_log logs/eln.dahuatech.com.access.log main; error_log logs/eln.dahuatech.com.error.log; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; location / &#123; proxy_pass http://eln.dahuatech.com; &#125;&#125; 测试的时候发现，即使绑定美国和香港的节点去curl，是能正常解析到其他机器上的。如下： 然而源站过来的请求IP集中到了只有一个，这太奇怪了。 故障解决后来发现ngnix后端会把http1.1转换成1.0变成短连接，这个连接存在的时间非常短，因为后端响应非常快。所以即使配上了least_conn，其实是没有任何效果的。这样负载均衡的nginx看到所有源站其实一直都是没有连接的，所以也就一直在给第一个转。 既然这样，就取消了least_conn改用轮询，nginx.conf也改成如下的样子： 最后终于均衡了，大功告成！ 后来琢磨了一下，是用sticky其实也是OK的。 所以说，有些情景使用域名不通的情况下，可以考虑直接使用IP，这样就绕过nginx了，不会破坏原来的长连接。 几个主流负载均衡软件配置cookie的方法1.Apache的话首先打开httpd.conf配置文件，确保如下配置没有被注释。 1LoadModule usertrack_module modules/mod_usertrack.so 再在virtual host中添加以下配置。 1234CookieName nameCookieExpires "1 days"CookieStyle CookieCookieTracking on 2.Nginx参考以下配置，设置Cookie。 123456789server &#123; listen 8080; server_name wqwq.example.com; location / &#123; add_header Set-Cookie name=xxxx; root html; index index.html index.htm; &#125;&#125; 3.Lighttpd参考以下配置，设置Cookie。 12345server.modules = ( "mod_setenv" )$HTTP["host"] == "test.example.com" &#123; server.document-root = "/var/www/html/" setenv.add-response-header = ( "Set-Cookie" =&gt; "name=XXXXXX" &#125;&#125; 扩展阅读https://cloud.tencent.com/document/product/214/2736http://blog.text.wiki/2015/08/01/nginx-sticky-problem.htmlhttps://cloud.tencent.com/developer/article/1004547]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次阿里云oss云存储删除失败的问题]]></title>
    <url>%2F2018%2F04%2F27%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E9%98%BF%E9%87%8C%E4%BA%91oss%E4%BA%91%E5%AD%98%E5%82%A8%E5%88%A0%E9%99%A4%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[公司每天云存储都要删除过期的内容，工作细节是这样的：每天零点，采集模块开始收集应该删除掉的内容，然后把这个消息传给阿里云MQ，阿里云MQ又把消息传给删除模块，删除模块拿到名单之后，开始调用阿里云OSS的删除API进行删除。架构如图： 但是今天登陆监控平台发现，昨天oss没有删除，上涨了80多个T，如图： 老板一看，卧槽这怎么可以，80多个T的云存储费用可是不容小视的，于是责令追查一下为啥会发生这样的情况。 昨天我的手机又没有收到任何阿里云消息队列告警的信息，可见MQ应该是没问题的，查看一下是否有MQ的产生和消费情况，如下图： 产生的消息基本都消费掉了，由此推断之前的过程都应该是OK的。再查看一下会不会是删除模块外网带宽到期的问题，此时发现两天的流量有显著的不同： 流量明显减少，可以说是删除模块执行任务少了。于是到执行OSS删除API的模块上去抓了几个包，里面情况如下： 但是跑到阿里云对应的bucket里看一下文件情况，比如https://lechangecloud.oss-cn-hangzhou.aliyuncs.com/lechange/4B01F1FPAGE4E9D_img/Alarm/20180427000913997_0_fa62bec6dee24cc0bee42e1ee3e75743_thumb_qcif.dav这个文件，这个文件明明还在里面躺着好好的。如图： 文件00：27的时候就在了，但是2：53分的时候调用阿里云OSS的API去删除，明明返回了200，但是文件却没有真正的从OSS删除掉。 我觉得这样就拿去跟阿里云撕逼还是有点不太妥当，又回到刚刚的那个包里，我发现里面还有一些返回的内容是这样的： 这个图跟之前的图明显路径上不同，而这些文件在OSS上确认是被成功删除掉的，可见的确是文件路径的问题：失败的文件路径是完全路径，而成功的都是相对路径。于是就告诉开发赶快整改代码，把路径统一…]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在安装docker私有仓库的时候遇到的openssl问题]]></title>
    <url>%2F2018%2F04%2F21%2F%E5%9C%A8%E5%AE%89%E8%A3%85docker%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E7%9A%84%E6%97%B6%E5%80%99%E9%81%87%E5%88%B0%E7%9A%84openssl%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[按照http://wiki.jikexueyuan.com/project/docker-technology-and-combat/local_repo.html 的方法本地安装一个私有仓库，在执行sudo pip install docker-registry这一步的时候，出现了这样的一个错误： 既然说我没有swig，于是我yum install swig -y，安装的是2.0.10-5.el7版本。然后再次pip install docker-registry，一顿噼里啪啦之后，这次成了这样： 又说没有openssl的文件，那执行yum install openssl-devel，OK了之后再次pip install docker-registry，再一次噼里啪啦，如下： 反馈我：/usr/include/openssl/opensslconf.h:44: Error: CPP #error &quot;&quot;This openssl-devel package does not work your architecture?&quot;&quot;. Use the -cpperraswarn option to continue swig processing.,这个提示大意是说openssl-devel版本不适合你的系统架构，也就是x86的去找x86的头文件，x86_64的去找x86_64文件，但现在是互相找不到对方。 既然说/usr/include/openssl/opensslconf.h这个第44行有错误，那我们就打开这个文件去看看第44行写的是啥： 123456741 #elif defined(__x86_64__)42 #include "opensslconf-x86_64.h"43 #else44 #error "This openssl-devel package does not work your architecture?"45 #endif46 47 #undef openssl_opensslconf_multilib_redirection_h 这里我把第44行改成了这样： 123456741 #elif defined(__x86_64__)42 #include &quot;opensslconf-x86_64.h&quot;43 #else44 #include &quot;opensslconf.h&quot; #去掉了原来的error提示，改成了安装opensslconf.h文件。45 #endif46 47 #undef openssl_opensslconf_multilib_redirection_h 这一次重新执行sudo pip install docker-registry，终于成功…]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在国王杯前夕评巴萨]]></title>
    <url>%2F2018%2F04%2F21%2F%E5%9C%A8%E5%9B%BD%E7%8E%8B%E6%9D%AF%E5%89%8D%E5%A4%95%E8%AF%84%E5%B7%B4%E8%90%A8%2F</url>
    <content type="text"><![CDATA[今天凌晨的马竞在西甲意外输给了皇家社会，巴萨的积分优势扩大到了12分。这个周末巴萨要跟塞维利亚打国王杯决赛，4月30号对拉科鲁尼亚的西甲联赛巴萨只要获胜，就会拿到今年的西甲联赛冠军，从而以冠军姿态在诺坎普迎接本赛季第二场国家德比。 巴尔韦德的困境巴萨今年可以说是低姿态开始：从内马尔突然的离开到西超杯被皇马灌了5个，不可为说不惨。但是巴尔韦德在联赛却目前保持不败，这个成绩单可以说是相当不错的，这中间还有在伯纳乌的三球胜利。 赛季中前段，巴萨三线顺风顺水，前有塞梅多惊艳开场，后有大祭司维尔马伦扎实顶上，主教练巴尔韦德也给了阿奈斯这样小将出场机会，哪怕登贝莱那时候养伤，报纸媒体一片其乐融融。如果保利尼奥再有进球，更是一片狂欢。 然后巴尔韦德的保守开始慢慢让人所诟病，他是一个重视防守的教练，这很好，但是他有了库迪尼奥也有了归来的登贝莱，结果反而不敢搞轮换，甚至坚持让布教授打封闭出场，虽然不少人抱怨，但是由于球队整体战绩还算平稳，所以没有大规模的重视。可是巴萨欧冠的结果跟恩里克的第二个赛季一样，倒在了与罗马的第二回合比赛里，连续三年没有闯入欧冠四强。 其实对战罗马的第一回合，巴萨的4：1已经是靠意志拼下来的比赛，球员难免在第二回合的心态上有所轻敌，这种心态上的轻敌难免会影响到身体，但是巴尔韦德的临场指挥也让人严重不满。落下这耻辱一战，媒体和球迷之前的“忍气吞声”一并爆发，狂轰滥炸，直到现在依旧有人说“哪怕真的赛季双冠，也会因为欧冠的失利而让那两冠索然无味”。 所以，巴尔韦德要在这个周日的国王杯决赛和对阵拉科鲁尼亚的西甲联赛里稳扎稳打，把国王杯和西甲冠军彻底拿到手里，这样整个人也能轻松一些。可是说来说去罗马一役这一个跟头摔得太疼了，在那么重大的比赛里失败，肯定需要在一个同样重大的比赛里胜利以挽回颜面，第二回合的国家德比无疑就是一个好的机会，如果巴尔韦德成功捍卫了诺坎普，“联赛双杀皇马+国内双冠”也能成为一个功劳。但是如果那场比赛，一心要打破巴萨不败金身的皇马真的成功了，那巴尔韦德势必在巴萨主帅的位置上也是飘摇。 所以巴帅，请务必要拿下国王杯冠军+西甲冠军！在第二个国家德比里也请拼尽全力！这样才能多少挽回一点“罗马之耻”的颜面。 夏季转会展望我个人认为，巴萨很有可能在今年夏天卖掉如下几个人：西莱森、戈麦斯、小苏亚雷斯、艾尔卡塞尔、比达尔，自由走人的可能会是小白。这些人能套现7000万应该就满足了。 巴萨后卫现在四个人皮克和维尔马伦属于潜藏的伤员病号，米纳技术还是太糙，稍微让人放心的就是乌姆蒂蒂，他的续约问题肯定是休赛期的一个大事。不过我觉得米纳其实可以再留一年看看，他身体素质很好，而且人还年轻没伤病，只要心态练得沉稳，当一个合格的中后卫不难。 至于中场，个人希望小白再踢一年，现在我也觉得一个满血的小白应付普通的联赛、欧冠小组赛和杯赛都不是什么难事。但是目前的媒体趋势是小白赛季结束会来中超重庆队，即使这样巴萨也需要一个山寨的坎特和一个山寨的埃里克森，而罗贝托集这两个属性于一身，所以他就是一个“奉献的砖”，但是这样如果比达尔真的不留下来的话，巴萨还需要补进一个右后卫跟塞梅多良性竞争，这个右后卫的人选就比较挠头了。贝莱林？或许是一个选择，但是这个选择跟当年小法一样—要是双输就不好了。 前场如果能拿下格里兹曼肯定是好的，艾尔卡塞尔这种“躲着后卫”的踢法，虽然进球效率可以，但是没有真正起到轮换苏亚雷斯的作用。这样巴萨还需要在板凳上补充一个中锋（不用多能进球，哪怕搅屎棍也可以），同时也做好登贝莱/苏亚雷斯/梅西/格里兹曼（假设他真的来）的轮换。 总而言之，现在巴萨还是回归433比较好，配合442和4312的变化。那么休赛期最重要的补强就是格里兹曼+能抗中卫的前锋+一个中场+一个优秀的边后卫。 我个人希望的引援名单如下：中场是魏格尔和B队的阿莱尼亚，埃里克森、博格巴和维拉蒂这三个不算是好的选择，要么太贵，要么节奏太慢。至于伊斯科、大卫席尔瓦、皮亚尼奇，那想都别想了，母队不会放人的。至于格雷茨卡，拜仁不是善茬；边后卫可以考虑贝莱林，这个要看一下阿森纳的新教练是谁，摩纳哥的法比尼奥也可以，我知道他现在改中场了，也不耽误来一下跟罗贝托交叉换位…前锋的话，我个人推荐B队阿奈斯试试看，其他的人选估计就是在西甲联赛内部找了；这几个位置，最重要就是中场！梅西当初在哈白布的配合下威力无穷，一旦巴萨的中场重新掌握了控制力，不用频繁回撤的梅西依旧会进球如麻，这一点毋庸置疑。 温格会来？我个人首先不希望巴尔韦德下课，毕竟现在巴萨联赛冠军十拿九稳，国王杯如果也揽入怀中，这样一个成绩单也是一个80分，如果这个分数都炒掉主教练，那么继任者的压力势必很大，所以我个人倾向巴尔韦德留任，好好想一下，等阿图尔以及可能会来的格里兹曼到位了，巴萨应该怎么打。 不过如果温格真的来了，我个人也是赞成的，因为阿森纳的球风本来跟巴萨相似，相信温格跟梅西等人也会无缝接入，到时候教授或许真的可以在巴萨圆了欧冠梦想，不过这个想法成真的可能性低于5%，想想就得了。 下赛季的任务1.进攻体系依旧围绕梅西建队，让梅西继续火力全开的同时保证休息，欧冠要他有大用；2.新球员（包括库蒂尼奥和登贝莱）适应巴萨的风格和体系，让皮克和布教授也能轮换得到休息；3.欧冠一定要进入四强；4.欧冠四强的基础上，西甲联赛冠军和国王杯能拿还是要拿，同时最好也能阻击皇马；]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>国际足坛</tag>
        <tag>巴塞罗那</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[国内Docker的加速方法]]></title>
    <url>%2F2018%2F04%2F20%2F%E5%9B%BD%E5%86%85Docker%E7%9A%84%E5%8A%A0%E9%80%9F%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[由于大陆政府的特殊政策，国内想访问一些国外的资源是非常的曲折和痛苦，比较有代表性的就是亚马逊的云存储以及docker，尤其在docker pull一些镜像的时候，更是心惊胆战，祈求不要出现timout，然而现实往往很骨感。如下图： 那么应该如何达到加速的效果呢？ 在CentOS 7里，对于使用systemd的系统，请在/etc/docker/daemon.json中写入如下内容：（如果文件不存在请新建该文件） 12345&#123; "registry-mirrors": [ "https://registry.docker-cn.com" ]&#125; 注意，一定要保证该文件符合 json 规范，否则 Docker 将不能启动。 之后重新启动服务。 12$ sudo systemctl daemon-reload$ sudo systemctl restart docker 注意：如果您之前查看旧教程，修改了docker.service文件内容，请去掉您添加的内容（–registry-mirror=https://registry.docker-cn.com）。 配置加速之后，如果拉取镜像仍然十分缓慢，请手动检查加速器配置是否生效，在命令行执行docker info |grep &#39;Registry Mirrors&#39; -A，如果从结果中看到了如下内容，说明配置成功。 现在再重新尝试一下docker pull training/webapp，看看效果： 仅用17秒就pull了几乎400MB的镜像，高下立判！]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Grafana里添加worldping插件]]></title>
    <url>%2F2018%2F04%2F19%2F%E5%9C%A8Grafana%E9%87%8C%E6%B7%BB%E5%8A%A0worldping%E6%8F%92%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[安装插件worldping是一个监控网站的dns、ping、http响应、https响应的插件，要安装它很简单，在granafa服务器里执行如下命令： 12grafana-cli plugins install raintank-worldping-appsystemctl restart grafana-server.service 执行完毕之后在grafana的界面里选择Plugins，然后在APP里找到worldping，启动它，但是此时发现需要一个api，如图： 此时你需要登录grafana的官网，然后点击api keys和ADD API KEY，就可以生成一个API KEY，名字可以随便起，如下： 将生成的api key保存好，并且填回到grafana的api key里，这样worldping插件就可以使用了，如图： 监控网站节点此时点击黄色旋涡，发现多了worldping的选项，点击worldping Home，如图： 然后点击+ New Endpoint，这里我输入我公司的官网域名，然后begin auto-discovery，如图： 生成了结果之后，点击add，此时开始检查几个大城市，如芝加哥、东京、纽约、巴黎等大城市连接到刚刚输入的域名的情况，如图： 大约需要1~2分钟后，数据检查完成，可以点击GO to Summary Dashboard，就会看到图像了： 为什么我这个图里没有http?因为在nginx里我们做了http强制rewrite跳转到https，所以是读不到值的。 删除网站节点如果要删除网站节点，还是在worldping里点击要删除网站后面的齿轮图标，如图： 然后选择configuration，这里可以修改网站域名，要删除的话，选择最下面的destory，输入DELETE确认，然后就可以点击DELETE删除了，如图：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>grafana</tag>
        <tag>图像监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用非root用户启动tomcat进程]]></title>
    <url>%2F2018%2F04%2F18%2F%E4%BD%BF%E7%94%A8%E6%99%AE%E9%80%9A%E7%94%A8%E6%88%B7%E5%90%AF%E5%8A%A8tomcat%2F</url>
    <content type="text"><![CDATA[使用非root用户启动进程是运维安全的一个主要环节，拿tomcat进程来说，如果是使用root用户去启动了tomcat，那么有一个严重的问题，那就是tomcat具有root权限。这意味着你的任何一个jsp脚本都具有root权限，所以那些不怀好意的人可以轻易地用jsp脚本去搞破坏，甚至删除你整个硬盘里的东西！所以为了活着，我们要极力避免这种现象。很多的软件都自带的用户/用户组，比如nginx、zabbix、elasticsearch，但是也有很多的软件没有这么贴心的服务，这就需要我们手动的更改了。 使用非root用户启动tomcat以tomcat为例，打算用chris账号(属于chen这个group)启动。那么首先先创建账号和组，如下： 12345[root@chen-docker ~]groupadd chen #创建chen这个组[root@chen-docker ~]useradd -s /bin/bash -g chen chris #在这个组里面添加chris这个用户[root@chen-docker ~]passwd chris #给这个用户设定密码[root@chen-docker ~]# id chrisuid=1000(chris) gid=1002(chen) groups=1002(chen) #可见添加成功 su chris切换到chris用户，在/home/chris里使用wget http://apache.fayea.com/tomcat/tomcat-9/v9.0.7/bin/apache-tomcat-9.0.7.tar.gz下载tomcat。然后解压缩在/home/chris里，因为chris用户在这里是有权限的。然后进行如下的操作： 12345cd ~/ 代表用户所在目录mkdir -p ~/shell-scriptcd ~/shell-script/touch start.shtoush stop.sh 这个start.sh的内容很简单，如下： 12345678#/bin/bashif [ "root" == "$USER" ] #不让root启动then echo "can't start with user 'root',retry after change user!" exit 1else cd /home/chris/apache-tomcat-9.0.7/bin/ &amp;&amp; ./start.shfi shutdown.sh的内容同理： 12345678#/bin/bashif [ "root" == "$USER" ] #不让root启动then echo "can't start with user 'root',retry after change user!" exit 1else cd /home/chris/apache-tomcat-9.0.7/bin/ &amp;&amp; ./shutdown.shfi chmod +x *.sh给上面两个脚本可执行权限，但是现在执行startup.sh或者shutdown.sh会出现一个问题： 12Neither the JAVA_HOME nor the JRE_HOME environment variable is definedAt least one of these environment variable is needed to run this program 这是因为chris用户没有权限去启动java这个可执行程序，如果使用java -version回答是bash: java: command not found，这个时候怎么办？ 编辑~/.bash_profile，在末尾处加上如下的内容： 然后source .bash_profile，再使用java -version确认一下应该是OK了。这个时候也是可以使用chris用户去启动刚刚的那个start.sh和shutdown.sh的。 由于我们的tomcat是源码解压缩，所以要使用root用户去创建一下/etc/init.d/tomcat。里面内容如下： 123456789#!/bin/bashcase $1 instart)su - chris -lc "sh /home/chris/shell-script/start.sh";; #如果要root启动，那就是su - root -lc "sh /home/utomcat/shell-script/start.sh";;stop)su - chris -lc "sh /home/chris/shell-script/shutdown.sh";;*)echo "parameter error, usage:(start|stop)";;esac 保存之后，执行一下service tomcat start看看效果。 如果要设置开机自启动，别忘了chkconfig --add tomcat和chkconfig tomcat on，在浏览器打开ip:8080看见汤姆猫~ 当普通用户要使用1024以下的端口众所周知，linux默认是不准许普通用户调用1024以下的端口的，那么遇到这样的需求怎么办呢？最好的方法是使用iptables。 首先让程序运行在非root帐户下，并绑定高于1024的端口，在确保能正常工作的时候，将低端口通过端口转发，将低端口转到高端口，从而实现非root运行的程序绑定低端口。要使用此方法可以使用下面的方式： 1234sysctl -w net.ipv4.ip_forward=1 #要长久保存，需要在/etc/sysctl.conf文件内修改，然后sysctl -p /etc/sysctl.confiptables -F -t natiptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to:8088 #将80端口转发到8088iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 8080 #这句话也可以 这么操作在速度上没有任何影响。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>centos</tag>
        <tag>运维安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[用非root启动进程以及启动docker]]></title>
    <url>%2F2018%2F04%2F18%2F%E7%94%A8%E9%9D%9Eroot%E5%90%AF%E5%8A%A8%E8%BF%9B%E7%A8%8B%E4%BB%A5%E5%8F%8A%E5%90%AF%E5%8A%A8docker%2F</url>
    <content type="text"><![CDATA[使用非root用户启动普通进程使用非root用户启动进程是运维安全的一个主要环节，拿tomcat进程来说，如果是使用root用户去启动了tomcat，那么有一个严重的问题，那就是tomcat具有root权限。这意味着你的任何一个jsp脚本都具有root权限，所以那些不怀好意的人可以轻易地用jsp脚本去搞破坏，甚至删除你整个硬盘里的东西！所以为了活着，我们要极力避免这种现象。 很多的软件都自带的用户/用户组，比如nginx、zabbix、elasticsearch，但是也有更多的软件没有这么贴心的服务，这就需要我们手动的更改了。 docker不应该使用root启动1.8版本之前的docker是不支持user namespace的，所以那样的话，如果在docker容器内部使用root运行app，那么不可否认，这个root和宿主机的root是同一个UID。但是，需要特别注意的是，容器内的root与宿主机上的root权限并不一定是相等的。 但是为了绝对的安全，还是推荐把docker升级到1.8以上，然后彻底避免用root去启动容器，在http://www.projectatomic.io/docs/docker-image-author-guidance/里最下面一段也明文说了---生产环境里不要用root用户去启动docker!!! 使用非root用户启动docker的办法如下：创建docker组：sudo groupadd docker将当前用户加入docker组：sudo gpasswd -a ${USER} docker重新启动docker服务：sudo service docker restart或sudo systemctl restart docker当前用户退出系统再重新登陆。 参考资料https://www.zhihu.com/question/25580965]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>安全</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用docker做一个主从同步的redis集群]]></title>
    <url>%2F2018%2F04%2F18%2F%E4%BD%BF%E7%94%A8docker%E5%81%9A%E4%B8%80%E4%B8%AA%E4%B8%BB%E4%BB%8E%E5%90%8C%E6%AD%A5%E7%9A%84redis%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[查看容器内部信息之前用docker run -it --name redis-master redis /bin/bash创建了一个redis的docker，现在登陆发现状态已经是exit，于是就使用docker container start 容器ID号or容器名称来重新启动。如图： 然后书里说到要用docker inspect来查看所挂载volume的情况，使用命令: 1[root@chen-docker ~]# docker inspect --format &quot;&#123;&#123; .Volumes &#125;&#125;&quot; f391531120b0 但是很不幸，系统反馈给我一个错误： 1Template parsing error: template: :1:3: executing &quot;&quot; at &lt;.Volumes&gt;: map has no entry for key &quot;Volumes&quot; 没有这个Volumes，那就干脆查看一下这个容器的所有信息：docker inspect f391531120b0，这个命令里面有Config、Mounts、HostConfig、NetworkSettings等等整个容器的所有信息，比如看一下NetworkSettings相关的内容，如图： 此时使用如下命令： 1234[root@chen-docker ~]# docker inspect --format &quot;&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;&quot; f391531120b0 #注意前面的.192.168.0.2[root@chen-docker ~]# docker inspect --format &quot;&#123;&#123; .NetworkSettings.MacAddress &#125;&#125;&quot; f391531120b002:42:c0:a8:00:02 这样就可以获取到内网IP和mac地址，同理换成docker inspect f391531120b0 | grep Mounts -A 10，看一下挂载信息，如图： 原来容器里的/data其实就是宿主机的/var/lib/docker/volumes/94b3c20a6d269c7498ab59ee45c560e84fed64a636767a4baa54fa7befbcd4ff/_data这个文件夹。为了验证这一点，我先到宿主机去创建一个叫aaa文件，如下： 12root@f391531120b0:/data# cat aaa 123123 再返回到宿主机上看： 12345[root@chen-docker ~]# cd /var/lib/docker/volumes/94b3c20a6d269c7498ab59ee45c560e84fed64a636767a4baa54fa7befbcd4ff/_data[root@chen-docker _data]# lsaaa[root@chen-docker _data]# cat aaa 123123 这就搞定了！ 主从同步排错就是按书里写的开始配置和启动redis-slave，但是却发现同步没有成功，在redis-slave日志里发现这样的话： 12332677:S 08 Feb 16:14:40.952 * Connecting to MASTER 172.168.10.70:637932677:S 08 Feb 16:14:40.952 * MASTER &lt;-&gt; SLAVE sync started32677:S 08 Feb 16:14:40.953 # Error condition on socket for SYNC: Connection refused 这个的原因就是redis主服务器绑定了127.0.0.1，那么跨服务器IP的访问就会失败，从服务器用IP和端口访问主的时候，主服务器发现本机6379端口绑在了127.0.0.1上，也就是只能本机才能访问，外部请求会被过滤。所以需要修改redis-master的redis.conf，注释掉bind 127.0.0.1，如果是线上生产环境建议绑定IP地址。 重新启动redis之后，发现同步依然失败，日志变成了这样： 12345690:S 17 Apr 09:27:35.906 * Non blocking connect for SYNC fired the event.90:S 17 Apr 09:27:35.907 # Error reply to PING from master: &apos;-DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect&apos;90:S 17 Apr 09:27:36.908 * Connecting to MASTER 192.168.0.2:637990:S 17 Apr 09:27:36.909 * MASTER &lt;-&gt; SLAVE sync started90:S 17 Apr 09:27:36.909 * Non blocking connect for SYNC fired the event.90:S 17 Apr 09:27:36.909 # Error condition on socket for SYNC: Connection reset by peer 这个日志的意思是说redis在没有开启bind和密码的情况下，保护模式被开启。然后Redis的只接受来自环回IPv4和IPv6地址的连接。于是还是要修改redis-master的redis.conf关闭保护模式：portected-mode no，然后重启redis-master即可。 容器内安装ping先检查你的容器是使用什么系统的景象，如果是ubantu那就是apt-get，安装ping的命令如下： 12apt-get updateapt-get install inetutils-ping 如何让容器一直启动如果用了一段时间的docker就会发现，我们的容器经常用了一段时间就自动退出了，docker ps已经找不到了，在docker ps -a里面了，如图： 然后我们docker start containerId想重新开启这个容器，可能这次来的更快，没几分钟容器又自己关了，由这个问题又可能引发其它很多的问题。 docker run指定的命令如果不是那些一直挂起的命令（比如运行top，不断echo），就是会自动退出的。-d命令是设置detach为true，根据官方的文档，意思是让这个命令在后台运行，但并不是一直运行，Docker容器后台运行,就必须有一个前台进程。主线程结束，容器会退出。 我们启动容器的时候不要-d命令启动，用-dit就好了，例如： 12docker run -d hello-world(不要这么做)docker run -dit hello-world(推荐)]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>redis</tag>
        <tag>主从同步</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用zabbix监控memcache]]></title>
    <url>%2F2018%2F04%2F03%2F%E4%BD%BF%E7%94%A8zabbix%E7%9B%91%E6%8E%A7memcache%2F</url>
    <content type="text"><![CDATA[监控memcache的原理跟监控redis差不多，都是通过一个类似info的东西可以查询到memcache的状态值，然后通过脚本去获取这些值给zabbix，当发现某值不正常就发出告警。 查询当年memcache状态的命令是echo stats |nc 127.0.0.1 11211，如果没有nc命令，那就yum install -y nc。 获得到的结果是这个样子的： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@lconline-ec2 ~]# echo stats |nc 127.0.0.1 11211STAT pid 1859 memcache服务进程IDSTAT uptime 491093 服务器已运行秒数STAT time 1522740969 服务器当前Unix时间戳STAT version 1.4.25 memcache版本STAT libevent 1.4.13-stableSTAT pointer_size 64 操作系统指针大小STAT rusage_user 14.321822 进程累计用户时间STAT rusage_system 14.095857 进程累计系统时间STAT curr_connections 5 当前连接数量STAT total_connections 51010 Memcached运行以来连接总数STAT connection_structures 8 Memcached分配的连接结构数量STAT reserved_fds 20STAT cmd_get 0 get命令请求次数STAT cmd_set 0 set命令请求次数STAT cmd_flush 0 flush命令请求次数STAT cmd_touch 0 touch命令请求次数STAT get_hits 0 get命令命中次数STAT get_misses 0 get命令未命中次数STAT delete_misses 0 delete命令未命中次数STAT delete_hits 0 delete命令命中次数STAT incr_misses 0 incr命令未命中次数STAT incr_hits 0 incr命令命中次数STAT decr_misses 0 decr命令未命中次数STAT decr_hits 0 decr命令命中次数STAT cas_misses 0 cas命令未命中次数STAT cas_hits 0 cas命令命中次数STAT cas_badval 0 使用擦拭次数STAT touch_hits 0STAT touch_misses 0STAT auth_cmds 0 认证命令处理的次数 STAT auth_errors 0 认证失败数目STAT bytes_read 357040 读取总字节数 STAT bytes_written 60197691 发送总字节数STAT limit_maxbytes 1073741824 分配的内存总大小（字节）STAT accepting_conns 1 服务器是否达到过最大连接（0/1）STAT listen_disabled_num 0 失效的监听数STAT time_in_listen_disabled_us 0STAT threads 4 当前线程数STAT conn_yields 0 连接操作主动放弃数目STAT hash_power_level 16STAT hash_bytes 524288 当前存储占用的字节数STAT hash_is_expanding 0STAT malloc_fails 0 STAT bytes 0 当前存储占用的字节数STAT curr_items 0 当前存储的数据总数STAT total_items 0 启动以来存储的数据总数STAT expired_unfetched 0 STAT evicted_unfetched 0STAT evictions 0 LRU释放的对象数目STAT reclaimed 0 已过期的数据条目来存储新数据的数目STAT crawler_reclaimed 0STAT crawler_items_checked 0STAT lrutail_reflocked 0 END 修改zabbix_agentd.conf，添加一个新的自定义项： 1UserParameter=memcached.stat[*],(echo stats; sleep 1) | telnet 127.0.0.1 11211 2&gt;&amp;1 | awk '/STAT $1 / &#123;print $NF&#125;' 然后重启zabbix-agent，模板就用github里的就好，看到的效果如下：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>memcached</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用zabbix去监控网站和tcp连接]]></title>
    <url>%2F2018%2F04%2F02%2F%E4%BD%BF%E7%94%A8zabbix%E5%8E%BB%E7%9B%91%E6%8E%A7%E7%BD%91%E7%AB%99%2F</url>
    <content type="text"><![CDATA[网页状态码监控在zabbix的web界面，配置–主机–选择一个有外网权限的服务器，比如选择zabbix server–Web检测，如图： 然后点击右上角的创建Web场景，然后依次填入名称，间隔，客户端等等，如图： 然后编辑步骤，先添加，填入对应的url，然后写上200状态码，意思就是返回200是OK的。保存即可，如果还有http认证，那么就继续填写认证。 至此，一个简单的监控官网状态码的配置过程就结束了，剩下就是增添一下触发器，如下： tcp连接监控首先在zabbix-agentd.conf里添加一个新的自定义监控项： 1UserParameter=tcp.status[*],netstat -a | awk '/^tcp/ &#123;++y[$NF]&#125; END &#123;for(i in y) print i,y[i]&#125;' | grep $1 | awk '&#123;print $NF&#125;' 然后service zabbix-agent restart重启客户端，模板就是https://gitee.com/careyjike_173/zabbix/tree/master/template 里的zbx_tcp_status_templates.xml，直接导入即可。如图： 然后自己配置一下time_wait/close_wait的告警阈值。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>web监控</tag>
        <tag>tcp连接</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用zabbix去监控php-fpm]]></title>
    <url>%2F2018%2F04%2F02%2F%E4%BD%BF%E7%94%A8zabbix%E5%8E%BB%E7%9B%91%E6%8E%A7php-fpm%2F</url>
    <content type="text"><![CDATA[开启状态统计nginx有一个status来获取nginx处理信息的总览情况，php-fpm也有一个状态统计。要打开这个状态统计，需要先打开php-fpm.conf，将pm.status_path = /status前面的注释去掉。 然后跑到nginx里，在nginx.conf里添加一个location： 1234567 location ~ ^/(status|ping) &#123; fastcgi_pass 127.0.0.1:9000; include fastcgi.conf; access_log off; allow 127.0.0.1; deny all;&#125; 然后重启一下php-fpm和nginx，在命令行里输入curl -s http://127.0.0.1:80/status，就会看到php的状态统计，如下图： php-fpm status详解pool - fpm池子名称，大多数为wwwprocess manager – 进程管理方式,值：static, dynamicstart time– 启动日期,如果reload了php-fpm，时间会更新start since – 运行时长accepted conn – 当前池子接受的请求数listen queue – 请求等待队列，如果这个值不为0，那么要增加FPM的进程数量max listen queue – 请求等待队列最高的数量listen queue len – socket等待队列长度idle processes – 空闲进程数量active processes – 活跃进程数量total processes – 总进程数量max active processes – 最大的活跃进程数量（FPM启动开始算）max children reached - 大道进程最大数量限制的次数，如果这个数量不为0，那说明你的最大进程数量太小了，请改大一点。slow requests – 启用了php-fpm slow-log，缓慢请求的数量 配置监控跑到zabbix-agentd.conf里添加一个自定义监控项，如下： 1UserParameter=php-fpm.status[*],/usr/bin/curl -s "http://127.0.0.1/php-fpm_status?xml" | grep "&lt;$1&gt;" | awk -F'&gt;|&lt;' '&#123; print $$3&#125;' 然后重启一下zabbix-agent，模板就是https://gitee.com/careyjike_173/zabbix/tree/master/template 里的zbx_php-fpm_templates.xml，直接导入即可！ 效果如下图： 没有监控到进程？zabbix有时候会在监控进程出现不太准的情况，比如我这个机器的php。配置了proc.num[php-fpm,,,]这个key，但是在zabbix-server死活都取不到值，如图： 但是在被监控机器里，进程是明明存在的： 这特么的是为啥？ 这就是因为proc.num[进程名,,,]里面的进程名是在/proc/进程PID/status里的name一栏获得的，比如我这个机器的php情况： name里写的是php-fpm56，所以key也要改成proc.num[php-fpm56,,,]，这个时候在zabbix-server就成功取值了，如图： 注意！/proc/进程PID/status的name会被截断为15个字符。所以在配置时要事前检查一下。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>php-fpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用zabbix去监控nginx]]></title>
    <url>%2F2018%2F04%2F02%2F%E4%BD%BF%E7%94%A8zabbix%E5%8E%BB%E7%9B%91%E6%8E%A7nginx%2F</url>
    <content type="text"><![CDATA[准备工作zabbix监控nginx，首先要确认nginx里是否有http_stub_status_module这个模块，一般来说，这个模块是自动安装的，nginx -V如下图： 如果你的nginx没有这个模块，请去看https://rorschachchan.github.io/2018/01/03/Nginx动态编译新的模块/ 。 然后在nginx.conf里添加一段话： 1234 location = /nginx-status &#123; stub_status on; access_log off;&#125; nginx -s reload一下，然后在命令行输入curl http://127.0.0.1/nginx-status，就会看到如下的界面： 这样就可以通过http_stub_status_module检查nginx情况了！ nginx status详解以上图的nginx status来做例子说明一下各个数字的意思：active connections – 活跃的连接数量accepts — 总共处理了3832000个连接handled — 成功创建3832000次握手requests — 总共处理了3295877个请求reading — 读取客户端的连接数writing — 响应数据到客户端的数量waiting — 开启keep-alive的情况下,这个值等于active – (reading+writing), 意思就是 Nginx 已经处理完正在等候下一次请求指令的驻留连接 配置监控有了模块，还需要添加一个脚本，然后就可以获取上面的数值了，脚本如下： 1234567891011121314151617181920212223242526272829303132#!/bin/bash# Method of useHOST="127.0.0.1"PORT="80" #这个根据实际情况填写URL="http://$&#123;HOST&#125;:$&#123;PORT&#125;/nginx-status"active() &#123; curl "$&#123;URL&#125;" 2&gt;/dev/null | grep "Active" | awk '&#123;print $NF&#125;'&#125;reading() &#123; curl "$&#123;URL&#125;" 2&gt;/dev/null | grep "Reading" | awk '&#123;print $2&#125;'&#125;writing() &#123; curl "$&#123;URL&#125;" 2&gt;/dev/null | grep "Writing" | awk '&#123;print $4&#125;'&#125;waiting() &#123; curl "$&#123;URL&#125;" 2&gt;/dev/null | grep "Waiting" | awk '&#123;print $NF&#125;'&#125;accepts() &#123; curl "$&#123;URL&#125;" 2&gt;/dev/null | awk NR==3 | awk '&#123;print $1&#125;'&#125;handled() &#123; curl "$&#123;URL&#125;" 2&gt;/dev/null | awk NR==3 | awk '&#123;print $2&#125;'&#125;requests() &#123; curl "$&#123;URL&#125;" 2&gt;/dev/null | awk NR==3 | awk '&#123;print $NF&#125;'&#125;ping() &#123; ps -ef | grep nginx | grep -v grep -c&#125;$1 然后再去zabbix_agentd.conf里添加一句话: 1UserParameter=nginx.status[*],/usr/local/zabbix/script/nginx_status.sh $1 然后service zabbix-agent restart，自定义项就搞定了。 如果要导入模板，https://gitee.com/careyjike_173/zabbix 这个朋友的模板已经非常全面了，根据实际情况修改之后再导入他的xml就好，感谢前人付出！]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[金山云api调用的几个例子]]></title>
    <url>%2F2018%2F03%2F29%2F%E9%87%91%E5%B1%B1%E4%BA%91api%E8%B0%83%E7%94%A8%E7%9A%84%E4%B8%A4%E4%B8%AA%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[今天另外一个运维要看一下金山云API返回的格式，于是就临时写了两个demo，也顺便记录下来，说不定以后开发脚本的时候可能用的着。 金山云跟阿里云的sdk不一样，阿里云有一个总的sdk，然后不同的服务还需要去分别下载对应具体的sdk；而金山的不是，他绝大多数的服务都是用那个总sdk。 查询数据库的脚本需要先获取https://github.com/kscdb/krds_openapi_sdk.git，然后执行python setup.py install安装所用的金山库。 这个脚本是查询某个数据库的具体情况： 脚本如下： 1234567891011121314#!/usr/bin/env python# -*- encoding:utf-8 -*-from kscore.session import get_sessionfrom krds_client import *#密钥ACCESS_KEY_ID = "这里填写ak"SECRET_ACCESS_KEY = "这里填写sk"#连接s = get_session()krds_client = KRDSClient(ACCESS_KEY_ID, SECRET_ACCESS_KEY, '地域名')r = krds_client.DescribeDBInstances(DBInstanceIdentifier='5c664b16-fbfe-4373-8a00-67c9476e7386',DBInstanceType='HA') #DBInstanceIdentifier后面是实例IDprint r 执行脚本之后，可以看到返回的结果包括数据库里很多的资料，如图： 如果不加参数的话，就是返回账号内所有的数据库情况。 查询服务器的脚本需要先获取https://github.com/KscSDK/ksc-sdk-python.git，然后执行python setup.py install安装所用的金山库。 这个脚本是查询下面这个服务器的情况： 脚本如下： 123456789101112#!/usr/bin/env python# -*- encoding:utf-8 -*-from kscore.session import get_session#密钥ACCESS_KEY_ID = "这里填写ak"SECRET_ACCESS_KEY = "这里填写sk"#连接s = get_session()client = s.create_client("kec", "地域名", use_ssl=True,ks_access_key_id=ACCESS_KEY_ID, ks_secret_access_key=SECRET_ACCESS_KEY)print client.describe_instances(Search=['js-online-hlsproxy-20']) #Search后面接实例名 执行脚本之后，可以看到返回的结果包括数据库里很多的资料，如图： 如果不加参数的话，就是返回账号内所有的服务器情况。 弹性IP相关的脚本脚本如下： 12345678910111213141516171819202122#!/usr/bin/env python#coding=utf-8#这个脚本是用来修改金山云的eip带宽import json,pprintfrom kscore.session import get_session# 密钥ACCESS_KEY_ID = "这里是ak"SECRET_ACCESS_KEY = "这里是sk"s = get_session()region='cn-shanghai-2'eipClient = s.create_client("eip",region, use_ssl=False,ks_access_key_id=ACCESS_KEY_ID,ks_secret_access_key=SECRET_ACCESS_KEY)#allEips=eipClient.get_lines() #这是获取LineID#allEips=eipClient.allocate_address(LineId:"a2403858-2550-4612-850c-ea840fa343f9",BandWidth:5,ChargeType:"PostPaidByDay") #这是创建eip#print allEips#allEips=eipClient.describe_addresses(MaxResults=7) #这是查询eip，一次输出7次for line in open("/具体路径/金山云eip名单.txt"): line = line.strip('\n') #去掉回车 eipClient.modify_address(**&#123;'AllocationId':line,'BandWidth':1&#125;) #将文件里的所有的eip带宽改成1M print ("带宽已经调整完毕！") 总体来说金山云的sdk文档还是比较挫。 参考资料https://github.com/KscSDK/ksc-sdk-pythonhttps://github.com/kscdb/krds_openapi_sdk]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>金山云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用pandas来做html表格]]></title>
    <url>%2F2018%2F03%2F27%2F%E4%BD%BF%E7%94%A8pandas%E6%9D%A5%E5%81%9Ahtml%E8%A1%A8%E6%A0%BC%2F</url>
    <content type="text"><![CDATA[前言最近电子商城慢sql问题引了小BOSS的重视，于是就打算给开发们搞一个表格，在表格里可以看到前一天阿里云数据库的慢sql。这一次我不打算用html邮件了，因为慢sql数量不固定，今天可能三个，明天可能五个，后天抽风可能就一百个。而html邮件的格式是要事先写死的，于是我就用pandas来做这个表格，直接生成一个html文件，通过访问浏览器去让开发看慢sql。 慢日志脚本我要承认，阿里云自带的api在线调试工具真是一个好东西，有了它，脚本demo可以直接生成，地址是：https://api.aliyun.com/?spm=a2c4g.750001.952925.6.1QrDYe ，于是乎，阿里云获取慢日志脚本test.py如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/usr/bin/env python#coding=utf-8import json from aliyunsdkcore import clientfrom aliyunsdkrds.request.v20140815 import DescribeSlowLogRecordsRequest clt = client.AcsClient('这里是ak','这里是sk','这里是地域')# 设置参数request = DescribeSlowLogRecordsRequest.DescribeSlowLogRecordsRequest()request.set_accept_format('json')request.add_query_param('DBInstanceId', 'RDS的ID号')request.add_query_param('StartTime', '2018-03-26T08:00Z') #3月26日早上8点开始request.add_query_param('EndTime', '2018-03-27T08:00Z') #3月27日早上8点结束request.add_query_param('DBName', '对应的数据库名')request.add_query_param('PageSize', 100) #这个值只能是30/50/100# 发起请求response = clt.do_action_with_exception(request)print response#把json格式的返回值改成dict格式slow_log=json.loads(response)num = slow_log['TotalRecordCount']Hostaddress = []LockTimes = []ParseRowCounts = []QueryTimes = []SQLText = []#将有用的值做成listif num &lt; 100: for i in range(0,num): Hostaddress.append(slow_log['Items']['SQLSlowRecord'][i]['HostAddress']) LockTimes.append(slow_log['Items']['SQLSlowRecord'][i]['LockTimes']) ParseRowCounts.append(slow_log['Items']['SQLSlowRecord'][i]['ParseRowCounts']) QueryTimes.append(slow_log['Items']['SQLSlowRecord'][i]['QueryTimes']) SQLText.append(slow_log['Items']['SQLSlowRecord'][i]['SQLText'])else: for i in range(0,100): Hostaddress.append(slow_log['Items']['SQLSlowRecord'][i]['HostAddress']) LockTimes.append(slow_log['Items']['SQLSlowRecord'][i]['LockTimes']) ParseRowCounts.append(slow_log['Items']['SQLSlowRecord'][i]['ParseRowCounts']) QueryTimes.append(slow_log['Items']['SQLSlowRecord'][i]['QueryTimes']) SQLText.append(slow_log['Items']['SQLSlowRecord'][i]['SQLText']) 这个response的格式是一个json，在www.json.cn里查看是这个样子： 可以看到返回值里面TotalRecordCount就是总返回值，如果这个值大于PageSize，那么就会有第二篇，需要手动翻篇。所以我这里直接最大值就是100，一篇100已经够开发看了… 脚本如下在上面的脚本里可以获取到所有慢sql的json格式，那么就可以再写一个脚本把json转化成html格式并且生成一个html文件，然后在nginx里直接把这个文件展示出来。既然用到了pandas库，那么就要先安装pandas,方法如下： 1234pip install --upgrade pippip install pandas如果有“Please upgrade numpy to &gt;= 1.9.0 to use this pandas version”的反应，那么执行下一句pip install -U numpy 生成html的整个脚本如下： 123456789101112131415161718192021222324252627#!/usr/bin/env python#coding=utf-8from test import Hostaddress,LockTimes,ParseRowCounts,QueryTimes,SQLText #从刚写的test.py里得到那些list变量import pandas as pddef convertToHtml(result,title): #将数据转换为html的table #result是list[list1,list2]这样的结构 #title是list结构；和result一一对应。titleList[0]对应resultList[0]这样的一条数据对应html表格中的一列 d = &#123;&#125; index = 0 for t in title: d[t]=result[index] index = index+1 pd.set_option('max_colwidth',200) #默认的行长度是50，这里我调成了200 df = pd.DataFrame(d) df = df[title] h = df.to_html(index=False) return hif __name__ == '__main__': result = [Hostaddress,LockTimes,ParseRowCounts,QueryTimes,SQLText] title = [u'HostAddress',u'LockTimes',u'ParseRowCounts',u'QueryTimes',u'SQLText'] #生成一个叫biaoge.html with open('/nginxhtml路径/biaoge.html', 'w') as f: f.write(convertToHtml(result,title)) print "html文件已经生成！" 执行效果将这个biaoge.html直接生成到nginx的html文件夹里，在浏览器里打开这个html就看到效果了，如图：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>pandas</tag>
        <tag>大数据分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次nginx出现了502的问题]]></title>
    <url>%2F2018%2F03%2F26%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1nginx%E5%87%BA%E7%8E%B0%E4%BA%86502%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[背景交待市场运营在手机APP端推送了一个“家装节，部分商品优惠打折”消息，用户可以通过点击这个消息，在APP进入到商城界面，如果是已经登录的用户将通过免登陆直接跳转，如果是没有登录的用户会登陆到登陆界面。但是刚推送就发现，通过这个推送点击，没有正常登陆到商城界面，而是返回了502。 nginx 502的错误，一般来说就是php-fpm的问题，我登陆到电商服务器发现，php-fpm运行正常而且php-fpm的进程数也很正常。但是查看到mysql，发现mysql的CPU飙升，如图： 于是登陆到数据库里，使用show processlist一看，数据库里有大量的语句处于sending data状态，而且执行时间令人发指（command项处于Sleep状态的进程表示其正在等待接受查询，因此它并没有消耗任何资源，是无害的）： 先赶快通知运营先把推送的消息界面停用掉，不要让更多的用户登陆失败。然后写了一个脚本批量的kill掉这些进程，看看能不能让数据库恢复正常，过程如下。 首先先得到show processlist展现的所有的情况: 1mysql -uroot -p密码 -h数据库地址 -e "show processlist" | grep -i 'Locked' &gt; locked_log.txt 然后获得前面的进程号，并且加上kill的指令: 12345#/bin/bashfor line in `cat locked_log.txt | awk '&#123;print $1&#125;'`do echo "kill $line;" &gt;&gt; kill_thread_id.sqldone 在登陆到数据库，然后执行上面生成的kill_thread_id.sql：: 1mysql&gt;source kill_thread_id.sql 但是发现，kill掉一批之后，又有了新的慢sql出现，CPU依旧高居不下，于是只能跟产品经理说明情况，在征得了产品经理无奈的同意之后，重启了数据库，幸好时间没有很长，就耽误二三分钟而已。重启了之后，CPU就降下去了。赶快叫开发童鞋在线补充一个索引给用户登录的表来解决这个慢sql问题，没有了慢sql就没有了502。 补充nginx499nginx如果爆错499的话，代表客户端主动关闭连接，原因就是后端脚本执行的时间太长了or数据库有慢mysql，调用方超出了timeout的时间，关闭了连接。 这个时候需要更改一下nginx.conf: 12proxy_read_timeout 10s;proxy_send_timeout 10s; 把上面两个值适度调大然后重启nginx即可。或者就是proxy_ignore_client_abort on;，这话就是让代理服务端不要主动关闭客户端的连接。 参考资料https://blog.csdn.net/zhuxineli/article/details/14455029https://segmentfault.com/a/1190000012326158]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用python调用redis的基本操作]]></title>
    <url>%2F2018%2F03%2F26%2F%E4%BD%BF%E7%94%A8python%E8%B0%83%E7%94%A8redis%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[前言最近有一个需求，里面涉及到把python获取到的数值存储到redis里，于是就简单研究一下python调用redis的方法。 python要调用redis的时候，需要先安装redis模块，有两个方法。第一个方法就是pip install redis，第二个方法就是easy_install redis，模块装完之后，就可以创建redis连接了。 redis-py提供两个类Redis和StrictRedis来实现Redis的命令，StrictRedis用于实现大部分官方的命令，并使用官方的语法和命令（比如，SET命令对应与StrictRedis.set方法）。 Redis是StrictRedis的子类，用于向后兼容旧版本的redis-py。 官方推荐使用StrictRedis方法，所以我这里只说StrictRedis。 如何连接连接的代码如下： 123456789101112&gt;&gt;&gt; import redis#这里是redis的基本情况&gt;&gt;&gt; host = '这里填写redis的host地址'&gt;&gt;&gt; port = 6379 #根据实际情况更改端口&gt;&gt;&gt; password = 'redis对应的密码'#使用StrictRedis去连接到目标redis&gt;&gt;&gt; r = redis.StrictRedis(host=host, port=6379, password=password, db=0) #db为选定的数据库，db=0代表选择了0号数据库。redis默认有16个数据库，在conf里面可以配置。如果没有指定的数据库，可以不写。&gt;&gt;&gt; r.set('age', '88')&gt;&gt;&gt; r.get('age')'88' 关系型数据库都有一个连接池的概念：对于大量redis连接来说，如果使用直接连接redis的方式的话，将会造成大量的TCP的重复连接，所以，就引入连接池来解决这个问题。在使用连接池连接上redis之后，可以从该连接池里面生成连接，调用完成之后，该链接将会返还给连接池，供其他连接请求调用，这样将减少大量redis连接的执行时间，那么使用StrictRedis的连接池的实现方式如下： 12pool = redis.ConnectionPool(host=host, port=6379, password=password)r = redis.StrictRedis(connection_pool=pool 或者使用pipeline（管道），通过缓冲多条命令，然后一次性执行的方法减少服务器-客户端之间TCP数据库包，从而提高效率，方法如下： 1234567891011接上文pipe = r.pipeline()#插入数据&gt;&gt;&gt; pipe.hset("hash_key","leizhu900516",8)Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.hset("hash_key","chenhuachao",9)Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.hset("hash_key","wanger",10)Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.execute()[1L, 1L, 1L] 批量读取数据的方法如下: 123456789&gt;&gt;&gt; pipe.hget("hash_key","leizhu900516")Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.hget("hash_key","chenhuachao")Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.hget("hash_key","wanger")Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; result = pipe.execute()&gt;&gt;&gt; print result['8', '9', '10'] #有序的列表 pipeline的命令可以写在一起，如p.set(&#39;hello&#39;,&#39;redis&#39;).sadd(&#39;faz&#39;,&#39;baz&#39;).incr(&#39;num&#39;).execute()，其实它的意思等同于是： 12345&gt;&gt;&gt; p.set('hello','redis')&gt;&gt;&gt; p.sadd('faz','baz')&gt;&gt;&gt; p.incr('num')&gt;&gt;&gt; p.execute()[True, 1, 1] 利用pipeline取值3500条数据，大约需要900ms，如果配合线程or协程来使用，每秒返回1W数据是没有问题的，基本能满足大部分业务。 如何存储上面已经举了一个age：88的例子，可见创建一个string类型的key并放入value是使用set方法，比如再多存几个名字： 123456789101112131415161718192021222324&gt;&gt;&gt; r.set('name', 'lilei')True&gt;&gt;&gt; r.get('name')'lilei'&gt;&gt;&gt; r.set('name2', 'zhaowei')True&gt;&gt;&gt; r.set('name3', 'james')True&gt;&gt;&gt; r.set('name4', 'yaoming')True#列出以name开头的所有key&gt;&gt;&gt; print r.keys("name*")['name3', 'name4', 'name2', 'name']#列出所有key&gt;&gt;&gt; print r.keys()&gt;&gt;&gt; r.dbsize() #当前数据库包含多少条数据 4L&gt;&gt;&gt; r.delete('name')1&gt;&gt;&gt; r.save() #执行“检查点”操作，将数据写回磁盘。保存时阻塞True&gt;&gt;&gt; r.get('name')&gt;&gt;&gt; r.flushdb() #清空r中的所有数据True 还有其他类型的存储方法，简单举例子如下： 1234567891011121314151617#创建一个hashr.hset('abc:def', 'name', "abcde")#获取一个hash的所有值print r.hgetall('abc:def')#获取一个hash的所有key print r.hkeys('abc:def') #创建listr.sadd('abcd:ef','nihao')r.sadd('abcd:ef','hello')r.sadd('xxxx','nihao')r.sadd('xxxx','good')#打印出该key中的值 listprint r.smembers('abcd:ef')#查询两个list中相同的值print r.sinter('abcd:ef', 'xxxx')#给两个list取并集print r.sunion('abcd:ef', 'xxxx') setnx是SET if Not eXists的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。python要使用它也是r.setnx(key,value)，当发现没有这个key的时候，就会插入这个新的key以及对应的value，如果发现有了个这个key了，那这条就等于没加。 如何删除py-redis中有个delete接口，既可以删除单个key，也可以全删除key，如果要删除几个key，用法是:r.delete(&#39;age&#39;)、r.delete(&#39;sex&#39;, &#39;age&#39;)，如果要全删除，那就是 12keys = r.keys()r.delete(*keys) 执行之后的效果等于flushall。 redis里默认情况下是不支持通配符的，那么要批量删除key怎么做呢？答案就是搭配xargs，比如要删除掉所有2018-03-开头的key： 1redis-cli -hredis地址 -a密码 keys "2018-03-*"|xargs redis-cli -hredis地址 -a密码 del python将两个list元素一一对应转换为dict使用python的zip函数和强大的集合操作可以方便的将两个list元素一一对应转换为dict，如下示例代码： 1234names = ['n1','n2','n3']values = [1,2,3] nvs = zip(names,values)nvDict = dict( (name,value) for name,value in nvs) 参考资料https://github.com/andymccurdy/redis-pyhttp://xiaorui.cc/2014/11/10/%E4%BD%BF%E7%94%A8redis-py%E7%9A%84%E4%B8%A4%E4%B8%AA%E7%B1%BBredis%E5%92%8Cstrictredis%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/http://debugo.com/python-redis/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用python调用echart画图]]></title>
    <url>%2F2018%2F03%2F22%2F%E4%BD%BF%E7%94%A8python%E8%B0%83%E7%94%A8echart%E7%94%BB%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[前言之前说了如何使用阿里云的SDK获取云存储的值然后发送表格邮件，但是最近领导又发话了，说这个邮件每天一封看的有点审美疲劳，要顺应“数据可视化”的趋势，于是就要求画图，力求直观，要做到“从众多数据中突出特别数据，从特别数据中突出高价值数据”。我之前用python的matplotlib画过，这一次尝试用echart来做图！ echart是不太良心的百度良心的开源作品，提供各种各样精美的作图方案，分分钟把图片做的高大上，吸引周围人的目光。不过我对前端的了解非常浅薄，但是没关系。这次使用pyechart插件！这个插件可以让python直接调用echart接口，选择需要的图形之后，直接往里查数据就好，简单粗暴见效快，而且支持3D，可以说是居家旅行常备物品。可以说，有了它，作图能力顶呱呱。感谢开发者大神们的辛苦工作！ 作图首先先需要安装pyecharts插件，命令是pip install pyecharts。 然后我们就可以写一个简单的案例，如下： 123456789101112131415#!/usr/bin/env python#coding=utf-8from pyecharts import Bar #导入第三方库#attr = ["&#123;&#125;day".format(i) for i in range(1, 8)] #这样的话X坐标就是1day、2day、3day...attr = ["Mon", "Feb", "Wed", "Thu", "Fri", "Sat", "Sun"] #这样X坐标就是星期v1 = [1.49, 2.09, 4.03, 2.23, 5.26, 7.71, 7.56] v2 = [0.3, 0.9, 0.2, 0.4, 0.7, 0.7, 0.6]v3 = [18.15, 13.22, 11.28, 17.99, 18.7, 19.7, 15.6]bar = Bar("乐橙云存储情况总览", "本图表展示过去一周的云存储情况") #这里是主标题和副标题bar.add("录像分享文件", attr, v1, mark_line=["average"], mark_point=["max", "min"]) #每一个值的名称以及要展现平均值和最大最小值bar.add("视频直播文件", attr, v2, mark_line=["average"], mark_point=["max", "min"])bar.add("云录像、报警图片、全景图片", attr, v3, mark_line=["average"], mark_point=["max", "min"]) bar.render('/tmp/111.html') #在/tmp文件夹里生成一个111.html文件 如果服务器里有nginx，那么把这个html文件放到nginx/html路径里，再在浏览器里打开就会看到这样的图： 而且还可以通过点击网页上“A值”、“B值”、“C值”就可以达到屏蔽相应值的效果，而且如果点击红色箭头的“数据视图”，还可以直接看到对应的数据，非常贴心非常屌，如图： 如果你觉得图片有点小，那么可以修改这个地方：bar = Bar(&quot;XXX情况总览&quot;, &quot;本图表展示过去一周的ABC情况&quot;，width=1000,height=900)，我这里把宽和高分别从默认值调成了1000和900。 如果想要在一个html里做多个图，比如要做三个柱状图，那么example如下： 123456789101112131415161718192021222324252627282930#!/usr/bin/env python#coding=utf-8from pyecharts import Bar, Gridattr = ["一班", "二班", "三班", "四班"]v1 = [54, 81, 32, 32] v2 = [68, 69, 27, 32] bar = Bar("赞成票","本图表展示赞成票情况")bar.add("年纪长", attr, v1, mark_point=["max", "min"])bar.add("副年纪长", attr, v2, mark_point=["max", "min"])attr2 = ["一班", "二班", "三班", "四班"]x1 = [2, 0, 0, 1]x2 = [1, 3, 0, 2]bar2 = Bar("反对票","本图表展示反对票情况",title_top='bottom',title_color='#1d12eb') #title_color是标题颜色，这个跟html的颜色取值一样bar2.add("年纪长", attr2, x1, mark_point=["max", "min"])bar2.add("副年纪长", attr2, x2, mark_point=["max", "min"])attr3 = ["一班", "二班", "三班", "四班"]y1 = [2, 0, 0, 1]y2 = [2, 0, 0, 1]bar3 = Bar("弃权票","本图表展示弃权票情况",title_pos='right',title_color='#eb1212') #title_pos是标题的位置，如果不特殊说明，会重叠bar3.add("年纪长", attr3, y1, mark_point=["max", "min"]) bar3.add("副年纪长", attr3, y1, mark_point=["max", "min"])grid = Grid() grid.add(bar, grid_width="40%", grid_height="30%", grid_bottom="60%", grid_right="55%") #grid_height和grid_width是每一个小图的大小grid.add(bar2, grid_width="40%", grid_height="30%", grid_bottom="60%", grid_left="55%") #grid_bottom和grid_top是垂直位置grid.add(bar3, grid_width="40%", grid_height="30%", grid_top="60%", grid_right="55%") #grid_right和grid_left是水平位置grid.render('/tmp/grid.html') #在/tmp文件夹里生成一个grid.html文件 例子中的数字都是我虚拟的，实际情况中，这些数字都应该是存储在redis这样的数据库里，然后取出来使用。 上面的两个例子仅仅是pyechart使用的冰山一角，如果想更多的了解，请去看一下文末pyechart的中文说明文档，无论是柱状图、雷达图、曲线图、3D图都有相关的使用讲解，内容特别丰富！ 参考资料http://echarts.baidu.comhttp://pyecharts.org/#/zh-cn/prepare]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>echart</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RabbitMQ的安装、配置与启动]]></title>
    <url>%2F2018%2F03%2F19%2FRabbitMQ%E7%9A%84%E5%AE%89%E8%A3%85%E3%80%81%E9%85%8D%E7%BD%AE%E4%B8%8E%E5%90%AF%E5%8A%A8%2F</url>
    <content type="text"><![CDATA[前言环境介绍：Centos 7 + RabbitMQ：3.6.12 + Erlang：20.0 安装erlang由于RabbitMQ使用erlang语言编写的，所以要先安装erlang语言环境。但是yum源里的erlang版本太老了，于是这里选择手动安装，使用Erlang官方推荐的Erlang Solutions安装方法如下： 1234yum install gcc gcc-c++ glibc-devel make ncurses-devel openssl-devel autoconf java-1.8.0-openjdk-devel git wget wxBase.x86_64 #先把其他模块准备好wget https://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpmrpm -Uvh erlang-solutions-1.0-1.noarch.rpmrpm --import https://packages.erlang-solutions.com/rpm/erlang_solutions.asc 此时，查看/etc/yum.repos.d/erlang_solutions.repo，应该是这个样子： 123456[erlang-solutions]name=CentOS $releasever - $basearch - Erlang Solutionsbaseurl=https://packages.erlang-solutions.com/rpm/centos/$releasever/$basearchgpgcheck=1gpgkey=https://packages.erlang-solutions.com/rpm/erlang_solutions.ascenabled=1 这个时候可以yum安装了： 1yum install -y esl-erlang 此时得到的erlang就是20.0版本的了，如图： 如果不想使用这个办法，可以使用源码安装的方式，https://packages.erlang-solutions.com/erlang/ 这里面有Erlang官方的下载包，拆包解压缩然后make &amp;&amp; make install即可。 安装RabbitMQ安装RabbitMQ跟其他普通软件差不多，先去官网下载目前较稳定的rpm包，然后安装，步骤如下： 12wget https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.4/rabbitmq-server-3.7.4-1.el7.noarch.rpmyum install -y rabbitmq-server-3.7.4-1.el7.noarch.rpm 如果出现了Transaction Check Error的错误： 可见是要安装的包与已有的包相冲突，此时需要yum list|grep erlang，如图： 再yum remove esl-erlang.x86_64，然后重新执行yum install那一步即可。 如果出现Requires: socat的错误，如图： 此时需要执行如下命令即可： 12yum -y install epel-releaseyum -y install socat 配置RabbitMQRabbitMQ安装完毕，先chkconfig rabbitmq-server on设置开机启动。然后，配置一下用户名。我这个机器的用户名不规范，需要把hostname里的中文去掉，比如改成：3-dvl-hlsproxy-001，那么就要在/etc/hosts里添加一句： 内网IP地址 3-dvl-hlsproxy-001 然后执行rabbitmq-plugins enable rabbitmq_management来安装WEB图形界面，然后拷贝rabbitmq.config.example到/etc/rabbitmq/里，并且改名叫rabbitmq.config，命令如下： 123cp /usr/share/doc/rabbitmq-server-3.7.4/rabbitmq.config.example /etc/rabbitmq/cd /etc/rabbitmq/mv rabbitmq.config.example rabbitmq.config 编辑rabbitmq.config这个文件，把%%{loopback_users, []}.改成{loopback_users, []}，保存之后，执行service rabbitmq-server restart来启动RabbitMQ。 如果启动之后，执行rabbitmqctl status不断的刷Error when reading /var/lib/rabbitmq/.erlang.cookie: eacces的错误的话，执行chown rabbitmq:rabbitmq /var/lib/rabbitmq/.erlang.cookie。 在浏览器里登录外网IP:15672就会看到RabbitMQ的WEB配置界面了， 账号和密码都是guest，输入之后就会看到如下的界面，可以在界面里看到3-dvl-hlsproxy-001的情况了，如图： RabbitMQ 3.0以后版本的WEB端口是15672,服务的端口是5672,这俩都可以在配置文件里面更改。至此RabbitMQ的安装与配置结束了，但是这个仅仅是最简单的配置，RabbitMQ自身有一套很详细的用户管理规则以及它支持Python等很多语言的管理，这些内容以后再详细说明。 参考资料https://packages.erlang-solutions.com/erlang/https://laucyun.com/9849587ce75f31d534d52f906c94368f.htmlhttps://www.rabbitmq.com/access-control.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
        <tag>RabbitMQ</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用nginx开启http2协议]]></title>
    <url>%2F2018%2F03%2F16%2F%E4%BD%BF%E7%94%A8nginx%E5%BC%80%E5%90%AFhttp2%E5%8D%8F%E8%AE%AE%2F</url>
    <content type="text"><![CDATA[部署过程HTTP/2是建立在TLS的基础上的，那么先要查看nginx的版本和openssl的版本，如果nginx版本在1.10.0以上且需要openssl版本在1.0.2以上那么就可以进行下一步了： 如果版本并不符合要求，可以按照https://rorschachchan.github.io/2018/01/03/Nginx动态编译新的模块/ 里的方法升级对应的模块版本。 先编辑https（443端口）对应的conf文件： 123456789101112131415161718192021server &#123; listen 443 ssl http2; #这里多加一句http2 server_name cuntao.lechange.com *.lechange.com; #这里填写实际的域名，我这里以cuntao.lechange.com为例 ssl_certificate /实际路径/server-com.crt; ssl_certificate_key /实际路径/server-com.key; ssl_session_timeout 30m; #客户端会话缓存时间 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #允许的协议 ssl_ciphers EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; #加密算法(CloudFlare 推荐的加密套件组) ssl_prefer_server_ciphers on; #优化 SSL 加密套件 ssl_session_cache builtin:1000 shared:SSL:10m; #SSL会话缓存类型和大小 ssl_buffer_size 1400; #每个MTU大小1400b location / &#123; root html; index index.html index.htm; &#125; error_page 404 /404.html; &#125; 保存之后再编辑http（80端口）对应的conf文件： 12345server &#123; listen 80 default; add_header Strict-Transport-Security max-age=15768000; return 301 https://$host$request_uri;&#125; 然后使用nginx -t检查一下是否文件有错误，如果是OK的话，那么就nginx -s reload平滑重启一下nginx即可。 验证HTTP/2协议是否开启很简单，有两个方法：1）登陆https://tools.keycdn.com/http2-test，将你的域名填写进去，查看一下配置成功： 2)在Chrome浏览器上可以通过安装HTTP/2 and SPDY indicator插件来检验，网址是https://chrome.google.com/webstore/detail/http2-and-spdy-indicator/mpbpobfflnpcgagjijhmgnchggcjblin ，如果地址栏出现蓝色的闪电就是该网站开启了HTTP/2协议，灰色的话就是HTTP/2协议没开启。 参考资料https://www.nginx.com/blog/nginx-1-9-5/https://blog.fazero.me/2017/01/06/upgrate-nginx-and-use-http2/https://iyaozhen.com/nginx-http2-conf.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>http协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于HTTP 2.0应该知道的事]]></title>
    <url>%2F2018%2F03%2F16%2F%E5%85%B3%E4%BA%8EHTTP-2%E5%BA%94%E8%AF%A5%E7%9F%A5%E9%81%93%E7%9A%84%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[HTTP 2.0的优势相比HTTP/1.x，HTTP/2在底层传输做了很大的改动和优化：1.每个服务器只用一个连接：HTTP/2对每个服务器只使用一个连接，而不是每个文件一个连接。这样，就省掉了多次建立连接的时间，这个时间对TLS尤其明显，因为TLS连接费时间;2.加速TLS交付：HTTP/2只需一次耗时的TLS握手，并且通过一个连接上的多路利用实现最佳性能。HTTP/2还会压缩首部数据，省掉HTTP/1.x时代所需的一些优化工作，比如拼接文件，从而提高缓存利用率;3.简化Web应用：使用HTTP/2可以让Web开发者省很多事，因为不用再做那些针对HTTP/1.x的优化工作了;4.适合内容混杂的页面：HTTP/2特别适合混合了HTML、CSS、JavaScript、图片和有限多媒体的传统页面。浏览器可以优先安排那些重要的文件请求，让页面的关键部分先出现、快出现，而且根本不会发生“浏览器明明在等关键的CSS和JS，而服务器还在发送黄图”的尴尬局面;5.更安全：通过减少TLS的性能损失，可以让更多应用使用TLS，从而让用户信息更安全。 HTTP 2.0性能增强之二进制分帧HTTP的定义大家都知道，叫超文本协议，也就是说http1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多。但是在HTTP/2里这里做了比较重大的改动—二进制分帧，HTTP/2在应用层(HTTP)和传输层(TCP or UDP)之间增加一个二进制分帧层。在这个新增的二进制分帧层里HTTP/2会将所有传输的信息分割为更小的消息和帧,并对它们采用二进制格式的编码 ，其中HTTP1.x的首部信息会被封装到Headers帧，而我们的request body则封装到Data帧里面。二进制与之前的文本不同，二进制只认0和1的组合。基于这种考虑http2.0的协议解析决定采用二进制格式，实现方便且健壮。 HTTP/2的格式定义十分高效且精简。length定义了整个frame的大小，type定义frame的类型（一共10种），flags用bit位定义一些重要的参数，stream id用作流控制，payload就是request的正文，如下图： HTTP 2.0性能增强之首部压缩虽然HTTP/2引入了二进制分帧的概念，但是试想如果所有的二进制帧都会带上Headers帧，这是多大的数据冗余传送啊。于是HTTP/2针对这个需求又搞出来一个东东—“首部表”。 “首部表”来跟踪和存储之前发送的键-值对，对于相同的数据，不再通过每次请求和响应发送；通信期间几乎不会改变的通用键-值对(用户代理、可接受的媒体类型等等)只需发送一次。事实上,如果请求中不包含首部(例如对同一资源的轮询请求)，那么首部开销就是零字节。此时所有首部都自动使用之前请求发送的首部。如果首部发生变化了，那么只需要发送变化了数据在Headers帧里面，新增或修改的首部帧会被追加到“首部表”。首部表在HTTP/2的连接存续期内始终存在,由客户端和服务器共同渐进地更新。 HTTP 2.0性能增强之TCP请求集中TCP的优势是很直白的：面向连接、提供可靠的数据传输服务、流量控制。那么有效地使用TCP连接的方法就是长时间连接传输大块数据。于是HTTP/2就尽大化的把这一特点发扬：所有HTTP/2通信都是在一个TCP连接上完成。前面说过，HTTP/2把HTTP协议通信的基本单位缩小为一个一个的帧，这些帧对应着逻辑流中的消息，并行地在同一个TCP连接上双向交换消息(注意这个“双向交换消息”)。举个例子，请求一个页面https://www.google.com，页面上所有的资源请求都是客户端与服务器上的一条TCP上请求和响应的！ 这样“单链接多资源”的方式，使到至上而下的层面都得到了好处： 1.可以减少服务链接压力,内存占用少了,连接吞吐量大了； 2.由于TCP连接减少而使网络拥塞状况得以改观; 3.慢启动时间减少,拥塞和丢包恢复速度更快。 综上所述，“资源合并减少请求”对于HTTP/2是无用的优化手段。 上面的文字说了要注意“双向交换消息”，那么啥是“双向交换消息”？ 就是把HTTP消息分解为独立的帧,交错发送,然后在另一端重新组装。专业一点说就是“一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的id将request再归属到各自不同的服务端请求里面”。这是HTTP/2重要的一项增强。事实上,这个机制会在整个Web技术栈中引发一系列连锁反应, 从而带来巨大的性能提升,因为： 1234可以并行交错地发送请求,请求之间互不影响;可以并行交错地发送响应,响应之间互不干扰;只使用一个连接即可并行发送多个请求和响应;消除不必要的延迟,从而减少页面加载的时间; Keep Alive与HTTP/2集中TCP的区别HTTP1.1的keep-alive是为了尽可能使用持久链接，以消除TCP握手和慢启动。但是keep-alive使用多了同样会给服务端带来大量的性能压力，并且对于单个文件被不断请求的服务(例如图片存放网站)，keep-alive可能会极大的影响性能，因为它在文件被请求之后还保持了不必要的连接很长时间。 举个例子：下载a.js创建一个TCP链接，就会需要TCP握手和慢启动而产生了约300ms下载延迟。当a.js下载完成后这时候b.js也要下载，如果a.js创建TCP链接是keep-alive的，b.js就可以复用其TCP而不需要重新TCP握手和慢启动（没有了那300ms）。 而HTTP/2是使用一个TCP链接的，其慢启动和握手只在第一次链接的时候产生一次，其后面链接都是持久化的。并且一个TCP下载多个资源，可以将TCP吞吐量最大化来提升性能，这方面可以参考一下TCP的拥塞预防及控制。 NGINX上如何配制HTTP/2上面说了这么多HTTP/2这个好那个好，是未来的趋势blablabla，但是要实现HTTP/2，还是需要“客户端和服务器都开启了HTTP/2”这一个首要条件。不过现在客户端（浏览器）大多数都已经支持HTTP/2，那么主要就是在服务器端如何开启HTTP/2，nginx的配置方法请见：https://rorschachchan.github.io/2018/03/16/使用nginx开启http2协议/ 。 按照这样的操作下来，服务器就开了HTTP/2协议，那些支持HTTP/2的浏览器在请求页面的时候就会走HTTP/2模式，而不支持HTTP/2的浏览器会议就按照HTTP/1.X的方式发送请求，如图： 支持HTTP/2的Web Server基本都支持HTTP/1.1。这样，即使浏览器不支持HTTP/2，双方也可以协商出可用的HTTP版本，没有兼容性问题。 参考资料http://www.alloyteam.com/2015/03/http2-0-di-qi-miao-ri-chang/comment-page-1/#commentshttps://segmentfault.com/a/1190000007637735https://github.com/creeperyang/blog/issues/23https://www.nginx.com/blog/nginx-1-9-5/https://ye11ow.gitbooks.io/http2-explained/content/part6.html]]></content>
      <categories>
        <category>大牛之路</category>
      </categories>
      <tags>
        <tag>http协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos 7里安装zsh来提升shell的高逼格]]></title>
    <url>%2F2018%2F03%2F15%2Fcentos-7%E9%87%8C%E5%AE%89%E8%A3%85zsh%E6%9D%A5%E6%8F%90%E5%8D%87shell%E7%9A%84%E9%AB%98%E9%80%BC%E6%A0%BC%2F</url>
    <content type="text"><![CDATA[zsh本体的安装先用chsh -l查看当前的bash情况，如下： 123456789 [root@zabbix ~]# chsh -l/bin/sh/bin/bash/sbin/nologin/bin/dash/bin/tcsh/bin/csh/usr/bin/tmux[root@zabbix ~]# 如果是centos的话，使用yum install -y zsh来安装zsh，装完了zsh然后就是装oh my zsh，使用wget方法安装： 1wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 再使用which zsh查看安装的zsh在/usr/bin/zsh，这个时候使用chsh -s /usr/bin/zsh，出现了Shell changed.这样就切换到了zsh界面，需要logout退出连接重进。 重新连接就会发现bash界面就变了，原本是路径的地方变成了一个小图标。界面主题是可以变化的，比如我个人比较喜欢af-magic这个模板，于是乎就把/root/.zshrc里的ZSH_THEME=&quot;robbyrussell&quot;改成ZSH_THEME=&quot;af-magic&quot;，保存文件，再一次退出连接重新进入就能看见模板变化了。 如果在使用vim的时候发现了tab键的补全爆错_arguments:451: _vim_files: function definition file not found，如下图： 这个时候需要把/root/.zcompdump改一个名字，比如叫.zcompdump-bak，然后重新ssh连接即可。 autojump插件安装autojump这个插件安装之后，zsh会自动记录你访问过的目录，通过j + 目录名可以直接进行目录跳转，而且目录名支持模糊匹配和自动补全，例如你访问过hadoop-1.0.0目录，输入j hado即可正确跳转。j –s可以看你的历史路径库，安装方法如下： 1git clone git://github.com/joelthelion/autojump.git 然后在autojump目录里执行./install.sh，此时屏幕会出现如下的显示： 把上面那个[[ -s /root/.autojump/etc/profile.d/autojump.sh ]] &amp;&amp; source /root/.autojump/etc/profile.d/autojump.sh autoload -U compinit &amp;&amp; compinit -u复制到/root/.zshrc的文件里，最好复制在source $ZSH/oh-my-zsh.sh这句话上面，保存之后source ~/.zshrc即可。 zsh-syntax-highlighting插件安装这个插件安装之后主要效果就是命令高亮，如果是错误的命令，颜色是红色，正确的命令是绿色的，安装方法如下： 12345cd .oh-my-zsh/pluginsyum install -y git #如果已经安装了git就不用执行的git clone git://github.com/zsh-users/zsh-syntax-highlighting.gitsource /root/.oh-my-zsh/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh添加到 .zshrc 的最后面source ~/.zshrc 效果立竿见影。 尾声至此，你现在的zsh应该具备如下几个特性：1、各种补全：路径补全、命令补全，命令参数补全，插件内容补全等等。触发补全只需要按一下或两下tab键，补全项可以使用ctrl+n/p/f/b上下左右切换。比如你想杀掉java的进程，只需要输入kill java + tab键，如果只有一个java进程，zsh会自动替换为进程的pid，如果有多个则会出现选择项供你选择。ssh + 空格 + 两个tab键，zsh会列出所有访问过的主机和用户名进行补全；2、即使你没有安装autojump，只要输入d，就会列出你在这个回话中访问的目录，输入前面的序号，就可以直接跳转；3、可以忽略cd命令, 输入..或者…和当前目录名都可以跳转；当然，除了上面几点，zsh还有很多丰富的插件可以使用，这就需要继续的探索了… 参考资料https://github.com/robbyrussell/oh-my-zshhttp://macshuo.com/?p=676]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[安装vim8.0的过程]]></title>
    <url>%2F2018%2F03%2F14%2F%E5%AE%89%E8%A3%85vim8-0%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1.先卸载老的vim 1yum remove vim-* -y 2.下载第三方yum源 1wget -P /etc/yum.repos.d/ https://copr.fedorainfracloud.org/coprs/mcepl/vim8/repo/epel-7/mcepl-vim8-epel-7.repo 3.安装vim 1yum -y install vim-enhanced 4.验证vim版本 12345rpm -qa |grep vimvim-enhanced-8.0.0704-1.1.26.el7.centos.x86_64vim-common-8.0.0704-1.1.26.el7.centos.x86_64vim-minimal-8.0.0704-1.1.26.el7.centos.x86_64vim-filesystem-8.0.0704-1.1.26.el7.centos.x86_64]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>编辑器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用expect来实现远程登录ssh]]></title>
    <url>%2F2018%2F03%2F14%2F%E4%BD%BF%E7%94%A8expect%E6%9D%A5%E5%AE%9E%E7%8E%B0%E8%BF%9C%E7%A8%8B%E7%99%BB%E5%BD%95ssh%2F</url>
    <content type="text"><![CDATA[先说说shebang我们在写一个shell脚本时，总是习惯在最前面加上一行#!/bin/bash,这个就是脚本的shebang,可以把它理解成是一种解释器。至于为什么叫这么个奇怪的名字，C语言和Unix的开发者Dennis Ritchie称它为可能是类似于“hash-bang”的英国风描述性文字； 贴一段wiki上的解释: 在计算机科学中，shebang是一个由井号和叹号构成的字符串行，其出现在文本文件的第一行的前两个字符。 在文件中存在shebang的情况下，类unix操作系统的程序载入器会分析shebang后的内容，将这些内容作为解释器指令，并调用该指令，并将载有shebang的文件路径作为该解释器的参数。 简单的说，它指示了此脚本运行时的解释器，所以，使用文件名直接执行shell脚本时，必须带上这个shebang; 此外，我们还可以在shebang后面直接附加选项，执行时默认使用选项执行； 比如test.sh的shebang为#!/bin/sh -x，那我们执行脚本时: 1./test.sh hello 相当于： 1bin/sh -x ./test.sh hello; 而expect编写的脚本，需要用到的shebang为/usr/bin/expect; 需要注意的是：在指定脚本解释器来执行脚本时，shebang会被指定的脚本解释器覆盖，即优先使用指定的脚本解释器来执行脚本（习惯性地用sh ./test.sh却提示command not found） 实例脚本expect的具体语法我这里就不说了，看一下下面的参考资料就好了。其实说来说去，就是根据命令栏上的反馈来输入对应的内容，举一个ssh登陆的例子。如图: 从这个我们非常熟悉的ssh登陆的过程就看到，在登陆的时候，页面会返回几个交互的问题，而我们就可以针对这几个问题的关键字来输入答案。最后也根据“Welcome”这个关键字认为我们已经登陆成功了，这样就直接在连接的服务器里操作命令。 于是根据这个思路，来写一个远程ssh到A机器上的脚本： 1234567891011121314151617#!/usr/bin/expect -fset timeout 30 #设定超时时间是30秒，如果是-1那就是永不超时spawn ssh root@A服务器IP地址 #这里开始ssh连接到目标服务器上expect &#123; "*(yes/no)?" &#123; #如果是第一次连接，那么命令栏里就会出现(yes/no)的字样 send "yes\r" #此时匹配yes expect "*password:" &#123;send "服务器密码\r"&#125; #如果命令栏出现了password的字样，直接填写密码 &#125; "*password:" &#123;send "服务器密码\r"&#125; #如果不是第一次连接，那么就会直接出现password，所以可以直接填写密码&#125;expect "*Welcome*" #连接成功就会出现welcome的字样send "echo '我就是你的爹地' &gt;&gt; /tmp/123321.txt\r" #此时执行第一个命令send "df -h\r" #执行第二个命令send "cp /tmp/123321.txt /tmp/123123.txt\r" #执行第三个命令interact #脚本fork的子进程会将操作权交给用户，允许用户与当前A服务器的shell进行交互 参考资料http://blog.sctux.com/?p=343http://www.zyy1217.com/2017/07/02/linux%20expect%E8%AF%A6%E8%A7%A3/https://github.com/jiangxianli/SSHAutoLoginhttps://peiqiang.net/2014/05/10/ssh-auto-login.htmlhttps://www.jianshu.com/p/9bee08dc3dca]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>expect</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用python去做一个生成随机码的页面]]></title>
    <url>%2F2018%2F03%2F13%2F%E4%BD%BF%E7%94%A8python%E5%8E%BB%E5%81%9A%E4%B8%80%E4%B8%AA%E7%94%9F%E6%88%90%E9%9A%8F%E6%9C%BA%E7%A0%81%E7%9A%84%E9%A1%B5%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[先说一下mkpasswdlinux里是自带生成密码的命令的，比较出名的一个是mkpasswd，另一个是passwdgen。 mkpasswd命令是附属在expect模块里的，如图 passwdgen的话也要手动执行一下yum install -y passwdgen来安装命令。 这里主要说说mkpasswd，它支持如下几个参数： 12345-l (length of password, default = 7) 指定密码的长度，默认是7位数-d (min # of digits, default = 2) 指定密码中数字最少位数，默认是2位-c (min # of lowercase chars, default = 2) 指定密码中小写字母最少位数，默认是2位-C (min # of uppercase chars, default = 2) 指定密码中大写字母最少位数，默认是2位-s (min # of special chars, default = 1) 指定密码中特殊字符最少位数，默认是1位 比如现在要生成一个含有“六位数字而且5位特殊字符的总共16位”的密码，那么命令就是：mkpasswd -l 16 -d 5 -s 5，再聚几个其他的例子，感受一下： 12345678[root@zabbix General_LeChange_Chn_IS_V5.8.00.R.20170814]# mkpasswd -l 16 -d 5 -s 5g]7Hu-L5,t+32%0m[root@zabbix General_LeChange_Chn_IS_V5.8.00.R.20170814]# mkpasswd -l 16 -C 5YvjtFWaV5jr8h%Wy[root@zabbix General_LeChange_Chn_IS_V5.8.00.R.20170814]# mkpasswd -l 16 -s 10qoB#^V_=/!??*59:[root@zabbix General_LeChange_Chn_IS_V5.8.00.R.20170814]# mkpasswd -l 16 -c 4 9mJOqymatvg*n9sl 脚本在此这个生成随机码的算法部分就使用上面那个mkpasswd了，省了我们不少事。 整个html界面的代码如下： 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset="utf-8"&gt;&lt;title&gt;随机密码生成器&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action="/cgi-bin/dropdown.py" method="post" target="_blank"&gt;&lt;select name="dropdown"&gt;&lt;h2&gt;密码长度：&lt;/h2&gt;&lt;option value="8" selected&gt;8&lt;/option&gt;&lt;option value="16"&gt;16&lt;/option&gt;&lt;option value="20"&gt;20&lt;/option&gt;&lt;option value="24"&gt;24&lt;/option&gt;&lt;option value="48"&gt;48&lt;/option&gt;&lt;/select&gt; &lt;br /&gt;&lt;input type="checkbox" name="runoob" value="on" /&gt; 包含小写字母 &lt;br /&gt;&lt;input type="checkbox" name="google" value="on" /&gt; 包含大写字母 &lt;br /&gt;&lt;input type="checkbox" name="runoob" value="on" /&gt; 包含数字 &lt;br /&gt;&lt;input type="checkbox" name="google" value="on" /&gt; 包含特殊字母 &lt;br /&gt;&lt;input type="submit" value="提交"/&gt; &lt;br /&gt;&lt;h2&gt;密码：&lt;/h2&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 补充再分享一个python生成密码的代码，但是这个密码不含特殊字符： 12345678#!/usr/bin/env python# -*- coding: utf-8 -*- import randomimport stringsalt = ''.join(random.sample(string.ascii_letters + string.digits, 8))print salt 参考资料https://balajiommudali.wordpress.com/2015/11/27/unable-to-install-mkpasswd-on-centos-6-4/http://www.runoob.com/python/python-cgi.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次mysql无法启动的解决过程]]></title>
    <url>%2F2018%2F03%2F12%2F%E8%AE%B0%E4%B8%80%E6%AC%A1mysql%E6%97%A0%E6%B3%95%E5%90%AF%E5%8A%A8%E7%9A%84%E8%A7%A3%E5%86%B3%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[正文今天开发人员反馈一个问题，就是某一台开发环境机器的mysql无法启动了，但是如果这台服务器重启的话，mysql就好使，而第二天就会出现mysql死掉然后无法启动的情况。我使用service mysqld restart，命令行反馈如下的内容： 123[root@iZ2373j9xivZ data]# service mysqld restartMySQL server PID file could not be found! [FAILED] Starting MySQL........The server quit without updating PID file (/data/mysql/data/sock/mysql.pid). [FAILED] 打开错误日志看一下，里面是这么写的： 123456782018-03-10 00:26:24 25919 [Note] InnoDB: Using CPU crc32 instructions2018-03-10 00:26:24 25919 [Note] InnoDB: Initializing buffer pool, size = 4.0GInnoDB: mmap(549453824 bytes) failed; errno 122018-03-10 00:26:24 25919 [ERROR] InnoDB: Cannot allocate memory for the buffer pool2018-03-10 00:26:24 25919 [ERROR] Plugin 'InnoDB' init function returned error.2018-03-10 00:26:24 25919 [ERROR] Plugin 'InnoDB' registration as a STORAGE ENGINE failed.2018-03-10 00:26:24 25919 [ERROR] Unknown/unsupported storage engine: INNODB2018-03-10 00:26:24 25919 [ERROR] Aborting 爆InnoDB: mmap(549453824 bytes) failed; errno 12，然后我就free -m查看一下，当前服务器的内存已经不够用了。 12345[root@iZ2373j9xivZ sock]# free -m total used free shared buffers cachedMem: 7869 7747 121 0 16 15-/+ buffers/cache: 7716 152Swap: 0 0 0 那么是什么在占用这台服务器的内存？使用ps aux | sort -k4nr |head -5 这个命令查找当前占用内存最大的五个进程一看，全是php-fpm，同时也发现服务器里面运行大量的php-fpm，在征得开发人员的同意之后，重启php-fpm进程，内存空出来很多。 此时再次service mysqld restart，发现mysql的错误日志改成如下的样子了： 12342018-03-12 10:53:42 28238 [Note] InnoDB: Highest supported file format is Barracuda.2018-03-12 10:53:42 28238 [Note] InnoDB: The log sequence numbers 16939991440 and 16939991440 in ibdata files do not match the log sequence number 16940121908 in the ib_logfiles!2018-03-12 10:53:42 28238 [Note] InnoDB: Database was not shutdown normally!2018-03-12 10:53:42 28238 [Note] InnoDB: Starting crash recovery. 这次变成了The log sequence numbers 16939991440 and 16939991440 in ibdata files do not match the log sequence number 16940121908 in the ib_logfiles!，我打开my.cnf，适当的调小了max_connections和innodb_buffer_pool_size，然后service mysqld restart的时候发现错误又变了： 123456782018-03-12 11:03:57 29190 [Note] InnoDB: 5.6.27 started; log sequence number 169401219182018-03-12 11:03:57 29190 [Note] Server hostname (bind-address): '*'; port: 33062018-03-12 11:03:57 29190 [Note] IPv6 is not available.2018-03-12 11:03:57 29190 [Note] - '0.0.0.0' resolves to '0.0.0.0';2018-03-12 11:03:57 29190 [Note] Server socket created on IP: '0.0.0.0'.2018-03-12 11:03:57 29190 [ERROR] Can't start server : Bind on unix socket: Permission denied 2018-03-12 11:03:57 29190 [ERROR] Do you already have another mysqld server running on socket: /data/mysql/data/sock/mysql.sock ?2018-03-12 11:03:57 29190 [ERROR] Aborting 这就是文件权限问题了，我再次打开my.cnf发现里面的user填写的是mysql，那么把/data/mysql/data/sock/mysql.sock这一系列的文件的所属人都改成了mysql用户，这一次重启mysql就OK了。 为什么这个mysql会好好的突然自动死掉呢？我发现日志里面有这样的字样：InnoDB: Database was not shutdown normally!，于是我猜想很有可能是php-fpm这进程不断地增长，占用的内存太大，导致mysql被linux的内核杀死了。于是查看/var/log/message的文件，结合mysql的错误日志时间找到了如下的字样： 12345Mar 10 00:26:22 iZ2373j9xivZ kernel: Out of memory: Kill process 1883 (mysqld) score 53 or sacrifice childMar 10 00:26:22 iZ2373j9xivZ kernel: Killed process 1883, UID 501, (mysqld) total-vm:6849508kB, anon-rss:429368kB, file-rss:176kBMar 10 04:11:38 iZ2373j9xivZ kernel: php-fpm invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0Mar 10 04:11:38 iZ2373j9xivZ kernel: php-fpm cpuset=/ mems_allowed=0Mar 10 04:11:38 iZ2373j9xivZ kernel: Pid: 4375, comm: php-fpm Not tainted 2.6.32-431.23.3.el6.x86_64 #1 证据确凿，php-fpm的无休止增长导致服务器的可用内存变小，最后内核把mysql杀死，修改php-fpm的文件之后，暂时好了点… 参考资料http://robinchen.me/tech/2016/03/14/tech-aliyun-centos-mysql-shutdown-itself-irregularly.htmlhttp://www.wisedream.net/2017/12/20/traps/mysql-corrupt/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>运维技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于HTTP-Alive应该知道的事]]></title>
    <url>%2F2018%2F03%2F11%2F%E5%85%B3%E4%BA%8EHTTP-Alive%E5%BA%94%E8%AF%A5%E7%9F%A5%E9%81%93%E7%9A%84%E4%BA%8B%2F</url>
    <content type="text"><![CDATA[总体概述七层协议是一个广为人知的协议，tcp协议是在传输层，http协议是在应用层，也就是说客户端与服务器端先建立tcp连接，然后在tcp连接的基础上传送http报文。 http协议是一个请求-应答的模式，也就是当没有启动keep-alive的时候，每一次建立http连接都是现用现建立，用完就断开的工作样式。而如果开启了keep-alive模式的话，客户端和服务器之间http连接就会被保持，不会断开（超过Keep-Alive规定的时间，意外断电等情况除外），当客户端发送另外一个请求时，就使用这条已经建立的连接。 Keep-Alive的规定时间在客户端（浏览器里）是如何确定的呢？例如Keep-Alive: timeout=5, max=100，表示这个TCP通道可以保持5秒，max=100表示这个长连接最多接收100次请求就断开。 Keep-alive在http 1.1版本里是默认开启的，只有加入Connection: close才会关闭，现在大部分浏览器都是使用http 1.1协议，所以说在客户端已经是默认发起keep-alive的连接请求。但是能否会完成一个完整的keep-alive还要看服务器端的具体配置情况。 在nginx里就直接支持keepalive_timeout指令，其使用0值来停用keep-alive，举例配置如下: 12345location /XXX/ &#123; alias /url/var/www/html/; keepalive_timeout 75; expires 5m; &#125; 使用长连接之后，客户端和服务端怎么知道本次传输结束呢？两部分：1. 判断传输数据是否达到了Content-Length指示的大小，这个是最简单的最傻瓜的，普遍应用于静态的图片或者页面；2. 往往动态生成的文件没有Content-Length，它是分块传输（chunked），这时候怎么办呢？就要根据chunked编码来判断，chunked编码的数据在最后有一个空chunked块，表明本次传输数据结束，这种情况更多应用于动态的页面。 进一步的说chunkedHTTP请求报文的格式是这样的： 1234&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt; 其中在请求头的地方有一个叫Content-Length的字段，如果没有这个字段那么就会有叫Transfer-encoding的字段，它用来表示http报文的传输格式，这个字段的取值有很多，但是真正有意义的只有一个—chunked。 如果一个HTTP消息（请求消息或应答消息）的Transfer-Encoding消息头的值为chunked，那么，消息体由数量未定的块组成，并以最后一个大小为0的块为结束。 每一个非空的块都以该块包含数据的字节数（字节数以十六进制表示）开始，跟随一个CRLF（回车及换行），然后是数据本身，最后块CRLF结束。在一些实现中，块大小和CRLF之间填充有白空格（0x20）。 最后一块是单行，由块大小（0）、一些可选的填充白空格、以及CRLF组成。最后一块不再包含任何数据，但是可以发送可选的尾部，包括消息头字段。消息最后以CRLF结尾。 注意1.chunked和multipart两个名词在意义上有类似的地方，不过在HTTP协议当中这两个概念则不是一个类别的。multipart是一种Content-Type，标示HTTP报文内容的类型，而chunked是一种传输格式，标示报头将以何种方式进行传输； 注意2.chunked传输不能事先知道内容的长度，只能靠最后的空chunk块来判断，因此对于下载请求来说，是没有办法实现进度的。在浏览器和下载工具中，偶尔我们也会看到有些文件是看不到下载进度的，即采用chunked方式进行下载； 注意3.chunked的优势在于，服务器端可以边生成内容边发送，无需事先生成全部的内容。HTTP/2不支持Transfer-Encoding: chunked，因为HTTP/2有自己的streaming传输方式。 http keep-alive与tcp keep-alivehttp的keep-alive与tcp的keep-alive可不是同一回事，意图也不一样。http的keep-alive是为了让tcp活得更久一点，以便在同一个连接上传送多个http，提高socket的效率。而tcp的keep-alive是tcp的一种检测tcp连接状况的保鲜机制。tcp的keep-alive是一个保鲜定时器，支持三个系统内核配置参数： 123echo 1800 &gt; /proc/sys/net/ipv4/tcp_keepalive_timeecho 15 &gt; /proc/sys/net/ipv4/tcp_keepalive_intvlecho 5 &gt; /proc/sys/net/ipv4/tcp_keepalive_probes keepalive是TCP保鲜定时器，当网络两端建立了tcp连接之后，闲置idle（双方没有任何数据流发送往来）了tcp_keepalive_time后，服务器内核就会尝试向客户端发送侦测包，来判断TCP连接状况(有可能客户端崩溃、强制关闭了应用、主机不可达等等)。如果没有收到对方的回答(ack包)，则会在tcp_keepalive_intvl后再次尝试发送侦测包，直到收到对对方的ack,如果一直没有收到对方的ack,一共会尝试tcp_keepalive_probes次，每次的间隔时间在这里分别是15s、30s、45s、60s、75s。如果尝试tcp_keepalive_probes,依然没有收到对方的ack包，则会丢弃该TCP连接。TCP连接默认闲置时间是2小时，一般设置为30分钟足够了。 也就是说，仅当nginx的keepalive_timeout值设置高于tcp_keepalive_time，并且距此tcp连接传输的最后一个http响应，经过了tcp_keepalive_time时间之后，操作系统才会发送侦测包来决定是否要丢弃这个TCP连接。一般不会出现这种情况，除非你需要这样做。 keep-alive与TIME_WAIT使用http的keep-alive，可以减少服务端TIME_WAIT数量(因为由服务端httpd守护进程主动关闭连接)。道理很简单，相较而言，启用keep-alive，建立的tcp连接更少了，自然要被关闭的tcp连接也相应更少了。 补充建议在服务器提供Web站点服务时(一个页面除了动态内容，还包含非常多的JS、图片、css文件等)开启keep-alive。在“服务器提供的是一个接口服务，除了动态内容，几乎没有引用任何静态内容”这样的场景，不建议开启keep-alive。 参考资料http://www.cnblogs.com/skynet/archive/2010/12/11/1903347.htmlhttps://hit-alibaba.github.io/interview/basic/network/HTTP.htmlhttp://51write.github.io/2014/04/09/keepalive/http://www.nowamagic.net/academy/detail/23350305]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>大牛之路</tag>
        <tag>http协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ssh连接port22:Socket error Event:32 Error:10053]]></title>
    <url>%2F2018%2F03%2F07%2Fssh%E8%BF%9E%E6%8E%A5port22-Socket-error-Event-32-Error-10053%2F</url>
    <content type="text"><![CDATA[今天遇到了一个奇怪的现象，据开发人员反馈，有一台阿里云服务器在控制台重启了之后，发现无法登陆了。我先使用阿里云的控制台打算远程登陆到这台机器发现，远程登陆总是显示密码错误。然后我使用xshell登陆对应的外网IP和22端口的时候发现爆出如下的错误： 12345678Connecting to X.X.X.X:22...Connection established.To escape to local shell, press 'Ctrl+Alt+]'.Socket error Event: 32 Error: 10053.Connection closing...Socket close.Connection closed by foreign host. 这种情况很罕见，google了一下也没有对于我有用的处理办法，于是我就只好给阿里云后台发了一下工单。授权给阿里云让他们登陆一下这台机器看一下里面发生了什么，阿里云的售后人员过了一会打过电话过来说，发现这台机器里面有人操作了chmod -R 777 /，破坏了比如/etc/passwd和/etc/shadow的权限，所以会爆出这样的错误。如图： 阿里的售后说他们也把几个跟登陆有关的文件暂时恢复权限，这样这个机器就可以成功登陆了，如图：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[孤儿进程和僵尸进程]]></title>
    <url>%2F2018%2F03%2F07%2F%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8B%E5%92%8C%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[原理与定义首先要知道，linux有父进程和子进程这样的说法。那父进程如何创建子进程呢？fork。 子进程的进行和父进程的进行是异步的，但是父进程就像父母一样对自己的小孩也有一定的控制欲，这个控制欲就表现在如果子进程如果结束了，它释放了之前占用的资源、内存、文件等等，但是它还保留了一点信息：进程号PID、退出状态、运行时间等等。而这些残留信息是父进程通过wait/waitpid来获取，如果父进程一直不获取，那么子进程就会一直保留这些信息直到海枯石烂。 孤儿进程：父进程退出，子进程继续进行，那么此时子进程就是孤儿进程。这个时候init进程（进程号为1）来作为子进程的监护人，发出wait/waitpid来完成状态收集工作； 僵尸进程：父进程没有退出，但是它迟迟不发出wait/waitpid来回收子进程的资源。就好比儿子死了，当爹的不给收尸，这个儿子就成了孤魂野鬼成了僵尸。 影响与危害孤儿进程是没有什么大的危害，虽然他虽然没有了亲生父亲，但是也有init进程来通过循环的wait()来处理它的善后工作，所以迟早会把占用的资源释放掉。 甚至有的用户可以把进程弄成孤儿进程，以使之与用户会话脱钩，并转至后台运行。这一做法常应用于启动需要长时间运行的进程，也即守护进程。另外，nohup命令也可以完成这一操作。 但是僵尸进程不一样，要是父进程对子进程一直不使用wait/waitpid，那么pid就会不回收，可是系统内的pid总是是有限的，这样久而久之就是对pid的一个霸占，新的进程也无法生成，这就是僵尸进程的危害。 如何处理僵尸进程僵尸进程是杀不死的，怎么办？杀他爹，把父进程杀掉了，那么这些僵尸就成了孤儿进程，然后再由init收养，最后入土为安。 查看当前服务器僵尸进程的方法： 1ps -A -o stat,ppid,pid,cmd | grep -e '^[Zz]' 如果服务器上的僵尸进程不是出自一个父进程之手，那么就用下面这个命令批量解决： 1ps -A -o stat,ppid,pid,cmd | grep -e '^[Zz]' | awk '&#123;print $2&#125;' | xargs kill -9 但是如果父进程是init进程，那么这样的僵尸进程怎么办？答案，不用刻意管他，相信init的能力，它迟早会被init回收的，成为僵尸进程也是暂时的。 参考资料https://zh.wikipedia.org/wiki/%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8Bhttps://zh.wikipedia.org/wiki/%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8Bhttp://blog.csdn.net/YuZhiHui_No1/article/details/53011390]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[蚂蚁金服运维面试全纪录]]></title>
    <url>%2F2018%2F03%2F07%2F%E8%9A%82%E8%9A%81%E9%87%91%E6%9C%8D%E8%BF%90%E7%BB%B4%E9%9D%A2%E8%AF%95%E5%85%A8%E7%BA%AA%E5%BD%95%2F</url>
    <content type="text"><![CDATA[早上接到蚂蚁金服的运维面试电话，有点突然袭击，下面是整个的面试记录。 首先，面试官先向我讲述了一下他们平时运维的工作内容，然后结合我的简历开始提问。 1）都用过我们的什么产品？这一阶段老老实实、正常回答工作中所用到的阿里云产品和使用情景。 2）VPC网络有哪些好处？我就答出来更加安全…面试官说其他方面呢，我就不知道了。【事后补充】VPC网路的灵活性更高，可以自由定义网段划分、IP地址和路由网络。 3)一个vpc的服务器如何与外网交互？我说可以改写路由或者通过iptables转发。 4）iptables里PREROUTING和POSTROUTING都是啥？PREROUTING处理刚到达本机并在路由转发前的数据包；POSTROUTING处理即将离开本机的数据包。 5）问：RDS在什么操作下会CPU飙升，任举一例？答：在我实际工作中，比较明显的是在数据同步的时候会飙升。 6）RDS为什么会在DTS的时候有飙升的现象？这个我答的不好，有点东拉西扯…（尴尬） 7）mysql备份的时候使用过什么参数？答：--skip-opt 防止运行中的MYSQL锁库加速数据备份的参数是什么？-q 提高导出性能-e 提高导入性能，使用包括几个VALUES列表的多行INSERT语法；--max_allowed_packet=XXX 客户端/服务器之间通信的缓存区的最大大小；--net_buffer_length=XXX TCP/IP和套接字通信缓冲区大小，创建长度达到net_buffer_length的行； 注意！max_allowed_packet和net_buffer_length在mysql里有参数值，不能超过参数值！查看方法：show variables like &#39;max_allowed_packet&#39;; 8）cache和buffer有什么区别？cache是缓存，弥补高速设备与低速设备的鸿沟引入的中间层，达到数据快取的目的（救火车与蓄水池）；buffer是缓冲区，用户流量整形，把大量的小的io整理一个平稳的大io，减少磁盘响应次数；buffer是即将要写入磁盘的，cache是要被从磁盘里读出来的。当然这只是普通用途，buffer用来读、cache用来写也是有可能的。具体问题具体分析。 9）他俩的调用有什么区别？我问是要说“块读取”什么的么，面试官说是。我就蒙说cache是块读取，buffer我不清楚…（尴尬 again）【事后补充】 10）谈一谈time_wait和close_wait，各自在什么情况下出现？time_wait和close_wait是出现在“四次挥手”的环节里，time_wait是服务器接收到客户端发来的断开TCP连接的请求，并且服务器发送确认断开的包给客户端，此时服务器处于time_wait状态，如果服务器等待两个msl的话，就会默认断开连接，如果想修改msl可以通过修改/etc/systl.conf文件；close_wait是客户端已经发送了断开TCP请求，但是服务器端没有接收到，也就是time_wait的上一步，此时这个资源就一直被程序霸占。 11）为什么time_wait需要等待两个msl?1.99行不行？2.01行不行？我当时说防止上一次连接中的包，迷路后重新出现，影响新连接。面试官好像觉得不是很满意…（尴尬 again）【事后补充】MSL是指一个片段在网络中的最大存活时间，2MSL是一个发送和一个回复所需的最大时间，如果直到2MSL，客户端都没有收到fin包，那么客户端就可以断定他发出去的ack已经被服务端接收，结束TCP连接。 12）说出一个你使用过的python库。我说我前两天用matpoltlib画图，就谈了谈这个画图的库。 13）python装饰器了解么？没什么深入的了解，就没敢答，怕被问死。 14）僵尸进程和孤儿进程，了解么？马蛋，这个让我给说反了…(闹心啊啊啊啊啊啊啊)【事后补充】孤儿进程：父进程退出，而它的一个或者多个子进程还在运行，这些子进程就叫孤儿进程，孤儿进程被init进程收养，由init进程对它们完成状态收集工作；僵尸进程：一个进程用fork创建了子进程，然后这个子进程退出了，而父进程并没有调用wait或者waitpid去获取子进程的状态信息，那么这个子进程的进程描述符还在系统中，这种进程叫僵尸进程； 孤儿进程不怕，由于孤儿虽然没有父母，但是有民政局（init进程）收养，孤儿进程退出后也有init做一切善后工作；而僵尸进程会一直霸占其PID号，但是系统总共的PID是有限的，这样就会让可用的PID越来越少，所以僵尸进程是要避免的。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>大牛之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper的选举原理]]></title>
    <url>%2F2018%2F03%2F05%2FZookeeper%E7%9A%84%E9%80%89%E4%B8%BE%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[前言Zookeeper是一款比较常见的式应用程序协调服务软件，如果配置了多台zookeeper自然要选择一个头头，这个头头就是leader，很明显不能所有的zookeeper都是leader，那样就失控了；也不能所有的zookeeper都是follower，那就群龙无首无法协调。 插播一句，这种一老大N跟班的模式是过去分布式软件里很常见的工作模式，而最近比较火热的区块链不同，它是一种去中心化的工作模式，大家人人都当节点，然后放在一起整合，有点原始社会的意思。所以说，算法有时候来自于人类学，也会在一定程度反过来上影响人类。 选举leader的方式是一种叫FastLeaderELection的算法，以3.4.6版本为例，它被保存在/usr/zookeeper/src/java/main/org/apache/zookeeper/server/quorum/这个文件夹下。 选举的中心思想实际上FastLeaderELection说的中心思想无外乎以下几个关键点： 全天下我最牛！在我没有发现比我牛的推荐人的情况下，我就一直推举我当leader，第一次投票那必须推举我自己当leader。 每当我接收到其它的被推举者，我都要回馈一个信息，表明我还是不是推举我自己。如果被推举者没我大，我就一直推举我当leader，是我是我还是我！ 我有一个票箱， 和我属于同一轮的投票情况都在这个票箱里面。一人一票重复的或者过期的票，我都不接受。 一旦我不再推举我自己了（这时我发现别人推举的人比我推荐的更牛），我就把我的票箱清空，重新发起一轮投票（这时我的票箱一定有两票了，都是选的我认为最牛的人）。 一旦我发现收到的推举信息中投票轮要高于我的投票轮，我也要清空我的票箱。并且还是投当初我觉得最牛的那个人（除非当前的人比我最初的推荐牛，我就顺带更新我的推荐）。 不断的重复上面的过程，不断的告诉别人“我的投票是第几轮”、“我推举的人是谁”。直到我的票箱中“我推举的最牛的人”收到了不少于N/2 + 1的推举投票。这也回答了为什么zookeeper在少于N/2 + 1的节点处于工作状态的情况下会崩溃了。因为，无论怎么选也没有任何节点能够获得N/2 + 1的票数。 这时我就可以决定我是flower还是leader了（如果至始至终都是我最牛，那我就是leader咯，其它情况就是follower咯）。并且不论随后收到谁的投票，都向它直接反馈“我的结果”。 判断依据上面第二步里说了，如果接收到其他被推举者的消息，而且判断出这个被推举者比我牛，我就要推举他，那么判断依据是啥呢？答案是依次比较epoch、zxid、serverid。 先说说啥是epoch、zxid、serverid： epoch: 表示选举轮数。 zxid: 事务zxid包含了本地数据的最后更新时间相关的信息。 serverid: 当前server的 ID, 通过配置文件指定(echo &#39;1&#39; &gt; myid)。 具体的判断过程是：接收到的消息中，有epoch比我大的，则选epoch大的消息中确定的server；如果epoch相等，则选zxid最大的server；如果zxid也相等，则选serverid最大的server(有的节点生来就是当leader的）。 为什么要有epoch呢？这样是为了防止中途有选举者掉线，他们错过了选举，再次连上来的时候，他们发现自己的投票轮已经小于现有的投票轮了，那么他们比如要清空自己的投票箱然后无条件的改为推荐接收到的最新选举中大家推荐的最牛的那个人（如果没有人比我牛，那还是推荐我自己）。由于有最后一条serverid大的最后压阵，而且serverid又不能重复，所以基本上都能最后选出一台作为leader。 参考资料http://blog.csdn.net/yinwenjie/article/details/47613309https://mozillazg.com/2017/03/zookeeper-fastleader-elect-leader.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从韩国民主电影三部曲浅谈我对民主的认识]]></title>
    <url>%2F2018%2F03%2F04%2F%E9%9F%A9%E5%9B%BD%E6%B0%91%E4%B8%BB%E7%94%B5%E5%BD%B1%E4%B8%89%E9%83%A8%E6%9B%B2%2F</url>
    <content type="text"><![CDATA[这个周末周五晚上看了《出租车司机》，周六下午看了《1987：黎明到来的那一天》，再加上之前就在B站看过又被下架的《辩护人》，韩国民主运动三部曲都看完了。 韩国民主运动电影还有一部叫《华丽的假期》，这个片子是2007年公映的，也是讲光州事件，但是这部片从电影角度上不如上面这三者，所以影响力和传播程度相对有限。 一直以来我对韩国的政治采取一种“黑”的态度，因为他们的总统基本没有好下场，哪怕是我个人比较喜欢的卢武铉总统也是以自杀结束了自己的一生，而且他们的演艺圈和体育圈也是以各种“黑”和“潜规则”出名。但是我不得不佩服韩国正直电影人的精神以及韩国正直记者们的精神，他们坚持了自己的操守而且履行了自己的职责，用骨气和勇气记录了他们能接触到的真相并且在日后拍成电影反思历史。 论民主化运动，韩国可以说是亚洲里第一档的存在，大型示威的次数加起来比越南、缅甸、柬埔寨加起来还要多，远超于同样是发达国家的日本。韩国民主化运动主要集中在1980-1987年全斗焕执政那一段时间，那时韩国人民虽然经历了初期经济水平腾飞的甜蜜，但是对后期经济调控不力和政府打压言论表示不满和愤怒。暴动的人民反抗意识比较强，不仅有大规模游行，甚至有这几部电影里没有提到的抢劫军火库的行为。而这些抢劫军火的行为日后也成了全斗焕在法庭上力图脱罪的一个辩控点。 这几部电影虽然被部分人影评“有明显的韩国特色，会导致审美疲劳”，但是并不耽误它们一次又一次的刷新票房记录，可见参与政治追求民主和公平其实是公民的一种本能。但是说实话，截止至今，光州事件虽然被平反但是没有得到彻底的清算。新闻说现任韩国总统文在寅先后观看了《出租车司机》和《1987：黎明到来的那一天》，会不会重审当年的光州罪犯，我们拭目以待。 民主可能本身不是一个效率很高的政治制度，因为它要坚持“少数服从多数”的原则，在具体条款颁布和施行的时候，由于不同人看待事物的水平和深度有高有低，以及侧重面的不同，那么肯定会有一些不一样的声音。而独裁的“一言堂”则相对效率很快，从历史来看，独裁政府甚至有战争上打败民主政府的先例，而且独裁政府挑头并且通过集权形式搞经济的话，在国家原有经济非常落后的前提下，的确可以快速进步，但是这种进步并不是那种“可持续发展”式的，而且中后期会由于民众监督不力，导致政府腐败的先例数不胜数。所以说集权就是一个春药，服用肯定会上瘾，但是也只会用暂时的爽换来将来的无穷尽的苦。独裁无论是理论还是事实都已经被当今社会唾弃，只有民主化才是迟早的选择，因为它至少可以守得住下限。 而且我个人认为，民主是一个持续的过程而不是一个简单的结果。绝对意义上的民主和拖沓低效的民主只会害了广大的底层百姓，极力避免的同时，也要最小程度的限制人滥用民主，这些就需要政府工作的透明化和规范化。 不过韩国的民主也有它的独特性，主要就是它有特殊的外界因素—-既不能得罪美国人，又不能惹毛了朝鲜（这一点跟台湾很像），所以无论是强权政府还是抗议民众都没有把事情搞得太过火。其次还有韩国中产阶级在抗议中也扮演了“理性和保守的一面”：他们是经济发展的受益者，对秩序有相当的敏感性，一旦社会民主斗争极端化，中产阶级便会退出民主运动，这是其保守性的表现。除此之外，还有比如基督教的传播代替了原有的儒家思想更追求自由等等因素，我这里水平有限，就不展开了。 最后补充一句，各位都知道《辩护人》里宋康昊的原型是卢武铉总统，据说片里宋康昊parter的原型就是韩国现在的总统—文在寅。]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>政治</tag>
        <tag>亚洲民主</tag>
        <tag>影评</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[动手做一个网络简历并且保存成PDF]]></title>
    <url>%2F2018%2F03%2F02%2F%E5%8A%A8%E6%89%8B%E5%81%9A%E4%B8%80%E4%B8%AA%E7%BD%91%E7%BB%9C%E7%AE%80%E5%8E%86%E5%B9%B6%E4%B8%94%E4%BF%9D%E5%AD%98%E6%88%90PDF%2F</url>
    <content type="text"><![CDATA[环境说明服务器:nginx浏览器:firefox 制作网页简历过程首先先下载简历的模板文件，过程如下： 1234wget http://labfile.oss.aliyuncs.com/courses/624/cv-template.zipunzip cv-templatemv cv-template/* .rm -rf cv-template* __MACOSX* 然后在浏览器里的地址栏里输入服务器外网IP，就可看到下面的界面，如图： 我们发现这个界面是可以编辑的，于是就在前人的基础上修改即可，这里感谢前人栽树！！！ 但是修改了并不是就保存了，如果你刷新这个界面发现又变成了初始的界面。所以这个时候我们要把修改过的网页的前端代码拷贝下来。 在firefox浏览器的配置里选择WEB开发者，如图： 然后选择查看器： 这个时候在页面就出现了整个网页的代码，选择复制—HTML外面： 然后把这个html代码拷贝到nginx服务器里的index.html里覆盖原有的内容，再重新刷新浏览器，就会成为已经保存过的界面了！ 将网页保存成PDF在浏览器里的配置里选择打印，然后现在页面设置里的勾选打印背景（颜色和图片）再修改一下页眉和页脚。再点击打印，默认情况就会保存成PDF文件了。 参考资料https://segmentfault.com/a/1190000006820290]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维工程师笔试题第十五套]]></title>
    <url>%2F2018%2F03%2F01%2FLinux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%AC%94%E8%AF%95%E9%A2%98%E7%AC%AC%E5%8D%81%E4%BA%94%E5%A5%97%2F</url>
    <content type="text"><![CDATA[正文1.粘包是什么意思？TCP和UDP是否会出现粘包？出现了粘包如何处理？[我的答案]粘包就是当客户端连续不断的往服务端发送数据包的时候，服务端接收的数据会出现两个数据包粘在一起的情况；UDP（非面向连接）是不会出现粘包的，因为UDP协议是基于报文的，UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。而TCP（面向连接）是基于字节流的，它无法识别包的长度，所以会出现粘包的现象。 解决办法主要有以下三种：1）发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了，有较高的效率而且少冗余，但是编程较复杂；2）发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来，编程简单但是效率一般甚至很低；3）可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开； 2.time_wait是什么情况？如果出现了过多的close_wait可能是什么原因？[我的答案]TIME_WAIT是主动关闭连接的一方保持的状态，在保持这个状态2MSLmax segment lifetime时间之后，彻底关闭回收资源。遇到TIME_WAIT数过大导致的服务器异常，很容易解决，修改下/etc/sysctl.conf就ok了。 如果一直保持在CLOSE_WAIT状态，那么只有一种情况，就是在对方关闭连接之后服务器程序自己没有进一步发出ack信号。换句话说，就是在对方连接关闭之后，程序里没有检测到，或者程序压根就忘记了这个时候需要关闭连接，于是这个资源就一直被程序占着。这个情况多半是代码的问题，在服务器端是无能为力的，要检查代码。 3.epoll和select的区别？边缘触发和水平触发的区别？[我的答案]select查询速度较慢，因为他每次产生fd时候会有整体fdset的拷贝，而且每次有回送，select要查询整个fdset；epoll查询速度较快，因为他为每个fd都regist了一个单独的回调函数。 水平触发(LT)：当epoll检测到其上有事件发生并通知应用程序时，应用程序可以不立即处理，这样当应用程序再次调用epoll中调用函数时，epoll会再次通知应用程序此事件,直到被处理。 边沿触发(ET)：当epoll检测到其上有事件发生并通知应用程序时，应用程序必须立即处理，并且下一次的epoll调用，不会再向应用程序通知此事件。 所以ET模式大大得降低了同一个epoll事件被重复触发的次数，因此ET模式工作效率比LT模式更高。select、poll、epoll的默认工作模式都是水平触发(LT)模式，但是epoll是支持边沿触发(ET)模式的。 4.varchar和char的区别是什么？utf8字符集下varchar最多存多少个字符？[我的答案]前面那个问题去看http://blog.51cto.com/chenx1242/1742467，这里说后面那个。在utf-8状态下的varchar，最大只能到 (65535 - 2) / 3 = 21844 余 1。在gbk状态下的varchar, 最大只能到 (65535 - 2) / 2 = 32766 余 1。 5.primary key和unique的区别？[我的答案]首先先说明primary key = unique + not null，其次Unique Key可以是空，可以在一个表里的一个或多个字段定义，也就是爱有几个有几个，同时存在也可以；但是Primary Key不能为空不能重复，而其一个表里只能有一个Primary Key。 6.乐观锁是啥，悲观锁是啥？[我的答案]悲观锁Pessimistic Lock, 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 乐观锁Optimistic Lock, 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。 两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。 7.如何在python的三引号里添加变量？[我的答案] 1234567891011121314151617~$ pythonPython 2.7.3 (default, Jan 2 2013, 16:53:07) [GCC 4.7.2] on linux2Type "help", "copyright", "credits" or "license" for more information.&gt;&gt;&gt; &gt;&gt;&gt; context = """Here is an example block template:... name: %(name)s... age: %(age)d... job: %(job)s... """&gt;&gt;&gt; &gt;&gt;&gt; print context % dict(name="Tim Wang", age=45, job="Coder")Here is an example block template: name: Tim Wang age: 45 job: Coder &gt;&gt;&gt; 8.redis满了会怎么样？[我的答案]默认情况下redis满了就不会存储新的数据了，不过这个可以调整，redis在达到指定内存的时候可以通过设定的策略来做不同的动作，常见策略如下：1）noeviction:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）2）allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。3）volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。4）allkeys-random: 回收随机的键使得新添加的数据有空间存放。5）volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。6）volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。 9.啥是“脏读”、“不可重复读”、“幻读”？[我的答案]脏读又称无效数据的读出，是指在数据库访问中，事务T1将某一值修改，然后事务T2读取该值，此后T1因为某种原因撤销对该值的修改，这就导致了T2所读取到的数据是无效的。 不可重复读是指在数据库访问中，一个事务范围内两个相同的查询却返回了不同数据。这是由于查询时系统中其他事务修改的提交而引起的。比如事务T1读取某一数据，事务T2读取并修改了该数据，T1为了对读取值进行检验而再次读取该数据，便得到了不同的结果。 幻读是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的“全部数据行”。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入“一行新数据”。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。 10.ext2、ext3、ext4的区别是啥？[我的答案]ext3和ext2的主要区别在于，ext3引入Journal。ext2和ext3的格式完全相同，只是在ext3硬盘最后面有一部分空间用来存放Journal（日志）的记录；在ext2中，写资料到硬盘中时，先将资料写入缓存中，当缓存写满时才会写入硬盘中；在ext3中，写资料到硬盘中时，先将资料写入缓存中，待缓存写满时系统先通知Journal，再将资料写入硬盘，完成后再通知Journal，资料已完成写入工作；在ext3中，也就是有Journal机制里，系统开机时检查Journal的资料，来查看是否有错误产生，这样就快了很多； ext4和ext3的主要区别在于:首先ext4与ext3兼容,ext3只支持32,000个子目录，而额ext4支持无限数量的子目录;ext3所支持的16TB文件系统和最大的2TB的文件，而ext4分别支持1EB（1,048,576TB，1EB=1024PB，1PB=1024TB）的文件系统，以及16TB的文件;ext3的数据块分配策略是尽快分配，而ext4是尽可能地延迟分配，直到文件在cache中写完才开始分配数据块并写入磁盘;ext4允许关闭日志，以便某些有特殊需求的用户可以借此进一步提升性能等等等等。 11.简述一下A记录与NS记录的区别1.A记录是名称解析的重要记录，它用于将特定的主机名映射到对应主机的IP地址上。你可以在DNS服务器中手动创建或通过DNS客户端动态更新来创建。2.NS记录此记录指定负责此DNS区域的权威名称服务器。3.A记录和NS记录的区别是，A记录直接给出目的IP，NS记录将DNS解析任务交给特定的服务器，NS记录中记录的IP即为该特定服务器的IP地址。4.NS记录优先于A记录，A记录优先于CNAME记录 参考资料https://blog.insanecoder.top/tcp-packet-splice-and-split-issue/http://blog.csdn.net/tiandijun/article/details/41961785http://www.redis.cn/topics/lru-cache.htmlhttp://blog.csdn.net/d_guco/article/details/53166722http://www.hollischuang.com/archives/934http://zhaodedong.leanote.com/post/Linux%EF%BC%9AExt2-Ext3-Ext4%E7%9A%84%E5%8C%BA%E5%88%AB]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>面试经验</tag>
        <tag>大牛之路</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[调用阿里云api获取阿里云数据同步服务（DTS）并且作图发送邮件的整个流程]]></title>
    <url>%2F2018%2F02%2F28%2F%E8%B0%83%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91api%E8%8E%B7%E5%8F%96%E9%98%BF%E9%87%8C%E4%BA%91%E6%95%B0%E6%8D%AE%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1%EF%BC%88DTS%EF%BC%89%E5%B9%B6%E4%B8%94%E4%BD%9C%E5%9B%BE%E5%8F%91%E9%80%81%E9%82%AE%E4%BB%B6%E7%9A%84%E6%95%B4%E4%B8%AA%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言在https://rorschachchan.github.io/2018/02/24/阿里云获取DTS服务延迟的脚本/ 文章里已经说了“领导要求每天查看阿里云dts同步的延迟情况和同步速率情况”，并且在https://rorschachchan.github.io/2018/02/27/使用matplotlib画图的一个脚本/ 里面也放了一个使用python matplotlib画图的demo，这篇文章的目的就是把整个过程实现，并且把dts图形以每日邮件的形式发送给领导的效果！ 实现需求的思路本次需求有四个动作，分别是获取一天以内的DTS延迟和同步速率、将获取到的DTS值做成PNG图像、将生成的PNG图像上传到阿里云云存储OSS、把图片展示到邮件里并发送给相关领导。由于第一步获取一天以内的DTS延迟和同步速率需要将这个脚本每小时执行一次，执行24次，才可以执行生成png图像这一步，所以后三个其实可以写成一个大脚本。不过在本文为了表述的清楚，就把各自不同用途写成了不同的脚本。 获取阿里云DTS延迟和同步速率的脚本这个脚本之前写过了，这里再拿出来晒一遍： 123456789101112131415161718192021222324252627282930313233#!/usr/bin/env python#coding=utf-8#这个脚本是用来获取dts延迟数字的from aliyunsdkcore import clientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionimport time,json,syssys.path.append('/解压缩路径/aliyunsdkdts/request/v20160801/') #这里看不懂去看https://rorschachchan.github.io/2018/02/24/阿里云获取DTS服务延迟的脚本/import DescribeSynchronizationJobStatusRequest# 创建 Client 实例clt = client.AcsClient('这里填写ak','这里填写sk','cn-shenzhen')# 创建 request，并设置参数request = DescribeSynchronizationJobStatusRequest.DescribeSynchronizationJobStatusRequest()request.set_SynchronizationJobId("这里填写DTS的ID号")response = clt.do_action_with_exception(request)delay = json.loads(response)rate = str(delay["Performance"]["FLOW"])[0:4] #由于同步速率默认是带单位的，这里就取前四位#用A.txt来存储延迟时长fd = open("/存储路径/A.txt","a")fd.write(str(delay["DataSynchronizationStatus"]["Delay"]))fd.write('\n')fd.close()#用B.txt来存储同步速率 fr = open("/存储路径/rate.txt","a")fr.write(rate)fr.write('\n')fr.close() 将获取到的值做成图片的脚本由于脚本执行环境是无图像的阿里云服务器，系统是centos 7，ps.slow这一步会爆错RuntimeError: could not open display，所以只能采取把生成的PNG图像文件保存到本地路径里的方法。脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/usr/bin/env python# -*- coding: utf-8 -*-import matplotlib as mplmpl.use('Agg') #在无法生成图像的环境下要添加了上面两句话import matplotlib.pyplot as pltimport numpy as npimport pylab as plx=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]#横坐标的内容labels=['10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','1','2','3','4','5','6','7','8','9']#y1是delay延迟时长with open('/存储路径/A.txt', 'r') as f: y1 = [] for line in f: lst = line.split('\n') #增加一个换行符，不然数字是不换行的 y1.append(float(lst[0]))#y2是rate同步速率with open('/存储路径/B.txt', 'r') as f: y2 = [] for line in f: lst = line.split('\n') y2.append(float(lst[0]))#输入对应的坐标，后面是颜色plot1,=pl.plot(x,y1,'r')plot2,=pl.plot(x,y2,'b')pl.xticks(x,labels)pl.title('这里写标题',size=20) #中文会显示乱码，推荐还是英文pl.xlabel('这里是X轴标题', size=14)pl.ylabel('这里写Y轴标题', size=14)pl.ylim(0.0,5.0)#曲线对应注释pl.legend([plot1,plot2],('Delay','Sync rate'),'best',numpoints=1)#开启网格pl.grid()#图片保存路径plt.savefig('/保存路径/图片名称.png', format='png') 将生成的图片上传到阿里云OSS的脚本由于不想让“领导去手动点开附件查看图像”，所以我们干脆把图片作为邮件的正文展示出来，那么就在html里就需要img src=图片的网络地址的方法。于是就把刚刚生成的图片上传到阿里云OSS里，这样就可以获得图片的网络地址。而且阿里云OSS是“相同文件名会覆盖”，所以不用再去删除。整个脚本内容如下： 1234567891011121314151617# -*- coding: utf-8 -*-import osimport shutilimport oss2access_key_id = os.getenv('OSS_TEST_ACCESS_KEY_ID', '这里填写ak')access_key_secret = os.getenv('OSS_TEST_ACCESS_KEY_SECRET', '这里填写sk')bucket_name = os.getenv('OSS_TEST_BUCKET', '这里填写bucket名称')endpoint = os.getenv('OSS_TEST_ENDPOINT', '这里填写内网end-point')# 确认上面的参数都填写正确了for param in (access_key_id, access_key_secret, bucket_name, endpoint): assert '&lt;' not in param, '请设置参数：' + param# 创建Bucket对象，所有Object相关的接口都可以通过Bucket对象来进行bucket = oss2.Bucket(oss2.Auth(access_key_id, access_key_secret), endpoint, bucket_name)bucket.put_object_from_file('上传到OSS的图片名称.png', '/服务器保存路径/图片名称.png') 将图片作为内容发邮件的脚本整个脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#!/usr/bin/env python# -*- coding: UTF-8 -*-import os,time,re,smtplib,loggingfrom email.mime.text import MIMETextfrom email.header import Headerdef send_mail(to_list, cc_list, html, sub): me = mail_user msg = MIMEText(html, _subtype='html', _charset='utf-8') # 格式化邮件内容为html，编码为utf-8 msg['Subject'] = sub # 邮件主题 msg['From'] = me # 发件人 msg['To'] = ";".join(to_list) # 收件人，将列表转换为字符串 msg['Cc'] = ";".join(cc_list) # 抄送人，将列表转换为字符串 try: send_smtp = smtplib.SMTP() # 实例化 send_smtp.connect(mail_host) # 连接smtp服务器 send_smtp.login(mail_user, mail_pass) # 使用定义的账号密码进行登录 send_smtp.sendmail(me, to_list+cc_list, msg.as_string()) # 发送邮件 send_smtp.close() # 关闭连接 return True except Exception, e: logging.basicConfig(filename='logger.log', level=logging.DEBUG) logging.debug(e) print ("ERROR!!!!") return Falseif __name__ == '__main__': mail_host = 'mail.dahuatech.com' mail_user = '这里填写发件人地址' mail_pass = '填写对应的密码' mailto_list = ['收件人邮箱地址'] mailcc_list = ['抄送人1的邮箱地址'，'抄送人2的邮箱地址'] html = """ &lt;body&gt; &lt;br&gt;&lt;img src="这里填写的是图片的http地址"&gt;&lt;/br&gt; &lt;table color="CCCC33" width="800" border="1" cellspacing="0" cellpadding="5" text-align="center"&gt; &lt;tr&gt; &lt;td test-align="center"&gt;上图是阿里云深圳VPC区数据同步过去24小时的情况。&lt;br /&gt; 注意事项 1:dts的延迟时间是5秒计算一次，api请求会取到最新的延迟时间，而控制台是每隔20秒才刷新一次； 注意事项 2:api在延迟时间取值为整数，即1.x显示为2，请知悉; 注意事项 3:此邮件是系统自动发出，如果有任何疑问请联系运维人员； &lt;/tr&gt;&lt;/br&gt; &lt;/table&gt; &lt;/body&gt; """ sub = "阿里云深圳VPC数据同步情况" if send_mail(mailto_list,mailcc_list,html,sub): logging.debug("Send mail succed!") else: logging.debug("Send mail failed") 上面四个脚本整个执行下来，效果如下，至此大功告成！ 参考资料https://github.com/aliyun/aliyun-oss-python-sdk/blob/master/examples/object_basic.pyhttps://hk.saowen.com/a/fe355cb5cc3ab17dbc84e9489621d2ab31da72b511092839832bc9e89d63bf71http://blog.csdn.net/baoli1008/article/details/47980779https://www.digglife.net/articles/html-mail-with-inline-images-python-perl.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个监控挂载盘的python脚本]]></title>
    <url>%2F2018%2F02%2F27%2F%E4%B8%80%E4%B8%AA%E7%9B%91%E6%8E%A7%E6%8C%82%E8%BD%BD%E7%9B%98%E7%9A%84python%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[前言公司产品线有一个公用的挂载盘，主要是用来方便各位开发人员去放置他们自己的一些工作材料，比如异常的日志或者tcpdump的抓包等等杂七杂八的东西，但是这个挂载盘由于使用人众多，容量自然要有监控，于是就有了写这个脚本的动机。 在这里我写了两个脚本，上面这个是用来监控磁盘容量，然后通过df -h的排序生成前十名占容量最大的文件夹，把这个文件夹的名字和对应的大小重定向到一个叫alarm.txt这个文件里，这个文件就是邮件正文。然后在确定他们的主人，统一加上公司邮箱后缀来得到他们主人的邮箱地址，最后对应他们各自的邮箱地址用下面那个脚本来发送文件夹容量过高的邮件。 监控挂载盘的脚本12345678910111213141516171819202122232425262728293031323334353637383940414243#!/usr/bin/env python# coding=utf-8import osimport AutoMailimport commands#设定变量判断是否挂载和挂载盘的容量mount = commands.getoutput("mount | grep ':.*nfs'|wc -l")size = commands.getoutput("df -h | grep share | awk '&#123;print $5&#125;' | cut -d '%' -f 1") ##建立发邮件的文本文件def Createalarm(): if os.path.exists('/root/chenscript/alarm.txt') == True: os.system("python /root/chenscript/weixin_sharealarm.py") print ("微信告警已经发送！") os.system("cd /root/chenscript; echo 'share盘容量大于80%，现在将调出容量排名前十位的文件夹名字及对应的容量，请各位处理一下不需要的文件！' &gt;/root/chenscript/alarm.txt") os.system("cd /挂载盘名称 ;du -s * --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹'|sort -nr |head &gt;&gt;/root/chenscript/alarm.txt") os.system("echo '\n' &gt;&gt; /root/chenscript/alarm.txt") if os.path.exists('/root/chenscript/alarm.txt') == False: os.system("cd /root/chenscript;touch alarm.txt")def Sendmail(): fp = open('/root/chenscript/alarm.txt', 'r') content = fp.read() AutoMail.send_mail('share挂载盘容量大于80%！收到邮件的各位请整理自己对应的文件夹！', content) #将邮件的文件刷新def Dellist(): os.system("cd /root/chenscript/;rm -f alarm.txt;touch alarm.txt")if mount == '1' and size &gt;= '80': print ("挂载盘存在！") print ("share盘容量大于80%...") Createlist() Sendmail() Dellist()elif mount == '1' and size &lt; '80': print ("挂载盘存在！") print ("share盘容量正常...")else: print ("挂载盘不存在，现在重新挂载...") os.system("mount -t nfs -o acl,rw,intr,soft,nolock,rsize=8192,wsize=8192 10.160.43.172:/share /share ") 发送告警邮件脚本1234567891011121314151617181920212223242526272829303132333435363738394041424344#!/usr/bin/env python#coding=utf-8#这个脚本的用途是用来发送邮件import smtplibfrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextfrom email.mime.application import MIMEApplicationmailto_list=[] #这里为空list，会从list.txt里一行一行的当做元素添加进来#生成list.txtif os.path.exists('/root/chenscript/list.txt') == True: os.system("cd /挂载盘名称;du -s * --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹'|sort -nr |head|awk \'&#123;print $2\"@dahuatech.com\"&#125;\' &gt;&gt;/root/chenscript/list.txt")if os.path.exists('/root/chenscript/list.txt') == False: os.system("cd /root/chenscript/;rm -f list.txt;echo '本人的邮箱地址'&gt;list.txt")with open('/root/chenscript/list.txt','r') as f: f=f.readlines()for i in f: i=i.strip('\n') mailto_list.append(i)mail_host="这里填写邮箱主机"mail_user="这里填写发送人的邮箱地址"mail_pass="发送人的邮箱密码"mail_postfix="dahuatech.com"mail_sender="与mail_host内容相同"def send_mail(sub, content): me=mail_sender msg = MIMEMultipart() msg['Subject'] = sub msg['From'] = me msg['To'] = ";".join(mailto_list) content1 = MIMEText(str(content), 'plain', 'utf-8') msg.attach(content1) try: s = smtplib.SMTP() s.connect(mail_host) s.login(mail_user,mail_pass) s.sendmail(me, mailto_list, msg.as_string()) print('发送成功！\n') s.close() except Exception as e: print(str(e))os.system("cd /root/chenscript/;rm -f list.txt;echo '我本人的邮件地址'&gt;list.txt") 执行的效果如下： 隐藏的知识点1）du -s是按照字节来统计，--exclude=&#39;yunwei&#39;是在排序的时候忽略掉yunwei这个文件夹，容后再用sort -nr|head是得到从大到小前10名，如果得到后10名就是sort -nr|tail；2）如果使用的是import commands，那么commands.getoutput得到的是字符串！3）用mount | grep &#39;:.*nfs&#39;来判断挂载盘是否存在是一个很简单的方式，如果挂了多个，就用ip in的方式来进一步判断；4）python要一行一行的读取文件，就readline；5）python按行读取文件，去掉换行符\n的方法： 12for line in file.readlines(): line=line.strip('\n') 6）import Automail的时候，就已经把Automail.py这个脚本固定住了，这时候mailto_list已经不能变化了，所以要把添加list.txt放到这个脚本里。 发了邮件，连吼带骂一顿，终于把share盘容量下降到了69这样一个美妙的数字…]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用matplotlib画图的一个脚本]]></title>
    <url>%2F2018%2F02%2F27%2F%E4%BD%BF%E7%94%A8matplotlib%E7%94%BB%E5%9B%BE%E7%9A%84%E4%B8%80%E4%B8%AA%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[准备工作之前在https://rorschachchan.github.io/2018/02/24/阿里云获取DTS服务延迟的脚本/ 里已经可以获取到阿里云DTS服务的延迟时长和同步速率。下一步就是把这些值以24小时为周期作一个图像，然后每天在固定时间发送到领导们的邮件里。 python作图的第三方工具叫matplotlib，安装步骤如下： 1234pip install matplotlib #画图模块pip install numpy #依赖的库pip install scipy #又一个依赖的库yum install -y Tkinter #如果是python3，那么就是yum install -y tkinter 脚本内容由于我是在centos 7里进行脚本操作，而linux服务器有没有安装图像，所以在执行import matplotlib.pyplot as plt的时候可能会爆错：RuntimeError: could not open display，这个时候需要在前面改成如下样式（注意先后顺序）： 123import matplotlib as mplmpl.use('Agg')import matplotlib.pyplot as plt 举一个简单的脚本例子如下，就是给予（x,y）然后连成曲线图的效果，脚本里数字的部分不加引号也是可以识别的，当然使用变量也可以。 12345678910111213141516171819202122232425262728293031323334353637383940414243#!/usr/bin/env python# -*- coding: utf-8 -*-import matplotlib as mplmpl.use('Agg') import matplotlib.pyplot as pltimport numpy as np import pylab as pl x=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]#横坐标的内容labels=['10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','1','2','3','4','5','6','7','8','9']a = '1'b = '2'c = '3'd = '4'#y1是延迟y1=['2','3','5','4','2','1','2','2','3','5','4','2','1','2','2','3','5','4','2','1','2','2','3','5']#y2是同步速率y2=[a,b,c,d,0.13,0.12,0.14,0.14,0.14,0.16,0.15,0.13,0.12,0.14,0.14,0.14,0.16,0.15,0.13,0.12,0.14,0.22,0.18,0.11]#输入对应的坐标，后面是颜色plot1,=pl.plot(x,y1,'r') #这里是有逗号的，用于参数解包plot2,=pl.plot(x,y2,'b') pl.xticks(x,labels)#图片的标题以及对应的字号大小pl.title('The DTS status of Shenzhen VPC',size=20)#X轴的标题和字号大小pl.xlabel('Time', size=14)#Y轴的标题，字号大小和长度pl.xlabel('Time', size=14)pl.ylim(0.0,5.0)#曲线对应注释pl.legend([plot1,plot2],('Delay','Sync rate'),'best',numpoints=1)#图片保存路径plt.savefig('/tmp/dts.png', format='png') 脚本执行效果之后，会在对应的路径里生成一个图片文件，然后把这个图片转移到windows，打开就看到效果了，如图： 这个图是全英文的，如果是中文的话，就会出现乱码，研究了半天也没搞明白，这一点让我很郁闷。 参考资料http://python.jobbole.com/81182/https://absentm.github.io/2017/03/18/Python-matplotlib-数据可视化/https://liam0205.me/2014/09/11/matplotlib-tutorial-zh-cn/https://morvanzhou.github.io/tutorials/data-manipulation/plt/1-1-why/https://www.lookfor404.com/%E8%BF%90%E8%A1%8Cggplot%E5%87%BA%E7%8E%B0%E9%97%AE%E9%A2%98no-display-name-and-no-display-environment-variable/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决https证书在赛门铁克认证失败的问题]]></title>
    <url>%2F2018%2F02%2F26%2F%E8%A7%A3%E5%86%B3https%E8%AF%81%E4%B9%A6%E5%9C%A8%E8%B5%9B%E9%97%A8%E9%93%81%E5%85%8B%E8%AE%A4%E8%AF%81%E5%A4%B1%E8%B4%A5%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[问题描述今天电子商城的市场接到一个故障，说更换了.lechange.com的https证书（原有的证书到期了，新买了一个依旧还是.lehcange.com域名证书）之后，订单在支付宝支付的时候提示支付失败。我把request id提供给支付宝的客服请他们查看一下后台，支付宝客服说我们电商的https证书没有认证成功。于是我就登陆https://cryptoreport.websecurity.symantec.com/checker/ 去检查一下电商的域名，果不其然，赛门铁克的反馈是错误的，如图： 但是登陆网站，在浏览器里却显示https证书是OK的，如图： 然后我用symantec的那个网站测试了一下电商平台开发环境的域名，发现也是OK的，如图： 这就郁闷了，到底哪里出问题了？ 问题排查首先跟研发确认，开发环境与线上环境在涉及到证书的代码是否一致，得到研发的确认之后。就检查服务器里的nginx，发现服务器nginx的配置文件里是没有涉及到ssl，无论是开发环境和线上环境都是通过阿里云slb配置的https证书。而且两者的证书指纹一模一样，如图： 既然都是用的一样的证书，为啥一个检验通过，另一个检验不通过呢？这个时候我想到线上环境与开发环境唯一的不同就是线上环境多了一个cdn，于是就登陆到cdn的控制页面，找到对应的https证书，发现cdn的https证书指纹也是跟上面的指纹一样，如图： 既然指纹一样，那证书也应该是一样的，场面又进入了一个僵局。 于是我就到一台服务器里使用curl -vv https://www.lechange.com，看到的结果如下： 提示未配置签发者根证书，我这时候想起来了，首先证书指纹一致不能说明证书是完全一致的，只能说明key文件是一样的！其次这个https证书是中级机构证书，那么中级机构颁发的证书链规则是这样的： 12345678-----BEGIN CERTIFICATE----------END CERTIFICATE----------BEGIN CERTIFICATE----------END CERTIFICATE----- 那么我怀疑就是https证书链那部分可能在cdn配置错误了，或许在slb配置错误了，甚至两个都配置错误了！ 于是干脆删除掉线上电商原有的https证书，重新导入cdn和slb的https证书，返回到symantec刷新，这次的检验结果就OK了。 补充虽然这个问题解决了，但是我还是不明白，为什么在网页端查看证书是绿色OK的呢？在sf.gg上提问之后，一个叫Avro的朋友是这么回答我的： 以chrome为例，他信任了[所在平台的信任证书列表][1]，而这些平台集成了一系列信任的根证书，如iOS 11 中可用的受信任根证书列表可以找到你的根证书“04 00 00 00 00 01 15 4B 5A C3 94 ”(序列号)，因此验证过程中没有问题，而对于其他的工具，如果未使用这些平台根证书信任列表依然需要完整的证书链（这个证书链在ssl握手过程中被下发）进行校验。 参考资料https://openclub.alipay.com/read.php?tid=3451&amp;fid=57&amp;page=1https://www.jianshu.com/p/84af353f43c5https://help.aliyun.com/knowledge_detail/39468.html?spm=a2c4g.11186631.2.2.w2qcWT]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>https证书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录Apache Storm的部署始末]]></title>
    <url>%2F2018%2F02%2F25%2F%E8%AE%B0%E5%BD%95Apache-Storm%E7%9A%84%E9%83%A8%E7%BD%B2%E5%A7%8B%E6%9C%AB%2F</url>
    <content type="text"><![CDATA[前言Storm是一个流式处理框架（你可以把它当成一种消息队列），开发人员开发出特定的项目，然后通过storm这个渠道下发各种任务，从而达到任务执行的效果。 Storm有两个比较重要的组件：nimbus和supervision，其中nimbus主要是承接任务和分配任务用，而每一个supervision可以有若干worker（视服务器硬件而定），而supervison的主要任务就是监控对应的worker，一旦worker死了，supervision就会把他们唤醒。 本次试验是用的是金山云服务器，storm的版本是1.0.2，配置是1个nimbus，三个supervision，每一个worker上只执行一个任务，总共三个任务。 准备工作安装storm之前需要在storm里新安装一套zookeeper，因为storm是需要一个zk集群的，nimbus和每一个supervisior是通过zk的心跳来传递存活的信息，于是我们就在每一个supervision里面安装一个zookeeper，并且启动zookeeper的server端，安装zookeeper的方法可以移步http://chenx1242.blog.51cto.com/10430133/1889715 。 上面这段话用图来说就是这样子： 启动zookeeper之后，就需要在nimbus和supervisior里安装storm，上面说过本次安装的storm是1.0.2版本，路径直接是/storm/apache-storm-1.0.2。 将storm安装完之后，需要在nimbus和supervisior里更改/etc/hosts文件，改成如下的格式： 1234567891011127.0.0.1 localhost nimbus的内网IP online-nimbus-001supervision1的内网IP supervision-001supervision2的内网IP supervision-002supervision3的内网IP supervision-003 zookeeper的内网IP zookeeper的名称 #注意，这里的zk是给模块拉取配置的zkstorm的zk1的内网IP storm的zk1 #这里的zk就是给storm集群用的zkstorm的zk2的内网IP storm的zk2 #如果storm的zk是standalone模式，这里就不要写了。storm的zk3的内网IP storm的zk3 #如果storm的zk是standalone模式，这里就不要写了。 保存完/etc/hosts之后，还有一个比较重要的步骤，就是在/etc/ld.so.conf.d/这个路径里面建立一个ffmped.conf这个文件，文件的内容如下： 12/storm/apache-storm-1.0.2/lib/storm/apache-storm-1.0.2/lib/3rd 注意，/storm/apache-storm-1.0.2是我的storm路径，在实际情况下需要根据自己的路径进行更改。 把这个ffmped.conf建立成功之后，我们可以测试一下，如果输入ldconfig的话，会出现如下的内容，就证明达到了我们的效果： storm本身的bin目录夹里也有很多命令可以直接使用，为了调用storm list方便，我们需要把bin/storm这个可执行文件作一个软连接，方法就是先cd /usr/local/bin/，然后ln -s /storm/apache-storm-1.0.2/bin/storm storm。这样的话，我们就可以直接使用storm list来查看任务列表了。 Storm的具体配置安装了storm，调整了命令行，同时也搞定了ffmpeg.conf，下面就是调整storm的配置文件了，nimbus和supervisior都要修改。 storm的配置文件叫storm.yaml，路径位于storm文件夹下的/conf/文件夹，我们需要在这个文件里面输入如下的内容： 下面对配置文件作一个简单的解释：1）storm.zookeeper.port:zk的默认端口2181；2）storm.cluster.mode:storm的集群运行模式，这里我们也是采用默认的distributed（分布式）；3）storm.local.dir:storm使用的本地文件的目录，这个目录必须存在而且storm进程可读写；4）supervisor.slots.ports：这个地方在nimbus里可以不用管，但是在supervisior里是需要改的，如果你只打开6700，那么就只放开了6700端口，即只有一个worker，如果你打开了6700、6701、6702三个端口，那么就意味这个supervisior将有三个worker在工作，由于这次试验里我们每一个supervisor只开启一个任务，所以在supervisior的storm.yaml里这个节点就只保留6700，其他的就全部注释掉；5）nimbus.task.launch.secs:task启动时的一个特殊超时设置.在启动后第一次心跳前会使用该值来临时替代nimbus.task.timeout.secs；6）worker.childopts:设定每个worker (JVM任务)的最小和最大内存； 更改完了storm.yaml之后，就要在nimbus里面安装zkclient。直接复制粘贴过来就好了。 如果你不喜欢storm自带的日志格式，想更改一下日志的内容，那么就要在/storm/apache-storm-1.0.2/log4j2文件夹里面修改worker.xml，不过在这里善意的提醒，最好在修改之前先备份原有的worker.xml。 连接具体任务这次的实验包用的是我所在的公司开发内部使用的包，先把这个包的内容复制到/storm/文件夹下，同时mkdir install和makir properties这两个文件夹，在install文件夹里有开发写的任务的jar包和启动程序，如下： 而在properties文件夹里，应该有这个任务的配置文件，如下： 由于我们已经事前在/etc/hosts里指定了zkclient需要访问的zk的ip地址了，那么如果zk项配置正确，zkclient这个时候是可以成功启动的。同时在install文件夹里./update_stormserver_config.sh也应该是反应正确的。 然后我们就可以启动storm了。 启动nimbus和supervision启动storm要先启动nimbus，在/storm/apache-storm-1.0.2/bin里面启动run_nimbus.sh，然后等一下会有一大片东西出现，再jps一下就能看到nimbus已经启动了，如图： 从上图我们可以看到，18141的进程就是zkclient，只不过在jps里它名字叫AppServerDaemon，而zkServer在jps里叫QuorumPeerMain。 如果 storm出现Did you specify a valid list of nimbus hosts for config nimbus.seeds?的错误提示，那么就是nimbus没有启动的缘故。 启动了nimbus之后，就可以在supervisor的机器里去效仿着启动supervisor，但是这里要注意，如果你开启了一个supervisior，那么按照我们上面的配置文件，就启动了一个6700端口的worker，这个时候在nimbus执行下派一个任务的命令，nimbus就会下派这个任务给这个worker。 下派命令的例子如下： 1storm jar storm-starter-0.9.2-incubating-jar-with-dependencies.jar com.lechange.recordshare.RecordShareTopology 1 这样就启动了一个叫videoshare的任务，这个任务只用1个worker。 如果在命令行里反馈这样的错误： 1Error: Could not find or load main class storm.starter.recordshare.RecordShareTopology 或者exception in thread main java.lang.NoClassDefFoundError这样的错误，那就要检查jar包和路径。 而如果你再打开一个supervisor，在nimbus端又下发了一个任务，那么这个任务就会给刚刚新启动的supervisor。这样，启动一个下发一个，就会对每一个worker具体干的任务情况有一个比较清晰的了解。 在nimbus上执行storm list，就可以获得上图的样子，可以看出，我在nimbus端下发了三个任务，就是topology_name这一栏，他们的状态也是active，而workers数量都是1，也就是说在那三台supervisor里都在工作。而跑到supervisor一看日志，也是对应有各自的任务日志。 至此整个storm和具体的模块工作的搭建就完成了。 补充如果你事前一口气把三个supervisor都打开了，即开启了3个worker，然后一口气在nimbus端，一口气输入了三个下发任务的命令，那么这三个命令会随机的到这三个worker里，没有任何顺序而言，你只能通过日志的关键词来判断具体的worker做哪些任务。 而如果你的worker数量少于nimbus下发任务的数量，会有什么反应呢？ 答案就是任务根本没有worker去干，在storm list里，多余的任务对应的num_workers的数字是0，而如果这个时候你新增一个supervisor到这个storm集群，那么这个任务就会吭哧吭哧开始工作了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>大数据分析</tag>
        <tag>storm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DockerFile创建一个nginx容器的全过程]]></title>
    <url>%2F2018%2F02%2F25%2FDockerFile%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AAnginx%E5%AE%B9%E5%99%A8%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[创建容器首先，随便建立一个文件夹，比如先mkdir sample，然后我在这个sample文件夹里建立一个Dockerfile，内容如下： 12345678FROM ubuntu:14.04MAINTAINER Chris Chan "chenx1242@163.com"ENV REFRESHED_AT 2016-12-05RUN apt-get -y update &amp;&amp; apt-get install -y nginxRUN mkdir -p /var/www/html/websiteADD nginx/global.conf /etc/nginx/conf.d/ADD nginx/nginx.conf /etc/nginx/nginx.confEXPOSE 80 从这个Dockfile里面看出：我们使用了ubuntu的基础镜像，然后下载了nginx，同时建立一个/var/www/html/website文件夹，然后又拷贝了宿主机上的两个文件，一个是global.conf，另一个是nginx.conf，这两个文件需要我们自己写。于是我们就要在sample下再建立一个叫nginx的文件夹，里面写上这两个文件，其中global.conf的内容如下： 12345678server &#123; listen 0.0.0.0:80; server_name _; root /var/www/html/website; index index.html index.htm; access_log /var/log/nginx/default_access.log; error_log /var/log/nginx/default_error.log;&#125; 而nginx.conf的内容如下： 123456789101112131415161718user www-data;worker_processes 4;pid /run/nginx.pid;events &#123; &#125;http &#123; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; gzip on; gzip_disable "msie6"; include /etc/nginx/conf.d/*.conf;&#125; 全部搞定之后，我们就来build这个镜像，比如这个镜像名叫做chentest/nginx001，在sample文件夹里使用的命令语句就是：docker build -t=&#39;chentest/nginx001&#39; .。 一顿七七八八之后，显示OK，docker ps -a就会显示我们新建的镜像，如图： 有了镜像，再在sample文件夹里新增一个文件夹，比如就叫webiste，里面有一个文件叫index.html。而index.html的内容如下： 1this is a nginxtest page. 保存退出之后，返回到sample目录。 现在我们可以制作一个容器了，制作容器命令是docker run -d -p 8080:80 --name test02 -v $PWD/website:/var/www/html/website chentest/nginx001 nginx -g &quot;daemon off;&quot;,这句话里规定容器的8080端口映射到宿主机的80端口，同时引入了当前目录的website目录到容器的/var/www/html/website目录，nginx也默认在前台进程进行。执行之后，docker ps -a看一下： 看见port这一栏已经显示8080与80端口的相勾结成功，于是我们可以登录这台机器的80端口看一下。 而如果现在我更改一下上面的index.html，改成另外一句话。比如说改成“why so serious??”,保存文件之后，直接刷新网页，就会看到网页的内容已经发生了变化，如图： 可见引入-v这个命令在容器里，可以随时调试内容，而不是每次都要重新打包生成镜像。这一点再调试阶段为我们提供了很大的方便。 docker端口映射的问题docker run命令里指定端口的格式是-p 容器端口:宿主机端口。如果想要随机指定就是大写的P。如图： 这里就是随机分配了一个32775端口给宿主机，访问的时候也是要访问这个32775端口。 有时候port这里却不显示端口映射的情况，如图： 这个情况是因为这个容器的status是exited，docker会在容器主进程结束后自动终止容器运行，而nginx启动后就会在后台运行，docker以为nginx已经结束运行了，所以就会停止容器。 源码安装nginx如何开机自启动切换到/lib/systemd/system/目录，创建nginx.service文件,文件内容如下： 12345678910111213[Unit]Description=nginx After=network.target [Service] Type=forking ExecStart=/usr/local/nginx/sbin/nginxExecReload=/usr/local/nginx/sbin/nginx reloadExecStop=/usr/local/nginx/sbin/nginx quitPrivateTmp=true [Install] WantedBy=multi-user.target 退出并保存文件，执行systemctl enable nginx.service使nginx开机启动，systemctl restart nginx.service重启nginx。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[DockerFile创建一个redis容器的全过程]]></title>
    <url>%2F2018%2F02%2F25%2FDockerFile%E5%88%9B%E5%BB%BA%E4%B8%80%E4%B8%AAredis%E5%AE%B9%E5%99%A8%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[正文本次目标是用Centos 7的基础镜像做一个redis容器供开发人员在开发环境里蹂躏。 首先，创建一个叫redis-test的文件夹，在这个redis-test文件夹里建立一个Dockerfile，内容如下： 1234567FROM centos:latestMAINTAINER Chris Chan "chenx1242@163.com"ENV REFRESHED_AT 2017-02-16RUN yum -y update &amp;&amp; yum -y install epel-release &amp;&amp; yum -y install redis &amp;&amp; yum -y install net-toolsEXPOSE 6379ENTRYPOINT [ "/usr/bin/redis-server" ]CMD [] 这里我们简单说一下整个Dockerfile的内容： 首先选择了基础镜像是centos的最新版，即centos 7，然后填写作者信息； 在yum这一块要注意，如果没有安装epel-release的话，是无法正常安装redis的，这是centos与ubuntu不一样的地方。至于后面又补充安装了net-tools是因为centos 7里不自带ifconfig命令，所以需要安装一下net-tools，这样就有了ifconfig了； 随即我们又开放了6379端口； 然后就是entrypoint和cmd，这两个命令的区别很重要，具体区别请看：http://cloud.51cto.com/art/201411/457338.htm 这篇文章。 然后我们就可以依照这个Dockfile去建立一个镜像，因为目的是要在“centos环境下建立一个redis”，那么我们这个镜像的名字就叫作lccentos/redis，具体操作就是在redis-test文件夹下执行docker build -t lccentos/redis .。 然后根据这个镜像需要制作一个容器，容器的名字就叫redisforcentos，那么命令就是：docker run -d -p 6379 --name redisforcentos lccentos/redis。 然后我们docker ps -a看一下效果，如下： 可见宿主机的32774端口和容器的6379端口“融为一体”，这个时候，我们测试一下这个redisforcentos的容器是否已经正常启动了redis，如图： 而且对于Docker来说，可以多个docker对应宿主机的同一个端口，比如我这台机器搞了两个redis，两个容器都可以指向6379的端口，如图： Dockerfile的优化原则1）ADD和VOLUME应该放在Dockerfile底部，因为它们相对比yum安装那些变化的更勤；2）EXPOSE可以一口气对应多个端口，比如EXPOSE 80 2003 2004 7002的效果跟下面的效果一样； 1234EXPOSE 80 EXPOSE 2003 EXPOSE 2004 EXPOSE 7002 3）ADD的操作应该放在Dockerfile的最下面； 参考资料http://dockone.io/article/255?spm=5176.100239.blogcont40494.25.8RXqDX]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云获取DTS服务延迟值的脚本]]></title>
    <url>%2F2018%2F02%2F24%2F%E9%98%BF%E9%87%8C%E4%BA%91%E8%8E%B7%E5%8F%96DTS%E6%9C%8D%E5%8A%A1%E5%BB%B6%E8%BF%9F%E7%9A%84%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[正文春节“嗖”的一下就过完了，在年前领导交代另一个任务，想要每天统计一下在阿里云DTS（数据同步）服务的延迟情况，于是我就要使用阿里云的api去写一个脚本，每小时运行一次，然后将这24个数字输出出来给领导过目。 阿里云dts的sdk包在这里：https://help.aliyun.com/document_detail/57694.html?spm=a2c4g.11186623.6.675.W811bN ，直接点击Python下载即可，不过这个地址经我测试使用非国内IP 地址是打不开的，需要使用国内IP地址下载。 下载完毕之后，上传到linux服务器并解压，解压后的样子如图： 由于我们这次只是查看同步作业状态，所用的py就是DescribeSynchronizationJobStatusRequest.py，现在我们就可以写脚本，假设这个脚本叫getDTS.py,那么整个内容如下： 12345678910111213141516171819202122232425262728#!/usr/bin/env python#coding=utf-8#auther:ChrisChan@2018-2-24#这个脚本是用来获取DTS服务的延迟值from aliyunsdkcore import clientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionimport jsonimport sys #由于这个包不是通过pip install的方式安装,要调用其它路径的python脚本就要使用sys方法sys.path.append('sdk压缩包的绝对路径')import DescribeSynchronizationJobStatusRequest # 创建Client实例clt = client.AcsClient('阿里云AK','阿里云SK','所属地域')# 创建request并设置参数request = DescribeSynchronizationJobStatusRequest.DescribeSynchronizationJobStatusRequest()request.set_accept_format('json')# 写上对应的服务IDrequest.set_SynchronizationJobId("这里写上DTS的ID")response = clt.do_action_with_exception(request)print responsedelay = json.loads(response)print "===================================================="print "当前延迟是：" + str(delay["DataSynchronizationStatus"]["Delay"])print "当前同步速度是：" + str(delay["Performance"]["FLOW"]) 整个脚本执行的效果如下： dts的延迟时间是5秒计算一次，API请求会取到最新的延迟时间，控制台是每隔20秒才刷新一次。 补充getDTS.py这个脚本获取到的response是一个str字符串，这里我使用json.loads来将其转化成了dict模式。但是除了这个方法还有两个方法： 123456789101112&gt;&gt;&gt; user"&#123;'name' : 'jim', 'sex' : 'male', 'age': 18&#125;"&gt;&gt;&gt; b=eval(user)&gt;&gt;&gt; b&#123;'age': 18, 'name': 'jim', 'sex': 'male'&#125;&gt;&gt;&gt; print b['sex']male&gt;&gt;&gt; exec("c="+user)&gt;&gt;&gt; c&#123;'age': 18, 'name': 'jim', 'sex': 'male'&#125; &gt;&gt;&gt; print c['name']jim 但是要注意！上面这两个方法有一定的安全隐患，而且只能全是字符串可用，如果有的value是True、False、Null这样的字眼的话，eval是不支持的，所以没法正确转换，就会爆这样的错：NameError: name &#39;True&#39; is not defined。 参考资料https://help.aliyun.com/document_detail/49453.html?spm=a2c4g.11186623.6.667.sRyVqYhttps://segmentfault.com/q/1010000000174694https://www.crifan.com/resolved_in_python_using_eval_to_force_variable_to_convert_a_string_to_a_dictionary_when_the_error_nameerror_name_39null39_is_not_defined/https://segmentfault.com/q/1010000000345915]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Atlas的几种常见故障解决方法]]></title>
    <url>%2F2018%2F02%2F23%2FAtlas%E7%9A%84%E5%87%A0%E7%A7%8D%E5%B8%B8%E8%A7%81%E6%95%85%E9%9A%9C%E8%A7%A3%E5%86%B3%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[使用atlas却发现“读库闲置，框架还是去主库读写数据”配置完atlas之后，发现使用jdbc框架的话，读库和写库各司其职，但是使用mybatis框架之后，就发现框架的读写都去了主库，把读库放置一边，那么这种情况是因为有事务存在的话，atlas就会强制走主库，遇到这种情况就检查一下是否有事务的存在，比如@Transactional，如果要解决的话，就加上@Transactional(propagation=Propagation.NOT_SUPPORTED)即可。 自动读写分离挺好，但有时候我写完马上就想读，万一主从同步延迟怎么办?SQL语句前增加 /*master*/ 就可以将读请求强制发往主库。在mysql命令行测试该功能时，需要加-c选项，以防mysql客户端过滤掉注释信息。不过这不能从本质上解决问题，使用Atlas需要考虑到这点，提高主机的IO性能，加大memory可以缓解延迟症状，但依旧不能避免延迟的出现，尤其是读多写少的应用。 resource limit的问题atlas有自己的连接池，会吃掉很多CPU, php应用端改用短链接来连接atlas, 这时候atlas对php发送来的sql只负责验证和转发的操作，后端DB的连接由atlas自己管理,未使用的连接线程进行剔除操作(DB的wait_timeout和interactive_timeout设置为300s,超时亦退出)。 1234562014-04-12 20:56:29: (warning) (libevent) event_del: event has no event_base set.2014-04-12 20:56:29: (critical) last message repeated 5 times2014-04-12 20:56:29: (critical) network-conn-pool-lua.c.144: socket() failed: Too many open files (24)2014-04-12 20:56:29: (warning) (libevent) event_del: event has no event_base set.2014-04-12 20:56:30: (debug) chassis-unix-daemon.c:168: 12951 returned: 129512014-04-12 20:56:30: (critical) chassis-unix-daemon.c:196: [angel] PID=12951 died on signal=11 (it used 16 kBytes max) ... waiting 3min before restart 如果MySQL后端的连接数也满了可能会报以下错误: 1232014-11-13 12:21:07: (critical) network_mysqld_proto_password_scramble: assertion `20 == challenge_len' failed2014-11-13 12:21:07: (warning) (libevent) event_del: event has no event_base set.2014-11-13 12:21:07: (critical) 可以临时增加MySQL connection数量: 1echo -n “Max processes=SOFT_LIMIT:HARD_LIMIT” &gt; /proc/`pidof mysqld`/limits 出现Too many open files的错误，怎么办？&gt;关于Too many open files错误，可能由两种情况引起:一、php长连接连接到atlas后，每个线程占用一个FD,直到超出系统资源限制而出现too many错误;二、php应用端发送到atlas的sql过多，大量并发的情况下，linevent维护的队列过多，每个event吃一个FD，超出系统资源限制引起Too many open files错误; 避免Too many open files错误,增加用户的ulimit值加大FD的使用量,可增加系统ulimit资源到 ~/.bash_profile文件或/etc/security/limits.conf文件: 123456# cat .bash_profile # .bash_profile......export PATHulimit -n 16384]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>atlas</tag>
        <tag>mysql</tag>
        <tag>读写分离</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何手动释放linux内存]]></title>
    <url>%2F2018%2F02%2F23%2F%E5%A6%82%E4%BD%95%E6%89%8B%E5%8A%A8%E9%87%8A%E6%94%BElinux%E5%86%85%E5%AD%98%2F</url>
    <content type="text"><![CDATA[在生产过程中，一些java模块会比较残忍的吃系统内存，然后如果这个模块写的比较挫，产生的垃圾就会比较多，如果linux系统的内存释放也不会及时，然后恶性循环，最后就把进程卡死，但是服务器是不可以down机的，所以这个时候就需要我们运维出来，手动的释放内存。 首先，我们登陆一台服务器，free -m看一下目前的情况： 然后cat /proc/sys/vm/drop_caches，会看到里面的值是0，0是不释放的意思。 sync,将系统缓存区中的脏数据写入磁盘中，包括已修改的i-node、已延迟的块I/O和读写映射文件。 echo 3 &gt; /proc/sys/vm/drop_caches 为什么这里是3呢？这是因为echo 1的话代表“清理页面缓存”，echo 2的话代表“清理索引节点（inode）链接”，echo 3就是包括上面两者。 sysctl -p,这样不用重启服务器也可以生效。出现下面的一连串文字之后，再free -m看一下： 从112释放到2790，可见效果立竿见影。 上面整个过程的自动化脚本是这样的： 12345678910#!/bin/bash#Author:Chris Chan#E-mail:chen_shuo@dahuatech.comoldmemory=$(free -m|sed -n '2p'|awk '&#123;printf $4&#125;')echo "开始的空余内存值："$oldmemorysyncecho 3 &gt; /proc/sys/vm/drop_cachessysctl -pcorrectmemory=$(free -m|sed -n '2p'|awk '&#123;printf $4&#125;')echo "释放完后的空余内存值："$correctmemory]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回家过年]]></title>
    <url>%2F2018%2F02%2F21%2F%E5%9B%9E%E5%AE%B6%2F</url>
    <content type="text"><![CDATA[我承认我是一个很恋家的人，但是我在3年之前还不是这样。 我记得我在哈尔滨上大学的时候，虽然坐火车也就一个半小时的时间，但是是“能不回家就不回家”，哪怕自己一个人蹲在寝室也是自由舒服，后来上班，我也是有很长的时间自己独住，只有周末才回去一次。那时候我奶不止一次的批评我“都快成一个客人了”。 真的应了那句传烂了的话“只有失去的才是美好的”，现在我人在杭州，天天忙成狗。最欢喜的事情第一个是涨工资，第二个是发工资，第三个是放假，第四个就是放假回家。当初的我总是忽略家庭的温暖，在家里逗留的时间不长，现在却倍感珍惜回家的机会，唉，那几年真是简单的可笑。 这一次回家过年看到了许许多多亲人：生病的大姨夫的精神状态也好了许多，不过他这次回来又害了一次发烧；小外甥和他那婴儿肥的脸蛋，在《守望先锋》里越死越勇；我那几个弟弟们全都瘦了也更精神了，从我妈和女票看我的眼神里，我觉得我的体重是应该好好管控一下了：体型太腐败。 短短的六天时间，吃完三姨家吃四姨家，吃完老叔家吃小舅家，总之就是带着女票游走于各种亲戚家。中途还抽空跟龙南数据班的几个老同事一起吃了顿“一口猪”，主要也是带我女票看看东北菜，看上去我这几个老同事们都过得很不错，至少几杯酒下去均红光满面，依旧插科打屁、大呼小叫。这次过年唯一可惜的是，没有给四姨夫装上翻墙软件，害得他要继续挠墙忍耐。 我吃我妈的菜已经吃了30年，但是这次过年真正在家里吃饭仅仅只有一顿。我妈烧了虾，做了孜然羊肉，而且煮了酸菜馅饺子。这都是我爱吃的，杭州的确能吃到很多美味，但我妈的手艺却是独一份儿。我跟我爹依旧话不算多，但是关系却比之前好了许多倍。有可能是我现在比以前有了一点进步，让我爸看起来顺眼了一点，这一次回家没有跟我爸单独喝上酒，但是他有几顿喝的很开心。看到他俩这个年过得快乐满足，我这个做儿子的，心底涌起了最大的温暖。 离开家的时候，依旧是箱子沉沉，里面有爸妈装的许多东西，有给我的也有给我女票她妈的，每一个东西都是代表了他们的心思。其实家中长辈身体健康、心情愉悦，就是给我们这些在外的儿女最大的宽慰了。假期就这样结束了，我也马上要踏上回杭州的航班，希望家里所有长辈都平平安安，也希望我今年能够达到自己给自己定下的目标！]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>春节</tag>
        <tag>心情</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[中国梦，宪政梦]]></title>
    <url>%2F2018%2F02%2F13%2F%E4%B8%AD%E5%9B%BD%E6%A2%A6%EF%BC%8C%E5%AE%AA%E6%94%BF%E6%A2%A6%2F</url>
    <content type="text"><![CDATA[本文原作者：《南方周末》评论部编辑戴志勇 天地之间，时间绽放。 这是我们在2013年的第一次相见，愿你被梦想点亮。 2012年，你守护自己的生活，他们守护自己的工作。守护这份工作，就是在守护他们对生活的梦想。 2012年，庙堂之上发出的宪政强音嗡然回响：”宪法的生命在于实施，宪法的权威也在于实施。”我们期待宪法长出牙齿，宪政早日落地。惟如此，才能成就这个沧桑古国的艰难转型；惟如此，国家与人民，才能重新站立于坚实的大地之上。 今天，已是能够梦想的中国，今天，已是兑现梦想的时代。经历过宪政缺失的”文革”梦魇，我们花费三十多年的时间来逐渐回归常理与常情。从土地联产承包责任制到个体户、乡镇企业到”民企”，稍稍归还国人自主安排生活的权利，我们便创造了繁华城市，收获了满仓粮食。 我们重新体认什么是真，什么是假，是其是，非其非；我们重燃对公义的热爱，对自由的向往。面对暴虐强力，我们双手相握，一起走过艰难时刻，迎接生活转机。 今天，我们终于可以从厚厚的历史尘埃中挺起胸，从琐碎的日常生活中抬起头，重走先辈的宪政长征，重温先辈的伟大梦想。 一百七十多年前，我们开始从天朝上国的迷梦中醒来。先败于英，后败于日。百姓愈加民不聊生，耻感深深刺痛中国士人。保国！保种！由洋务而君宪，由立宪而革命。从器物到制度再至文化，激愤者不惜彻底打倒”孔家店”，决绝地将自己的文明连根拔起。 辛亥革命后，清帝退位，先辈们终于建立了亚洲第一个共和国。但是，一个自由、民主、富强的宪政中国并没有随之而来。 国家内外，战争连连；人群内外，残酷不断。 一度，人们远离仁，远离义，远离天道，远离对自由的坚守。 一度，人们认错为对，指鹿为马，万千生灵生机断绝。 美梦与山河，齐齐破碎。自由与宪政，双双消隐。 度尽人世劫波，深味人性幽暗，我们依然是能做梦的人，有颗能做梦的心。 今天，我们断断不只梦想物质丰盛，更希望性灵充盈；我们断断不只梦想国力能强盛，更希望国民有自尊。新民和新国，救亡与启蒙，谁也离不开谁，谁也不能压倒谁。而宪政便是这一切美梦的根基。 兑现宪政，坚守权利，人人才能心如日月流光溢彩；鳏寡孤独才能感受冬日暖意而非瑟瑟发抖；”城管”与小贩才能谈笑风生；房屋才能成为自己与家人的城堡； 兑现宪政，限权分权，公民们才能大声说出对公权力的批评；每个人才能依内心信仰自由生活；我们才能建成一个自由的强大国家。 兑现宪政大梦，每个人才能做好个人的美梦。而这需要我们就从手边做起，就从守护此时此刻的生活做起，而不要将重任留给子孙。 很多人一直深深懂得这一点，很多人早就努力践行这一点。 不是杰出者才做梦，是善于做梦者才杰出。 你的天赋权利就是可以梦想，并且兑现梦想！ 为你的梦想鼓掌，为这个国家的梦想加油，这就是很多新闻人的梦想，是他们不大不小的野心。他们忠于新闻，更忠于内心。愿你也有个玫瑰色的美梦；自由成就自己，完成天之所赋。 总会梦想人人都可以做一个有尊严的人，不论身居高位，还是街头卖艺； 总会梦想人人内心有爱，即使罪犯也未必穷凶极恶，总有恻隐之心自由闪动； 总会梦想阶层只是引人自由流动的动力，而不再是相互猜忌和仇视的天堑；总会梦想这五千年文明生生不息，为改善人类的现代处境，捧出一掬甘冽清泉…… 兑现这一千一万个梦想，才能抚平这一百多年的刻骨痛楚。 兜兜转转一百七十年，美梦成真何其难！一百七十年后，依然有人渴望良知萌新芽，重温天命之谓性；依然有人坚持要求权利一一落地，政治复归于正，公义自在流淌。 依然有人相信，不管多难，梦想终会落实为宪政良制，风行为敦敦美俗。 先辈们筚路蓝缕，践义成仁。如今，后人承继其志，燃灯前行。 兑现梦想，自然要借鉴前贤智慧，与古人的信仰、习俗和情感和解。儒释道法墨，百家皆是源泉；周汉唐宋明，代代皆有可取。 但这决不是要复古，古人不能给予今天所需的一切。只是不再轻易贬损先辈，平心静气地吸收转进，以让中华文明开新花，结新果。 兑现梦想，自然要吸取世界经验。所以要认真审视希腊民主，罗马法治，借鉴英美宪政，追赶现代科技文明。 但这也不是仅仅作一个西方文明的优等生，西人有西人演进的轨迹，同样未必能直接给予我们今天所需的一切。 我们要站在自己的大地上，与各国人民一起，生活出一种古今相融的新生活，文明出一种中西合璧的新文明。在古今中西的激荡中，要遵循人类共通的价值，也要不惮于做自己的新梦。 称美古人，赞扬邻居，不是因为他们足够完美，而是因为我们熟悉他们眼中洋溢的快乐，心底流淌的自由。 中国人本应就是自由人。中国梦本应就是宪政梦。 宪政之下，才能国家持续强盛，宪政之下，才有人民真正强大。兑现宪政梦想，才能更好地外争国权，维护国家的自由；才能更好地内争民权，维护人民的自由。而国家的自由最终必得落脚于人民的自由，必得落脚于人人可以我口说我心，人人可以用心做美梦。 生而为人，谁能不热爱自由？这自由，不仅是权利针对权力而言，也是宽恕针对报复而言，是般若针对无明而言，是仁爱针对暴虐而言，是有道针对无道而言。 大道之行，天下为公；万物自在，各正性命。这就是古人的梦想，先辈的梦想，也是今天很多人的梦想。 中国梦，自由梦，宪政梦。 万物速朽，但梦想永在。万物诞生，因梦想不灭。梦想就是生生之几，就是当你失败了一百次，那第一百零一次充实你内心的不死之希望。 依然有人倾听你的梦想，期待你敢于做梦。你从苦难中爬起，他们为你加油；你尝尽人世冷暖，他们为你加油；你收获美好生活，他们为你加油……他们别无所资，惟有对梦想的执着；他们别无所长，惟有对真相的追求。 一句真话能比整个世界还重，一个梦想能让生命迸射光芒！]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>中国政治</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于logrotate的额外补充]]></title>
    <url>%2F2018%2F02%2F12%2F%E5%85%B3%E4%BA%8Elogrotate%E7%9A%84%E9%A2%9D%E5%A4%96%E8%A1%A5%E5%85%85%2F</url>
    <content type="text"><![CDATA[https://rorschachchan.github.io/2018/02/12/日志文件管理者：Logrotate/ 里面已经简单介绍了logrotate命令，这里还有一些额外补充的东西： 1）查看logrotate对log文件的具体执行情况的语句是cat /var/lib/logrotate.status，效果如图： 2）使用-v或-d参数时，显示log does not need rotating，这是因为logrotate在对status未记录的文件进行转储时，会在status添加一条该文件的记录，并将操作时间设为当天。之后程序再次对此文件进行转储时发现这个文件今天已经操作过，就不再进行相关操作。要是想解决这个问题可以使用-s指定logrotate状态文件； 3）分割日志时报错：error: skipping &quot;/var/log/nginx/test.access.log&quot; because parent directory has insecure permissions (It&#39;s world writable or writable by group which is not &quot;root&quot;) Set &quot;su&quot; directive in config file to tell logrotate which user/group should be used for rotation.这是当前用户不是root，需要添加su root list这个语句到对应的logrotate配置文件里，比如： 123456789101112131415/var/log/nginx/*.log &#123; su root list #第一句添加 daily missingok rotate 52 compress delaycompress notifempty #ifempty create 0640 www-data adm sharedscripts postrotate [ ! -f /var/run/nginx.pid ] || kill -USR1 `cat /var/run/nginx.pid` endscript&#125; 4）如果觉得使用logrotate很麻烦，而当某个文件过大的时候，要实现把该文件压缩并且拆成若干个指定大小的文件，怎么办？ 1tar -zcvf 新文件名.tar.gz 原文件名 | split -b 每个分格包大小 -d -a 1 - 新文件名.tar.gz 比如：tar -zcvf ABC.tar.gz ABC | split -b 4000M -d -a 1 - ABC.tar.gz。这个命令就是把ABC这个文件压缩成ABC.tar.gz，但是如果ABC大于4000M就会切块，切成ABC.tar.gz.0,ABC.tar.gz.1,ABC.tar.gz.2……这个样子。 123//使用split命令，-b 4000M 表示设置每个分割包的大小，单位还是可以k// -d 参数指定生成的分割包后缀为数字的形式//-a x来设定序列的长度(默认值是2)，这里设定序列的长度为1 如果要把这一堆已经切块的文件重新接压缩的命令：cat ABC.tar.gz.* | tar -zxv; 5）如果用kill -HUP来重启一个包含守护进程的进程，比如httpd，一条语句搞定： 1ps -ef | grep httpd | grep -v grep | awk '&#123; print $2; &#125;' | xargs -L 1 sudo kill -HUP 这里面首先用awk获取到httpd的pid进程号，然后把这个进程号传给了xargs，通过-L 1来一次提取一行pid值，然后分批进行kill -HUP;如果想要更改配置而不需停止并重新启动服务，请使用kill -HUP。在对配置文件作必要的更改后，发出该命令以动态更新服务配置。 6）想更多的了解守护进程，参看http://www.cnblogs.com/mickole/p/3188321.html；]]></content>
      <categories>
        <category>技术与工作</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>logrotate</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[日志文件管理者：Logrotate]]></title>
    <url>%2F2018%2F02%2F12%2F%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E7%AE%A1%E7%90%86%E8%80%85%EF%BC%9ALogrotate%2F</url>
    <content type="text"><![CDATA[前言服务器在服务运行的时候，难免会生成大量日志，一般来说遇到日志过多的情况，就会写一个看门狗：监控磁盘容量的大小，如果磁盘剩余空间小于某个值，就去日志文件夹里把一个月或者几个月之前的废弃日志删除掉以达到释放磁盘空间的目的。 但是往往有的时候过期的日志很重要，或者即使是一周的时间内，也会生成容量非常可观的日志，那么就需要使用logrotate命令来管理这些日志，这个命令是linux自带的。 logrotate这个命令的用法请看：https://linux.cn/article-8227-1-rel.html和https://linux.cn/article-4126-1.html 。 实验开始首先，假设服务器里某个日志文件夹里的日志auc.log.10是这样的： 然后在logrotate的配置文件是这么写的： 12345678/mnt/hswx/auc/logs/auc.log.10 &#123; 这里是目标日志的绝对路径 daily 每天执行一次 minsize 200M 文件容量大于200M开始处理，如果到了时间但是没有大于200M，不会处理 compress 压缩 dateext 文件会以日期为后缀 create 777 root root 新建的那个日志文件属性是777 rotate 2 保留最多2个文件&#125; 然后执行logrotate -vf /etc/logrotate.conf，看到的效果是： 命令执行后，服务器create了新的auc.log.10，而且属性变成了777，同时把原有的部分压缩成gz的格式。 上面那个测试的对象是已经过期的日志，现在我们要压缩当前的日志，目的是在压缩了auc.log并且重命名之后，可以生成新的auc.log，同时这个新的auc.log会被写入。 现在我们尝试一下，把原来的配置文件改成这样： 123456/mnt/hswx/auc/logs/auc.log &#123; weekly minsize 200M compress rotate 2&#125; 但是执行之后，我们发现变成了这样： 原来的auc.log不见了，而出现的auc.log.1里面的内容是原来auc.log的内容，可见原有的auc.log已经被顶掉了。这是因为我们上面的配置文件里面没有加上dateext，所以默认会以.1、.2、.3为后缀。 问题是我们没有生成auc.log，那么这段时间的日志就会找不到auc.log而凭空消失。可见这个方法没有达到我们的目的，需要改进。 改进之后我们这个内部模块auc只有重新启动这个进程才会生成auc.log，既然要解决这样的问题，我们很自然的就想到kill -HUP这种平滑启动的方式，但是要注意！kill -HUP对deamon会进行重新读取配置启动，但是对于普通的进程只会把其杀死！而这个auc就是一个普通的java程序，没有配套的守护进程。所以只能使用一般的重启方式来达到生成auc.log这个目的。 首先我们把原来的配置文件改成这样： 1234567891011/mnt/hswx/auc/logs/auc.log &#123; weekly #每周执行 dateext #以日期作为后缀 minsize 200M #到达了200M自动执行，不然即使到了一周的时间也不执行 compress #压缩 rotate 2 #最多保留两个文件 sharedsripts postrotate #在执行完日志压缩之后就执行如下动作 /bin/bash /root/restart.sh #动作就是执行这个绝对路径的脚本 endscript #收工&#125; 而这个restart.sh的内容很简单: 1234#!/bin/bashcd /mnt &amp;&amp; ./stopAUC.sh #停止auc进程cd /mnt &amp;&amp; ./startAUC.sh #启动auc进程echo HAHAHAHA！！！ #表示已经OK了，让我们发出杠铃一般的笑声 现在我们重新跑一下logrotate，logrotate -vf /etc/logrotate.conf。看一下效果： 可以看到先把日志改名压缩，完事后也执行了restart.sh这个脚本，再日志里一看，auc.log也顺利生成了！ 参考资料http://www.pythondev.org/post/8.htmlhttps://www.jianshu.com/p/87e2fd01393c?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendationhttps://segmentfault.com/q/1010000000120419]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个暗藏杀机的脚本]]></title>
    <url>%2F2018%2F02%2F11%2F%E4%B8%80%E4%B8%AA%E6%9A%97%E8%97%8F%E6%9D%80%E6%9C%BA%E7%9A%84%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[脚本背景老总最近总是发现某台relay服务器的CPU值会突然彪很高，于是勒令几位工程师检查问题，但是工程师一时半会也想不到究竟是什么程序这么耗费CPU，于是就委托运维写一个脚本，具体要求是这样的：每隔一秒钟输出一下top命令的前十二行情况（其实就是配置总览和耗费cpu前五名程序情况），将这些情况保存到一个文件里，如果这个文件大于500MB，就把这个文件删除（为啥要删除？我也不知道），重新再生成一个文件用来保存top命令结果。 分析由于脚本无法自己跳出运行并检查自己的大小，所以这个任务需要两个脚本，一个是单纯的把top命令重定向到一个文件（recordTOP.sh），另一个脚本就是一个if判断大小（checksize.sh）。再加上crontab每一天一检查（其实完全没必要，500MB足够top这个命令跑5天的），应该可以满足开发人员的需求。 脚本内容获取top.txt的脚本recordTOP.sh如下： 12345678910#!/bin/bash#written by ChenShuo @2016-8-15#Desription:每一秒钟记录一次top命令里占用cpu前五程序while true do $(top -bn 1 | head -12 &gt;&gt; /root/top.txt) echo "------------------------------------------------" &gt;&gt; /root/top.txt sleep 1 done 判断top.txt大小的脚本checksize.sh如下： 12345678910#!/bin/bash#written by ChenShuo @2016-8-15#Desription:当recordTOP.sh文件大小超过500MB的时候将会重新覆盖size=$(ls -l | grep top.txt |cut -d " " -f 5)if [[ $size -ge 536870912 ]] then $(ps -ef|grep recordTOP.sh|grep -v grep|awk '&#123;print $2&#125;'|xargs kill -9) $(rm -rf /root/top.txt) bash /root/recordTOP.sh &amp; fi crontab这一步我就略掉不写了。 补充说明1）top不可以直接重定向，如果是top &gt; 123.txt，它将会不断的导入，因为top就是一个实时更新的命令，所以这里要用top -bn 1|head 12 &gt;&gt; /top.txt； 2）shell脚本里调用shell，不能采用$()的方法了，因为$()是一个返回值，而.sh是一个不断进行的脚本，所以要用bash +脚本名的方式； 3）recordTOP.sh这个脚本是可以同时存在多个的，但是如果不小心后台启动多个，用checksize脚本ps -ef语句就会报错，因为获得到的不是一个数字，而是多个数字，没法一波kill掉。同理，直接调用checksize也会报错，因为没有ps -ef的值； 4）因为是要先关闭原来的top重定向脚本，所以才用了保守的ps -ef，然后kill的方式，这里不可以使用pkill，因为pkill是干掉整个类型程序，比如pkill -9 java，就是干掉所有java的进程。而在linux里，千万不可以pkill -9 sh，可以想象一下，这个命令的结果就是会从ssh上跳出，同时无法登陆，因为整个sh都被你杀死了。那么真的出现了这个结果怎么办？答曰：重启，重启能救命。 整个执行效果如下，可见top.txt文件是在不断的扩大，由于是测试，我把文件大小调整为20000字节，即大于20000字节就覆盖原文件，当文件大于20000字节的时候，就会把原来的top.txt删除，同时生成一个新的top.txt。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>top</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[http返回码是000...]]></title>
    <url>%2F2018%2F02%2F11%2Fhttp%E8%BF%94%E5%9B%9E%E7%A0%81%E6%98%AF000%2F</url>
    <content type="text"><![CDATA[正文今天开发童鞋在测试往一个网站发请求的时候，发现返回码是000，如图： 众所周知，常见的返回码是以下四种： 12342XX 成功；3XX 重定向；4XX 客户端错误；5XX 服务器端错误； 但是000是啥玩意？简单的说就是没有有效的http状态码，比如连接被拒绝，连接超时等。 使用curl -w &quot;%{http_code}\n&quot; -m 5 https://60.191.94.115:38303/cloudSignalling/events/deviceState ; echo &quot;Exit code: $?看一下详细的code，显示如图： 可以看到提示：curl: (60) Peer certificate cannot be authenticated with known CA certificates，翻译过来就是对方的证书不能用已知的CA证书验证。但是下面也说了可以用-k或者--insecure来跳过这一步。 于是我又使用curl -I -k https://60.191.94.115:38303/cloudSignalling/events/deviceState这个命令，效果如图： 里面这一下说的就很明白了，405，方法不正确，再搭配一下curl -k -w &quot;%{http_code}\n&quot; -m 5 https://60.191.94.115:38303/cloudSignalling/events/deviceState，看一下： 这么上下一结合，明白了GET是不准许的，准许POST。于是反馈给60.191.94.115告诉他们把前后台接口请求方式、参数传递方式都拿回去整改。 参考资料http://www.1987.name/365.htmlhttps://superuser.com/questions/501690/curl-http-code-of-000]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>http</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将redis加入到elk日志系统里]]></title>
    <url>%2F2018%2F02%2F09%2F%E5%B0%86redis%E5%8A%A0%E5%85%A5%E5%88%B0elk%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9F%E9%87%8C%2F</url>
    <content type="text"><![CDATA[之前在https://rorschachchan.github.io/2018/01/16/记录日志系统ELKB-5-6-4的搭建过程/里面，我画的那个架构图里说了整个架构可以加入redis，但是在文章里我没有写到redis怎么加进去。为了让整个系统更好的分层，是非常建议引入Redis的，毕竟Redis服务器是logstash官方推荐的broker选择。Redis作为一个缓存，能够帮助我们在主节点上屏蔽掉多个从节点之间不同日志文件的差异，负责管理日志端（从节点）的人可以专注于向 Redis 里生产数据，而负责数据分析聚合端的人则可以专注于从Redis内消费数据。所以这一次实验要把redis加进去，同时也要部署一个nginx，让elk再去采集nginx的日志。 整个架构图图下： 部署redis安装redis的方法请去看http://blog.51cto.com/chenx1242/1793895，我这里使用的redis版本是4.0.6，在执行make test的时候可能会有如下的错误： 那就安装新一点的tcl吧，方法如下： 12345wget http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gztar xzvf tcl8.6.1-src.tar.gz -C /usr/local/cd /usr/local/tcl8.6.1/unix/./configuremake &amp;&amp; make install 然后重新去make test就会看到成功的字样，如图： 现在redis的漏洞比较多，大多数就是因为密码太简单导致的，所以把redis密码改一下，在redis.conf里，改成如下的样子： 123456789bind 内网IP地址 127.0.0.1 ###仅允许内网和本机访问protected-mode yes ###保护模式开启port 6379 ###端口默认为6379，按需修改daemonize yes ###守护模式开启pidfile /usr/local/redis/redis.pid ###指定pid文件路径和文件名logfile "/usr/local/redis/redis.log" ###指定日志文件路径和文件名dbfilename redis.rdb ###指定数据文件RDB文件名dir /usr/local/redis/ ###指定数据文件RDB文件的存放路径requirepass 『YOURPASSWORD』 ###设置访问密码，提升密码强度 保存之后启动redis即可。 如果redis是主从配置，若master配置了密码则slave也要配置相应的密码参数否则无法进行正常复制的。需要在slave的redis.conf里找到#masterauth mstpassword，去掉注释，也改成跟master一样的密码，重启一下即可。 nginx的安装这里就不写了，直接看http://www.runoob.com/linux/nginx-install-setup.html这个就行了。 安装x-packx-pack是elk官方提供的认证授权插件，安装方法很简单，分别找到下面三个文件，然后后面加上install x-pack即可： 123./elasticsearch-plugin install x-pack --batch ./logstash-plugin install x-pack ./kibana-plugin install x-pack 如果要查看已经安装的插件，那就是： 1234[root@chen-elk-001 bin]# ./elasticsearch-plugin listx-pack[root@chen-elk-001 bin]# ./kibana-plugin listx-pack@5.6.4 如果kibana-plugin要卸载x-pack，那就是：./kibana-plugin remove x-pack。 重启服务即可登录，默认的登录用户名: elastic，密码:changeme。 这里注意一下，./logstash-plugin install x-pack的时候可能是出现ruby源的错误，如图： 这是因为中国特色社会主义的网络限制访问https://rubygems.org，一般来说，可以把它更改成阿里的ruby源https://ruby.taobao.org/，不过如果你的服务器无法跨越长城的话，那么更改也是不好使的，所以在这一步，我选择离线安装x-pack。也就是先把https://artifacts.elastic.co/downloads/packs/x-pack/x-pack-5.6.4.zip这个文件下载到本地上传到服务器的root文件夹里，然后安装： 123[root@chen-logstash-001 bin]# ./logstash-plugin install file:///root/x-pack-5.6.4.zipInstalling file: /root/x-pack-5.6.4.zipInstall successful 配置filebeat由于这个nginx我们需要先让filebeat把nginx.log和error.log先推到redis存储，然后再由redis推到logstash。配置filebeat.yml的具体信息如下: 1234567891011[root@iZbp10hw6wezxmrvrcjyhlZ filebeat]# grep -iv '#' /etc/filebeat/filebeat.yml | grep -iv '^$'filebeat.prospectors:- input_type: log paths: - /usr/local/nginx/logs/*.log #这里是nginx的日志文件夹 output.redis: #以下这部分都是新加的 enabled: true hosts: ["127.0.0.1:6379"] key: logindexer_list #与redis配置文件里的key遥相呼应 password: 『YOURPASSWORD』 #跟上面的密码遥相呼应 配置完毕之后，启动filebeat，命令语句：/etc/init.d/filebeat start -c /etc/filebeat/filebeat.yml。 配置logstash由于这台logstash已经开启了一个logstash进程，那么再收集nginx的日志需要新开一个logstash进程，也需要新写一个conf文件，假设新的conf文件是nginx-logstash.conf，它的写法如下： 1234567891011121314151617181920212223input &#123; redis &#123; host =&gt; "10.168.173.181" type =&gt; "redis-input" data_type =&gt; "list" key =&gt; "logindexer_list" port =&gt; 6379 password =&gt; "ChenRedi$" &#125;&#125;# filter configration hereoutput &#123; elasticsearch &#123; hosts =&gt; [ "10.162.80.192:9200" ] user =&gt; elastic password =&gt; changeme index =&gt; "nginxlogstash-%&#123;+YYYY.MM.dd&#125;" #这个是新的索引 &#125;stdout &#123; codec =&gt; rubydebug &#125;&#125; 现在logstash不支持多个实例共享一个path.data，所以要在在启动不同实例的时候，命令行里增加--path.data PATH，为不同实例指定不同的路径。启动logstash之后，看到显示如下： 再到nginx的日志看一下，因为logstash里没有做日志的切割，所以是整个一个类似字符串的形式发送了过来： 果然有这样的日志，可见logstash与nginx的redis已经正确连接。在elasticsearch里，使用curl -u 账号密码 &#39;localhost:9200/_cat/indices?v&#39;查询索引的时候，就会看到那个nginxlogstash，如图： 参考资料https://doc.yonyoucloud.com/doc/logstash-best-practice-cn/input/redis.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>大数据分析</tag>
        <tag>elk</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql-Atlas从库始终没有建立连接怎么办]]></title>
    <url>%2F2018%2F02%2F09%2FMysql-Atlas%E4%BB%8E%E5%BA%93%E5%A7%8B%E7%BB%88%E6%B2%A1%E6%9C%89%E5%BB%BA%E7%AB%8B%E8%BF%9E%E6%8E%A5%E6%80%8E%E4%B9%88%E5%8A%9E%2F</url>
    <content type="text"><![CDATA[最近发现阿里云线上环境有一台hls模块的数据库从库一直没有连接，而主库却一直连接不断。在阿里云控制后台看到连接情况如下图： 上图是主库的，下面那个是从库的，两者差距很大，可见这样的配置是错误的，因为读库根本没有使用，也就是说读库的那份钱是在浪费！ 来到对应的atlas服务器查看配置，看到atlas 的配置里规定管理接口的用户名和密码是默认的原始套餐，端口被改成了2346，如下面， 于是我们就在模块服务器（也就是图里的online-hls-001)上登录这个atlas服务器的管理端口，看一下效果： 发现mysql根本没有反应，可当我们telnet去atlas的2346端口的时候，发现端口是通的： 于是我们返回到atlas 的配置文件，把这台hls模块服务器的ip地址添加到clients-ips这个字段里。 然后再用hls服务器去测试一下atlas的管理端口，mysql -hatlas服务器ip地址 -uuser -ppwd，然后使用select * from backends;,发现里面的两个库一个连接成功，另一个是失败的： 两个库都可以ping通，state却有这样的差别。由此可见这台atlas根本没有连接到从库，导致从库的连接数始终为0。这个时候我们就要检查从库配置的账号密码是否正确，而且在阿里云控制后台给从库开启这个atlas的白名单，然后重新启动这个mysql-proxy进程，再登录atlas管理端口查看，发现从库由down转up了： 但是此时的atlas日志里却出现了很多forbidden的warning的提示： 这时候我们返回atlas的配置文件，把之前的修改过的client-ips这个字段注释掉，让所有合法ip都连接，然后重启atlas，这样这种forbidden ip的警告日志就会消失。 稍等一会，就会看到从库上也会出现连接数了，至此一切恢复到正常状态，故障排除！ 本次故障排除感谢https://highdb.com/?s=atlas这位大神的帮助！ 文末补充数据库访问使用了事务的话，从库也会建立连接，只是连接量要小于“非事务访问”，而不是一点连接都没有。 一般来说，在atlas配置文件里，主库写一个，而从库最好把主库和从库都写进去，如果希望从库承担读的任务多一点的话，可以把权重调高，比如我想从库与主库的读任务比是2：1，那么就可以这么写： 1234#Atlas后端连接的MySQL主库的IP和端口，可设置多项，用逗号分隔proxy-backend-addresses = 主库地址:3306#Atlas后端连接的MySQL从库的IP和端口，@后面的数字代表权重，用来作负载均衡，若省略则默认为1，可设置多项，用逗号分隔proxy-read-only-backend-addresses = 从库地址:3306@2,主库地址:3306@1]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>读写分离中间件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[脚本里添加crontab的方法]]></title>
    <url>%2F2018%2F02%2F08%2F%E8%84%9A%E6%9C%AC%E9%87%8C%E6%B7%BB%E5%8A%A0crontab%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一般来说，增加计划任务都是crontab -e，然后在里面添加内容。但是在一些脚本里，需要自动添加，那么这种情况怎么办？ 第一种方法重定向crontab到其他文件： 123crontab -l &gt; crontab.bakecho "*/1 * * * * ./yourscript &gt; /dev/null 2&gt;&amp;1" &gt;&gt; crontab.bakcrontab crontab.bak 如果想删除某个计划任务，就进去crontab -e删除就好，crontab.bak不用管，不用担心内容会自动变成crontab.bak的样子。 第二种方法如果你觉得使用crontab 文件这种方法心里没有底的话，就选择最妥善的方式，也就是下面这样： 1echo "*/1 * * * * ./yourscript &gt; /dev/null 2&gt;&amp;1" &gt;&gt; /var/spool/cron/root 当crontab突然失效时，可以尝试/etc/init.d/crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>crontab</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在百花之中干掉一个杂草连接...]]></title>
    <url>%2F2018%2F02%2F08%2F%E5%9C%A8%E7%99%BE%E8%8A%B1%E4%B9%8B%E4%B8%AD%E5%B9%B2%E6%8E%89%E4%B8%80%E4%B8%AA%E6%9D%82%E8%8D%89%E8%BF%9E%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[正文早上接到阿里云的服务器报警，说有一台服务器的流量超标，这个服务器的外网带宽是5M，但是登陆进去使用iftop -i eth1发现里面的流量已经几乎跑满，如图： 我这个服务器的名称叫online-mts-001，为啥会有一个mail25.u.tsender.com，这个是什么鬼？莫非是通过我的服务器去连接这个“邮箱”域名？于是我就ping了一下这个mail25.u.tsender.com，结果如图： 看到这个域名对应的ip地址是115.29.177.8，嗯，115.29.177.8，哎？这个ip地址好熟悉啊，卧槽，这特么不是这个online-mts-001的外网ip么？ 也就是说我这个机器在我不知道的情况下被人绑定了一个域名！但是我这个服务器不是网页服务器，上面那个tsender.com的域名打不开，我检查了服务器一番，发现这个机器没有被人入侵的痕迹，只能说是被人有意/无意（无意的可能性更大，比如看错了阿拉伯数字）绑定了域名。 被人绑定了域名就好比被人起了外号一样，一旦非本人操作就不太好往下摘了，查了很多资料都没有办法，毕竟主动权不在我这里了。 但是回头过来，我们的重心是要解决那个占据了3M带宽的连接，netstat看了一下，发现这个连接的具体信息如下： 仅仅是干掉连接的话，方法有很多，关闭网卡再重开或者关闭相应的服务都可以，但是现在的问题是这台服务器是生产环境的服务器，它主要是给用户提供视频拉流，通过抓包分析得知，这位183.228.128.188的用户合法通过外网连接到了这台视频服务器，而且拉取的是高清视频，所以才占据了这么大的带宽。不过我们还是决定先断开这位用户的连接同时不动其他用户的连接，这位183.228.128.188的用户在客户端虽然会发觉视频断开，但是有缓存和人为刷新的客观因素，实际的体验不会差太多，至少不会投诉400… 那么如何干掉一个established连接同时保证其他连接呢？请使用tcpkill。 tcpkill的下载比较有说法，下面是安装步骤： 1234567wget http://rpm.repo.onapp.com/ramdisk-hv/centos6/dsniff/libnids-1.24-1.el6.x86_64.rpmwget http://rpm.repo.onapp.com/ramdisk-hv/centos6/dsniff/libnet-1.1.5-1.el6.x86_64.rpmwget http://rpm.repo.onapp.com/ramdisk-hv/centos6/dsniff/dsniff-2.4-0.14.b1.el6.x86_64.rpmyum install libICE libSM libXmu -yrpm -ivh libnet-1.1.5-1.el6.x86_64.rpmrpm -ivh libnids-1.24-1.el6.x86_64.rpm rpm -ivh dsniff-2.4-0.14.b1.el6.x86_64.rpm 请按顺序操作，不然的话dsniff就会报错： 1234warning: dsniff-2.4-0.14.b1.el6.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 0608b895: NOKEYerror: Failed dependencies:libnet.so.1()(64bit) is needed by dsniff-2.4-0.14.b1.el6.x86_64libnids.so.1.24()(64bit) is needed by dsniff-2.4-0.14.b1.el6.x86_64 安装完毕之后，就会生成tcpkill命令，如图： 然后断开上面那个大带宽连接的命令是：./tcpkill -i eth0 src port 9132 and dst port 9595 and src host 115.29.177.8 dst host 183.228.128.188或者./tcpkill -s 115.29.177.8:9132 -d 183.228.128.188:9595。 但是要注意一下！tcpkill一定要运行在能接收到应答包的主机上在，最好运行在连接或半连接存在的一端主机上，因为tcpkill会发现这个连接里有数据传输进而感知并且干掉。而且tcpkill默认情况下是只能干掉established状态的连接，对于假死连接（连接在，但是数据不传输）或者半连接（由于tcp keeplive没打开而又没有数据向对端发送，导致一直无法感知次连接其实已经断开）是无法断开的。 如果遇到上述所说的假死连接和半连接就需要手动更改tcpkill的源码，更改原理在https://yq.aliyun.com/articles/59308。 如果使用的系统是ubuntu or debian，还可以使用cutter命令，apt-get install cutter下载即可。使用方法：http://www.cyberciti.biz/tips/cutting-the-tcpip-network-connection-with-cutter.html。 至于第一个问题，怎么把这台服务器上的域名撤除，我倒要好好想想了… 参考资料http://www.cyberciti.biz/howto/question/linux/kill-tcp-connection-using-linux-netstat.phphttp://www.gnutoolbox.com/tcpkill-command/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix里item取值超时怎么办？]]></title>
    <url>%2F2018%2F02%2F08%2FZabbix%E9%87%8Citem%E5%8F%96%E5%80%BC%E8%B6%85%E6%97%B6%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[正文开发同学新开发了一个模块，需要运维监控一下8683\8682\9002这三个端口，于是我就在zabbix里把这三个端口进行了监控，但是却无法返回值，如图： 可见其他的自定义监控项是好使的，偏偏三个监控端口的项都是not-supported。我就进去到item里看看，type of information和data type都是正常的，而且每三十秒一次更新，应该是没有什么问题的。 于是我就去zabbix的server使用zabbix-get去试试，到底是怎么回事儿，使用结果如图： 可见使用zabbix_get是可以取到值的，而且取值都正确，三个正常的端口反馈都是1，而不存在的端口（9002）的反馈是0。可是,我发现使用zabbix_get取值pid是结果秒出，而取值net.tcp.listen则是等了几乎5秒钟才获得结果。那么问题就出在这里了。 调整zabbix_agentd.conf里的Timeout值，把其设定为10，然后重启zabbix进程就OK了。 补充1）https://www.xiaomastack.com/2015/07/03/zabbix_net-tcp-listen/comment-page-1/#comment-319，很多时候端口监听会出错，于是就用自定义键值的方法，但是小马哥博客里的这个方法在centos里是无法启动，zabbix会报语法错误。由于公司的zabbix是2.2版本，等我有时间需要细化一下这个语法。 2）调整unsupport items检查时间的方法是：在Adiministration里选择General然后在右侧下拉菜单里选择Other，然后修改Refresh unsupported items (in sec)的值，这个值得意思是“每多少秒去重新检查一下那些not_supported的值”。 3)这种长时间获取key的行为，很容易导致zabbix unreachable poller processes more than 75 busy这个错误，所以尽可能的不要添加这样的监控，而换用其它的方式。导致zabbix unreachable poller processes more than 75 busy这个错误的另一个原因就是可能有某台zabbix-agent死机了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>运维监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十六年，九个队，一份爱]]></title>
    <url>%2F2018%2F02%2F07%2F%E5%8D%81%E5%85%AD%E5%B9%B4%EF%BC%8C%E4%B9%9D%E4%B8%AA%E9%98%9F%E4%BC%8D%EF%BC%8C%E4%B8%80%E4%BB%BD%E7%88%B1%2F</url>
    <content type="text"><![CDATA[原文地址：https://www.theplayerstribune.com/caron-butler-retiring/ 我妈第一次坐飞机的时候可真心把她吓得不行，我想她那时候肯定对Pat Riley有一些悄悄的不满。 那是2002年NBA选秀后的一天，我们乘Pat Riley派来的球队机飞翔在30000英尺的高空，从威斯康辛出发到佛罗里达的迈阿密热火队报到。我现在一闭上眼也能想起当时我妈妈Mattie坐在一个宽敞的椅子里，时而看看我时而看看窗外，前后张望的样子。她的脸上交织出坐飞机的恐惧，但又很自豪的复杂表情。 “这整个飞机只为我们几个服务的么?”她简直难以置信，要知道整个飞机上的乘客只有我、我的家人和两个热火队的工作代表。 我其实也是觉得如此的不可思议，但是我要管理好自己的神态，让自己显得比较酷。我坐在的位置上，平复自己的心情，保持正常的呼吸。球队代表给我展示了属于Alonzo Mourning和LaPhonso Ellis的专位，这看上去太梦幻了。 我对我母亲说“这一切太梦幻了”。 我一直在告诉我自己，现在我已经是热火队的一份子了。不是我吹牛，我也曾经在康大的时候也坐过飞机去打比赛，但是从来没做过头等舱，这在那个时刻我就坐在这架专机比头等舱还要牛逼的地方。那是Pat Riley级别的仓位。我一直让自己尝试冷静，“Caron，冷静，你很棒，你是个爷们，你要表现的就像以前那样从容。” 当我回忆起来当时的情景，觉得实在太滑稽了。我一直试图去安抚我那位紧张的老妈，而其实我内心的紧张不比她少多少。 这就是16年前我去迈阿密热火队报到的情景，从此开始了我的NBA生涯。如果那时候你跟我说我要在十多年的职业生涯里为9个队伍打球，我想我的表情会跟当时飞机上我的老妈一样。 但是事情就这么发生了，顺其自然，这16年真是一段棒极了的旅行。而今天，我宣布正式从NBA退役。 你知道，我其实很想写一封信给年轻时候的自己，不过我想12岁的我应该压根不会理会这封穿越时空的信。如果他发现信封里没有钞票，可能就会直接把它扔进垃圾桶里。然后会嘲笑我现在的光头并且补上一刀“哥们，你真老”。 但我现在就想告诉你那些让我NBA梦成真的人和故事。而这一切的一切都要从当时热火队总裁Pat Riley开始。 我出生在威斯康星州的拉辛，在18岁之前我没有踏出过那里半步，不过我有听说过芝加哥，也见过有人在迈阿密的海滩上放风筝。除了康涅狄格州那两年，拉辛就是我的全部。大城市？我只有在电影和电视里看到他们的样子。 然后就是参加NBA选秀，不久我就接到Pat Riley总裁的电话，然后我成了迈阿密的一份子，那一切的一切彷佛是发生在我身体之外的。我觉得我可牛逼了，你知道么？我那时候简直是全世界最幸福的人，我准备把人生最好的青春时光投身于职业篮球，我要让家族骄傲，要让整个拉辛骄傲。 但我第一天踏进热火队训练馆的时候迎接我的不是派对，生活也不想在海边抽雪茄那么潇洒，迎接我的是“你的更衣间在这里，你迟到了，你应该早来一个小时的，明天开始训练，对了，你叫啥来着？” 这就是我到训练馆听到的第一句话，这就是热火给我的第一感觉。它让我停止了“从专机到专车，全家在迈阿密的豪华旅行，每个人都以我为豪”的感觉，开始了真刀真枪的训练—-我看到Pat Riley就站在训练场场边，他手上带着总冠军戒指，他很正经的跟你说，马上去好好训练或者从训练馆出去。 迈阿密的纸醉金迷让很多年轻人迷失，不过那种夜生活对我没有什么侵蚀力。我14岁的时候就有了我第一个儿子，我年少的时候可没少蹲过号子，记得我16岁的时候，警察曾经在我学校的储物柜里搜出来了毒品和手枪，我也被拘留了一段时间。我出自黑人街头，小时候经历了很多哥们朋友死掉。所以我没有期待过什么幸福温暖的日子，那时候，篮球是我唯一守护的东西。我尽力的不让那些声色犬马去分散我的注意力。 不过那时候我毕竟还是一个小孩，虽然我心态还算端正，但是我却不知道如何百分百的把精力都投入到训练里去。 最开始的几个月对于我整个职业生涯来说是非常重要的，热火队从一开始培养我的比赛观和胜负观，你把它想像成是一个称之为愿望也好，意志力也好，反正就是一个坚定的信念，我想正是这个信念让我能在NBA待这么久。我们为热火队打球，为Pat Riley总裁和Stan Van教练卖命。他俩教会了我如何正确的身体训练，正确的战术训练，叮嘱我们正确的去准备比赛，告诫我们细节决定成败。而这些都是你每晚在TNT直播中看那些NBA球员时所看不见的。 幸运的是，我很早就领悟到“天赋并没有你想象的那么重要”这个道理，当然，有天赋肯定很赞，但是如果你在比赛里倾尽所有、全力以赴，哪怕你的对手比你能跳能跑，但是你也有很大的几率赢球。钻研，不断地打磨技术，这才是赢球的不二法则。如果有人说“在NBA这么高水平的比赛里，基本功并不是重要”，这话简直就是痴人说梦。 Pat Riley教练会以各种不同的方式教我事情，我永远不会忘记他会在我的更衣柜上留下字条，我会在训练前看到这些字条，上面有些写的是我技术上缺陷和需要进步的地方，有些写的是励志的话语。那虽然只是简单的一两句话的便条，但是每一句话都对我有着绝大的影响，这就是我跟我篮球教父之前所建的秘密联系通道—用我们自己的语言去彼此沟通，正是这每一张字条让我成为了一个更好的篮球选手。多年之后，我转会去了雷霆队。我开始效仿当年Pat Riley给我留字条那样的给Kevin Durant留字条，KD是我的小兄弟。我很惊讶和感激在他的MVP的获奖演讲里他特别提到了这个事儿。但是我看来，我只是做了我的篮球恩师Pat Riley做的事情。 第二年，当我得知被交易去湖人队的时候，我很受伤，我以为Pat Riley跟我在篮球层面的之间是有特殊关系的。我的意思是说，如果我当时在Pat Riley的位置上也会把自己拿去交易Shaq的。如果你看着镜子中自己，然后说你比Shaq对这个队伍更有价值，那我无话可说，因为我实在不想打击你的自尊心。 不过那种失落并没有持续很久啦，这就是在联盟里生存的学费。就像我前面说的，我在拉辛住了十多年，我也希望终老迈阿密。我还记得跟D-Wade、Brian Grant、Eddie Jones、Alonzo这些家伙一起打球的日子，那是一段令人难以置信的学习经历，我会永远记得和那些家伙一起玩的开心时光。但是这就是生意，不久后我就动身出发去洛杉矶报到，身边的人从Dwyane Wade变成了Kobe Bryant，Dwyane Wade是我的铁哥们，但是这个世界也没几个人会拒绝跟Kobe联手。当我到了洛杉矶也就大约一周的时间吧，当初到迈阿密的紧张感觉被我忘个干净。 我仅仅在湖人效力了一个球季就被交易去了华盛顿奇才，有趣的是，那个交易对我来说没什么伤害。我认为那是一个很好的决定，当时的奇才队有很多年轻的充满天赋的选手，我很高兴有机会成为他们的一员。 华盛顿的六年是我一生中最棒的时光，在奇才队我两次入选全明星赛。我和Antawn Jamison、Brendan Haywood、以及当时还没有称呼自己是“Hibachi”的Gilbert Arenas在东部打出了一片天,我永远记得华盛顿人民是多么的热爱那支奇才队。纵然迈阿密和洛杉矶都是超级大城市，但是华盛顿却是我职业生涯效力时间最长的地方，那是我第二个篮球之家。 交易帮助我学习到了篮球生意的真相，我不论到哪个球队，都试图在训练里做一个榜样，就用当初在迈阿密学到的那套。我在健身房里专注训练，总是要求自己做的更好，总是要求自己记住细节。在每一支队伍里我都与队友们打成一片，我的意思是，换做是你整天跟这帮队友们泡在一起，如果你不是太拘谨的话，会很容易融入这个集体的。 不过我毕竟辗转了九个城市，这漂泊的生活对我的家庭来说是很困难的。要知道，我那时仅仅在菲尼克斯就待了一个月左右的时间，我的妻子Andrea又不得不收拾行李搬家去下一站，所以我的孩子们总是在不停的转学转学。我妈–她一直以我为荣，即使我不是比赛中的MVP，但是只要我命中投篮但是没有拿下比赛最佳球员她都会在场边不爽（谢谢你，老妈）。但我也深知，为了我的篮球生涯，其实我的家庭牺牲了很多。 我现在感谢上苍，我依旧活着，这简直是一个奇迹。我现在想谈谈生与死，上周，我回拉辛去参加一个葬礼，那是一个26岁的小伙子，从他的车上逃离的时候被警察连开数枪。我本人不认识他，但是我理解那种感觉。因为我和那些在拉辛长大的朋友，我们都知道死亡随时都降临的恐惧感。我深深地理解被困在那里是一种什么滋味，我很幸运我走出来了。我知道那些被杀或者误入歧途的人没有离开那座城市。我参加过很多个葬礼，那很难受。不过很奇怪，在生活中你会像我一样已经达到了一定的高度，当周围人告诉你你已经挺过来了，你也会想“我真的做到了”，就是这样，但是并不是那么简单。我想我还是回回到家乡来看看的，以后也常回来。 对于现在的我来说那些拉辛的孩子就跟曾经的我一样，我也出生在这里，我也曾经是拉辛的孩子，我也做过各式各样的蠢事。但是我从中交了学费，要知道从教训里学习的确不是一个容易的事儿，我花的时间比我母亲期望的时间要长，但是我最终还收获了经验。一旦我有一个目标，就要付出全部，我不想让那些相信我的人失望。我能拥有如此多的东西，我已经很知足了。 文章的最后我想说几个人，这可能会像是一连串名单，毕竟我在联盟里摸爬滚打了这么多年，肯定有很多人要去感谢，如果我忘记了提到某人，那请准许我提前道歉。 在我开始第一场NBA比赛之前，我的妻子就对我说无论我去哪里她都会跟着，这么些年，她一直信守当初的承诺。这辈子讨到她做老婆真是我的福气，无论是现在还是将来她都会是我生命里最棒的那部分。 感谢BJ Evans、Rob Wilson、Tim Donovan、Andy Elisberg、Jay Sabol、Marjie Kates、Shivani Desai、Tim Grover 和整个Arison家族在我职业生涯初期给我的帮助。 我要感谢Buss 家族、Mitch Kupchak、Magic Johnson、Alison Bogli和Eugenia Chow在洛杉矶给我的支持。 感谢Ernie Grunfeld、Milt Newton、Tommy Amaker、Sashia Jones、Candace、Susan O’Malley在华盛顿给我的帮助。 感谢老板Mark Cuban和主教练Rick Carlisle在达拉斯给我的帮助。 还有我在快船队的队友们：Blake Griffin、DeAndre Jordan、CP3–正是你们让我从重伤中走出来，重获新生。 Matt Barnes、Lamar Odom、Chauncey Billups还有我的偶像Grant Hill，我不会忘记跟你们一起的那段日子。 我一直都梦想能穿着雄鹿队的队服打球，感谢John Hammond和Senator Kohl，你们圆了我的梦，说实话在家乡打球的感觉真好！谢谢你们。 在雷霆队，我要感谢总经理Sam Presti、KD和Russell Westbrook。 在活塞队，我要感谢Tom Gores，而且在底特律能跟Stan Van重聚，并且与我的哥们Andre Drummond、Reggie Jackson和Caldwell-Pope一起打球。 Vlade Divac，是你在2016年给那个躺在沙发里以为生涯到此结束了的我打了电话，让我再去国王队跟Rajon Rondo和DeMarcus Cousins打了一年球。 还有一个需要特别说的，那就是刚刚去世的我永远的哥们Rasual Butler，我俩同一年进入联盟。像我一样，Rasual Butler也是一个辗转多队的浪人，但他身上有我敬佩的一切特征—勤奋、专业、积极、体育精神。他是一个人民交口称赞的好队友。哥们，NBA的家人们会想你的。 我的粉丝们，你永远不会知道你们曾经带给我的快乐。谢谢你们的支持!我希望每当你想到Caron Butler这个名字的时候，你会记得我曾经是多么的热爱和尊重比赛，我也希望你们会记住我付出所有时的那个形象。我知道这是一个陈词滥调，但那个形象对我来说要比比赛还要重要–这让我可以去面对一个严峻的未来。 我现在仍然会深深地回想起2002年那次飞往迈阿密的情景，当时我和我的家人在热火队的飞机上—不是因为昂贵或奢侈，也不是因为我第一次去海边。而是因为那是我一生中第一次真的感觉要去某个地方。 在NBA打球是我的梦想，我和所有这些伟大的教练和队友们一起度过了这16年，那是一段比我想象的要好的时光。我虽然身体已经不适合打NBA的比赛，但是篮球依旧在我的生活里，我会以另外的一种形式继续跟它在一起。 我只想让你们都知道我拥有我自己的生命，但正是有了你们的帮助，这个生命才活的如此多姿多彩。]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>NBA</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录Uwsgi与Django成功勾搭的始末]]></title>
    <url>%2F2018%2F02%2F07%2F%E8%AE%B0%E5%BD%95Uwsgi%E4%B8%8EDjango%E6%88%90%E5%8A%9F%E5%8B%BE%E6%90%AD%E7%9A%84%E5%A7%8B%E6%9C%AB%2F</url>
    <content type="text"><![CDATA[环境说明Uwsgi版本：2.0.14(yum install安装）django版本：1.10.6（pip install安装）python版本：2.7.5(阿里云 centos 7自带）nginx版本：1.10.2（yum install安装） 正文在https://rorschachchan.github.io/2018/02/02/Uwsgi的安装和简单使用/里面，我们已经实现了网页打开出现”good bye,logan”的效果，可见Web Client &lt;===&gt; uWSGI &lt;===&gt; Python是通畅的，现在我们要调整看看django与uwsgi是否是通畅的。 首先，我们在/django这个目录下，django-admin.py startproject logan，建立了一个叫logan的project，然后在/django/logan/logan里会有一个自动生成的wsgi.py，打开一看，里面的内容如下： 12345678910"""WSGI config for logan project.It exposes the WSGI callable as a module-level variable named ``application``.For more information on this file, seehttps://docs.djangoproject.com/en/1.10/howto/deployment/wsgi/"""import osfrom django.core.wsgi import get_wsgi_applicationos.environ.setdefault("DJANGO_SETTINGS_MODULE", "logan.settings")application = get_wsgi_application() 我们原来的目标就是测试django跟uwsgi的链接是否正常，那么返回到/django/logan，使用python manage.py runserver 0.0.0.0:8000启动django，然后打开浏览器，在地址栏里输入外网ip:8000，看到了如下的界面： 可见django已经启动成功，但是前面说过了，这种方法只能测试环境里小规模的玩玩，完全不推荐拿去生产化境里。所以现在我们用uwsgi在8000来启动一下django。 首先，先停止了原来我们启动的django。 然后，使用命令uwsgi --http :8000 --wsgi-file logan.py,反馈错误信息如下： 出现这个错误，那就yum install uwsgi-plugin-python，同时使用uwsgi --plugin python --http-socket :8001 --wsgi-file /django/logan/logan/wsgi.py，这样却又出了一个新错误： 提示说：ImportError: No module named logan.settings。可是当我使用python客户端单独测试的时候，这个语句是可以使用的，如图： 很多人都卡在了这种情况，这个时候我们需要换一个命令：uwsgi --plugin python --http-socket :8001 --chdir /django/logan/ --wsgi-file /django/logan/logan/wsgi.py。然后我们在浏览器地址栏里输入外网地址：8001就可以看到如下网页： 可见，我们已经通过uwsgi启动了原本已经关闭了的django，这样就达到了Web Client &lt;===&gt; uWSGI &lt;===&gt; Django的目的。 如果过程中出现了端口被占用的情况，比如8002端口已经被使用了： 12probably another instance of uWSGI is running on the same address (:8002).bind(): Address already in use [core/socket.c line 764] 那么就可以使用lsof -i:8002，然后把对应的进程干掉就好了。 最后附赠python脚本一个，这个脚本可以显示python的path，内容如下： 12345import osprint '===== sys.path / PYTHONPATH ====='for k in sorted(os.environ.keys()): v = os.environ[k] print ('%-30s %s' % (k,v[:70])) 参考资料http://www.python88.com/topic/101/http://www.nowamagic.net/academy/detail/1330334]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>uwsgi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins与钉钉机器人实现手机端获取当前服务日志]]></title>
    <url>%2F2018%2F02%2F06%2FJenkins%E4%B8%8E%E9%92%89%E9%92%89%E6%9C%BA%E5%99%A8%E4%BA%BA%E6%90%AD%E9%85%8D%E6%89%8B%E6%9C%BA%E7%AB%AF%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E6%9C%8D%E5%8A%A1%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[马上要过年了，各位运维们除了因为买不到回家的火车票而嚎嚎大哭之外也开始扩容服务器和提前调整监控值，目的就是为了过一个消停的春节。可是这毕竟十天左右不在公司，要是模块真出了什么意外肯定没法第一找到日志分析问题，毕竟这几天都在串门拜年和醉生梦死中度过，走到哪都要再背一个笔记本实在太不方便了。 那么这个时候，我就琢磨使用手机端来启动服务器里脚本，让这个脚本可以去获取当前的日志，然后再把结果返回到手机端。这样就不用到哪里都带那个一看就很扫兴的公司笔记本电脑了。 使用手机端启动服务器里脚本？我又不会开发android和ios，那么肯定就要使用第三方工具，我条件反射的想到了jenkins，因为jenkins是用手机可以登录的，那么在手机端得到结果用什么呢？在微信公众号和钉钉机器人里，我选择了钉钉机器人。 创造钉钉机器人我的钉钉版本是4.2.6.37，首先在左上角头像的三角菜单有一个机器人管理，如图： 然后选择自定义机器人，给它起个名又换一个图标之后，添加到一个群聊里，如图： 添加的时候，这个机器人会生成一个webhook，它的结构应该是：https://oapi.dingtalk.com/robot/send?access_token=XXX，后面的XXX是标识符，不同的标识符代表不同的机器人，这个标识符如果丢了，可以在机器人头像点击一下然后选择机器人设置重新看到。 编写机器人脚本机器人的官方说明网址就是https://open-doc.dingtalk.com/docs/doc.htm?spm=a219a.7629140.0.0.zZIvnt&amp;treeId=257&amp;articleId=105735&amp;docType=1，这里面已经把使用方法写的够清楚了。我这里的这个python脚本是用json的格式，如下： 1234567891011121314151617181920212223242526272829303132#!/bin/python#coding: utf-8import json,urllib2#这里是机器人对应的Webhook地址url = "https://oapi.dingtalk.com/robot/send?access_token=这里输入你机器人的标识符#这里是头，原样复制就好header = &#123; "Content-Type": "application/json", "charset": "utf-8" &#125;#这里是传送的消息data = &#123; "msgtype": "text", "text": &#123; "content": "这里是消息正文！" &#125;, "at": &#123; "atMobiles": [ "A的手机号", "B的手机号" ]， "isAtAll":False #这里True代表要发给所有人，False的话，要代表消息只发给A和B这两个人 &#125; &#125;sendData = json.dumps(data)request = urllib2.Request(url,data = sendData,headers = header)urlopen = urllib2.urlopen(request)print urlopen.read() 直接执行这个脚本，就会看到我刚新建的钉钉机器人在群聊里说话了。 机器人搭配nginx上面那个脚本已经可以初步实现我们的目的，但是有一个缺点，就是正文内容不能过长。但是我想多打印一点日志，至少50行，怎么办？我想了想，可以把日志放进nginx的一个网页里，然后用钉钉机器人反馈这个网页地址啊，这样内容想写多少就可以写多少了。 假设我现在获取到的日志的文件写进一个叫chairmanmao.html里，在浏览器打开看是这样的： 那么上面那个机器人的python脚本就要改成这样： 1234567891011121314151617181920212223242526272829303132#!/bin/python#coding: utf-8import json,urllib2,commandscommands.getstatusoutput('echo -e "THIS IS TEST MESSAGE！ \n" &gt; /路径/chairmantail.html') #这里可以给网页加一个标题commands.getstatusoutput('cat /路径/chairmanmao.txt &gt;&gt; /路径/chairmanmao.html') #这里就是把诗词写进html文件里#这里是机器人的webhook地址url = "https://oapi.dingtalk.com/robot/send?access_token=这里输入你机器人的标识符"header = &#123; "Content-Type": "application/json", "charset": "utf-8" &#125;data = &#123; "msgtype": "link", "link": &#123; "text": "点击网址就可获取到本次日志查询的结果", "title": "日志查询结果已经生成！", "picUrl": "http://p1x3hd2at.bkt.clouddn.com/nanshen.jpg", #这里可以加一个缩略图片 "messageUrl": "http://服务器外网IP地址/chairmanmao.html" &#125;, "at": &#123; "isAtAll":True # at为非必须 &#125; &#125;sendData = json.dumps(data)request = urllib2.Request(url,data = sendData,headers = header)urlopen = urllib2.urlopen(request)print urlopen.read() 执行这个脚本可以看到机器人发送的信息如下： 然后打开这个网址，就看到完整的网页信息： 到时候把毛主席诗词换成实际的日志文件就好了，不用一口气打印所有的日志出来，tail -n 50 日志文件名，50行足够用了。 配置Jenkins脚本写完了，机器人也写完了，这个时候就要添加“启动端”。安装Jenkins的步骤我这里就不写了，直接可以去看https://rorschachchan.github.io/2018/02/05/Jenkins安装与创建简单任务/。现在去登录Jenkins的网页，去添加一个新的Job，比如我这个Job就叫“获取模块日志”，如图： 如果是要在Jenkins上去读取其他服务器的日志，就可以在构建project的时候选择参数化构建过程，然后配置参数ip，到时候把这些ip传递给目标脚本。如果觉得这样hold不住，可以不用jenkins的这个功能，把ip写到脚本里去，一了百了： 在构建那一步，选择Execute Shell，然后里面写上具体的shell命令，如果在上面使用了参数，那么参数就可以在这里使用，我的脚本里是没有ip这个参数的，在图里写$ip就是做一个例子讲解一下用法而已： 在构建后操作这一步可以选择E-mail Notification，这样如果失败了会发送邮件通知。如果用不着就什么都不用选。然后就是保存好这个project，点击左侧菜单栏的立即构建，就会看到下面Build History会多一个#1出来，同时钉钉机器人也在群里发消息，这个#1就是构建的记录，这个纪录多了的话，新纪录会覆盖掉老的记录。 点击这个#1，选择控制台输出，就能看到具体的操作结果了，跟在shell界面里执行的效果差不多的。可见操作成功，目的已经达到了！ 以后需要调用脚本，就在手机端浏览器里登陆jenkins，然后构建一下这个project，同时就可以看到钉钉里机器人有反馈了。 参考资料https://xu3352.github.io/linux/2017/05/01/jenkins-restart-remote-server-tomcathttps://github.com/typ431127/zabbix_dingding]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>jenkins</tag>
        <tag>钉钉</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一次官网打不开的经历]]></title>
    <url>%2F2018%2F02%2F06%2F%E4%B8%80%E6%AC%A1%E5%AE%98%E7%BD%91%E6%89%93%E4%B8%8D%E5%BC%80%E7%9A%84%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[今天有人反映官网在登陆的时候，chrome浏览器不能正常打开页面，反而会出现一个下载框。我使用IE浏览器尝试登录官网，页面也不是正常的页面，而是下面的内容： 由于官网的域名跳转是在阿里云的域名解析的地方配置的，于是就登陆到阿里云的域名解析地方，查看了一下发现，这里的配置是www.lechange.com会302跳转到home.lechange.com，而ping一下home.lechange.com得到的ip地址是一个负载均衡的地址，然后在阿里云的控制台查询这个负载均衡的情况，发现这个负载均衡后面挂载的是两台服务器A和B。 于是我在浏览器里面直接输入负载均衡的ip地址，发现还是像上面那样错误的php界面，而浏览器地址栏使用两个服务器的外网ip却是正常可以打开的。这个时候初步怀疑是SLB的问题，而我当时就觉得就凭上面这一点就去跟阿里撕逼不太妥当，但是事实告诉我们事情不是那么简单的。 我检查一下slb的端口配置情况，分别是http 80转8080和https 443转80，可见这个网站有两个协议，一个是http的而一个是https的，我们刚才虽然在浏览器里直接使用A和B的外网ip访问是可以正常打开页面，只能说明http协议是OK的，我们还要测试一下https协议访问的效果。 我就在浏览器地址栏里进一步尝试，发现使用A外网ip：8080访问是OK的，而使用B外网ip：8080访问就是PHP的文字界面。于是基本问题定位到B服务器里有文件的配置错误。 登陆到B服务器里，在nginx的conf文件夹里发现一个多余的文件，打开内容如下： 12345678910111213141516server &#123; listen 8080; server_name www.lechange.com (file://www.lechange.com/) www.lechangebuy.com (file://www.lechangebuy.com/); index index.html index.htm index.php; root /data/www/ecstore; add_header pos 'web2'; # location / &#123; # rewrite ^/(.*)$ https://www.lechangebuy.com/$1; # &#125; location /public &#123; root /data/www/ecstore; &#125; access_log /data/logs/nginx/access.log; #access_log off; &#125; 而原来nginx是有正常的conf文件，现在又多余了一个这个文件，可见是因为没有无法正常解析.php的文件，两个文件都在占用8080端口时出现了冲突，所以就导致这样php download界面的情况。删除这个多余的文件后，重启nginx，清除浏览器缓存，再重新尝试就正常打开页面了。 为什么会多一个这样的文件，后来把各位运维人员严刑拷打一顿才知道，原来有一次某运维小弟在B服务器里面做跳转的测试，测试完毕之后忘记了把这个多余的文件删除，原本这一切是没有问题的，但是可能服务器nginx经历了重启，于是就加载了这两个conf文件，就把这个隐藏的问题暴露了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[往github里上传代码]]></title>
    <url>%2F2018%2F02%2F05%2F%E5%BE%80github%E9%87%8C%E4%B8%8A%E4%BC%A0%E4%B8%80%E4%B8%AA%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[说来惭愧，使用hexo博客这么久了，但是真正使用github保存代码却是第一次。因为要打算自己搞一个jenkins试试自动化部署，所以就打算把我那些不堪入目的代码放在github上，然后用jenkins去执行。今天这篇文章就是来记录如何把本地的代码文件上传到github上的过程，本次过程是在windows下操作的。 建立远端仓库首先登录github的界面，然后建立一个新的仓库（repository），如图： 在建立仓库的时候，要注意最好选择一下Initialize this repository with a README这个选项，这样可以省去一些麻烦，如图： 在这里就用我刚建立的仓库—chentest。 建立本地仓库首先我们先去http://windows.github.com/上下载git工具，在安装的时候你还可以顺便登陆，如果没有github账号的话这一步可以跳过的。 安装完毕你的鼠标右键应该多了一个功能Git Bash Here，此时，可以在电脑找一个文件夹，这个文件夹不推荐安装在C盘，假设我就在E盘根目录下叫chentest的文件夹，这个文件夹名称应该与我们刚刚建立的github仓库名称相同。不然的话，可能在git pull的时候爆fatal: refusing to merge unrelated histories这个错误。 在这个chentest的空文件夹空白处，右键鼠标，然后选择Git Bash Here，就会出现一个类似dos的命令行窗口，此时需要输入git init，这个时候发现chentest文件夹里多一个隐藏文件叫.git，这就代表本地仓库已经创建成功了。 配置公私钥然后就是建立一个SSH key，以后你上传任何东西到远端仓库的时候都要输入这个key，那么在命令窗口输入ssh-keygen -t rsa -C &quot;你的GitHub注册邮箱&quot;，此时会让你输入一个文件路径，这个路径就是存放SSH key公钥和私钥的地方，由于我这个电脑已经在默认的/c/user/33664/.git/id_rsa已经存放了hexo博客的上传密钥了，于是我就手动把路径改成了/c/user/33664/.git/id_rsa-github，如图： 这里注意！如果你也之前有一个git id_rsa密钥的话，我个人强烈推荐这个密钥跟之前的id_rsa密钥是一样的。 在浏览器里返回到github的settings主页，在SSH and GPG keys里点击New SSH key，然后就把刚刚生成密钥的pub版输入进去，这个公钥是可以告诉别人的，但是私钥要保密好。如图： 再命令行里输入ssh -T git@github.com，这时候会让你输入一下/c/user/33664/.git/id_rsa的密钥，由于我刚刚把id_rsa-github密钥和id_rsa密钥内容是一样的，所以就输入正确了。如图： 进一步配置此时，再在命令行里输入如下的语句： 12345git config --global user.name "your name"git config --global user.email "your_email@youremail.com"git remote add origin git@github.com:用户名/Git仓库名称.git #我这个例子里就是chentest.gitgit config branch.master.remote origin git config branch.master.merge refs/heads/master 一个项目可以同时拥有好几个远端仓库为了能够区分，通常会起不同的名字。通常主远端仓库被称为origin。 加完之后进入.git，打开config，这里会多出一个remote “origin”内容，这就是刚才添加的远程地址，也可以直接修改config来配置远程地址。如图： 下载与上传由于这次是我们第一次上传，那么按照惯例，我们需要先下载一下，使用git pull origin master --allow-unrelated-histories，然后输入id_rsa密钥，看见chentest就多了那个README.md文件了。把这个README.md文件改成这样： 12# chentest这是一个做测试的仓库，做好了之后，就先尝试把代码传上去，然后结合Jenkins来搞！ 同时也写一个新的代码，比如这个文件就叫test1.md，里面内容是： 1234#/bin/bashecho "hello,chrisChan!"echo "this is your first git"ifconfig 这个shell脚本内容就是输出两个废话，然后打印ip地址。保存test1.md，然后在命令行里输入如下的内容： 123git add README.mdgit commit -m "提交注释" #这个注释内容是会在网站上体现出来的git push origin master git push命令会将本地仓库推送到远程服务器，而之前说过的git pull命令则相反。同样的输入id_rsa密钥，然后就会看到文件成功上传了！如图： 来到github网站里一看，果然刚刚写的那个test1.md出现了，如图： 结语通过刚才的操作，我想各位应该对github操作有一点初步的了解。其实Git命令行是一个版本控制工具，Github是一个用Git做版本控制的项目托管平台。形象解释的话Git相当于是弓，GitHub是靶，你的代码是箭，弓把箭射到靶上。 参考资料https://www.jianshu.com/p/0fce531dba31http://blog.csdn.net/zhangmingbao2016/article/details/73478899http://www.cnblogs.com/findingsea/archive/2012/08/27/2654549.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins与Github组合成持续集合环境]]></title>
    <url>%2F2018%2F02%2F05%2FJenkins%E4%B8%8EGithub%E7%BB%84%E5%90%88%E6%88%90%E6%8C%81%E7%BB%AD%E9%9B%86%E5%90%88%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[生成Token码首先登录github，在首页选择settings，如图： 然后点击最下面的Developer settings，点击Personal access tokens，最后点击Generate new token，如图： 输入名称和权限，权限选择repo和admin:repo_hook这俩，如图： 然后就会生成一个token密码，这个token密码请妥善保存，丢失或者删除就GG了。 将Token码配置到Jenkins浏览器返回到Jenkins界面，在首页里点击系统管理，然后选择系统配置，在系统配置里面添加一个GitHub Servers，在Add Credentials这一步的时候，要把kind改成Secret text，如图： 这里Secret的地方就是填写刚刚生成的Token码。 保存之后，点击一下test connection，如果出现Credentials verified for user xxx, rate limit: xxx的字样就是成功了，如图： 设置webhooks在github里找一个源码库，选择settings，然后点击小菜单栏里的Webhooks，再点击右边的Add Webhook即可，如图：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jenkins的安装与创建简单任务]]></title>
    <url>%2F2018%2F02%2F05%2FJenkins%E5%AE%89%E8%A3%85%E4%B8%8E%E5%88%9B%E5%BB%BA%E7%AE%80%E5%8D%95%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[安装与启动环境：CentOS 7.0 + java 1.8 安装方式： 12345yum install yum-fastestmirror -y #安装自动选择最快源的插件#添加Jenkins源:sudo wget -O /etc/yum.repos.d/jenkins.repo http://jenkins-ci.org/redhat/jenkins.reposudo rpm --import http://pkg.jenkins-ci.org/redhat/jenkins-ci.org.keyyum install jenkins #安装jenkins 启动方式：sudo service jenkins start，如果没有java是无法启动的。 Jenkins默认端口是8080，如果要更改端口，需要先vim /etc/sysconfig/jenkins，然后修改JENKINS_PORT=&quot;8080&quot;为自己想要的端口号即可。 访问方式：浏览器输入http://your server ip:8080/，然后会看到这样的一个界面，打开这个文件，输入里面的key就可以访问jenkins了。 然后就是让你安装插件，如果是新手的话，可以安装系统推荐的插件，如果插件安装失败不要怕，可以日后手动补上。 插件安装完毕之后，就是自己创建一个管理员账号和密码，输入之后，点击右下角保存并完成。 然后就可以看到Jenkins初始化的首页。 镜像安装docker安装jenkins也很简单粗暴，但是官方的jenkins镜像可能拉取比较慢，推荐先去加速，国内docker加速的方法在此：https://rorschachchan.github.io/2018/04/20/%E5%9B%BD%E5%86%85Docker%E7%9A%84%E5%8A%A0%E9%80%9F%E6%96%B9%E6%B3%95/ 。 安装步骤如下： 123456docker pull jenkins cd /data/docker run -d --name jenkins -p 8080:8080 -v /data/jenkins:/var/jenkins_home jenkins #做了一个挂载chown -R 1000 /data/jenkins #将权限打开，不然的话jenkins无法正常启动docker start jenkinscat /data/jenkins/secrets/initialAdminPassword #网页需要的验证码 此时登录http://your server ip:8080/就会正常访问了，其余的步骤跟上面的一致。不过镜像安装有点瑕疵，就是tag是V2.60.3，有点老，有些插件已经不支持了。 创建任务假设现在要创建一个Job(任务)，这个任务就是输出当前服务器的外网IP地址，那么就点击首页里的新建任务，然后输入任务名，补充一句，生产环境里的Job名最好不用中文，不做死就不会死，然后选择构建一个自由风格的软件项目，如图： 在源码管理的地方，我们暂时选择None，待日后把jenkins与github相关联之后，就可以通过github来配置源码了。在构建触发器的地方，我们选择Poll SCM，这里说一下这几个触发器选项的意思： 1234Build after other projects are built： Build periodically ： 周期进行项目构建（它不关心源码是否发生变化），可以配置如下：0 2 * * *（每天2:00 必须build一次源码）Build when a change is pushed to GitHub： 只要github上有提交了，jenkins没有自动检测到并构建，这设置之后在github中也需要设置才能生效Poll SCM：定时检查源码变更（根据SCM软件的版本号），如果有更新就checkout最新code下来，然后执行构建动作。可以配置如下：*/10 * * * * （每5分钟检查一次源码变化） 构建步骤这里有很多的选项，我们选择Execute Shell，里面可以写shell命令也可以写shell脚本，这里我就写入一个很简单的ifconfig命令去查看一下IP地址，如图： 构建后操作这里也有很多的选项，这里我选择E-mail Notification，然后输入自己的邮箱地址，这样如果构建失败了，就可以发邮件提醒。如图： 配置完毕之后，点击左下角保存即可。 查看任务效果返回到Jenkins的首页，我们看到多了那个刚才新建的任务，然后点击任务名旁边的小三角，选择立即构建，如图： 然后就会看到构建的历史，点击任意历史记录的控制台输出，就会看到效果，的确是操作了ifconfig命令的效果：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Jenkins</tag>
        <tag>持续集成</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper集群的搭建与配置]]></title>
    <url>%2F2018%2F02%2F05%2FZookeeper%E9%9B%86%E7%BE%A4%E7%9A%84%E6%90%AD%E5%BB%BA%E4%B8%8E%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[Zookeeper的下载地址：https://github.com/apache/zookeeper/archive/master.zipzkclient的下载地址：https://github.com/sgroschupf/zkclient 至于zookeeper的作用和原理我这里就不多赘述了，大家有兴趣可以去查查，这里主要就是动手操作。 搭建集群首先先看一下本次zk实验服务器的名称和IP情况，这里我们选择了三台服务器作zkserver，因为三台是标配，一台的话就只有leader没有follower，不是很稳定的结构，当然啦如果你的公司土豪的话是可以玩三十台： 123dvl-mrszk-001 10.117.0.125dvl-mrszk-002 10.117.1.158dvl-mrszk-003 10.168.152.227 对这三台服务器都要进行如下的步骤: 1)先把zookeeper.zip传到linux里，然后解压到/usr文件夹下； 2)进入/usr/zookeeper/conf文件夹，vim zoo.cfg，在最下面补充上面的三个zkserver，见图： 3)再来到/usr/zookeeper/data文件夹，如果里面有文件就清空所有文件，如果是1号zkserver就echo 1 &gt; myid，如果当前机器是2号zkserver就echo 2 &gt; myid，依次类推，这里一定要注意，不可以都写一样。 4)vim /etc/hosts，还要把这三台机器的ip地址和名字都写进去，如下： 12345127.0.0.1 localhost::1 localhost localhost.localdomain localhost6 localhost6.localdomain610.117.0.125 dvl-mrszk-00110.117.1.158 dvl-mrszk-00210.168.152.227 dvl-mrszk-003 5)再来/usr/zookeeper/bin文件夹，./zkServer.sh start启动zk，然后再./zkServer.sh status查看进程情况，如图看见第一台和第三台zkserver的身份是follower，第二台是leader： 至此整个zk集群就搭建并且启动完成了。注意：zookeeper集群时，zookeeper要求半数以上的机器可用，zookeeper才能提供服务。 故障排除如果这里有启动失败的情况，比如Error contacting service. It is probably not running.这样的字样，那么有这么几种可能：1）data文件夹下的myid有数字重复或者是数字漏写的情况；2）zoo.cfg里的指定日志文件夹没有手动创建；3）/etc/hosts下的名字与zoo.cfg里的server字段不相符，注意一下，/etc/hosts里的127.0.0.1的名字不要与本ip后面的名字一模一样，不然zk也无法识别！4）/etc/hosts名字使用了中文，java系对中文是很不友好的。 如果出现的Cannot open channel to X at election address /A.B.C.D:3888的日志报错，检查一下zoo.cfg里的123与myid的123是否一致。 配置文件详解1.tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。2.dataDir：顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。3.clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。4.initLimit：这个配置项是用来配置 Zookeeper 接受 客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 52000=10秒。5.syncLimit：这个配置项标识 Leader 与 Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是22000=4秒。6.server.A=B：C：D：其中 A 是一个数字，表示这个是第几号服务器；B 是这个服务器的 ip 地址；C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号。 验证成果Zookeeper的配置工具叫Zooinspector，下载地址是：https://issues.apache.org/jira/secure/attachment/12436620/ZooInspector.zip，下载完直接解压缩就可以在windows里使用。 我们实验的这三台服务器只有内网，但是如果要连接zooinspector，还是需要通过外网权限连接的，这里可以配一个iptables转发规则，配iptables的步骤在这里：http://chenx1242.blog.51cto.com/10430133/1875950 ，照葫芦画瓢即可，但是要注意，zk的端口是2181。 当然，如果不想费事的话，就直接给zkserver配一个外网IP，直接连接。 成功连接到zooinspector，就会看到这样的内容，这里的lcconfig是手动添加的，右击鼠标，选择add node，然后直接写上lcconfig就行，这个名字是根据实际需要填写的： 上面我们已经配置了zkserver集群而且还启动zkserver进程，现在还需要zkclient，zkclient就是请求发起的一方，然后我们可以在各个的模块服务器上部署zkclient服务，通过启动zkclient服务，来让这些模块统一从zooinspector里取值，这样就达到了批量配置，同时保证一致性的效果。 zk的模板文件是_tpl.properties为结尾的文件，我这里模块的名字叫mrs，那么在实验里这个模板文件就是mrs_tpl.properties，这个mrs_tpl.properties里有这样的一个字段，如图： 而我们在zooinspector里对应就这么填写： 保存zooinspector，然后从windows返回到linux，启动zkclient服务和对应的模块进程，如果配置都正常的话，那么程序就会正常启动，ps -ef|grep java就会看到一个叫lczk.AppServerDaemon的进程。这个时候在去看一下mrs的配置文件： 可以看到areaAk取得值就是zk里面data_center里面access_key里面的ak的值，其他的几个值也是同理。可见整个zk已经配置成功，模块都进行了统一配置，而且这些配置既然能被一个接受，同时也会被其他相同的模块服务器所接受。这样就达到了批量配置的效果。 拓展阅读http://ibruce.info/2014/10/23/zookeeper/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>zookeeper</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Uwsgi的安装和简单使用]]></title>
    <url>%2F2018%2F02%2F02%2FUwsgi%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[正文运维平台的搭建已经提上日程，而我选用了大家比较常用的Uwsgi+nginx+django的架构，这里先记录一下安装Uwsgi的过程。 这里解释一下Uwsgi+nginx+django，我们整个流程如下图： 这里我们可以看出，web server是无法与我们的app（django等等）进行直接对话，他需要通过uwsgi这个桥梁，这个桥梁很重要，虽然我们使用django的runserver功能也会打开一个页面，但是这个页面是很脆弱的，小规模使用还好，要是放在网络上供很多人点击的话，根本就是脆不经风。 uwsgi是啥，请查看文末的参考资料，写的已经非常好了。我这里就简单说下： uwsgi 实际上也是一个http服务器，只不过它只面向python网络应用程序。虽然uwsgi也是http服务器，但是却不能直接使用它部署python web应用程序，否则会出错。 在本文中，uwsgi所扮演的的角色是后端http服务器，nginx扮演的角色是前端http服务器，hello.py是客户端应用程序。用户从网页浏览器中发出请求，nginx服务器收到请求后，会通过它的uwsgi模块将用户的请求转发给uwsgi服务器，uwsgi服务器处理完毕后将结果返回给 nginx，浏览器将最终的结果展现给用户。 Uwsgi的安装比较简单，推荐使用yum install Uwsgi直接下载使用，而不推荐用pip install uwsgi，因为pip安装的话，虽然也能成功（如下图红框），是没有uwsgi.ini文件的，其实没有这个uwsgi.ini是无足轻重的，因为这个文件可以自己写，但是对于生手来说，没有这个文件可能会心里发毛，就无法按照攻略继续下去，所以我更推荐用yum安装，如图： 为了纪念我们的金刚狼同志，我们就写一个叫logan.py，里面的内容是这样的： 123def application(env, start_response): start_response('200 OK', [('Content-Type','text/html')]) return "good bye,Logan..." 然后我们就可以启动这个uwsgi看看效果，使用uwsgi --http :8001 --wsgi-file logan.py，把端口设定为8001，同时指定协议是http，然后加载的文件就是logan.py，启动之后，如图： 遇到这种情况，你就yum install uwsgi-plugin-python，然后把命令做一点点修改，改成：uwsgi --plugin python --http-socket :8001 --wsgi-file logan.py。 屏幕会出现一大堆文字，然后提示，uwsgi已经启动成功了。在浏览器输入服务器外网地址:8001看一下效果，如图： 我们在root目录下再写一个测试的文件，这次我们写一个比较老实的python脚本来测试，这个脚本就叫test.py，里面的内容如下： 12345678910#!/usr/bin/python#coding=utf-8import osimport sysdef application(environ, start_response): status = '200' output = 'this is a test for uwsgi,HOHO~' response_headers = [('Content-type', 'text/plain'),('Content-Length', str(len(output)))] start_response(status, response_headers) return output 还是用刚才的方法，依旧可以打开网页，其实上面这个简单的uWSGI程序更好理解整个套路，只需要实现一个名为application的函数就可以了，该函数有两个参数，environ为包含有http请求的环境变量，start_response为一个函数，用来设置http头。在这个函数里，我们只需要调用一次start_response函数，设置一下HTTP返回头，再return一个HTTP body即可。 至此，整个uwsgi就安装成功了。 参考资料http://xiaorui.cc/2017/02/16/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3uwsgi%E5%92%8Cgunicorn%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B8%8A/http://uwsgi-docs.readthedocs.io/en/latest/tutorials/Django_and_nginx.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
        <tag>uwsgi</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从excel的大单元格里快速提取内容]]></title>
    <url>%2F2018%2F02%2F01%2F%E4%BB%8Eexcel%E7%9A%84%E5%A4%A7%E5%8D%95%E5%85%83%E6%A0%BC%E9%87%8C%E5%BF%AB%E9%80%9F%E6%8F%90%E5%8F%96%E5%86%85%E5%AE%B9%2F</url>
    <content type="text"><![CDATA[我公司的服务器信息会保存在一份高加密的excel里，由于历史遗留问题，里面的格式节选一部分出来是这样的： 注意看，ip地址不分内网外网是放在一个大的单元格里，中间是用空格隔开的，造成了这样的视觉效果。 现在公司需要把所有的服务器重新更换到新的zookeeper，那么使用ansible在批量处理的时候，就需要提取这些服务器的内网ip地址录入到/etc/hosts文件里，但是由于服务器实在太多不可能一个一个手动从excel的单元格挑选出“内网IP地址”复制粘贴，那么就需要进行一下批量挑选内网IP地址的操作。 首先我们先把整个IP的单元列里的”（公）””（内）”的字样去掉，然后把整列全部拷贝，粘贴到notepad里，看到它们变成了这样的样子： 在notepad里，双引号之间的内容会被认为同一行，所以这里我们需要使用“替换”功能把所有的双引号去掉，让它变成下面这样： 这样就可以把上面的内容复制到一个新的excel去，发现每一个内容对应了一行，即一个小单元格： 然后我们把第一行染成黄色，第二行染成绿色，当然颜色你可以选择自己的口味，然后使用excel的“格式刷”功能，一拉到底，让他们变成条纹状： 然后在excel里找到“筛选”功能，先选择住这一条纹块，然后选择“按颜色筛选“，由于我们需要内网IP，那么我们就留下绿色内容即可，如图： 得到效果如下： 这样就可以把整个内容拷贝进ansible的hosts文件里，然后搭配ansible批处理这些内网IP，双管齐下，大大的提升了提取数据的效率。 如果遇到偶尔三行（即中间有空格行）的情况，那么就在notepad那一步的时候，把空格行干掉，不如下图的情况里，第五行和第八行是空格行，可能是当初记录人员复制的时候自带了空格： 如果是空格很多的情况，那么就需要批处理一次性的把所有空格都干掉。干掉的方法，还是使用notepad的“替换功能”，选择“正则表达式”，然后把\n[\s|]*\r替换成空值就可以了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>excel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[再见，魔兽世界]]></title>
    <url>%2F2018%2F02%2F01%2F%E5%86%8D%E8%A7%81%EF%BC%8C%E9%AD%94%E5%85%BD%E4%B8%96%E7%95%8C%2F</url>
    <content type="text"><![CDATA[var ap = new APlayer({ element: document.getElementById("aplayer0"), narrow: false, autoplay: false, showlrc: 0, music: { title: "暴风城主题音乐", author: "World of Warcaft", url: "http://p1x3hd2at.bkt.clouddn.com/stormwind.mp3", pic: "http://p1x3hd2at.bkt.clouddn.com/wow.jpg", } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 这张月卡马上就要用完了，我想我的《魔兽世界》生涯也要到头了。 地球时代我是从大学的时候就开始接触《魔兽世界》，当时是在同寝的xur同学的推荐下，注册账号买了CDKey，然后跟着他在六区黑翼之巢创建了角色，那是一个留着武士头和山羊胡的暗夜精灵德鲁伊，起了个带有劲舞团性质的ID叫“删除过去”。记得德鲁伊刚出生是人形态，泰达希尔里背着一个木棒棒，靠着“愤怒”这个技能打人。于是乎，我就搓出了一个又一个原谅色的冲击波，波遍了泰达希尔的每一个角落，波倒了一个又一个萨特和野熊。当时我作为一个萌新，什么都不懂，后来在一个另外的德鲁伊的帮助下，开始做任务升级，顺便粗略的了解了魔兽最基本的操作。这个德鲁伊是我在游戏里认识的第一个朋友，是一个萌妹子，ID叫什么我忘了，不过后来她游戏上的很少了，依稀记得后来某一个半夜我在西瘟疫之地变成小豹子一个一个挠亡灵的时候，她上过一次线，等级好像是20~30级的样子，我俩说了一会话，具体说的是什么我已经记不清了，那就是我俩最后一次说话。 从泰达希尔港出来，我就开始了艾泽拉斯的冒险之路：去月光林地学变熊变豹子，拖尸到血色修道院，打过那么一两次诺莫瑞根，在荆棘谷的森林里穿梭，长期蹲在塔纳利斯刷“XD求组祖尔法拉克”。 当时寝室里没有电脑装wow，总去学府三和学府四那两条街的网吧玩，就这样我成了被盗号的重灾户。记得最过分的那次上号发现角色干脆消失了，还有一回上号发现，角色被扒的就剩下一个裤衩、一个披风和一个狼头样子的皮甲头，还别说，这造型跑出去比较拉风。后来九城推出了密保卡，就是充值卡后面的8x8的数字卡，虽然有一小段时间遏制了盗号，不过缺点就是要随身带着密保卡。在网吧开机坐下了发现没带密保卡，又跑回寝室取卡的事情，我当初可没少干。 这个德鲁伊就这样摸爬滚打到了六十级满级的时候，开始刷三大本（前后斯坦索姆，通灵学院，黑石塔上层），那时候的黑下是一个冷门本，黑石深渊更不要说了，打一次就花费了几乎一下午的时光。那段反复的刷斯坦索姆和通灵学院的日子给银色十字军捐过不少亡灵印记。后来加入了工会跟工会开始打熔火之心，记得公会团长叫火枪队长，一个男人类战士，其他的一团的队员我现在还能记住名字的有：京乐春水（德鲁伊）、Hater（女人类牧师），魂之血杀（暗夜大元帅战士）。那时候的MC已经没有DOT限制了，但是还要做水元素任务，带着圣水去灭火。接触的第一个G团是祖尔格拉布，当时德鲁伊是一个稀缺职业，我就开始去打工兼消费挣俩小钱，用那点G去买拍爪子的材料。在祖格G团认识了同大学的一个哥们，叫阿尔萨斯之心，是一个女人类圣骑士，他那个时候就有祖格龙了，但是没玩太久，60级没完事就把号给卖了…MC通了后，公会团开始打黑翼之巢，我记得当时的BWL老1还有BUG，远程和治疗可以跳在窗户上。到了老2就卡的死去活来，好不容易过了老2，接下来的三个就一片通途。然后又花了一个晚上打掉了克洛玛古斯。我那时候奈法利安和克洛玛古斯打得不多，仅有的几次击杀也没有掉落怒风胸和怒风肩，这成了我60级的一个怨念。 在打BWL的时候，安其拉版本已经开始了。G团也开始做安其拉废墟的生意，我也在其中一次无疤者奥斯利安的身上得到了废墟法杖，换掉了之前埃克索图斯的挖掘锤，为了这个废墟法杖我还卖了一张卡，那时候一张卡是300G，那次好像是我唯一的一次卖卡。说到卖卡我想起来，我人生的第一只千金虎是一个暗夜盗贼赞助的，ID好像叫小什么哥，当时的G真的很值钱，非常非常感谢他。 我在地球时代RAID的最高纪录就是安其拉神殿到公主、NAXX打了蜘蛛区前二、DK区到了老1、憎恶区的帕奇维克好像是没过，反正就是一个很一般的进度啦。然后公会团就有了一些动荡，我个人总觉得德鲁伊打人不爽，还是拿起大刀砍人过瘾，于是就开始了玩战士小号的生涯，ID叫燕小鱼。战士满级后不久就开了“远征前夕”，也就是那个全民刷战场换大元帅的时代。我那时候也在YY里加入了联盟军校，开始了没日没夜刷大奥的日子，先换了猪头锤，又换了雷矛羊，最后拿着一堆牌子去换一身漂亮的大元帅，直到现在我的YY名称依旧是以“联盟军校”开头。 我玩战士的时候还认识了一个男矮人牧师，叫赤红丹朱，这个哥们手法很骚，以前是玩部落的，记得有一次我俩要去荒芜之地，在莫高雷的高原上，他说这里曾经是他玩部落开始的地方，然后看着脚下这片大草原心潮澎湃，我俩一起战斗过不少副本，从斯坦索姆到祖尔格拉布，他没有坚持到70级就不玩了，账号也给我了…我后来去他的新浪博客看过，背景音乐是王若琳的《有你的快乐》，后来的某一天，发现他的新浪博客内容就被全删光了。 燃烧的远征记得那是7月份，大二刚开学没多久，我就穿过黑暗之门开始了燃烧的远征。那时候我先升的是战士，在地狱火堡垒里面拿大砍刀砍来砍去。七十级的raid就是先从卡拉赞开始，当时我的小战士就当主t，当时跟的团团长ID是叫小豆宝宝，一个侏儒术士。那时候卡拉赞的bug很多，埃兰可以卡门，马克扎尔王子也可以卡地点。我个人对于卡拉赞比较有印象的是虚空龙，那是这个十人小团队一个比较有成就感的boss。 往后就是打格鲁尔，那个时候我记得隔壁寝室的老朱已经开始练他的女暗夜盗贼了，那个时候我俩开始比较频繁的厮混在一起，肩并肩的不上课跑去网吧打魔兽，我印象最深的一次就是他当时为了刷一个午夜护腿在沙塔斯找了一个猎人，但是这个猎人不是很靠谱，在奴里围栏一个人忙乎从早上八点到晚上八点，结果还没出，给老朱气得牙痒痒。 TBC的时候，就有了日常任务的概念，每天早上要做奥格瑞拉和虚空龙任务，后来又有了奎岛日常，日复一日的刷声望。玛瑟里顿这个副本公会团当时没有正经打，直接就开始打风暴要塞，当时打掉了凤凰和奥术师和机器人。而毒蛇神殿我跟公会打得不多，记得有打过瞎子外加鱼斯拉。这个时候，邪神禁地祖阿曼上线了，开始了有事没事冲箱子的新征程。我印象里整个70级就是一个很多bug的版本，祖阿曼体现的尤为明显，里面BUG有术士副本拉人以及祖尔金跳柱子。但是即使这样我也只冲成功过一次四箱，那一次是t6级别队伍带队，完全没用bug。除了那一次剩下的基本就是两箱，三箱屈指可数。 然后我现实的一个的哥们由于学业的问题不能继续跟团队RAID无奈只能把账号暂给我打理，于是我改玩了他的暗夜女精灵牧师，ID叫外面下雨了（后面简称下雨）。我开始跟《荣耀》公会活动，会长就是鼎鼎有名的震撼。荣耀公会最早是桑德兰服务器的，后来由于想当联通区的第一工会，就集体转服到泰拉尔。当时我也是第一次接触牧师，完全是抱大腿的姿势跟他们一团打掉阿克和伊利丹。他们打阿克因为要录视频所以是不用bug的，真真的要考验跑火的功力。第一次打伊利丹我印象很深，当时寝室里有电脑了，由于很多人当时进度很慢，所以打伊利丹的时候，全楼道的wower都来看，然后啧啧惊叹。 跟着震撼一边打进度团也一边打公会的G团，记得当时t5一套是五万金，t6一套是十五万金。再加上卖武器饰品，一趟下来也分到不少，而且还能直接跟老板换卡，据说公会当时用的付费ts语音也是用老板的钱买的。 那时候打进度团主要就是开荒太阳井，我用那个牧师号拿了全服第一个t6鞋，首down双子的战报也上了nga，地址在：http://nga.178.com/read.php?tid=1644774 ，视频也被传上了优酷，但是现在那个视频找不到了，不过记得BGM还是很好听的。当时进度团活动时间是晚上七点到早上五点，真的很累人，最后击杀基尔加丹我并没有参与。但是震撼的指挥和语音口头禅给我留下了很深的记忆，他的确是一个很赞的指挥。 燃烧的远征也是我寝室山哥沉迷魔兽并且活跃的日子，当时山哥投奔了部落玩德鲁伊。我记得他们团第一次过血沸很惊险，当时血沸还有大约5%的血，T都躺光了，就在BOSS准备大肆屠杀的时候，结果血沸那时候点名，好巧不巧的点名了一个盗贼，那贼开着闪避上去顶掉了最后5%的血。其实FD就是这样，需要实力的同时也需要那么一点运气。 巫妖王之怒当时由于大陆魔兽推迟开巫妖王，那时候我跟老朱、涛哥、永森、老刘、阿俊、小勇几个寝室的哥们还有那个下雨一起转战去了台服，改玩部落。当时我是防骑，老朱改玩牧师，涛哥是法师，老刘是盗贼兼指挥，小勇是术士、阿俊是德鲁伊、永森是萨满，下雨依旧是牧师，不过老朱主要玩的是神牧，下雨主要是暗牧，必要的时候会切奶。 老朱的魔兽之路开始于60级，当时他第一个职业是法师，最开始的时候他跟xur打赌会尽快的把等级练到骑小马的等级，话说老朱练号的速度是很快的，他也是我们几个人里玩职业好象最多的。从法师到萨满，然后还有盗贼，但是直到这次玩上了牧师，他终于找到了灵魂的归属，发现原来牧师才是他的本命。 除了老朱我多说说老刘，老刘原名刘义超，是我们年级的一个牛人，很瘦，戴个眼镜，走路有点发飘。用他话说从小身体就不好，所以不是很喜欢运动，除了打魔兽打dota就是看漫画再不然就是用psp打麻将，老刘的经典语录就是“对于我来说，每一把DOTA都是一把新的DOTA”。老刘是一个很聪明的人，打游戏思路很清晰，很少反重复的错误。他为了游戏也肯砸钱，那时候都是老刘给我们搞代理。老刘巅峰的时候在第七天堂打主力牧师，我也亲眼见过他那时候打便当二十五人英雄十字军，后来由于要带我们几个就放弃了第七天堂，转来跟我们一起组团队。当时我们几个人一边小团队打十人icc，一边也跟个工会活动。 不过后来老刘觉得公会团打得不爽，揭竿而起，自立门户开起了25人H ICC金团。每周四，都会看到一个叫德意忘形的德鲁伊在达拉然喊人刷屏，喊满了就向冰冠堡垒浩浩荡荡的出发，由老刘带队指挥，当然我们也会偷偷摸摸的黑下几件装备和一点金。老刘指挥虽然不如震撼激情，但是思路很有条理，基本上战斗力不算很差的团一个下午就打掉2到3个区。当时我已经大四下半学期了，由于有驾校考试，所以当时老刘的金团我参与了也就一半，不过在金团里我得到了大盾冰冠冰川之墙，当时好像是花了4万金。最可惜的一次就是他们有一次开出了英雄的异物逐除，卖了17万金，按当时的物价换算是二千多块人民币!那次的金团真是赚翻了。 我们十人团的进度是“十人十字军试炼最高差两次就大十字军”、“ICC普通全通”、“h我记得没过冰龙”，因为不久就要毕业了，就没有很全力的去开荒。毕业后从此我们几个战友就四散天涯：老刘回齐齐哈尔，永森和阿俊回佳木斯，涛哥留在哈尔滨，我、小勇和老朱回大庆上班，而下雨就一直在国外，直到现在也没有回来。 现在除了涛哥和老朱，我还有联系之外，其他人我已经联系不上了，也不知道他们过得好不好。 魔兽的八十级之前的版本可以说陪伴了我在大学的大多数时光，那也是我魔兽生涯唯一玩部落的时光。 大地的裂变到了八十五级我又回归国服了，重返联盟命。由于大学里各位同学都开始了新的生活，我也开始直到现在的魔兽独行侠之路，独自练级独自打战场。 也从此之后，我就再也没有正经的跟过公会团，要么是打随机本看看剧情，要么就是打金团。其实我对八十五级的印象不多了。不过要说一下，八十五刚开始的5h真的很难，经常小怪的治疗一个打断不到就满血了，记得那时候打一个影牙城堡就累的死去活来。硬要说大裂变里印象比较深的，也就是打托尔巴拉德和打巨龙之魂，比如很多战士一起开剑刃风暴一起命令怒吼，场面非常壮观。那个时候我也把战士的种族转成了狼人，也背上了触手剑爬在地上跑来跑去。最后没事干，就趁此机会又练起来一个牧师和一个女人类圣骑士，开始了我的圣光追寻之旅。 熊猫人之谜到了九十级，朋友也多了起来。主要是跟单位里的磊哥、建哥、亮哥和迪哥一起在奥拉基尔服务器玩。磊哥原先是亡灵贼，后来投奔了联盟转了女人类，但是一直都纠结女人类的动作不如男亡灵飘逸。磊哥自封外号“阿拉希小王子”，长期在农场神出鬼没，也善于在战歌抗旗。迪哥是男德莱尼萨满，满地插柱子，他是一个个性男人，死活不去网吧，坚持就在家里玩。不过迪哥玩魔兽的时间并不长，也就几个月的时间他就投奔去三国杀和单机游戏了。健哥是一个猎人，单刷无敌，他那时候是我们几个里最有G的，输出也最为残暴，不过后来他由于工作原因也忍痛割爱了。亮哥是血DK，号称“通信公司第一DK”，不过我们四个很少玩在一起，毕竟上线时间其实是错开的。 熊猫人的本我印象比较深的就是“攻打奥格瑞玛”，至于之前的恐惧之心、永春台神马的我压根就没参与过。当时我的小牧师也算练的不错了，主要得益于我下班没事经常混迹在NGA看帖子，再加上那个版本对戒律牧也特别的友好，偶尔在金团也能拿到治疗第一的补助。而磊哥一直想要箱子BOSS的马刀，最后他也算圆梦了。至于建哥一直眼馋的火鹰，好像一直都是没有达成。 这里我要感谢磊哥，当时我俩在祖尔格拉布翻新之前去刷过祖格虎，结果出虎的时候，磊哥高风亮节让给我了，满足了我开上“红色法拉利”的梦想。 德拉诺之王一百级给我的游戏感觉就是高开低走，尤其是要塞，从最开始新鲜成了后期的累赘。虽然它给了我很多战火装备，但是也让我越来越少出去。整个德拉诺之王我最喜欢的副本就是黑石铸造厂，很有六十级副本的味道，容错率很低。那个时候也认识了以骄傲纹身为首的几个朋友，也打了金团攒了不少钱，这些钱后来也都被我换成了点卡。 至于地狱火堡垒这个副本我印象不多，翻来覆去就打了两三遍h，还都是跟G团，最后过了h的阿克蒙德，m难度我压根没尝试，后来由于公司里各个朋友们由于现实各种情况AFK，我也开始改玩单机游戏，上号就是刷刷阿什兰和四本刷金，消磨时间休闲娱乐。 军团再临到了一百一十级，几乎整个一百级都没玩的老朱重返魔兽，一口气练了牧师、死骑和恶魔猎手三个职业，我俩也配合打了几个高层大秘境，没有老朱的日子就是我自己慢慢肝神器，每周争取打一次低保，再混一次世界BOSS。也就是这张点卡玩完，我觉得魔兽已经对于我来说没有什么留恋的了，该体验的我差不多都体验过了，没体验到了我也不在乎了。我把牧师停在暴风大教堂，把战士停在暴风要塞，把圣骑士停在激流堡，下线。 至此，我整个魔兽的生涯就算总结完了。 PVP有关地球时代的野德不算很强，除了战歌抗旗好像就是补刀了。那时候我看过一个叫dazeroth的暗夜德鲁伊Unstoppable系列视频，觉得很吊，他的视频不算很多，但是打得很棒，然后再看德鲁伊就是一个中国风很浓的暗夜德鲁伊视频，但是我忘了他的名字了。改玩了战士之后，就看Swifty的视频和苹果牛的视频，看直播就看太极龙。牧师的话，看Hydra是最多的。 我个人认为PVP是魔兽的一个重要的玩法，不过这种玩法随着玩家属性暴涨而变得不再公平（不过有几个乱斗还是挺好玩的）。我竞技场打得不算多，从70年代组织55战队去每周去混10场到现在，加起来不超过200场的JJC实战经验。不过战场混得经验丰富，打一些战场也有自己的心得，比如征服之岛要上来抢车间，大奥如果速推不成功就要抢冰雪墓地耐心打平推，打战歌中场压制住了等于赢了8成，风暴之眼先抢墓地再抢骑，控制了地盘后第一时间去墓地堵人等等等等。但是战场毕竟各位玩家PK水平参差不齐，打战场其实更多就是一个图个乐。 至于搏击俱乐部，我没玩太多，不过金牌挑战我还是很喜欢的。 结束语魔兽世界陪伴了我12年的时光，现在回首来看，我个人最喜欢的是WLK，因为那个版本装备比较好看，其次相对来说各个职业的能力都比较平均，最重要的就是身边有一堆战友并肩作战；其次就是TBC，他在一定程度上弥补了很多60级的缺陷，而且极大地提升了惩戒骑、野德、元素萨等混合职业的存在感，不过TBC的BUG实在太多（我重复几次了？），光一个阿克我就见识过不下4种BUG打法，这一点是TBC的败笔；再其次就是90级和地球时代；大灾变和军团再临他们俩并列再后面一点。 我爱魔兽，他是我的另一个世界，因为我觉得在现实世界里能做的事情，在魔兽世界能做的更多。不可否认，我曾经在魔兽世界上投入了大量的时间，这耽误了我很多现实中的事儿，不过我还是认可它给我带来了不少的快乐。我还记得在06年的路边书摊会买魔兽世界带副本地图和掉落的攻略的那个宅男；我也记得当初那个小德鲁伊在灰谷，一边看着新浪魔兽任务详解，一边在地图上费劲的查找线索；我也记得当初圣骑士到了查索拉盆地的时候，被那种仙剑风的音乐陶醉；我也记得在阿什兰和奥特兰克山谷，战士那一身部落血的豪爽。但是一切缘分都有到头的时候（或许我将来会有机会到网易的魔兽世界部门上班，不过这个暂且不提），虽然我不能亲眼看见联盟一统艾泽拉斯，但是我还是要说，谢谢暴雪做的这款精良的游戏，感谢你陪我走过的这12年，谢谢跟我并肩作战过的战友，没有你们，我也无法享受这段丰富而美好的时光。 最后，我要用《军团再临》里面伊利丹的那个口信内容作为我整个魔兽世界生涯的结尾： 我留下的水晶里其实有三条口信 最后一条是给你的，勇士 你证明了你对艾泽拉斯的忠诚 你的奉献和牺牲都足以与我媲美 但你还得付出许多，更多! 此刻敌人正在集结，阴云正在汇聚 从今天起，守护我们的世界和亲人的重任 就交给你了 再见了，那些一路陪伴我的NPC们，我要离开你们了，去开始新的征程。]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>魔兽世界</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[浅谈raid0,raid1,raid10,raid01等等硬盘阵列搭配]]></title>
    <url>%2F2018%2F01%2F31%2F%E7%AE%80%E6%9E%90raid0-raid1-raid10-raid01%E7%AD%89%E7%AD%89%E7%A1%AC%E7%9B%98%E6%90%AD%E9%85%8D%2F</url>
    <content type="text"><![CDATA[RAID 0RAID 0可用于两个或更多硬盘或SSD。目标是提高读的性能。 数据以特定大小（通常为64KB）的块写入，并在可用驱动器中平均分配。下图显示了带有三个硬盘的RAID 0阵列的示意图。RAID控制器将第一个数据块写入硬盘1，第二个数据块写入硬盘2，第三个数据块写入硬盘3，第四个数据块再次写入硬盘1,以此类推，RAID 0中的三个1TB硬盘提供3TB的存储空间。 由于数据分布均匀，所以在访问的时候会从硬盘1~硬盘3提取数据，然后拼接在一起就是一个完整的数据。理论上从3个硬盘的RAID 0阵列读取数据比从一个硬盘读取要快3倍，换言之，使用RAID 0读数据的能力跟磁盘数量成正比。 RAID 0也有缺点：如果其中一个磁盘出现故障，从其他磁盘上的数据拼起来就不再是一个完整的数据了。另外，磁盘越多，则发生磁盘故障的可能性也越高。所以如果磁盘阵列里包含着对您来说很重要的数据，则最好创建频繁的备份。 RAID 1RAID 1用于创建数据的自动副本。RAID 1会将同一份数据写入两个单独的磁盘，如果A盘出现故障，仍然可以在B磁盘上读取所有数据，当然这是比较壕的，毕竟做一件事用了两块盘。这里要注意！镜像和备份可不是一样！！！如果你不小心从一个磁盘A上删除了一个文件，或者某个文件被病毒侵蚀了，那它再另一个磁盘B上也是一样的待遇。只有真正的备份才能使所有文件保持其保存状态。因此，如果想不让宝贵数据陷入灾难，创建频繁的备份是必须的。 RAID 1中的读性能通常与单独的硬盘差不多—-从A和B里一起读数据，谁出数据快就采用谁的，写的话就是要同时写到两个盘里去。因此，使用RAID 1来获得额外更多的读写性能是不太可能的。以下是RAID 1的工作原理图，如果HDD1坏了，那么HDD2直接上任，若HDD1里的东西被删除了，那么HDD2也会被删除，即使它上任了也是坏的。 RAID 10和RAID 01所谓RAID 10,其实就是磁盘阵列先RAID 1,后RAID 0,同理，RAID 01也是先RAID 0,后RAID 1。无论是1+0还是0+1，都至少需要4个硬盘。 这里先看一下RAID 10和RAID 01的效果图： 就像图里说的“在六个硬盘列里，RAID 10比RAID 01更安全”。的确，RAID 10也凭借很棒的容错能力和恢复能力当选了大多数的RAID配置，为什么不要RAID 01呢？那就是如果在RAID 0那一步磁盘就坏了，那RAID 1那步就没有意义了，因为生成的镜像全是坏镜像。 RAID 3RAID 3是这样的：若有n块盘，其中拿出1块盘作为校验盘，剩余n-1块盘相当于作RAID 0同时读写，当n-1那里的其中一块盘坏掉时，可以通过校验码还原出坏掉盘的原始数据。这个校验方式比较特别，事奇偶检验，1 XOR 0 XOR 1=0，0 XOR 1 XOR 0=1，最后的数据是校验数据，当中间缺了一个数据时，可以通过其他盘的数据和校验数据推算出来。但是这存在了问题，由于n-1块盘做了RAID 0，每一次读写都要牵动所有盘来服务，而且万一校验盘坏掉就完蛋了。 RAID 5 and 6上面说了RAID 10是一个很棒的方案，但是它的实现至少需要4个硬盘，这一点太伤钱了，于是就出现了RAID 5。与RAID 0一样，数据被分成块并执行写入处理，同时把RAID 3的“校验盘”也分成块分散到所有的盘里。同时，产生并写入称为“奇偶校验”的冗余代码。因此，即使其中的一个硬盘出现故障，也可以根据剩余的数据和奇偶校验来计算出丢失的数据，然后生成完整的状态数据。由于无论需要配置多少个硬盘，保存校验只使用一台设备的容量，容量效率随着待配置硬盘数量的增加而提高。RAID 5模式下硬盘读取数据的速度很快，因为它是从多个驱动器同时处理的。预计速度将与要配置的驱动器的数量成比例地增加。但是，数据的写入/更新涉及奇偶校验的创建/更新，所以写入性能不高。 RAID 5已经提供了一定程度的可靠性,然而也牺牲了一定的读取速度。RAID 5的局限性还表现在RAID 5仅能在一块硬盘发生故障的情况下修复数据,如果2块硬盘同时发生故障,RAID 5则无能为力。于是RAID 6应需诞生了，RAID 6同RAID 5最大的区别就是在RAID 5的基础上除了具有P校验位以外,还加入了第2个校验位Q位。当一块磁盘出现数据错误或者丢失的时候,恢复方法同RAID 5,无须使用Q校验位。当两块磁盘上的数据出现错误或者丢失的时候,恢复方法为:利用上边给出的P,Q的生成公式,联立方程组,无论受损的数据是否包括P或者Q,总是能够解出损失的两位的数据。 RAID 50 and 60在硬盘数量较少的情况下，RAID 5是极好的选择，如7-8块硬盘组成的RAID。但是，当硬盘的数量更多的时候，如10块、20块甚至100块，那么RAID 5就无法胜任了。RAID 50是在RAID 5的基础上，将多个RAID 5组以RAID 0的形式组成在一起。可以这么认为，一个RAID 5组在这里就是一个“大硬盘”，再把这些“大硬盘”以RAID 0的形式组成在一起。而RAID 60的组成就是在RAID 6组的上面组成一个RAID 0。理论上说在写入性能方面，RAID 50相比RAID 5要好太多，而RAID 50相比性能冠军RAID 10要差一点，考虑到RAID 5在一些负载面前的平庸性能，RAID 50是个不错的中间选择。和RAID 5和RAID 10一样，RAID 50也提供极好的读性能，同时RAID 50即使使用最低配置，也需要六个硬盘，所以安装成本很高。 如果担心一个RAID组里面同时有2块硬盘发生故障，导致数据丢失，那么可以选择使用RAID 60。RAID 60提供更高的安全性，相应的其可用容量会比RAID 50少点，RAID 60即使使用最少的配置，也需要8个硬盘，所以安装成本相当高。 结语以上几个磁盘阵列，从读的能力来说：RAID 5 ≈ RAID 6 ≈ RAID 60 &gt; RAID 0 ≈ RAID 10 &gt; RAID 3 ≈ RAID 1从写的能力来说:RAID 10 &gt; RAID 50 &gt; RAID 1 &gt; RAID 3 &gt; RAID 5 ≈ RAID 6 ≈ RAID 60如果将来有一天你对这篇文章记得不是很清晰了，那么但愿你可以记住下面这张图，这几幅图虽然对于RAID 上不是完全的准确，但是已经很大的表达清楚了各种RAID的特点了。 参考资料https://us.hardware.info/reviews/4123/raid-0-raid-1-raid-10-and-raid-5-how-do-they-actually-workhttp://support.huawei.com/enterprise/zh/knowledge/KB1000149118/https://zh.wikipedia.org/wiki/RAIDhttp://www.hpc.co.jp/raid_kaisetsu.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>raid</tag>
        <tag>磁盘阵列</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible-playbook如何获取ip]]></title>
    <url>%2F2018%2F01%2F31%2FAnsible-playbook%E5%A6%82%E4%BD%95%E8%8E%B7%E5%8F%96ip%2F</url>
    <content type="text"><![CDATA[公司的模块都新加了加密算法，现在就是需要把约100台机器的/etc/hosts文件里的zookeeper server的ip调整成新的ip 地址，目前在ansible控制机上已经写好了带有新的zookeeper server的ip的/etc/hosts文件，然后计划是把这个新文件下发到大约100台具体模块的服务器里，然后这100台机器的文件中把他们各自的ip和hostname添加到这个新的/etc/hosts文件上。 于是就写了一个ansible-playbook: 123456789101112---- hosts: all tasks: - name: 将原有的hosts文件备份 shell: mv /etc/hosts /etc/hosts_bak - name: 将ansible端的hosts复制到各自机器上 copy: src=/root/hosts dest=/etc/ owner=root group=root mode=0544 - name: 在新的hosts文件后面追加各自机器内网ip和hostname lineinfile: dest=/etc/hosts line="`ansible_all_ipv4_addresses` `ansible_hostname`" 但是写完之后执行出来，却是这样的效果： 而我想要的是这样的效果： 遇到这种情况怎么办？ 后来调整了一下，变量用IP: ““，而不是ansible_all_ipv4_addresses。 修改了之后的playbook 如下： 1234567891011121314---- hosts: all vars: IP: "&#123;&#123; ansible_eth0['ipv4']['address'] &#125;&#125;" tasks: - name: 将原有的hosts文件备份 shell: mv /etc/hosts /etc/hosts_bak - name: 将ansible端的hosts复制到各自机器上 copy: src=/root/hosts dest=/etc/ owner=root group=root mode=0644 - name: 在新的hosts文件后面追加各自机器内网ip和hostname lineinfile: dest=/etc/hosts line="`IP` `ansible_hostname`" 这样就达到目的了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>ansible</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql查看实时语句和慢sql]]></title>
    <url>%2F2018%2F01%2F30%2Fmysql%E6%9F%A5%E7%9C%8B%E5%AE%9E%E6%97%B6%E8%AF%AD%E5%8F%A5%E5%92%8C%E6%85%A2sql%2F</url>
    <content type="text"><![CDATA[查看实时语句Mysql除了手动执行的语句，还有很多在后台由其他模块执行的语句，按理来说，那些由其他模块执行的语句是不能实时查看的，因为这个资源消耗特别的大，但是当我们实在需要查看实时sql语句的时候也不是做不到，需要手动开启一个日志开关general_log。 首先登陆mysql，然后执行show variables like &quot;general_log%&quot;;，看一下反馈的结果，如下： 12345678mysql&gt; show variables like "general_log%";+------------------+-------+| Variable_name | Value |+------------------+-------+| general_log | OFF || general_log_file | |+------------------+-------+2 rows in set (0.04 sec) 发现这个Value是off，那么就说明实时记录general_log没有开启，如果我们要开启它很简单，如下： 123mysql&gt; set global log_output = file;mysql&gt; set global general_log = 'ON';mysql&gt; set global general_log_file = '/tmp/mysql/general_log.log'; 可见我们不仅打开了general_log的开关，而且设置日志输出方式为文件（如果设置log_output=table的话，则日志结果会记录到名为gengera_log的表中，这表的默认引擎都是CSV）。同时规定它的保存位置是/tmp/mysql/general_log.log。 但是这个是临时方法，如果mysql重启了那么就会失效，如果想要永久有效的话，就要编辑my.cnf，添加下面两句话： 12general_log = 1general_log_file = /tmp/mysql/general_sql.log 这里要注意！开启general_log会影响性能，谨慎使用!正式系统用完要关闭!!!关闭的语句SET GLOBAL general_log = &#39;OFF&#39;;。 查看慢sql慢sql的意思就是那些执行很慢的sql，这些sql拖慢进程的执行效率而且有很大的优化空间。默认的来说，执行时间超过1秒就算慢sql了，在mysql里输入show variables like &#39;long%&#39;，就会看到如下的内容： 1234567mysql&gt; show variables like 'long%';+-----------------+----------+| Variable_name | Value |+-----------------+----------+| long_query_time | 1.000000 |+-----------------+----------+1 row in set (0.00 sec) 这个long_query_time是可以更改的，这里是1，那就是代表查询时间大于(不是大于等于)1秒的都是记录到日志，最大值是10。如果写的是0，那么就是输出所有的语句。 这里多说一句，使用命令set global long_query_time=4修改慢查询阈值为4秒后，需要重新连接或新开一个会话才能看到修改值。你用show variables like &#39;long_query_time&#39;查看是当前会话的变量值，你也可以不用重新连接会话，而是用show global variables like &#39;long_query_time&#39;;。 那么记录这些慢日志的地方在哪呢？使用show variables like &#39;%slow_query_log%&#39;;看看： 12345678mysql&gt; show variables like '%slow_query_log%';+---------------------+-----------------------------------------------+| Variable_name | Value |+---------------------+-----------------------------------------------+| slow_query_log | OFF || slow_query_log_file | /tmp/mysql/DB-Server-slow.log |+---------------------+-----------------------------------------------+2 rows in set (0.00 sec) 这里说明慢日志的地址是/tmp/mysql/DB-Server-slow.log，但是慢日志记录的功能没有启动。如果要启动，语句是：set global slow_query_log=1;，跟上面开启实时日志general_log一样，这个方法仅仅是一个临时方法，重启了mysql就会失效，如果要长期生效，还是在my.cnf文件里添加如下两句话： 12slow_query_log =1slow_query_log_file=/tmp/mysql/DB-Server-slow.log 慢日志还有一个系统变量叫log-queries-not-using-indexes，它的意思是未使用索引的查询也被记录到慢查询日志中，哪怕他可能执行的非常快（可选项）。如果调优的话，建议开启这个选项。另外，开启了这个参数，其实使用full index scan的sql也会被记录到慢查询日志。如下： 12345678910mysql&gt; show variables like 'log_queries_not_using_indexes';+-------------------------------+-------+| Variable_name | Value |+-------------------------------+-------+| log_queries_not_using_indexes | OFF |+-------------------------------+-------+1 row in set (0.00 sec)mysql&gt; set global log_queries_not_using_indexes=1;Query OK, 0 rows affected (0.00 sec) 如果你想自己试试慢sql是否被记录，那么可以使用select sleep(5);这样的语句，执行效果如下： 123456789101112131415mysql&gt; select sleep(5) ;+----------+| sleep(5) |+----------+| 0 |+----------+1 row in set (5.00 sec)mysql&gt; select * from mysql.slow_log;+---------------------+---------------------------+------------+-----------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+| start_time | user_host | query_time | lock_time | rows_sent | rows_examined | db | last_insert_id | insert_id | server_id | sql_text | thread_id |+---------------------+---------------------------+------------+-----------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+| 2018-01-30 21:45:23 | root[root] @ localhost [] | 00:00:05 | 00:00:00 | 1 | 0 | | 0 | 0 | 1 | select sleep(5) | 2 |+---------------------+---------------------------+------------+-----------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+1 rows in set (0.00 sec) 参考资料http://www.cnblogs.com/kerrycode/p/5593204.htmlhttps://www.cnblogs.com/qmfsun/p/4844472.htmlhttp://www.cnblogs.com/jasondan/p/3491258.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Goaccess---良心nginx日志分析工具]]></title>
    <url>%2F2018%2F01%2F30%2FGoaccess-%E8%89%AF%E5%BF%83nginx%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[Goaccess是一个非常良心的开源软件，它的良心之处体现在如下方面： 安装简单； 操作容易； 界面酷炫； 安装安装Goaccess十分的简单，在centos里直接yum install goaccess，如果yum源里没有goaccess，可以先安装epel。安装epel的方法如下： 123wget http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpmwget http://rpms.famillecollet.com/enterprise/remi-release-6.rpmrpm -Uvh remi-release-6*.rpm epel-release-6*.rpm 配置和使用安装完goaccess之后，我们需要在/etc/goaccess.conf里添加如下几句话： 123time-format %Tdate-format %d/%b/%Ylog-format %h %^[%d:%t %^] “%r” %s %b “%R” “%u” 保存退出之后，我们就可以通过goaccess来分析nginx日志了，语句格式也很简单：goaccess -f nginx日志的绝对路径。比如我的nginx日志是access-chen.log，查看一下里面的内容： 虽然有规律，但是看上去很乱，需要在分析日志之前喝两瓶静心口服液。 然后我就goaccess -f access-chen.log，就会看到如下的界面： 这一下，整个日志看起来更加友好，更加直白，更加高大上。足以吸引周围人的羡慕目光。 但是这里面还是有一个注意点：goaccess默认支持的日志格式是nginx默认的日志格式，也就是nginx.conf里的如下格式： 如果你的日志格式是有过更改的，而且还不想改回来，那么就需要去/etc/goaccess.conf里对应的log-format进行更改。 这还没有完，goaccess还可以生成html，这里goaccess -f access-chen.log -a &gt; /nginx安装路径/html/chen.html。然后在浏览器里登陆到这个服务器的chen.html，就会看到整个日志情况的网页排版，如图： 这样的话，我们可以每一天都发一份当天的日志html去运维人员的信箱里，这样更加方便我们分析日志。 缺点虽然前面说了那么多goaccess的优点，但是缺点也是有的，比如goaccess的粒度太粗，只能按天分割，如果要按小时分割，需要先grep出来，这个做法比较挫我懂… 还有一个缺点，就是访问人的来源只能定位到国家，无法具体定位到省市县村屯… 参考资料http://blog.maxhemby.se/determine-the-apache-traffic-load/#respond]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>日志统计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[处理掉积压过多的activemq持久化消息]]></title>
    <url>%2F2018%2F01%2F29%2F%E5%A4%84%E7%90%86%E6%8E%89%E7%A7%AF%E5%8E%8B%E8%BF%87%E5%A4%9A%E7%9A%84activemq%E6%8C%81%E4%B9%85%E5%8C%96%E6%B6%88%E6%81%AF%2F</url>
    <content type="text"><![CDATA[问题描述在项目使用activemq 5.14时，客户端发送消息而没有得到回复（在不考虑消费者是什么问题的情况下），导致持久化消息不断积压而得不到释放，最后造成队列堵塞而嗝屁。 一般来说遇到这样的情况，可以在配置文件中配置消息的过期时间和死信处理来防止消息的积压，配置如下： 1234&lt;plugins&gt; &lt;!-- 86,400,000ms = 1 day --&gt; &lt;timeStampingBrokerPlugin ttlCeiling="10000" zeroExpirationOverride="10000"/&gt; &lt;/plugins&gt; 配置消息过期时间使用timeStampingBrokerPlugin插件,ttlCeiling：表示过期时间上限（模块程序写的过期时间不能超过此时间，超过则以此时间为准），zeroExpirationOverride：表示过期时间（给未分配过期时间的消息分配过期时间），一般来说这两个值是一样的。执行之后，message过期则客户端不能接收，那些已经过期的message将会保存在data/kahadb目录下。 但是最近发现了一个问题，就是data/kahadb这个目录最近越来越大，越积越多。但是这个topic和quere又依旧是“持续订阅”的，它的消费者还在。遇到这样的情况，如何在activemq里配置呢？ 解决办法 配置message过期自动丢弃策略 12345678910111213 &lt;borker&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;policyEntry topic="&gt;" expireMessagesPeriod="60000"&gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy processExpired="false" /&gt; &lt;/deadLetterStrategy&gt; &lt;/policyEntry&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt;&lt;/borker&gt; 标签processExpired=&quot;false&quot;表示不保存过期消息到死信队列，处理手段为删除，为true则是保留。标签expireMessagesPeriod=&quot;60000&quot;属性表示每隔60秒钟检查message是否过期。topic=&quot;&gt;&quot;表示该策略对所有topic都生效。而topic=&quot;active.&gt;&quot;就表示该策略对以active.开头的所有topic生效，注意有个点号.。 message过期时间设置上面那步搞定了之后，再修改timeStampingBrokerPlugin标签里ttlCeiling=&quot;360000&quot; zeroExpirationOverride=&quot;360000&quot;表示过期时间为360000ms（1小时）。 123456&lt;borker&gt; &lt;plugins&gt; &lt;!-- 86,400,000ms = 1 day --&gt; &lt;timeStampingBrokerPlugin ttlCeiling="360000" zeroExpirationOverride="360000" /&gt; &lt;/plugins&gt;&lt;/borker&gt; 解决“空队列”的方法如果不是那种“持续订阅”的topic，那就简单了，配置如下： 123456789&lt;broker xmlns="http://activemq.apache.org/schema/core" schedulePeriodForDestinationPurge="10000"&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;policyEntry queue="&gt;" gcInactiveDestinations="true" inactiveTimoutBeforeGC="30000"/&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt; &lt;/broker&gt; schedulePeriodForDestinationPurge执行清理任务的周期，gcInactiveDestinations=&quot;true&quot;表示启用清理功能，inactiveTimoutBeforeGC=&quot;30000&quot;这个是Topic或Queue超时时间,在规定的时间内，无有效订阅，没有入队记录，超时后就会被清理。 参考资料http://activemq.apache.org/timestampplugin.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>消息队列</tag>
        <tag>activemq</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python里调用redis的方法]]></title>
    <url>%2F2018%2F01%2F29%2FPython%E9%87%8C%E8%B0%83%E7%94%A8redis%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[正文Python 2.7里不是自带redis模块的，那么在调用redis的时候自然也会报错，比如： 遇到这种情况怎么办？ 第一种方法： 1pip install redis 第二种方法： 1easy_install redis 第三种方法：去登录https://github.com/andymccurdy/redis-py，下载包上传到linux里之后，python setup.py install。 flask模块的安装也是同理。 注意！这里只有Redis，如果使用StrictRedis会报错：AttributeError: &#39;Redis&#39; object has no attribute &#39;StrictRedis&#39;。这个是版本的问题。见https://github.com/andymccurdy/redis-py/issues/188 参考资料http://debugo.com/python-redis/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ssh连接port 22: Connection refused]]></title>
    <url>%2F2018%2F01%2F29%2FSsh%E8%BF%9E%E6%8E%A5port-22-Connection-refused%2F</url>
    <content type="text"><![CDATA[金山云有一个服务器需要连接到数据库但是总是失败，检查之后发现它的VPC配错了，更改VPC之后，这台服务器也会更换一个新的内网IP地址，但是问题来了，更换了内网IP之后，从跳板机连接，提示port 22: Connection refused。 ssh -v 新的ip地址发现根本没有到Connection established。直接就提示port 22: Connection refused。这基本可以断定不是跳板机的问题了，那么就需要在远程机器里看配置。 但是远程机器是无法连接的啊，怎么办？从金山控制台“连接实例”。 然后键盘随便按一下，就会看到linux界面，输入账号名和密码，这里密码不支持复制粘贴，需要手动输入。然后就会看到如下界面。 这样，我们就可以登陆这台机器了，然后vim /etc/ssh/sshd_config，看到最上面有这样的内容。 这个listenaddress后面就是跳板机ssh的地址，但是这个地址还是老的，而不是更改过后的内网ip地址，所以ssh的连接自然就是refuse。所以我们只需要手动更改成新的内网ip地址就好了。 更改完之后，重启一下服务器或者/etc/init.d/sshd restart就可以从跳板机上正常连接了。 如果在/etc/init.d/sshd restart的时候爆出“address family must be specified before ListenAddress”的错误，那么就把AddressFamily移到ListenAddress上面就可以了，如图：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>ssh</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SFTP不能连接服务器怎么办？]]></title>
    <url>%2F2018%2F01%2F27%2FSFTP%E4%B8%8D%E8%83%BD%E8%BF%9E%E6%8E%A5%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%80%8E%E4%B9%88%E5%8A%9E%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[今天在跳板机上传送文件，发现使用SFTP连接的时候，出现了这样的一个拒绝情况： 登陆到这个跳板机里，使用tail /var/log/secure，看到了拒绝的具体信息，如下： 这个时候，我就需要locate sftp-server，用locate定位一下sftp文件，但是发现服务器竟然回答我-bash: locate: command not found。 于是就yum -y install mlocate，安装mlocate之后执行updatedb，需要等待一小会，然后再次执行locate sftp-server，就可以得到sftp-server的文件路径了，如下图： 打开sshd的配置文件，vi /etc/ssh/sshd_config，把Subsystem这一行前面的#去掉： 然后重启启动ssh服务，语句是/etc/init.d/sshd reload，重新连接一下，发现就恢复正常了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>sftp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible部署模块的时候出现中文乱码的问题]]></title>
    <url>%2F2018%2F01%2F27%2FAnsible%E9%83%A8%E7%BD%B2%E6%A8%A1%E5%9D%97%E7%9A%84%E6%97%B6%E5%80%99%E5%87%BA%E7%8E%B0%E4%B8%AD%E6%96%87%E4%B9%B1%E7%A0%81%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[今天在部署服务的时候遇到了一个很罕见的现象，线上有15台服务器是手机推送消息的服务，新来的小运维使用ansible批量跑部署脚本的时候，发现手机端接收到来的消息全是乱码，然后登陆到服务器，查看日志发现，日志里面就是乱码，如图： 由于这个问题用户是有感知的，所以属于“事故”级别了，于是小boss大怒，叫运维赶快回滚，然后让开发赶紧重新检查代码，然后开骂测试都是吃屎的么这么大的一个问题都看不出来真是一群猪伤不起啊。 开发看了半天自己的代码，发现没有任何问题，战战兢兢跑来跟新来的小运维窃窃私语，结果我发现这个模块用手动单独部署，日志却是正常的，中文显示十分OK。 这一下开发就腰杆硬了，说这不是我的锅啊我是无辜的啊老子天天辛苦加班没有功劳也有苦劳没有苦劳也有疲劳老子的代码经得住考验这一切就是部署的问题。 于是我就查看了一下ansible的配置文件，vim /etc/ansible/ansible.cfg，发现了问题所在： 这里最后三行需要改成下面的样子，这样就解决了乱码问题。 1234#module_lang = C#module_set_locale = Falsemodule_lang = zh_CN.UTF-8module_set_locale = True]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>ansible</tag>
        <tag>自动化部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CentOS 6.x安装php 5.6和redis扩展的全过程]]></title>
    <url>%2F2018%2F01%2F26%2FCentOS-6-x%E5%AE%89%E8%A3%85php-5-6%E5%92%8Credis%E6%89%A9%E5%B1%95%E7%9A%84%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[安装PHP 5.6过程如下： 123456789101112yum clean allyum update 整体升级一下yum包yum install -y epel-releaseyum list installed | grep php 检查时候安装过PHPrpm -Uvh http://mirror.webtatic.com/yum/el6/latest.rpm yum -y install php56w.x86_64yum -y --enablerepo=webtatic install php56w-develyum -y install php56w-xml.x86_64 php56w-gd.x86_64 php56w-ldap.x86_64 php56w-mbstring.x86_64 php56w-mcrypt.x86_64 php56w-mysql.x86_64 php56w-pdo.x86_64 php56w-opcache.x86_64yum -y install php56w-fpmchkconfig php-fpm on 开机自启动/etc/init.d/php-fpm start 启动进程php -v 查看是否安装成功 注1：如果想更换到php5.5或5.4版本, 直接把上面的56w换成55w或者54w就可以了；注2：php-opcache和php-xcache会有效的提高php执行速度； 装php的扩展其实不是很麻烦，主要的步骤如下：1）在扩展模块的客户端文件夹里面使用phpize，这样会生成一个configure文件；2）执行configure文件，后面要加上php的路径；3）将“模块.so”文件名添加到php.ini文件里，重启php-fpm进程；4）通过so文件去调用扩展模块的客户端，实现连接对应的模块； 安装redis扩展过程如下： 123456redis-cli -v 检查是否安装了redisredis-server -vwget http://pecl.php.net/get/redis-2.2.8.tgz tar -zxvf redis-2.2.8.tgzcd redis-2.2.8 phpize 一个专门挂接php扩展的工具，该命令一定要使用在php的模块文件夹主目录下，这里报错Cannot find config.m4。因为phpize要根据模块生成模块的配置文件放在模块文件夹下面 12345./configure --with-php-config=/usr/bin/php-configmake &amp;&amp; make installmake testvim /etc/php.ini 在php.ini里添加一句“extension="redis.so"”service php-fpm restart]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>centos</tag>
        <tag>php</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一个连接两个文件的python脚本]]></title>
    <url>%2F2018%2F01%2F26%2F%E4%B8%80%E4%B8%AA%E8%BF%9E%E6%8E%A5%E4%B8%A4%E4%B8%AA%E6%96%87%E4%BB%B6%E7%9A%84python%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[背景交代公司在阿里云上有一个模块叫mrs，一共120台，它是跟云录像有关的，这个服务一直都是云服务器里没有公网但是购买了公网SLB，然后20个为一组配置到一个SLB里，这个SLB是按流量收费的。但是最近到了年末，各种账目审核，领导发现这个SLB的费用太惊人了，这么搞不够挣的。但是实在没办法，因为云录像嘛，肯定流量很大，如图： 纵然流量大，但是开源节流也是必须的，于是领导就责令开发赶快想出一个办法，减少SLB的费用。于是开发们拉上运维就吭哧吭哧的开始算经济账，最后确定每一个云服务器买7M带宽，然后流量全部走公网，把SLB的架构舍弃掉。 但是开发在这个模块V2.0里有一个变化，就是Zookeeper需要读取到每一台设备的外网IP，同时这个外网IP必须跟机器是一一对应的，这样模块才能正常工作。 原来的zookeeper在servermap是长这样的： 1234["内网IP"] = &#123;app = "mrs", weight = 100&#125;,["内网IP"] = &#123;app = "mrs", weight = 100&#125;,["内网IP"] = &#123;app = "mrs", weight = 100&#125;,剩下略 而现在开发要求改成这样： 1234["内网IP"] = &#123;app = "mrs",mrsReportIp = "对应的外网IP",weight = 100&#125;,["内网IP"] = &#123;app = "mrs",mrsReportIp = "对应的外网IP",weight = 100&#125;,["内网IP"] = &#123;app = "mrs",mrsReportIp = "对应的外网IP",weight = 100&#125;,剩下略 那么这就要把两个文件合并起来了，而且是在合并后做到一对一，不能把IP搭配串了。 准备工作首先，阿里云的网页控制台是无法做到“包年包月的服务器批量永久升级基础带宽”的，只能通过API实现。那么开启了外网IP之后，服务器就会有一个对应的外网IP地址，然后在控制台里，点击“导出资源列表”，只选择服务器名称、内网IP和外网IP。 然后在生成的excel表格里，剪除掉不需要的服务器以及服务器名称，然后保证“内网IP”在前，“外网IP”在后的样式，而且不要服务器名只保留IP,然后把这个文件复制到linux里，起个名，比如叫IP.txt,如图： 12345[root@paas-online-crs-001 tmp]# cat IP.txt10.161.236.231 3.3.3.310.161.235.150 2.2.2.210.51.10.182 4.4.4.410.117.219.72 1.1.1.1 再把已经使用的zookeeper复制一下，放到一个叫mingdan.txt的文件里，如图： 12345[root@paas-online-crs-001 tmp]# cat mingdan.txt["10.117.219.72"] = &#123;app = "mrs", weight = 100&#125;,["10.161.235.150"] = &#123;app = "mrs", weight = 100&#125;,["10.161.236.231"] = &#123;app = "mrs", weight = 100&#125;,["10.51.10.182"] = &#123;app = "mrs", weight = 100&#125;, 脚本思路我最开始打算用awk的NR、FNR去写，但是发现由于我这个文本的结构太过复杂。awk对付这样的力不从心，稍不好就把人搞得无法自拔，于是就考虑使用python的字典。 各位都知道，字典里key是不能重复的，而我又不想把这个脚本搞得太复杂，就想在mingdan.txt里的每一行加上序号，用这个序号去当key，而后面的内网IP就作为value，这样保证一一对应。加序号的方法很多，你可以在vim状态下:set number，然后手动复制粘贴。不过我是用的是如下两个命令： 12sed -i 's/^[ \t]*//g' mingdan.txt #这一步是添加每一行序号sed -i 's/\t/ /g' mingdan.txt #添加序号之后，会生成一个ta 然后mingdan.txt就成了这样： 12345[root@paas-online-crs-001 tmp]# cat mingdan.txt 1 ["10.117.219.72"] = &#123;app = "mrs", weight = 100&#125;,2 ["10.161.235.150"] = &#123;app = "mrs", weight = 100&#125;,3 ["10.161.236.231"] = &#123;app = "mrs", weight = 100&#125;,4 ["10.51.10.182"] = &#123;app = "mrs", weight = 100&#125;, 万事俱备，现在就要把IP.txt和mingdan.txt按照相同的内网IP整合成一个文件！ 脚本正文这个脚本是不怕mingdan.txt和IP.txt的IP顺序的。 1234567891011121314151617181920212223#!/usr/bin/env python#coding=utf-8import refd = &#123;&#125; #先设置一个新的空字典叫fd#以下都是最后拼字符串用的aaa = '["'bbb = '"] = &#123;app = "mrs",mrsReportIp = "'ccc = '",weight = 100&#125;,' #首先先判断mingdan.txt里是否存在for l in open('mingdan.txt', 'r'): ar = re.split(r'[ ""]',l) #做分割，把内网IP切出来 print "ip is :" + ar[2] #确认是否分割出来的是内网IP地址 fd[ar[0]] = ar[2] #把这个内网IP地址当作value，前面的序号就是key with open('out.txt', 'w') as fw: for l in open('IP.txt', 'r'): ar = l.split() if ar[0] in fd.values(): #如果IP.txt里面的内网IP与字典fd里的value相符合 fw.write(aaa + ar[0] + bbb + ar[1] + ccc) #拼成一个完整的字符串 fw.write('\n') #保存文件print('文件整合完毕，请查看out.txt的结果！') 执行结果执行效果输出如下： 123456[root@paas-online-crs-001 tmp]# cat out.txt ["10.117.219.72"] = &#123;app = "mrs",mrsReportIp = "1.1.1.1",weight = 100&#125;,["10.161.235.150"] = &#123;app = "mrs",mrsReportIp = "2.2.2.2",weight = 100&#125;,["10.161.236.231"] = &#123;app = "mrs",mrsReportIp = "3.3.3.3",weight = 100&#125;,["10.51.10.182"] = &#123;app = "mrs",mrsReportIp = "4.4.4.4",weight = 100&#125;,[root@paas-online-crs-001 tmp]#]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix-proxy的搭建和配置全过程]]></title>
    <url>%2F2018%2F01%2F26%2FZabbix-proxy%E7%9A%84%E6%90%AD%E5%BB%BA%E5%92%8C%E9%85%8D%E7%BD%AE%E5%85%A8%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[Zabbix-proxy的用途和构建图Zabbix-server是建立在金山云的，现在需要监控阿里云的redis，但是阿里云跟金山云之间通信是无法走内网的，如果直接让zabbix-server与redis直接联系，一旦公网的信息被截获的话，整个金山区的zabbix可能都会遭殃，那么既然有这种“远程监控+当监控的位置通信不便”的需求，就搭建一个zabbix-proxy来解决问题。 Zabbix-proxy是一个监控代理服务器，它收集监控到的数据，先存放在缓冲区，保存的时间可以通过配置文件设定，然后再传送到zabbix-server，这样也大大减缓了zabbix-server的压力，注意！监控代理需要一个单独的数据库，因为它的数据库表名与zabbix-server的数据库表名是一样的，如果不单独分开，后果就是数据错乱。 有人看到这里可能问了，说来说去你的zabbix-proxy跟阿里的redis依旧是走公网的啊！虽然这样也是走公网，我现在只需要配置一个防火墙规则来让他俩保证通信即可，通过防火墙来提升安全系数。架构如图： 安装Mysql 5.5Zabbix-proxy机器情况：金山云centos 6.5，安装zabbix版本：3.0.8 1234567891011[root@js-online-cjhmq-002 opt]yum list installed | grep mysql #列出已经安装过的mysql情况[root@js-online-cjhmq-002 opt]yum -y remove mysql-libs.x86_64 #把之前的mysql连根拔起[root@js-online-cjhmq-002 opt]# rpm -ivh http://repo.mysql.com/yum/mysql-5.5-community/el/6/x86_64/mysql-community-release-el6-5.noarch.rpmRetrieving http://repo.mysql.com/yum/mysql-5.5-community/el/6/x86_64/mysql-community-release-el6-5.noarch.rpmPreparing... ########################################### [100%] 1:mysql-community-release########################################### [100%][root@js-online-cjhmq-002 opt]groupadd zabbix #新建用户组zabbix[root@js-online-cjhmq-002 opt]useradd -g zabbix -u 808 -m zabbix#-g：指定用户所属的群组；#-u：指定用户id。#-m：自动建立用户的登入目录； 现在要修改一下/etc/yum.repos.d/mysql-community.repo这个文件，将5.5的enabled改为1,5.6的enabled改为0： 123456789101112131415# Enable to use MySQL 5.5[mysql55-community]name=MySQL 5.5 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.5-community/el/6/$basearch/enabled=1 #这里改成1gpgcheck=1 gpgkey=file:/etc/pki/rpm-gpg/RPM-GPG-KEY-mysql# Enable to use MySQL 5.6[mysql56-community]name=MySQL 5.6 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.6-community/el/6/$basearch/enabled=0 #这里改成0gpgcheck=1gpgkey=file:/etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 然后执行yum install mysql-community-client mysql-community-devel mysql-community-server php-mysql， 安装服务端和客户端，安装完毕之后可以mysql -h127.0.0.1看一下。 安装完毕之后，修改一下/etc/my.cnf，如图： 12innodb_buffer_pool_size = 512M #这个根据服务器性能填写，这个机器是2核2G的，所以我拿出半个G给mysqlinnodb_file_per_table=1 #这个是新增的字段，设置InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据目录 mysql安装完毕之后，我们还要导表进去，如图： 123456service mysqld startmysqladmin -uroot password '123456'mysql -uroot -p123456 -e 'create database zabbix_proxy character set utf8;'mysql -uroot -p123456 -e "grant all privileges on zabbix_proxy.* to zabbix@localhost identified by 'zabbix';"mysql -uroot -p123456 -e "flush privileges;"mysql -uzabbix -pzabbix zabbix_proxy &lt;/解压路径/zabbix-3.0.8/database/mysql/schema.sql 至此，mysql部分已经全部搞定。 安装Zabbix-proxy先去https://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/3.0.8/下载zabbix-3.0.8.tar.gz，上传到proxy服务器里。 12tar -zxvf zabbix-3.0.8.tar.gz./configure --prefix=/usr/local/zabbix-3.0.8 --sysconfdir=/etc/zabbix --enable-proxy --enable-agent --enable-ipv6 --with-mysql=/usr/bin/mysql_config --with-net-snmp --with-libcurl --with-openipmi --with-unixodbc --with-ldap --with-ssh2 --enable-java 如果出现了configure: error: Invalid LDAP directory - unable to find ldap.h，解决方法就是： 1yum -y install openldap* Zabbix-proxy的配置打开/etc/zabbix/zabbix_proxy.conf，需要修改几个地方： 123456789101112ProxyMode=0 #0是主动模式，1是被动模式Server=A.B.C.D #这里填写zabbix-server的内网IPHostname=J.Q.K.A #这里要与/etc/hosts下的名字一模一样LogFile=/tmp/zabbix_proxy.logDBHost=localhostDBName=zabbix_proxyDBUser=zabbixDBPassword=zabbixConfigFrequency=120 #主动去server端去拉去配置更新的频率120秒一次DataSenderFrequency=60 #发送采集的监控数据到服务器端，默认是1秒，我们一分钟发送一次#ProxyLocalBuffer=0 #ProxyLocalBuffer表示数据传递给server之后还要在proxy里保存多久（单位为小时）。如果注释就是代表不删除。#ProxyOfflineBuffer=1 #ProxyOfflineBuffer表示数据没有传递给server的话还要在proxy里保存多久（单位为小时）。如果注释就是代表不删除。 然后就是启动proxy: 1# /usr/local/zabbix_proxy/sbin/zabbix_proxy 用netstat查看一下端口和进程是否都OK： Zabbix-server端的配置登入zabbix-server的网页，如图添加proxy： 点击“create proxy”之后，就对应填写资料吧： 这里对上面的几个选项多说几句： 12345678Connections to proxy：服务器如何连接到被动代理：无加密（默认），使用PSK（预共享密钥）或证书。Connections from proxy：从活动代理中选择允许的连接类型。 可以同时选择几种连接类型（用于测试和切换到其他连接类型）。 默认为“无加密”。#点击Certificate之后又两个参数：Issuer：允许颁发证书。 证书首先通过CA（认证机构）验证。 如果CA有效，则由CA签名，则可以使用Issuer字段来进一步限制允许的CA。 该字段是可选的，如果您的Zabbix安装使用多个CA的证书，则使用该字段。Subject：允许的证书。 证书首先通过CA验证。 如果它有效，由CA签名，则主题字段可用于仅允许Subject字符串的一个值。 如果此字段为空，则接受由配置的CA签名的任何有效证书。 #点击PSK之后又两个参数：PSK identity：预共享密钥身份字符串。PSK ： 预共享密钥（hex-string）。 如果Zabbix使用mbed TLS（PolarSSL）库，Zabbix将使用GnuTLS或OpenSSL库，64位十六进制（32字节PSK），最大长度为512位十六进制数（256字节PSK）。 示例：1f87b595725ac58dd977beef14b97461a7c1045b9a1c963065002c5473194952 保存之后，就在zabbix-server用zabbix-get去ping一下proxy，看看返回值是否是1，如果是zabbix_get [18290]: Check access restrictions in Zabbix agent configuration，就检查一下刚才的hostname等值是否正确。 被监控机器的配置在被监控的阿里云redis里安装zabbix-agent，在agentd.conf里把hostname写成自己在/etc/hosts里的hostname，Server地址和ServerActive的地址都要写成proxy的外网IP地址。保存之后启动agent进程，这个时候在proxy端是可以通过zabbix_get得到这台被监控机器的值，如图： 在Zabbix-Server的WEB界面里，为阿里云的redis新建一个host，Agent interface那里填写被监控的机器IP，端口是10050，Monitored by proxy的地方要写成刚刚添加的proxy。如图： 上面已经提到过，用proxy模式并且zabbix的客户端也是主动模式提交数据，这样能大大提高采集效率，降低zabbix服务器端和proxy端的压力。现在我们希望添加的还是使用zabbix_agent的方式，新加到zabbix_proxy里面的主机使用zabbix_agent（active）的方式。注意在模板的克隆要选择full clone，不要选“clone”，那样的话就仅仅是把iterm的名字克隆过去而已，如图： 然后在items选择具体的类型，根据需要，想改那个改哪个，如图，注意！我图里写的是Zabbix agent，但是type这里选择Zabbix agent (active)。 改完之后，保存一下，就会看到type都是zabbix agent（active）了。 最后在host里把这个机器添加到proxy的模板里，如图： 在Administration的Proxies也看到效果了，如果server与proxy没有正确连接的话，last seen的地方会是--，如果连接的话就会显示具体时间，如图: 返回到hosts里，查看那个被监控的redis机器也成功被监控到了，ZBX已经变绿。如图： 因为我们线上环境基本都是用的zabbix_proxy方式是active方式，然后客户端也是active方式，既然都是active方式，那么zabbix_agent的Hostname就很重要，打个比方如果再zabbix_server端把一个主机的Hostname改了，然后客户端那边也改了，服务端和客户端的Hostname是统一的，但是proxy那里还记录的是旧Hostname，然后就会在proxy日志里面看到下面一条： 1cannot send list of active checks to "proxy内网IP地址": host [virt_proxy内网IP地址] not found proxy主动模式下，ConfigFrequency默认的是3600秒一小时，显然有点大了，可以适当的调低一下，如10分钟或者几分钟什么的。然后出现问题多看看zabbix服务端和proxy的日志，对症下药。 参考资料http://www.51niux.com/?id=156http://www.cnblogs.com/wangxiaoqiangs/p/5336630.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>监控技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[centos服务器更改系统时间]]></title>
    <url>%2F2018%2F01%2F25%2F%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9B%B4%E6%94%B9%E6%97%B6%E5%8C%BA%E4%B8%BAutc%2F</url>
    <content type="text"><![CDATA[将时区改为utc开发提出需求说，某个模块是给洋人使用，于是把阿里云服务器里的时间改成UTC时间。我登陆到服务器里使用date查看了一下，发现目前使用的是东八区时间，如图： 首先先开启UTC，方法就是在/etc/sysconfig/clock的文件里修改这样一处：UTC=true。这样即使机器重启，UTC时间依旧会“BIOS ▶ UTC时区转换 ▶ 系统时间”的顺序正常使用。 在Centos 6.5里，各时区的时间是在一个叫/usr/share/zoneinfo/的文件夹下，在里面我们发现了我们的目标—-UTC，如图： 然后就是修改，方法如下： 12mv /etc/localtime /etc/localtime-bakln -s /usr/share/zoneinfo/UTC /etc/localtime 先把老的时间文件备份，然后把UTC文件做一个软连接过来即可。我们所熟悉的date命令就是/etc/localtime的输出结果。 现在去date一下，看看结果，果然改成了UTC： 这个时候，如果你服务器里装的是nginx的话，就会发现nginx日志里的时间也会变成UTC而不会再是CST了。 更改系统时间云服务器一般来说系统时间都是正确的，但是自己的服务器可能在安装系统之后的时间是不统一的，这样可能在集群里就会出问题。时间同步的步骤如下： 1234yum install -y ntpdate #下载ntp同步工具mv /etc/localtime /etc/localtime-bak #备份原有文件cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime #时区调整为上海ntpdate us.pool.ntp.org #与时区服务器同步时间 然后在crontab里添加一个每10分钟同步时间的命令：*/10 * * * * /usr/sbin/ntpdate us.pool.ntp.org | logger -t NTP。 如果服务器是没有公网的，那么也就无法下载ntpdate，此时只能用date -s命令手动更改时间，比如：date -s 23:40:00、date -s 20180703。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>阿里云</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阿里云购买、启动、停止ecs等等操作的python脚本]]></title>
    <url>%2F2018%2F01%2F24%2F%E9%98%BF%E9%87%8C%E4%BA%91%E8%B4%AD%E4%B9%B0%E3%80%81%E5%90%AF%E5%8A%A8%E3%80%81%E5%81%9C%E6%AD%A2ecs%E7%9A%84python%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[以下所有脚本都是在python 2.7的环境亲自测试的。阿里云的ak/sk是没有地域概念的，在任何地域都可以使用。 购买服务器以在新加坡购买服务器为例子： 12345678910111213141516171819202122232425262728#!/usr/bin/env python#coding=utf-8#注意！服务器创建完毕之后，状态是关机的。from aliyunsdkcore import clientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionfrom aliyunsdkecs.request.v20140526 import CreateInstanceRequest# 创建 Client 实例clt = client.AcsClient('阿里云ak','阿里云sk','新加坡的地域') #各地域的缩写请看：https://help.aliyun.com/document_detail/40654.html?spm=5176.doc25499.2.14.yh6n8c# 创建 request，并设置参数request = CreateInstanceRequest.CreateInstanceRequest()# 设置ECS细节request.set_ImageId("centos_7_04_64_20G_alibase_201701015.vhd") #这里是镜像request.set_InstanceName("xjp-test-001") #这里写名称xjp-test-001request.set_SecurityGroupId("sg-23t6c6mjw") #这里是安全组request.set_Password("W2.bi7FX1dyb)T3Wh^,[") #这里是密码，推荐使用https传输，安全request.set_InstanceChargeType("PrePaid") #确定是包年包月request.set_Period("2") #先买两个月的request.set_SystemDiskCategory("cloud_efficiency") #注意，如果是海外的机器的话，要额外说明，海外的机器只有高速云盘和SSD盘# 设置实例规格request.set_InstanceType("ecs.s2.large")# 发起 API 请求并打印返回response = clt.do_action_with_exception(request)print response 服务器停机停止ECS的脚本如下： 1234567891011121314#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import StopInstanceRequestlist1 = ['要停机的ecs id1','要停机的ecs id2','要停机的ecs id3'...]clt = client.AcsClient('阿里云ak','阿里云sk','地域名')for i in list1: shutdown = StopInstanceRequest.StopInstanceRequest() shutdown.set_InstanceId(i) action = clt.do_action_with_exception(shutdown) print "现在停机:" + i print action 服务器启动启动ECS的脚本如下： 1234567891011121314#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import StartInstanceRequestlist = ['要停机的ecs id1','要停机的ecs id2','要停机的ecs id3'...]clt = client.AcsClient('阿里云ak','阿里云sk','地域名')for i in list: start = StartInstanceRequest.StartInstanceRequest() start.set_InstanceId(i) action = clt.do_action_with_exception(start) print "现在启动:" + i print action 查询阿里云镜像查询ECS镜像的脚本如下： 123456789101112131415#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import DescribeImagesRequestimport aliyunsdkcore.requestclt = client.AcsClient('阿里云ak','阿里云sk','地域名')request = DescribeImagesRequest.DescribeImagesRequest()request.set_accept_format('json')# 发起请求response = clt.do_action_with_exception(request)print response 查询服务器规格查询ECS规格的脚本如下： 123456789101112131415#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import DescribeInstanceTypesRequestimport aliyunsdkcore.requestclt = client.AcsClient('阿里云ak','阿里云sk','地域名')request = DescribeInstanceTypesRequest.DescribeInstanceTypesRequest()request.set_accept_format('json')# 发起请求response = clt.do_action_with_exception(request)print response 参考资料https://help.aliyun.com/document_detail/25499.html?spm=5176.doc25501.6.857.wR0MHP]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>阿里云api</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Crontab里解决脚本时间重叠的问题]]></title>
    <url>%2F2018%2F01%2F24%2FCrontab%E9%87%8C%E8%A7%A3%E5%86%B3%E8%84%9A%E6%9C%AC%E6%97%B6%E9%97%B4%E9%87%8D%E5%8F%A0%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[正文Linux里的Crontab是一个好东西，但是它的默认最小执行频率是1分钟，但是我们在实际生产环境里有的时候遇到的脚本执行时间是大于1分钟的，这样就会出现一个很尴尬的情况，就是在1分钟过后，系统进程会出现多个脚本，neck and neck式的在后台运行，比如这样： 从上面的图可以看到，10点36分log499.sh没有执行完毕，10点37又开始了执行了一个新的log499.sh脚本。这种脚本冲突肯定不是我们所希望的，那么如何才能保证后台只是在一段时间里只执行一个脚本呢？ 这个时候我们就要使用文件锁，flock，这种方法要比判断pid高大上的多。 首先假设我们的脚本名字叫abc.sh，这个脚本文件的执行时间是要大于1分钟的，同时我们再设定一个锁文件，位置就叫/tmp/abc.lock,这个文件可以是空的，然后crontab -e，添加一句命令如下： 1* * * * * flock -xn /tmp/abc.lock -c 'sh /路径/abc.sh &gt;&gt; /记录日志的路径 2&gt;&amp;1' 这个时候静候crontab启动abc.sh，通过ps -ef|grep abc，发现在后台始终只有一个abc进程。 但是有的时候会有这样的一个问题，就是abc执行一次之后，在下一次该执行的时候却没有执行，好像crontab失效了一样，对于这样的情况，就需要添加下面的语句到abc.sh末尾： 123rm -rf /tmp/abc.lock #删除掉原有的锁文件sleep n #睡n秒touch /tmp/abc.lock #再新建一个锁文件 这样不断地更新lock锁文件，就会保证crontab每次都会按期执行。 这里要注意一下，里面我加了一句sleep n，这里的n是为了跨分钟的存在，这是为了防止没有走到下一个分钟又会生成一个新的lock锁文件，这样还是会出现重复启动脚本的情况。 这里就涉及到flock的一个原理：在每一次执行任务的时候都会先去尝试取到锁文件，如果取到了锁文件，那么就会下一步，反之就会放弃执行。A任务在运行的时候已经占据了lock文件，那么B任务来了，发现没有lock了，就不会执行任务。 这里我们使用了flock的三个参数： 123-x, --exclusive: 获得一个独占锁-n, --nonblock: 如果没有立即获得锁，直接失败而不是等待-c, --command: 在shell中运行一个单独的命令 当然，flock还是有很多丰富的参数可以供各位使用，大家就各自去google一下吧。 参考资料http://blog.csdn.net/fdipzone/article/details/38284009http://chuansong.me/n/285635151949https://segmentfault.com/q/1010000008039907]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>crontab</tag>
        <tag>运维技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[yum提示Error: rpmdb open failed]]></title>
    <url>%2F2018%2F01%2F24%2Fyum%E6%8F%90%E7%A4%BAError-rpmdb-open-failed%2F</url>
    <content type="text"><![CDATA[今天在一台机器里，使用yum安装的时候，出现了如下的故障： 这种情况就是RPM数据库被破坏了，这个时候就需要我们重建数据库，于是就输入如下的命令： 1234cd / var / lib / rpm /for i in ` ls | grep 'db.' ` ; do mv $i $i .bak ; donerpm -- rebuilddbyum clean all 重新cleanup就正常了。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>shell</tag>
        <tag>yum</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[由一个实例浅析sed用法]]></title>
    <url>%2F2018%2F01%2F23%2F%E7%94%B1%E4%B8%80%E4%B8%AA%E5%AE%9E%E4%BE%8B%E6%B5%85%E6%9E%90sed%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[首先，假设我们有一个文件，叫123.txt，cat一下看到里面的内容是这样的： 12345678[root@func-lms-001 ~]# cat 123.txt jamescurry durantwadeyaoming messi[root@func-lms-001 ~]# 如果我们想在james前面加上lebron，那么采用的sed语句就是：sed -i &#39;/^james/s/^/lebron /&#39; 123.txt，如果要在curry后面加上champion，那么采用的语句就是：sed -i &#39;/^curry/s/$/ champion!/&#39; 123.txt。 使用完上面两句话之后，再#cat一下，看下效果： 12345678[root@func-lms-001 ~]# cat 123.txt lebron jamescurry champion! durantwadeyaoming messi[root@func-lms-001 ~]# 现在我们要把durant前面加上FMVP这几个字母，按照上面的语句找葫芦画瓢的话，应该是：sed -i &#39;/^durant/s/^/FMVP /&#39; 123.txt。但是很抱歉，这个语句是错误的！因为^是匹配开头durant的意思，而我们再看一下durant那一行的开头是空格。 那么就要用liunx的正则来匹配空格，于是这句话就变成了：sed -i &#39;/^\s\+durant/s/^/FMVP/&#39; 123.txt，^\s\+这个就是正则里匹配空格的意思 。 cat一下： 12345678[root@func-lms-001 ~]# cat 123.txt lebron jamescurry champion!FMVP durantwadeyaoming messi[root@func-lms-001 ~]# 那么现在要在messi后面加上”GOAL !!!”，就很简单了。语句是：sed -i &#39;/^\s\+messi/s/$/ GOAL !!!/&#39; 123.txt。 以上我们把有/无空格情况下的首尾添加字符都练习了一遍，下面我们要看看如果要在中间添加怎么办？ 比如说，有一天苦逼的运维接到开发PL的邮件，说”由于安全基线要求，现在需要监听内网端口“，具体的需求就是把所有含tomcat的模块里的server.xml的文件里添加上内网IP。 原有的server.xml的节选如下： 12345678910&lt;Service name="LMS"&gt; &lt;Connector port="8080" connectionTimeout="20000" protocol="org.apache.coyote.http11.Http11NioProtocol" redirectPort="8443" enableLookups="false" disableUploadTimeout="true" maxThreads="500" minSpareThreads="20" acceptCount="100"/&gt; &lt;Connector port="8088" connectionTimeout="20000" protocol="org.apache.coyote.http11.Http11NioProtocol" redirectPort="8443" enableLookups="false" disableUploadTimeout="true" maxThreads="500" minSpareThreads="20" acceptCount="100"/&gt; &lt;Connector port="8099" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine defaultHost="localhost" name="Catalina"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase" /&gt; &lt;/Realm&gt; 现在要把&lt;Connector port=&quot;8099&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;这一句里面加上内网IP:1.2.3.4，改成这样： 12345678910&lt;Service name="LMS"&gt; &lt;Connector port="8080" connectionTimeout="20000" protocol="org.apache.coyote.http11.Http11NioProtocol" redirectPort="8443" enableLookups="false" disableUploadTimeout="true" maxThreads="500" minSpareThreads="20" acceptCount="100"/&gt; &lt;Connector port="8088" connectionTimeout="20000" protocol="org.apache.coyote.http11.Http11NioProtocol" redirectPort="8443" enableLookups="false" disableUploadTimeout="true" maxThreads="500" minSpareThreads="20" acceptCount="100"/&gt; &lt;Connector port="8099" address="1.2.3.4" protocol="AJP/1.3" redirectPort="8443" /&gt; &lt;Engine defaultHost="localhost" name="Catalina"&gt; &lt;Realm className="org.apache.catalina.realm.LockOutRealm"&gt; &lt;Realm className="org.apache.catalina.realm.UserDatabaseRealm" resourceName="UserDatabase" /&gt; &lt;/Realm&gt; 请问怎么做？ 答案1： 1sed -i '/&lt;Connector port="8099"/s/port="8099"/port="8099" address="1.2.3.4"/g' server.xml 答案2： 1sed -i 's@Connector port="8099"@&amp; address="1.2.3.4"@' server.xml]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix添加网卡内外流量监控]]></title>
    <url>%2F2018%2F01%2F23%2FZabbix%E6%B7%BB%E5%8A%A0%E7%BD%91%E5%8D%A1%E5%86%85%E5%A4%96%E6%B5%81%E9%87%8F%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[现在笔者想对host名单里面的zabbix_server进行网卡的内外流量情况的一个监控，首先登录zabbix之后，configuration—hosts，出现如下的菜单： 现在可以看到这个zabbix_server后面link了很多个模板，正是因为link了很多的模板，所以导致它的items非常多，42个。现在是要在zabbix_server里添加两个新的监控项，这一步跟模板其实没有什么关系，只需要在items里直接添加items即可。 我们先添加网卡外流量的items，整个配置如图所示： 里面具体的数值可以自己更换，比如Applications什么的，key\units\Use custom multiplier这些是固定的，全部写完之后就可以save。 找葫芦画瓢，我们可以再添加一个网卡的内流量监控，也是一样的套路，如图所示： 有了items，就要有trigger，有了items里的key，那么trigger也很简单，这里的expression多时候各位都是从网上ctrl+c下来，却不能ctrl+v，因为会红字报错—-Incorrect item key &quot;net.if.in[eth0,bytes]&quot; provided for trigger expression on &quot;服务器名称&quot;，于是就有很多不明真相的吃瓜群众就走“add”路线，然后发现要走add路线还要先把服务器添加到对应的模板上去。其实大可不必，这个expression是可以自己写的，但是一定要确定trigger跟items是配对的。以外网流量所示： 在这里我添加成了1K，这样是为了方便监控，具体数值因情况而异，而且重要性我选择了无。 最后就是要形成图表来糊弄领导，让领导感受一下什么叫做高大上，在graph的界面里选择create graph，然后就如图所示的填写： 一个是红色线，一个是绿色线，双龙戏珠，save。 最后来到Monitoring—Graphs里，找到正确的host,group和graph，就会看到激动人心的图表了： 这里要注意几点，有时候zabbix反应较慢，可能写好的key会出现not support的情况，这个时候可以先登录zabbix_server去zabbix_get一下，zabbix_get的方法之前有讲过，请见http://chenx1242.blog.51cto.com/10430133/1738820 ，如果zabbix_get是成功返回值的，先检查对应的单位（结果是浮点值，但是units设定是一个整数值肯定会not support）,如果单位检查正确，就修改zabbix重新check的时间，实在不行就重新建立一个items。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>服务器监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Nessus进行漏洞扫描的过程]]></title>
    <url>%2F2018%2F01%2F23%2F%E4%BD%BF%E7%94%A8Nessus%E8%BF%9B%E8%A1%8C%E6%BC%8F%E6%B4%9E%E6%89%AB%E6%8F%8F%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[对于一个服务器运维工作者，掌握和运用一门漏洞扫描的工具也是行走江湖的必备项，Nessus就是漏洞扫描的强力武器。Nessus为一款当下比较流行的系统弱点扫描与分析软件，他的优点是操作简单（配置几乎全web化），而且页面精美、扫描项广泛；缺点就是目前不支持中文… 下载与安装要安装Nessus，需要登陆https://www.tenable.com/products/nessus/select-your-operating-system,选择对应的系统，我这个服务器是centos 7，那么就选择下图里红色的那个rpm包： 点击之后，出来一个同意条款，同意之后就开始自动下载。但是要安装nessus仅仅有程序是不够的，还需要一个对应的验证码，在上面那个界面里，下拉一点有一个get an activation code的check，点击之后跳转到https://www.tenable.com/products/nessus/nessus-plugins/obtain-an-activation-code，里选择家用free版，点击下面的register now： 注册是很简单的，填写名称和电邮就可以了。不久后就会在电子邮件里面获得一个校验码。 把下载的那个Nessus-6.11.1-es7.x86_64.rpm包上传到centos之后，rpm -ivh Nessus-6.11.1-es7.x86_64.rpm进行安装，安装完成之后，service nessusd start启动进程，启动完毕之后，使用netstat -lnpt|grep 8834，来检查一下8834端口是否被监听，如图： 端口监听OK，那么在浏览器里输入https://服务器外网IP地址:8834打开控制web界面，如果有提示当前连接不安全，无视掉就可以。nessus的欢迎界面如下： 注册一个账号之后，在这个界面里面选择home那一条，输入邮箱里面获得的那个注册码： 整个的配置就完事了，继而就是nessus自动安装的过程，大约需要几分钟： 整个安装完毕之后，就会看到nessus的主界面，简单明了的风格： 至此整个nessus的安装过程结束。 配置扫描策略以及启动扫描任务nessus扫描漏洞的流程很简单：需要先”制定策略”，然后在这个策略的基础上建立”扫描任务”，然后执行任务。首先，我们先建立一个policy，如图： 点击New Policy之后，就会出现很多种扫描策略，这里我们选择Advanced Scan(高级扫描)： 我给这个测试的扫描策略，起名叫”chenchenchen”，如图： 对于上面这个图，Permissions是权限管理，是否可以准许其他的nessus用户来使用你这个策略；Discovery里面有主机发现、端口扫描和服务发现等功能；assessment里面有对于暴力攻击的一些设定；Report里面是报告的一些设定；Advanced里面是一些超时、每秒扫描多少项等基础设定，一般来说这里默认就好。我们主要来看看那个plugins。 Plugins里面就是具体的策略，里面有父策略，具体的父策略下面还有子策略，把这些策略制定得体的话，使用者可以更加有针对性的进行扫描。比如我这个策略是针对于centos系统的扫描策略，那么一些冗余的项目大可以完全不要，举个例子： 在上面这个图里面，我不需要amazon linux local security checks这个“亚马逊linux本地安全检查”父策略，那就把它disabled掉，而对于centos local security checks这个父策略呢，我又不需要那几个关于bind的子策略，那我就单独把那些子策略disabled掉，这样等等操作，就搭配成为了一个用时不长但是又包含了所有制定的检查项的策略，然后点击save保存。 保存完后，我们就发现policy里多了一条chenchenchen的记录： 既然策略有了，现在我们就来制定一个任务。在主界面里选择My Scans,点击New Scans,这个时候还是有很多个图标，但是我们选择后面的User defined，如图： 这里我们就看到了我们已经制定好的那个chenchenchen策略，点击这个chenchenchen之后，就要给这个依赖chenchenchen策略的任务起名字以及需要扫描的网络段，由于我这个测试机的内网ip段是10.132.27.0，于是我就写了“10.132.27.0/24”，任务名字叫chentest： 启动扫描任务点击save保存之后，就会看到My Scans里多了这个chentest的任务，点击三角播放箭头，那么这个任务就开始执行了！如图： 从该界面可以看到扫描任务的状态为Running（正在运行），表示chentest扫描任务添加成功。如果想要停止扫描，可以单击方块（停止一下）按钮。如果暂停扫描任务，单击暂停按钮。 扫描完毕之后，我们就会看到一个结果反馈，如图： 具体的颜色代表，在旁边有描述，例子里这些蓝色的info代表没有重大漏洞，点击一下蓝色，还会出现更加详细的信息，包括IP地址、操作系统类型、扫描的起始时间和结束时间： 同时，nessus还支持pdf、web、csv等多种方式汇报扫描结果，至此，整个nessus漏洞扫描的全过程就结束了。 Nessus配置smtpNessus漏洞扫描是提供邮件服务，可以将扫描的结果发送给指定的邮箱。配置它的方法很简单，先登陆Nessus的界面，点击左上角的settings，然后选择左侧菜单栏里的Smtp server，如图： 再就是填写对应的项目，我这里发送邮件的地址是：chenx3314@sina.com，接受的地址是124208739@qq.com，由于发送邮件使用的是新浪的邮箱，那么host就填写新浪的smtp服务器，即smtp.sina.com，如果是要SSL加密的话，端口写465，同时在Encryption那里选择Force SSL，在Auth Method那里选择login的鉴权方式，然后输入chenx3314@sina.com的账号密码，如图： 点击Send Test Email，然后输入接收的邮箱，如果是多个邮箱那么就用英文逗号隔开。看到成功的提示就是OK了： 然后就可以到邮箱里面看到那个测试的邮件内容：]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>nessus</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mysql清除磁盘碎片]]></title>
    <url>%2F2018%2F01%2F23%2Fmysql%E6%B8%85%E9%99%A4%E7%A3%81%E7%9B%98%E7%A2%8E%E7%89%87%2F</url>
    <content type="text"><![CDATA[任务背景接到金山云报警短信，说某数据库的容量已经达到了90%的水位线，于是登陆控制台查看详细情况。 在控制台首先发现，每一天的磁盘容量的确有所波动，那么就证明开发人员写的“资源回收”模块是在正常运行的，如图： 那么就说明没有什么数据是可以删的，既然删不掉多余的数据又不想多掏钱扩磁盘容量，只能从“磁盘碎片”下手了。而InnoDB引擎清理磁盘碎片的命令就是OPTIMIZE。 具体操作首先我先查询一下所有的“磁盘碎片情况”，使用语句如下： 1select CONCAT(TABLE_SCHEMA,'.',TABLE_NAME) as 数据表名,concat(truncate(sum(DATA_LENGTH+DATA_FREE+INDEX_LENGTH)/1024/1024,2),' MB') as total_size, concat(truncate(sum(DATA_LENGTH)/1024/1024,2),' MB') as data_size,concat(truncate(sum(DATA_FREE)/1024/1024,2),' MB') as data_free, concat(truncate(sum(INDEX_LENGTH)/1024/1024,2),'MB') as index_size from information_schema.tables group by TABLE_NAME order by data_length desc; 或者使用select table_schema, table_name, data_free, engine from information_schema.tables where table_schema not in (&#39;information_schema&#39;, &#39;mysql&#39;) and data_free &gt; 0;也可以，这个是查询data_free大于0的所有表。 然后看到我这个叫history_device_flow_day的表里情况如下： 表里的data_free就是磁盘碎片的量，比如我现在要干掉history_device_flow_day里所有的磁盘碎片，是975MB，于是先查询一下这个history_device_flow_day的存储引擎，使用语句如下： 1show table status from jsonlinefssrds where name='history_device_flow_day'; 上面语句里的jsonlinefssrds是对应的数据库，看到的效果如下： 存储引擎是InnoDB，那么就可以启动清除碎片的语句了：OPTIMIZE TABLE 数据表表名;，因为OPTIMIZE TABLE只对MyISAM、BDB和InnoDB表起作用。 再执行了OPTIMIZE TABLE history_device_flow_day;之后，大约9分钟，就会看到“OK”的字样： 估计有的朋友会问，那上面不是明明写了“Table does not support optimize, doing recreate + analyze instead”吗？这个其实无妨，实际上磁盘碎片已经被清除掉了。我们可以再用一次查询磁盘碎片的命令看一下，如图： 的确释放了900多M。 或者使用ALTER TABLE 表名 ENGINE = Innodb;（只是InnoDB的表可以这么做，而且据说这么做更友好）来达到清理磁盘碎片的目的，这个命令表面上看什么也不做,实际上是重新整理碎片了。当执行优化操作时,实际执行的是一个空的ALTER命令,但是这个命令也会起到优化的作用,它会重建整个表,删掉未使用的空白空间。 补充为什么会产生磁盘碎片？那是因为某一个表如果经常插入数据和删除数据，必然会产生很多未使用的空白空间，这些空白空间就是不连续的碎片，这样久而久之，这个表就会占用很大空间，但实际上表里面的记录数却很少，这样不但会浪费空间，并且查询速度也更慢。 注意！OPTIMIZE操作会暂时锁住表,而且数据量越大,耗费的时间也越长,它毕竟不是简单查询操作。所以把OPTIMIZE命令放在程序中是不妥当的,不管设置的命中率多低,当访问量增大的时候,整体命中率也会上升,这样肯定会对程序的运行效率造成很大影响。比较好的方式就是做个shell,定期检查mysql中 information_schema.TABLES字段,查看DATA_FREE字段,大于0的话,就表示有碎片，然后启动脚本。 参考资料http://pengbotao.cn/mysql-suipian-youhua.htmlhttp://irfen.me/mysql-data-fragmentation-appear-and-optimization/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>数据库</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一道传说中是百度面试的shell试题]]></title>
    <url>%2F2018%2F01%2F23%2F%E4%B8%80%E9%81%93%E4%BC%A0%E8%AF%B4%E4%B8%AD%E6%98%AF%E7%99%BE%E5%BA%A6%E9%9D%A2%E8%AF%95%E7%9A%84shell%E8%AF%95%E9%A2%98%2F</url>
    <content type="text"><![CDATA[【问题】写脚本实现，可以用shell、perl等。把文件b中有的，但是文件a中没有的所有行，保存为文件c，并统计c的行数。翻译成人话就是，假设有一个文件a是:abcd 文件b是:1234ab 现在要求输出“b有a没有”的行，即1 2 3 4，然后wc -l一下。 【思路】两个文件比较，第一想法就是diff，但是diff无论是-c还是-y会牵扯进大量的&gt; &lt; + -不说，而且diff命令是直白对比，即使字母相同但所在行不同，也会被diff记录。如果再用for in语句然后一项一项对比也不会很清晰的解决这个问题，所以要换个方法。 第二个方法就是comm命令，但是这个命令有一个前提，就是要sort排序，comm比diff高明之处在于它只比较内容而不在意是否同一行，但是要注意对比文件的先后。comm -12 a b是找”a和b都有”的项，comm -23 a b就是找”a有而b没有”。 【解答】perl我不会，我就用shell写： 123456#!/bin/bash#written by ChrisChan @ 2016-4-21sort a.txt&gt;a1.txt #排序，不然会有提示sort b.txt&gt;b1.txtcomm -23 b1.txt a1.txt &gt;c.txt #由于是要找b有a没有的,就要b写在前，a写在后echo $(cat c.txt|wc -l) 其实还有一个更简单的，只用一句话: 1grep -v -x b.txt -f a.txt|wc -l 很多书上不写grep -x -f的意思，这里补一下：-f:指定范本文件，其内容含有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每列一个范本样式。-x:只显示全列符合的列。 从一个题就能轻松看出shell的能力级别，用diff死纠缠就是初级，用comm就是中级，而grep就是高级。的确是一个好题。 【补充】如果考python，求这种类似“你有我没有”的东西，用set里面的差集算法。 12345678910&gt;&gt;&gt;A=&#123;1，2，3，4&#125;&gt;&gt;&gt;B=&#123;3，4，5，6&#125;&gt;&gt;&gt;print(A-B)set([1,2]) #A有B没有&gt;&gt;&gt;print(A ^ B)set([1,2,5,6]) #差集的补集&gt;&gt;&gt; A&amp;B&#123;3, 4&#125; #交集&gt;&gt;&gt; A|B&#123;1, 2, 3, 4, 5, 6&#125; #全集]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>面试经验</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决Zabbix在web界面中文显示的问题]]></title>
    <url>%2F2018%2F01%2F22%2F%E8%A7%A3%E5%86%B3Zabbix%E5%9C%A8web%E7%95%8C%E9%9D%A2%E4%B8%AD%E6%96%87%E6%98%BE%E7%A4%BA%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[注意！这个是解决web界面中文显示乱码的问题，不是zabbix web界面全中文汉化的问题。 2.2版本的处理方法zabbix里给host或者item等项目起中文名字的时候，可能在graph上无法正确显示中文字符，如图： 那么遇到这样的情况其实很简单，就是zabbix的web界面没有安装中文字库的问题，那就对症下药，下载中文字库。 中文字库的下载地址在这里：http://linux.linuxidc.com/2012%E5%B9%B4%E8%B5%84%E6%96%99/11%E6%9C%88/22%E6%97%A5/Zabbix%E4%B8%AD%E6%96%87%E4%B8%8D%E8%83%BD%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98/ ，下载“LinuxIDC.com下载-kaiti.tar.gz”。 后把这个文件改一下名，可能很多linux不识别那个中文字“下载”,mv LinuxIDC.com下载-kaiti.tar.gz kaiti.tar.gz，tar -zxvf kaiti.tar.gz 然后就会发现当前路径里生成了一个叫kaiti.ttf，这个就是我们所需要的中文“楷体”字体文件。 来到zabbix的web字体路径，在我的机器里，这个负责字体的文件夹叫/usr/local/nginx/html/zabbix/fonts/。虽然各位安装zabbix的路径各有差别，但是这个文件夹一般都是在nginx or apache的html下，所以很好找的。 在这个fonts文件夹里默认已经有一个叫DejaVuSans.ttf的文件了，于是就把这个kaiti.tff也放到这个文件夹下。 光有字体文件没有用，还需要在配置文件里使用这个字体文件，于是就vim一下同样在nginx or apache/html/zabbix/include的defines.inc.php。把里面所有的DejaVuSans替换成kaiti，.tff这个后缀是不用加的。然后保存退出，重新刷一下界面就看到效果了。 vim的替换语句 :%s/DejaVuSans/kaiti/g 3.x版本的处理方法现在zabbix已经升级到3.x了，上述的方法已经失效了，这里记录一下新的中文配置方法。 首先从windows里，拷贝一个中文字体的文件到zabbix的服务器的/usr/share/zabbix/fonts文件夹里，比如我先择了“楷体”，这个文件叫simkai.ttf，chmod +x simkai.ttf 给予可执行权限。 然后vim /usr/share/zabbix/include/defines.inc.php，修改两处地方，分别是第四十五行，把原来的改成simkai，如图： 还有一处就是第九十三行，也是改成SIMKAI： 保存文件之后，刷新一下zabbix界面即可。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>运维与监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[防盗链的等等相关]]></title>
    <url>%2F2018%2F01%2F22%2F%E9%98%B2%E7%9B%97%E9%93%BE%E7%9A%84%E7%AD%89%E7%AD%89%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[为什么网站们都要限制流量？无论是网站服务器亦或是游戏服务器还是邮件服务器，说穿了也是一台电脑，也有CPU和内存。只不过服务器的CPU功能比个人电脑的CPU功能强大，比如个人电脑的CPU一秒钟能算1亿个数，那么服务器的CPU一秒钟就能算十亿个数。毕竟个人电脑只针对个人，但是服务器是要“接客”的，有了强大的硬件做后盾，网页/游戏/邮箱才不会那么轻易的Down掉。 但是CPU不是人类大脑，人脑是越用越聪明，CPU是越用越磨损，毕竟始终在连电的环境下。于是乎，没有必要的运算能省就省，一个人省一次，十万个人就省十万次，一千万个人就省一千万次，这样达到积少成多的目的。 CPU计算的是各种数据，而这些数据也叫作流量。有用的流量、有价值的流量通过CPU计算无可厚非，但是出现了没有用的流量或者是别人盗用我们的资源，那么这种情况能避免都要避免。什么叫盗用我们的资源，比如自己网站（网站A）上的图片或者视频，被其他人直接复制网站然后粘贴到他们的主页（网站B）上，其他用户登录了B网站，然后点击了那个图片和视频，由于是网址重链接，里外里提供数据的还是我们的服务器。也就是说B网站就是一个中介，而真正提供服务的是网站A，但是广告费和点击率都要网站B赚走了，这事儿实在是叔可忍婶不可忍。 什么是盗链？如何发现被盗链？什么叫盗链，上面已经说的差不多了，如果上面的文字没有看懂的话，举个例子，如果您看到了这两个图片，证明这个网站就是在盗链。 这两个就是一个盗取的是QQ空间的图片，另一个就是百度的图片。用其他网站的图片这事儿本身是无所谓的，只要不涉及版权问题，都希望自己的作品能广泛传播，但是请不要直接通过网址重定向，厚道一点的行为应该是：“图片另存为”，然后到目标网站上去重新上传一下。 这里再多说一点网站的基础知识。 PV值：PV=page view，网站是有少则一个网页多则N多网页组成的一个整体，PV值就是统计用户访问网站的总页数。比如www.JQK.com这个网站，今天有100个用户登录，平均每个用户翻阅了里面5个网页。那么这个网站的PV值就是500。若一个IP地址，对一个页面刷新10000次，PV值也是1.要查询网站的PV值登陆http://www.alexa.cn就行。 Hit值：这个就是对网页里每个元素的点击量，一个网页里的图片就是一个元素，一个flv文件也是一个元素，一首歌曲也是一个元素。这些的总量就是hit值，hit值越高就证明这个网站被人查看的情况越高，那么也证明网站的高人气，那么自然广告也会卖出去很多钱。 因为建网站这事儿关心到了金钱利益，网站越被人关注，自然价值也越大。于是会有一个公式来评判网站的“每日贡献”：总流量=访问流量+下载流量= Page view值 x 页面大小+下载文件大小 x 下载次数 作为管理者，每天观察一下自己一亩三分地儿的网站数据情况是本职工作。但是有时候也会遇到网站流量很惊人的情况，一般来说，网站流量过大（CPU运转很多）的原因如下： 1）网站是一个很大的网站：比如说淘宝，京东，网易，youtube,facebook那种大网站，里面成万上亿的网页，而且每天又有那么多人登陆，自然浏览量很大。虽然这些大集团的服务器也是少则几千，多则上万，甚至在不同地区也会有不少的服务器集群，但是这几万台服务器需要提供的数据会很多也是不争的事实。这种现象是正常的。 2）网页内容太大：可能本身网站是一个小网站，加起来也就十页二十页的内容，但是每一天的流量依旧很惊人，那么很有可能是单页或者某几页的字节太大。比如网页里有太多的图片，太多的视频，太多的其他链接，也有可能是前端码农们给这个网页的规划不合理。导致这个网页每一次被点击都要大费周折（hit值和PV值不高，但是日流量很高），长此以往不仅会耽误用户的整体体验，对服务器也是一个重大伤害。 3）搜索引擎产生了大量的数据流量：网站需要推广，于是就在各种搜索引擎上打广告，也有自己网站的很多图片用于外部调用。这样的结果就是本身来观摩网站的人很少，但是“借着引擎经过”的人很多，所以就会有PV值不高，但是Hit值和日流量很高的现象出现。 4）图片或者其他元素被盗链：第一部分就说过了，别人拿我们的图片去吸引别人关注，然后别人想要深入了解，还要来使用我们的服务器去提供详细数据。这种“用我们的牌子住我们的房，吃我们的饭却不给我们钱”的现象实在应该被弄死。这种现象的特征也是PV值不高（没人真正点击网站），但是Hit值和日流量很大（自己服务器的数据都给别的网站提供了）。 5）网站被DDos攻击了：被一些恶意的IP地址频繁登陆，来回的刷流量。这样迫使CPU做出运算的行为其实就是在远程的破坏服务器的硬件CPU，遇到这种现象，之前Nginx文章里有写，要么通过access.log找到这些IP封掉，要么就在配置文件里加上限制limit-rate。 服务器是如何知道图片是从站外而来的呢？在http协议里有一个重要的选项叫refer，这个选项的内容就是该元素的来源地址。如果这个元素是服务器自己提供的，那么头文件里是没有refer这个选项的。通过refer这个信息，我们也可以知道登陆网站的客户是从哪个网站点击链接而来的。这样方便进行一个统计和规划。 假如，我在QQ空间里面发现一个图，然后右键图片，选择”在新标签栏里打开图片”，这时候通过浏览器“审查元素”的功能，能查查看请求头信息和响应头信息，发现响应头信息里多了一个refer，里面的内容就是图片的源地址： 我在QQ空间里看腾讯的照片自然是可以的，但是如果我在别的网站里看腾讯的照片，加重了腾讯服务器的负担，自然腾讯公司会不满意。于是腾讯服务器发现当前要引用这个图片的地址与refer头信息不是一个来源之后，就不会把这个图片的数据传送过来，于是就看到那个“此图片来自QQ空间，未经准许不可饮用”的警告图片。 既然知道了服务器是如何判断文件是否盗链，那么只要伪装一个refer就可以欺骗服务器达到“反防盗链”的目的了。至于这部分，可以自己单独研究。如何使用Nginx反盗链？ 同样的使用Nginx.conf，在http的大括号下面，新建一个location，加入如下信息： 12345678910111213141516location ~ .*\.(wma|wmv|asf|mp3|mmf|zip|rar|jpg|gif|png|swf|flv)$ &#123;#指定对以上几种类型的文件建立防盗链 valid_referers none blocked *.alala.com alala.com;#盗链的范围不包括alala.com和alala.com下的二级网站， if($invalid_referer) &#123; #rewrite ^/ http://www.alala.com/error.html; return403;#如果发现有引用以上文件的地址与refer头信息不符的情况，直接重定向成error.html这个网页，服务器返回403，forbidden。 &#125;&#125; 使用第三方模块ngx_http_accesskey_module实现Nginx防盗链实现方法如下： 下载NginxHttpAccessKeyModule模块文件：http://wiki.nginx.org/File:Nginx-accesskey-2.0.3.tar.gz； 解压此文件后，找到nginx-accesskey-2.0.3下的config文件。编辑此文件：替换其中的$HTTP_ACCESSKEY_MODULE为ngx_http_accesskey_module； 用一下参数重新编译nginx： ./configure –add-module=Nginx目录/to/nginx-accesskey然后执行: make &amp;&amp; make install 修改nginx的conf文件，添加以下几行： 123456location /download &#123; accesskey on; accesskey_hashmethod md5; accesskey_arg "key"; accesskey_signature "mypass$remote_addr";&#125; 其中：1.accesskey为模块开关；2.accesskey_hashmethod为加密方式MD5或者SHA-1；3.accesskey_arg为url中的关键字参数；4.accesskey_signature为加密值，此处为mypass和访问IP构成的字符串。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>http</tag>
        <tag>网络相关</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次配置http跳转https的过程]]></title>
    <url>%2F2018%2F01%2F18%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E9%85%8D%E7%BD%AEhttp%E8%B7%B3%E8%BD%AChttps%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[公司最近搞了一个数据运营平台，这个平台会以web界面的形式把各个数据展示出来，这个项目是我们一个经理的重点关照项目。把平台模块部署完毕并且启动之后，又把这个平台服务器的外网IP绑定到alkaid.lechange.com这个域名上，在浏览器里输入https://alkaid.lechange.com,就看到了前端同行们写的网页。 但是我们的霸气经理说这样不行，说要更多要求更高标准更好体验，于是乎提出一个需求就是：在输入alkaid.lechange.com的时候会自动跳转到https://alkaid.lechange.com。 既然如此，我们就在nginx上原有的nginx.conf里补充几个配置文件： 12345#include upstreaminclude upstream.conf;# include serversinclude alkaid.conf;include alkaid-https.conf; 这样在执行nginx.conf的时候，就会调用upstream.conf、alkaid.conf和alkaid-https.conf，我们主要看一下这三个文件。 alkaid.conf文件如下： 123456789server &#123; listen 80; server_name *.lechange.com; proxy_buffering off; location / &#123; rewrite ^/ https://alkaid.lechange.com permanent; client_max_body_size 100m; &#125;&#125; 这里我们监听了80端口，下面那个client_max_body_size 100m是用来设定nginx+php上传文件的大小，这里规定是100m，这个可以写进nginx.conf里，如果有对上传文件方面感兴趣，可以看http://www.cnblogs.com/zhwl/archive/2012/09/18/2690714.html 。 再来看看alkaid-https.conf，如下： 1234567891011server &#123; listen 10000; server_name *.lechange.com; proxy_buffering off; location / &#123; proxy_pass http://alkaid_backend; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_redirect off; &#125;&#125; 这里监听了10000端口，location写的是http://alkaid_backend,这个alkaid_backend是啥东西? 这个时候我们就需要看一下upstream.conf，里面内容是: 1234upstream alkaid_backend &#123; server X.X.X.X:JQK; check interval=5000 rise=2 fall=5 timeout=1000 type=tcp default_down=false;&#125; X.X.X.X是模块服务器的内网IP地址，而JQK是模块服务器的模块端口，这里要根据实际的情况来写。可见alkaid_backend对应的就是模块服务器和它的端口，下面是检查间隔等等数值。 现在我们启动nginx，然后把nginx的外网地址绑定去alkaid.lechange.com这个域名，在浏览器里输入alkaid.lechange.com，就会达到自动跳转的目的了！ 这里要额外多说一下，我们这里设定了80的配置文件也设置了443的文件，但是这俩文件的转发过程却不同：alkaid-https.conf文件把443的请求转向了平台模块服务器的服务，而alkaid.conf文件把凡是从80端口进来的请求直接全部永久重定向到https://alkaid.lechange.com ，但是这个alkaid.lechange.com还是会去访问平台模块服务器的服务，也就是说alkaid.conf文件多了一步重定向。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将电商平台测试环境添加了域名和https]]></title>
    <url>%2F2018%2F01%2F18%2F%E5%B0%86%E7%94%B5%E5%95%86%E5%B9%B3%E5%8F%B0%E6%B5%8B%E8%AF%95%E7%8E%AF%E5%A2%83%E6%B7%BB%E5%8A%A0%E4%BA%86%E5%9F%9F%E5%90%8D%E5%92%8Chttps%2F</url>
    <content type="text"><![CDATA[情况描述今天电商平台来了新的产品经理。摸了一遍情况之后，提出了两个需求，第一个是要把测试环境也要上https，达到与线上一致；第二个就是测试环境要配上域名，不要再用IP地址登陆。 配置域名是很简单的，在阿里云的云解析上直接给测试环境新加一个域名，然后对应添加阿里云外网SLB的IP地址即可。进入页面也发现首页地址显示正常，但是再点点就发现了里面有点不对。 没错，现象就是“只有首页是域名，其他网站都是IP”， 遇到这个情况，我就跑去nginx.conf里，看一下server_name的配置，看到的确写得是func.lechange.com，如图： 于是就在页面上使用ctrl+shift+c查看具体情况，发现里面的代码是这个样的： 这就人赃俱获了，开发已经在html里把地址写死了，使用了绝对路径而不是相对路径，于是就打回让开发自己慢慢改。 然后又回到SLB界面，新增新的https监听，前端端口443，后端是80，搭配正确的证书，SLB保存之后，在浏览器输入测试环境的https://网址之后，发现整个界面全乱了，如图： 但是使用http://网址去访问还是正常的，如图： 很明显，这是因为https下跨协议调用http的是不行的，所以那些css、js如果不支持https的话就无法正常显示。使用ctrl+shift+c看错误更加明显。 遇到这个问题，就有如下几种方法： 第一种：将所有的访问路径都写死https，不过这个我们公司代码规范不准许;第二种：去掉URL中的http://或https://，将其替换为//，这样，浏览器就可以根据当前页面的请求方式来动态切换了；第三种：可以在&lt;head&gt;中添加&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;upgrade-insecure-requests&quot;&gt;,浏览器会在加载HTTP资源时自动替换成HTTPS请求；第四种：在nginx里写一个proxy_redirect跳转，这个就比较有技术含量了； 参考资料https://thehackernews.com/2015/04/disable-mixed-content-warning.htmlhttps://www.tuicool.com/articles/ARVVFjIhttps://developer.mozilla.org/en-US/docs/Web/Security/Mixed_content/How_to_fix_website_with_mixed_content]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>网络基础</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维工程师笔试题第十四套]]></title>
    <url>%2F2018%2F01%2F17%2FLinux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%AC%94%E8%AF%95%E9%A2%98%E7%AC%AC%E5%8D%81%E5%9B%9B%E5%A5%97%2F</url>
    <content type="text"><![CDATA[前言这几天一边看着《nginx高性能WEB服务器详解》，一边看着基础知识。那么最容易入眼的基础知识是什么呢？当然是面试题了，于是乎就找出来一些阿里（含滴滴和蚂蚁金服）的运维面试题，以题带看。 看完之后觉得阿里真的不是盖的，面试题的质量比那些晚上乱七八糟的题质量好多了，细节抠的真是非常细。我记得曾经有一个前辈曾经说过，工作中我们经常注意一些奇淫技巧，但是忽视了基础知识的重要性，现在好多程序员不会认认真真地读本书，喜欢快餐文化，受了市面上很多培训机构的影响，这是要不得的。 最后再说一句，以下所有的题都属于“开放性”试题，可以根据基本点去发散，说出你的理解和认识。但是注意，不要避重就轻耍滑头，问A，可以发散到A1、A2…但是不要发散到X、Y、Z，然后大谈特谈XYZ，这种“小聪明”就是找死的行为。 废话到此为止，上题1）http一般是无状态的，怎么让它变成有状态的？[我的答案]http协议跟IP协议、UDP协议一样都是无状态的，http的无状态意思是“每次的请求都是独立的，它的执行情况和结果与前面的请求和之后的请求是无直接关系的，它不会受前面的请求应答情况直接影响，也不会直接影响后面的请求应答情况”。补充一下，TCP是有状态的，它的请求并不独立，它通过包头的一些控制字段来分别包的关系，这里可以自行脑补一下“三次握手”的图。 那么http是无状态的这一点是无法改变的，那么要变得“有状态”，就需要引入cookie和session，通过这两个机制去实现一个有状态的WEB应用。用一个表达式可以这么理解：Web应用=http协议+session、cookies等状态机制+其他辅助的机制。 2）解释一下cookie和session的区别[我的答案]session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中，session是一个抽象概念，开发者为了实现中断和继续等操作，抽象出来的一个“会话”，接上面那道题，session这个东西是有状态的，服务器要维护一个有状态的东西是很消耗资源的（比如内存和空间），我估计天猫京东那规模的电商，肯定有一个专门的session集群。 Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式，cookie是一个实际存在的东西，它是在http协议中定义在header中的字段。同一个域名给的cookie肯定是一样的，所以每一个cookie（key）对应的session（value）是唯一的。 session的常见实现要借助cookie来发送sessionID给客户端，如果浏览器禁用cookie，那么就要通过重写url来获取sessionid，各位可以联想一下电商的购物车，购物车可以实现在一个网站的不同页面把东西都放进一个购物车，这就是session的重点应用。现在也很流行一个token，其实token和sessionid是一个意思。 3）多进程和多线程的区别，自己喜欢用哪个？为什么？[我的答案]多进程：服务器每当接收到一个客户端信息的时候，从主进程里生成一个子进程与客户端建立连接开始交互，每一个子进程之间互相独立不受干扰，完成任务就收回资源，内存等也会被回收；多线程：服务器每当接收到一个客户端信息的时候，从主进程里生成一个线程与客户端建立连接开始交互,多个线程位于同一个进程内，可以互相访问同样的内存等资源，彼此之间会有影响；我个人更喜欢多进程，因为简单粗暴！ 关于多进程、多线程、同步、异步的原理，可以去看一下《nginx高性能WEB服务器详解》，第54页到56页的内容。 4) lvs脑裂如何解决，为什么会产生双master？双master时VIP通不通?[我的答案]产生双master的原因：1）服务器开启了iptables防火墙，阻碍了心跳信息传输；2）服务器心跳网卡等信息写错了，导致心跳信息发送失败；3）心跳方式不搭配，心跳广播冲突；4）软件出bug了； 额外补充一句，要排除脑裂问题，第一步是检查iptables,很可能是由于iptables把心跳信息隔断了，重要的话不说三遍也重要！ 其他两个问题不会了，我在实际工作里没有接触到。 5) 为什么TCP比UDP的信息更加可靠？详细说说tcp滑动窗口原理，窗口的大小如何确定。TCP可靠性由三个机制保证：1. 序号（TCP报文的序号）2. 确认（ACK机制）3. 重传（超时或者冗余的 ACK）tcp在传输的时候，因为接受方B能力有限，不可能一口气吃下所有发送方A所有的数据流信息，所以B要限制A每次发送的字节数量，并且一一确认，确认了之后A才可以继续发。这样的话，A的在发送数据流的时候就会有四种形态：1.已发送已确认；2.已发送但没被确认；3.未发送但是接受方已经准备好空间来接收；4.未发送但是接受方尚未准备好空间来接收；随着数据流的传输，这个形态是会时刻发生变化的，通过接受方B返回的确认信息来改变2的大小，同时B也会根据一次关于发送方A要发送多少字节确认自己的空间来改变3的大小。 6) 简单说说cdn的工作原理，如何评估一个cdn sp做的好不好。[我的答案]cdn的工作原理：通过权威dns服务器来实现优质节点的选择，通过缓存来减少源站的压力。 IT界有个很有名的比喻，正向代理是“找马云借钱”，反向代理是“给10086打电话”，而反向代理就是CDN的实现原理雏形的一部分。详情可以看：http://www.iweir.cn/zheng-xiang-dai-li-yu-fan-xiang-dai-li/ 。 7）dns查询的过程说一下，为什么要有cname而不是直接返回一个cdn边缘节点的ip。[我的答案]先说一句题外话，dns主要是基于udp的！dns查询的过程以www.taobao.com为例：1.在浏览器键入www.taobao.com,其实真正dns协议里用到的是www.taobao.com.最后还有一个点，可能是因为美观等原因，一般都不显示;2.查询本地缓存（host文件或者是浏览器的缓存）中有没有该域名对应的记录，有的话就直接用了;3.向运营商的DNS服务器发起dns解析的请求，一般称运营商的DNS服务器为local dns;4.local dns会查询本地的缓存，local dns设置的缓存时间是有讲究的，过长过短都不好。另外local dns的查询是运营商的事，这里面水很深，外部不可控(这也是天朝能搭建特色墙的根源的思想雏形)；5.local dns如果没有缓存，会把域名从右往左扫描，依次请求对应的服务器，例如对于域名www.taobao.com.，先去问负责.的根域名服务器，就是传说中全球只有几台的那些服务器，他们会答复.com是谁管理的，然后local dns又去找管理.com的服务器（假设名字为S1），去问问taobao.com是谁管，一般来说，在S1查到的记录是一条cname记录（阿里毕竟大公司，自己管理自己旗下的域名），然后就转到了阿里自己的DNS服务器上来了，一般称之为权威服务器；6.权威服务器是阿里自己建的，然后根据公司内部的一些配置啊，调整啊，查到www.taobao.com.对应的服务器是谁，返回一个IP地址；7.local dns缓存这个IP地址，并且回复浏览器；8.浏览器和对应的IP地址的服务器建立TCP连接，发送HTTP报文； 用图表示就是： 至于说为什么不返回cdn边缘节点IP，是因为使用CNAME记录可以很方便地变更IP地址，毕竟服务商掌握着IP的生杀大权，哪一天需要换IP了，在这方面很不方便。 8）举例说下正则表达式和扩展正则表达式、例如：url、ip、邮箱的正则表达式？[我的答案]这三个都是网上找的，正则这个东西还是要多练多写。url的正则表达式：([/w-]+/.)+[/w-]+.([^a-z])(/[/w- ./?%&amp;=]*)?|[a-zA-Z0-9/-/.][/w-]+.([^a-z])(/[/w- ./?%&amp;=]*)?ip的正则表达式：^(1\d{2}|2[0-4]\d|25[0-5]|[1-9]\d|[1-9])\.”+”(1\d{2}|2[0-4]\d|25[0-5]|[1-9]\d|\d)\.”+”(1\d{2}|2[0-4]\d|25[0-5]|[1-9]\d|\d)\.”+”(1\d{2}|2[0-4]\d|25[0-5]|[1-9]\d|\d)$邮箱的正则表达式：^[a-zA-Z0-9.!#$%&amp;’+\/=?^_`{|}~-]+@a-zA-Z0-9?(?:.a-zA-Z0-9?)$ 9）解释raid0、raid1、raid01、raid10、raid5、raid6，并分析各自读写性能？[我的答案]https://rorschachchan.github.io/2018/01/31/简析raid0-raid1-raid10-raid01等等硬盘搭配/ 10）raid为什么不搞个raid50、raid15，不能搞是因为有什么冲突还是什么等等?[我的答案]raid50是有的，但是用途不广泛。raid15我是没听说过，因为raid1的写本身就不强（一样的内容要写两个盘里），raid5的写入能力更烂，那么raid15的磁盘写能力简直就是灾难。而且花了硬盘的钱只能存实际一半的量，正常人都不会这么做的。 拓展阅读https://segmentfault.com/a/1190000007243675http://mertensming.github.io/2016/10/19/cookie-session/https://wizardforcel.gitbooks.io/network-basic/content/index.htmlhttps://coolshell.cn/articles/11564.htmlhttps://coolshell.cn/articles/11609.htmlhttp://blog.sina.com.cn/s/blog_93b45b0f0101a4ix.htmlhttp://www.cnblogs.com/549294286/p/5172435.htmlhttps://wizardforcel.gitbooks.io/network-basic/content/7.html（这个墙裂推荐，基础知识）http://blog.jobbole.com/105500/http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.failover.html]]></content>
      <categories>
        <category>大牛之路</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[实战Kibana的日志关键词搜索和日志可视化]]></title>
    <url>%2F2018%2F01%2F17%2F%E5%AE%9E%E6%88%98Kibana%E7%9A%84%E6%97%A5%E5%BF%97%E5%85%B3%E9%94%AE%E8%AF%8D%E6%90%9C%E7%B4%A2%E5%92%8C%E6%97%A5%E5%BF%97%E5%8F%AF%E8%A7%86%E5%8C%96%2F</url>
    <content type="text"><![CDATA[准备工作首先，先下载一个elastic网站上下载一个它提供的demo—莎翁的《亨利四世》，下载地址是https://download.elastic.co/demos/kibana/gettingstarted/shakespeare.json 。 打开这个json字符串，里面就是《亨利四世》的话剧剧本，长得是这个样子： 可以看到里面有play_name、speaker、speech_number、line_id等等名称，每个名称后面都有一个对应的值。 然后启动elasticsearch，按照上面的文件格式生成索引。语句如下： 1234567891011121314curl -XPUT http://localhost:9200/shakespeare -d '&#123; "mappings" : &#123; "_default_" : &#123; "properties" : &#123; "speaker" : &#123;"type": "string", "index" : "not_analyzed" &#125;, #确定type是字符 "play_name" : &#123;"type": "string", "index" : "not_analyzed" &#125;, "line_id" : &#123; "type" : "integer" &#125;, #确定type是数字 "speech_number" : &#123; "type" : "integer" &#125; &#125; &#125; &#125;&#125;'; 导入刚刚下载的那个json：curl -XPOST &#39;localhost:9200/shakespeare/_bulk?pretty&#39; --data-binary @shakespeare.json 具体elasticsearch的增删改查语法可以参看阮大师的http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html ，个人建议将elasticsearch和mysql对比一下，这样更方便理解。 然后后台启动kibana，确认5601端口已经stand by，如图： 然后在浏览器地址栏输入服务器外网ip：5601打开kibana。 导入数据结束之后，使用curl &#39;localhost:9200/_cat/indices?v&#39;，去查看一下效果，如果看到index里有shakespeare那一栏就是导入成功了，如图： 在启动Kibana后，Kibana会自动在配置的es中创建一个名为.kibana的索引（上图第二个），这个索引用来存储数据，注意！不要删除了它。 Kibana的界面搜索如果此时的kibana里是第一次配置的话，那么第一步就是配置新索引，我们之前在生成索引的时候写的是shakespeare，那么现在也写shakespeare，然后点击create，如图： 然后在菜单栏左侧的discover里选择刚刚建立的shakespeare，就会看到这样的东西： 在Search上就可以进行搜寻，比如说我搜寻freedom，如图： 如果我搜寻KING HENRY IV，他不分大小写的把所有king、henry、iv都搜索出来。 如果我想搜寻line_id的第一行到第三行，那么语句就是line_id:[1 TO 3]，如图： 如果想在上面的基础上进一步细化，比如说要在line_id是从第一行到第三行，同时_type是scene的语句：line_id:[1 TO 3] AND _type:scene： 假如不想要scene，那么就把AND改成NOT。 如果这个时候只想关注一些指定的字段，那么可以将鼠标移动到索引下面的字段上，然后选在add即可，同样的移动上面已经选择的字段选择remove进行移除，比如我们试一下这个speaker： add之后在点击右侧的具体的speaker，就会看到里面的细节，比如这位westmoreland（威斯摩兰伯爵）： 这个时候就能看见这位伯爵大哥的台词细节，在第几场的第几节，说的是什么台词。再返回菜单左侧点击这个speaker，我们还会看到一个比重： 从这里就很清晰的看到，FALSTAFF（法斯塔夫）这个哥们的台词最多，也符合书里塑造的那个嗜酒话痨的艺术形象。而我们的KING HENRY IV(亨利四世)的台词只是第四位，占比重11%而已… 这样具体的搭配搜索之后，可以点击界面右上侧的save进行保存搜寻结果，再搭配share分享搜索结果的url网址，如图： Kibana的图像化展示Kibana也能做到类似grafana那样的炫酷图象化展示，更加立体的表现日志情况，首先选择左侧菜单栏里的Visualize（可视化）： 然后点击Create a Visualization,里面既有很多种图形供你选择，有饼型，有箭头的，有文字的，有仪表盘的，如图： 我们这里先建立一个饼型的，还是上面那个台词多少的例子，首先选择shakespeare作为数据源，然后点击split slices，如图： 然后在Aggergation里选择Terms，然后在Field里选择Speaker,size那里写8,最后点击上面的那个三角播放键，看看结果： 这就很清晰的看出，亨利四世一共说了1086句话，占比11.11%。 如果我们再加一个Split Slices，这一次在原有的specker的基础上选择play_name，图象变成了一个同心圆，最外面的一层就是新增的“play_name”的情况，如图显示FALSTAFF的所有台词会在两个play_name里出现： 如果这个盘子里不想统计FALSTAFF这个话包，就添加一个过滤器，选择speaker is not，后面写上FALSTAFF即可，如图： 效仿刚才的方法也可以做一个仪表盘，如图： 可视化的数据也可以save和share，同样在web界面的右上角。保存的数据是可以在左侧菜单栏里的Dashboard里展示，做成一个类似zabbix那样的展示！]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>elk</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[工作所用的模块回滚脚本]]></title>
    <url>%2F2018%2F01%2F17%2F%E5%B7%A5%E4%BD%9C%E6%89%80%E7%94%A8%E7%9A%84%E6%A8%A1%E5%9D%97%E5%9B%9E%E6%BB%9A%E8%84%9A%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[前言与脚本内容部署中常备一个回滚脚本也是很有必要的，我所在公司的服务器模块名都是在初始化的时候写进/etc/role_install这个文件里，如下图的这个服务器就是fss服务器： 再比如下面这个服务器，虽然包含nginx的组件但是httpproxy的服务器： 那么有了这样的前提，整个回滚的脚本内容如下： 12345678910111213141516171819202122232425262728293031#!/bin/bash#Written by ChrisChan @July-4th-2017#Desription:这是一个回滚的脚本。module=$(cat /etc/role_install |grep -v zkclient|grep -v nginx)echo -e '\033[31m现在将执行回滚操作，本次回滚只回滚普通模块，不包含nginx和zkclient!\033[0m' echo "回滚的模块名称："$moduleecho -e '\033[33m如果想取消回滚操作，请ctrl+c立即停止本脚本...\033[0m'sleep 5cd /dxpbackup/hswx/$module &amp;&amp; zip $module.zip -x "*og*" -r . #到备份的文件夹里去压缩mv /dxpbackup/hswx/$module/$module.zip /mnt/hswx echo $module".zip文件已经生成！" until [ "$decision" == "Y" -o "$decision" == "y" -o "$decision" == "N" -o "$decision" == "n" ]do read -p "请问是否用回滚的压缩包覆盖到/mnt/hswx下？(y/n)" decision echo "您的选择是："$decision if [ $decision == Y -o $decision == y ] then echo "现在已经开始覆盖..." rm -rf /mnt/hswx/$module #先把原来的内容删除 unzip /mnt/hswx/$module.zip -d /mnt/hswx/$module #重新解压缩进去 echo -e '\033[32m覆盖已经完成，可以直接执行/startall脚本!\033[0m' elif [ $decision == N -o $decision == n ] then echo -e '\033[32m生成的'$module'.zip文件保存在/root文件夹里\033[0m' else echo -e '\033[31m输入字符不符合!请重新输入!\033[0m' fidone 新的知识点！1）zip在压缩文件夹的时候要过滤掉某些文件使用“-x”参数，比如说要在AAA文件夹里面过滤掉abc和jqk这两个文件，那么语句就是zip AAA.zip -x &quot;abc&quot; -x &quot;jqk&quot; -r .或者是zip -r -x=abc -x=jqk AAA.zip . 这样两个语句。 如果你要过滤掉的是一个文件夹，比如那么就要在文件夹后面名字加上一个，下图就是要压缩整个auc文件夹为456.zip但是又不想要lib这个文件夹，就使用了`zip 456.zip -x “lib“ -r .`： 不过如果文件夹里还有其他lib开头的文件夹也会被过滤掉，这一点要注意。 2）本shell里面涉及了逻辑判断，而[[和[的区别如下图： 3）如果if语句中出现报错“[: too many arguments”，很有可能就是字符串变量中可能存在空格，shell解析时将其认为是多个参数，再进行判断时，无法知道该获取哪个值，所以最好都用双引号括起来； 4）如果是“变量a等于aa且变量b等于bb 或者 变量c等于cc且变量d等于dd ” 这样的判断句怎么写？答曰： [ $a = “aa” -a $b = “bb” ] || [$c = “cc” -a $d = “dd” ] 参考资料https://zhangge.net/4776.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ansible的几个基本语句]]></title>
    <url>%2F2018%2F01%2F17%2FAnsible%E7%9A%84%E5%87%A0%E4%B8%AA%E5%9F%BA%E6%9C%AC%E8%AF%AD%E5%8F%A5%2F</url>
    <content type="text"><![CDATA[开篇的废话批处理工具我最早接触的是pssh，因为它实在很简单粗暴，但是它由于太简单粗暴了，应付十台二十台机器还OK，应付五十台一百台服务器就心有余力不足了（而且xshell右键有一个“发送键入到所有会话”的功能，与pssh效果几乎一样），而且我还不太喜欢puppet，总觉得那玩意跟我八字不合，于是乎，在新头头的推荐下，我把目光放在了Ansible。 Ansible的安装很简单，在Redhat环境下直接yum install -y ansible就行。Redhat已经将Ansible公司收购了，所以在安装上提供了不小的便利。 Ansible在安装完毕之后，会在/etc/ansible/目录下看见一个叫hosts的文件，这里是所有你要控制的服务器的ip们，可以排列写，比如： 123192.168.1.122192.168.1.133192.168.1.144 也可以分组写，比如： 1234567[aliyun]10.22.33.4410.22.33.45[jinshanyun]121.23.45.66121.23.45.67121.23.45.68:2222 （这个不是使用ssh默认的22端口，就需要特别指出） 默认情况下，Ansible会把命令全用于这个hosts文件，比如 ansible all -m ping -u ashin这句话意思是整个hosts里的机器以ashin账户启动，而且都要ping 一下当前本机。 具体语句怎么连接主机与要控制的远程机器请按之前写的“http://chenx1242.blog.51cto.com/10430133/1763978”一文进行操作，这里先说几个命令语句： 1)ansible all -m shell -a &quot;/bin/echo hello&quot;对hosts里所有的机器一起使用”输出hello这个文字”。-m shell可以忽略不写，但是不是shell而是其他的模块就要写出来； 2)ansible aliyun -m copy -a &quot;src=~/projects/tests/t.py dest=~&quot;把hosts里aliyun组的机器的/projects/tests/t.py复制到~目录下；[注意！]copy模块不支持变量路径，也就是说如果目标服务器的部署路径不同，copy不会很智能的去访问.bash_profile来得到用户的自定义变量，写变量替换路径是不会达到目的的。 3)ansible jinshanyun[0:9] -i -m file -a &quot;dest=~/tests state=absent&quot;把hosts里jinshanyun组中从0~9这十台机器的/tests文件夹删除掉，absent是“缺席，不在”的意思； 4)ansible 192.168.1.133 -m ping这句话=ping 192.168.1.133； 5)ansible v1 -m service -a &quot;name=mysql state=started&quot; -u ashin --sudo -K以用户名为ashin登陆hosts里所有v1组的机器，然后检查mysql是否是started状态，若不是就start，同时要输入root的密码作为确认； 6)ansible 10.11.22.* -m user -a &quot;name=foo password=foo&quot; --sudo -Khosts文件里所有10.11.22开头的机器，都要添加一个新的用户名foo，同时密码是foo，并且输入root密码确认身份； 7)ansible v1:!v2 -m apt -a &quot;name=git state=latest&quot;检查所有属于v1组同时还不属于v2组的机器里的git文件是否是最新版本； 8)ansible webservers:&amp;dbservers -a &quot;/sbin/reboot&quot; -f 10 --sudo -K重新启动既是webservers组又是dbservers组的所有机器； 9)ansible webservers -m raw -a &#39;yum -y install python-simplejson&#39;用ansible去链接低版本的centos时，就乎出现“ansible requires a json module, none found! ”的错误，需要远程机安装samplejson包。raw模块是靠底层ssh的通讯，不依靠python的模块，所以如果碰到低版本的系统，如果command和shell模块无法使用，可以先用这条命令安装完需要的包。 10)ansible all -m synchronize -a &quot;src=/chenshuo/1.sh dest=/chenshuo delete=yes&quot;synchronize原意是“同步”，而这个模块是分发模块，这句话的意思是把控制端的/chenshuo/1.sh分发给host文件里的所有ip服务器，delete=yes意思是以控制端服务器的文件为准。 11)ansible 10.168.194.89 -m synchronize -a &quot;mode=pull src=/chenshuo/nba.txt dest=/chenshuo/a.txt&quot;将10.168.194.89这台服务器上的/chenshuo/nba.txt拉到控制服务器的/chenshuo文件夹下，顺便改名叫a.txt。 12)ansible all -m get_url -a &quot;url=https://pypi.python.org/packages/56/2b/9c9c113fb88082950067a42cc99e3c61f1df72035f89bb0bdf0a60308ca0/pexpect-4.1.0.tar.gz#md5=562a1a21f2a60b36dfd5d906dbf0943e dest=/chenshuo&quot;把那一大串网址的下载连接下载到host文件里的所有ip的/chenshuo文件夹下。 13)ansible 10.117.14.37 -m script -a &quot;/chenshuo/free.sh&quot;在10.117.14.37上执行操作端的free.sh，注意操作端必须要有free.sh这个脚本，而10.117.14.37这台机器上并不一定要有。 参考资料http://blog.csdn.net/iloveyin/article/details/46982023]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Ansible</tag>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix用户密码忘记怎么办]]></title>
    <url>%2F2018%2F01%2F17%2FZabbix%E7%94%A8%E6%88%B7%E5%AF%86%E7%A0%81%E5%BF%98%E8%AE%B0%E6%80%8E%E4%B9%88%E5%8A%9E%2F</url>
    <content type="text"><![CDATA[zabbix的超级用户也是人，人就难免会忘记密码（或者清除了当前浏览器的缓存），忘记密码不要怕，因为zabbix所有的用户数据都是保存在server机器上的mysql里，只要打开zabbix_server.conf，就会查得到mysql的登录账号密码以及zabbix对应的数据库。（这里多说一句，zabbix自带的guest基本就是一个废物，forget it~） 在zabbix_server机器上输入mysql的账号密码来到mysql里，USE zabbix，然后SELECT * FROM users,就会看到笔者的画面。 这个时候就可以使用数据库的update命令去更改密码，比如说新的密码是“woshitiancai”，就可以写update users set passwd=md5(&quot;woshitiancai&quot;) where userid=&#39;1&#39;;然后就可以用woshitiancai来登陆啦~ 但是！！！你以为这就结束了吗？nononono！！！ 很多人即使更改了密码还是登陆不上去，很简单，那就是你连用户名都忘记了！或者是用户名你记得但是你手贱在zabbix的administration里的users对原来的设定增加了新东西，而且这些东西还特么的是中文！！！于是就像我上面图那样出现了???的字样。 那些？？？很重要吗？当然了！！！因为那些才是zabbix的登录用户名！！！看见了吗，zabbix使用蛋疼的alias作为真正的登录名而不是用name or surname，这真是一个蛋疼的事儿！ 那么剩下的问题很简单了，就是把???改变成中文，使用语句set names utf8; 然后界面就成了这样： 这次再使用“主管理员”搭配新的密码就可以华丽的登录了！~~我他妈当时都差点要把这个user表格删掉然后重拽一个表格进来，但是终于还是被我识破了，啊哈哈哈哈，我真是个天才！！！]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker出现客户端与服务端有差的错误...]]></title>
    <url>%2F2018%2F01%2F16%2FDocker%E5%87%BA%E7%8E%B0%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%B8%8E%E6%9C%8D%E5%8A%A1%E7%AB%AF%E6%9C%89%E5%B7%AE%E7%9A%84%E9%94%99%E8%AF%AF%2F</url>
    <content type="text"><![CDATA[今天用docker搞redis镜像的的时候，出现了这样的错误提示：Error response from daemon: client is newer than server (client API version: 1.24, server API version: 1.22)，如图： 可见使用了docker version的时候也有提示：当前docker客户端比服务端版本更新。这样是无法创建镜像的，遇到这个问题很简单，那就是重启一下docker，命令如下： 12systemctl stop dockersystemctl start docker 然后我们再docker version看一下效果： 我做这个的时候，docker升级了也一样可以读到原先的镜像，但是出于保险起见我们也应该学会如何保存和导入镜像，比如现在我现在有这个叫docker.io/ubuntu的镜像，如图： 如果要备份它的话，语句就是： 1docker save docker.io/ubuntu &gt; /root/ubuntu.image 这里备份后的文件名就是ubuntu.image。 如果要导入的话，语句就是： 1docker load &lt; /root/ubuntu.image 这样导入的话，images create时间是不变的。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录日志系统ELKB 5.6.4的搭建过程]]></title>
    <url>%2F2018%2F01%2F16%2F%E8%AE%B0%E5%BD%95%E6%97%A5%E5%BF%97%E7%B3%BB%E7%BB%9FELKB-5-6-4%E7%9A%84%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言ELK是最近比较流行的免费的日志系统解决方案，注意，ELK不是一个软件名，而是一个解决方案的缩写，即Elasticsearch+Logstash+Kibana（ELK Stack）。这哥几个都是java系的产品，但是众所周知，java的东西很吃内存和CPU，Logstash在当作为收集日志的Agent时，就显得太过臃肿了。听说直播平台“斗鱼”团队很为logstash占用资源的情况很而苦恼，后来为了解决这个问题，他们自己写了一个agent。不过后来官方在logstash-forwarder的基础上推出了beat系列，里面包括四个兄弟，分别是：Packetbeat（搜集网络流量数据）；Topbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）；Filebeat（搜集文件数据）；Winlogbeat（搜集 Windows 事件日志数据）。而Filebeat也就这样加入了“日志收集分析”的团队里，所以虽然大家还是习惯性的叫ELK，其实准确的说法已经是ELKB了。 ELKB这几个哥们的分工如下： Elasticsearch：分布式搜索和分析引擎，具有高可伸缩、高可靠和易管理等特点。基于 Apache Lucene 构建，能对大容量的数据进行接近实时的存储、搜索和分析操作。通常被用作某些应用的基础搜索引擎，使其具有复杂的搜索功能； Logstash：数据收集额外处理和数据引擎。它支持动态的从各种数据源搜集数据，并对数据进行过滤、分析、丰富、统一格式等操作，然后存储到用户指定的位置； Kibana：数据分析和可视化平台。通常与 Elasticsearch 配合使用，对其中数据进行搜索、分析和以统计图表的方式展示； Filebeat：ELK 协议栈的新成员，在需要采集日志数据的 server 上安装 Filebeat，并指定日志目录或日志文件后，Filebeat 就能读取数据，迅速发送到 Logstash 进行解析，亦或直接发送到 Elasticsearch 进行集中式存储和分析。 设计架构 本文的设计结构就是这样，其中红色的redis/RebbitMQ部分可以省略（我这个例子里暂省略），让日志直接传递到logstash，如果日志量较大，最好还是添加上redis，同时再横向扩容Elasticsearch，搞成一个集群。 对于这几个模块服务器多说几句：1）Logstash要选择计算能力强的，CPU和内存比较丰满的；2）Elasticsearch要选择磁盘容量大的，同时CPU和内存也比较丰满的； 实验软件版本Elasticsearch 5.6.4Logstash 5.6.4Kibana 5.6.4Filebeat 5.6.4Java 1.8+，安装方法：http://blog.51cto.com/chenx1242/2043924由于ELKB这几个东西都是墙外的，墙内的下载可能会比较费劲。所以我稍后会把所有ELKB的5.6.4程序都放在51CTO的存储空间里，需要的朋友可以去下载，还是那话，虽然ELK升级频率很快，但是5.6.4已经足够稳定了。 实验服务器情况 安装Elasticsearch 5.6.4以下所有操作都是root下进行的: 12curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.4.rpmrpm -ivh elasticsearch-5.6.4.rpm 然后编辑/etc/elasticsearch/elasticsearch.yml，不然的话logstash无法与之相连： 123cluster.name: my-application #如果是集群的es就把这个打开，Elasticsearch 启动时会根据配置文件中设置的集群名字（cluster.name）自动查找并加入集群，端口是9300network.host: 0.0.0.0 #取消注释，并且改成0.0.0.0http.port: 9200 #取消注释 保存之后，启动并且添加开机启动： 12systemctl start elasticsearch systemctl enable elasticsearch 使用curl localhost:9200能看到这样的情景就证明已经成功启动了： 安装kibana 5.6.4以下所有操作都是root下进行的: 1234curl -L -O https://artifacts.elastic.co/downloads/kibana/kibana-5.6.4-linux-x86_64.tar.gztar xzvf kibana-5.6.4-linux-x86_64.tar.gzcd kibana-5.6.4-linux-x86_64/vim config/kibana.yml 把kibana.yml里的server.host: localhost改成server.host: 0.0.0.0，然后保存退出，在kibana的bin文件夹里执行./kibana即可。如果要后台启动就是nohup /kibana安装路径/bin/kibana &amp;。 启动之后，如图： 安装Logstash 5.6.4以下所有操作都是root下进行的: 12curl -L -O https://artifacts.elastic.co/downloads/logstash/logstash-5.6.4.rpm rpm -ivh logstash-5.6.4.rpm 如果安装的时候爆错：/usr/share/logstash/vendor/jruby/bin/jruby: line 388: /usr/bin/java: No such file or directory。那么就先which java查看一下java的文件，然后做一个软连接过去，然后重装logstash即可，如图： 用户可以使用TLS双向认证加密Filebeat和Logstash的连接，保证Filebeat只向可信的Logstash发送加密的数据（如果你的logstash和filebeat是内网通信，而且你认可当前内网的安全度，这一步可以省略）。同样的，Logstash也只接收可信的Filebeat发送的数据。这个功能默认是关闭的，要开启的话需要先vim /etc/pki/tls/openssl.cnf，如图： 找到[ v3_ca ]的字段，在底下添加subjectAltName = IP:logstash的内网IP字段，保存退出来到/etc/pki/tls/，执行下面命令： 1openssl req -x509 -days 365 -batch -nodes -newkey rsa:2048 -keyout private/logstash-forwarder.key -out certs/logstash-forwarder.crt 来生成一个期限为365天的IP SAN证书对，如果想生成一个十年的证书，就把365改成3650即可，如图： 安装完毕之后，vim /etc/logstash/logstash.yml，编辑成如下的样子： 然后在/etc/logstash/下手动建立一个目录conf.d，在conf.d里新建一个logstash.conf的文件，如下： 123456789101112131415161718192021222324252627282930313233343536373839$ cat /usr/local/logstash/config/conf.d/logstash.conf#在输入部分，配置Logstash通信端口以及添加SSL证书，从而进行安全通信。input &#123; beats &#123; port =&gt; 5044 ssl =&gt; true ssl_certificate =&gt; "/etc/pki/tls/certs/logstash-forwarder.crt" ssl_key =&gt; "/etc/pki/tls/private/logstash-forwarder.key" &#125;&#125; #在过滤器部分，我们将使用Grok来解析这些日志，然后将其发送到Elasticsearch。以下grok过滤器将查找“syslog”标记的日志，并尝试解析它们，以生成结构化索引。filter &#123; if [type] == "syslog" &#123; grok &#123; match =&gt; &#123; "message" =&gt; "%&#123;SYSLOGTIMESTAMP:syslog_timestamp&#125; %&#123;SYSLOGHOST:syslog_hostname&#125; %&#123;DATA:syslog_program&#125;(?:\[%&#123;POSINT:syslog_pid&#125;\])?: %&#123;GREEDYDATA:syslog_message&#125;" &#125; add_field =&gt; [ "received_at", "%&#123;@timestamp&#125;" ] add_field =&gt; [ "received_from", "%&#123;host&#125;" ] &#125; syslog_pri &#123; &#125; date &#123; match =&gt; [ "syslog_timestamp", "MMM d HH:mm:ss", "MMM dd HH:mm:ss" ] &#125; &#125;&#125; #输出部分，我们将定义要存储的日志位置output &#123; elasticsearch &#123; hosts =&gt; [ "10.162.80.192:9200" ] #这个地址是elasticsearch的内网地址 index =&gt; "filebeat-%&#123;+YYYY.MM.dd&#125;" #设定这个是索引 #index =&gt; "auclogstash-%&#123;+YYYY.MM.dd&#125;" #这行是后来作实验的，可以忽视 user =&gt; elastic #这个是为了将来装x-pack准备的 password =&gt; changeme #同上 &#125;stdout &#123; codec =&gt; rubydebug &#125;&#125; 然后就是启动并且添加开机自启动: 12systemctl start logstash systemctl enable logstash 安装filebeat以下所有操作都是root下进行的,在模块服务器上安装filebeat的方法如下: 12curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.6.4-x86_64.rpm rpm -ivh filebeat-5.6.4-x86_64.rpm 之前在logstash上生成了一个IP SAN证书，现在需要把这个证书传递给filebeat的机器里，使用scp语句如下： 1scp -pr root@10.162.80.171:/etc/pki/tls/certs/logstash-forwarder.crt /etc/ssl/certs/ #10.162.80.171就是logstash的内网IP 输入logstash的密码，并且密钥文件复制完毕之后，需要修改filebeat.yml，于是#vim /etc/filebeat/filebeat.yml： 12345678910111213141516[root@func-auc-001 log]# grep -iv '#' /etc/filebeat/filebeat.yml | grep -iv '^$'filebeat.prospectors:- input_type: log paths: - /mnt/hswx/auc/logs/*.log #这个是那个auc模块的路径 - /第二个日志路径/*.log #如果有第二个文件路径的话 tail_files: true #从文件末尾开始读取 document_type: "newnginx-api" #logstash那里已经设定了index，如果要使用了document_type，那么在logstash的index就要这么写："%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;" # 以下是规避数据热点的优化参数： spool_size: 1024 # 积累1024条消息才上报 idle_timeout: "5s" # 空闲5s上报 output.logstash: hosts: ["10.162.80.171:5044"] #这个地方要写logstash的内网地址 ssl.certificate_authorities: ["/etc/ssl/certs/logstash-forwarder.crt"] #这里就是刚刚复制的那个密钥文件路径 #注意上面是ssl而不是tls，1.0版本才是tls，如果这个写错了，启动的时候会出现“read: connection reset by peer”的错误 注意！Filebeat的配置文件采用YAML格式，这意味着缩进非常重要！请务必使用与这些说明相同数量的空格。 保存之后，使用/etc/init.d/filebeat start启动filebeat，如图： 故障解决ELK几个部件现在都已经启动了，并且互相telnet端口都是通的，在elasticsearch的服务器上使用curl -XGET &#39;http://elasticsearch内网IP:9200/filebeat-*/_search?pretty&#39;却出现这样的情况： 而使用tailf /var/log/filebeat/filebeat去查看filebeat的日志是这样的： 再看看logstash-plain.log，里面的情况是这样的： 从此可见，filebeat与logstash的联系是error状态，那么停止filebeat的进程，改用/etc/init.d/filebeat start -c /etc/filebeat/filebeat.yml，重新在elasticsearch的服务器上使用curl -XGET &#39;http://elasticsearch内网IP:9200/filebeat-*/_search?pretty&#39;发现已经成功读到了我们之前配置的目录“/mng/hswx/auc/log”，如图： 配置kibana在浏览器输入kibana服务器外网IP：5601打开kibana的web界面，把idenx pattern的地方改成filebeat-*(同之前配置的index索引一致)，然后点击create，如图： 然后就得到了细节的web界面，如图： 点击左侧框的Discover，就会看到梦寐以求的日志web界面，如图： 看一下红色框的内容里面有时间，有host主机，有source来源，还有具体的日志信息，我们再去func-auc-001这个日志源主机上查询一下日志： 两个日志是一样的，可见实现了预期的日志展示的目标！ 最后一步，就是把kibana与nginx联系起来（也可以把kibana做阿里云负载均衡的后端服务器），这样通过nginx/负载均衡来访问kibana的界面，对kibana来说更安全。配置端口监听如图，再把kibana服务器挂在负载均衡后面即可。 参考资料https://www.ibm.com/developerworks/cn/opensource/os-cn-elk-filebeat/index.htmlhttps://www.ibm.com/developerworks/cn/opensource/os-cn-elk/http://www.jinsk.vip/2017/05/24/elksetup/https://renwole.com/archives/661https://www.zybuluo.com/dume2007/note/665868https://www.elastic.co/guide/en/beats/libbeat/5.6/getting-started.htmlhttps://discuss.elastic.co/search?q=ERR%20Failed%20to%20publish%20events%20caused%20by%3A%20read%20tcphttp://jaminzhang.github.io/elk/ELK-config-and-use-Filebeat/ （这个博主很好，但是就是博客无法留言，这点比较坑）]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>大数据分析</tag>
        <tag>ELK</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从“No space left on device”到删除海量文件]]></title>
    <url>%2F2018%2F01%2F16%2F%E4%BB%8E%E2%80%9CNo-space-left-on-device%E2%80%9D%E5%88%B0%E5%88%A0%E9%99%A4%E6%B5%B7%E9%87%8F%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[开发发现某个云服务器无法启动进程，提示“No space left on device”，但是使用df -h查看容量的时候，明明还有很多的空间。于是使用df -i，发现inode节点已经全部用光了，所以现在不能建立任何新的文件。如图： 既然如此就要查出来是哪个文件夹里会有如此多的文件来占用这些inode,使用一个小脚本：for i in /*; do echo $i; find $i | wc -l; done，获取到/mnt下有一个文件占用了绝大多数的inode，如图： 于是就进入到mnt这个文件夹里，慢慢找寻到底是哪个文件夹，用上面那个语句一点一点缩小范围，最后确定文件夹原来就是data文件夹，如图： 现在如果要rm -rf data/*的话，是没有效果的，有效果的话也很慢。而且很有可能报-bash: /bin/rm: Argument list too long的错，因为这个文件夹里面的小文件实在太多了，有足足两百五十多万个，那么怎么样处理这样的情况？ 用find搭配-type f -exec rm {} \;可能会引起内存溢出，用文件夹重置命令搭配--reference也没什么效果。 这时最好的方法就是使用rsync! 先yum install rsync，当然了现在inode是饱和的状态，yum install是会报错的： 那么就需要手动删除一些文件，腾出来一部分inode供yum使用，安装完毕rsync之后，找到一个空文件夹，如果没有空文件夹，就手动建立一个。 使用命令：rsync --delete-before -a -H -v --progress --stats /空文件夹的路径/ /海量小文件的路径/ 说一下上面几个参数的意思： 123456–delete-before 接收者在传输之前进行删除操作–progress 在传输时显示传输过程-a 归档模式，表示以递归方式传输文件，并保持所有文件属性-H 保持硬连接的文件-v 详细输出模式-stats 给出某些文件的传输状态 如果你开了这个服务器的两个窗口，一个是执行上面的命令，另一个是在海量文件夹里执行ls，这个时候ls命令是卡死的，过了大约2分钟，就会看到ls展示的文件喷涌而出，整个电脑屏幕好比黑客帝国一样，异常壮观。 静等大约20分钟，整个文件夹删除干净，inode也释放了97%，世界恢复了清静。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Google Authenticator给ssh进行登录验证]]></title>
    <url>%2F2018%2F01%2F16%2F%E4%BD%BF%E7%94%A8Google-Authenticator%E7%BB%99ssh%E8%BF%9B%E8%A1%8C%E7%99%BB%E5%BD%95%E9%AA%8C%E8%AF%81%2F</url>
    <content type="text"><![CDATA[普通情况下的服务器登录，是“服务器+密码”这种直白的验证方式，但是这种方式太过简单，一旦密码泄露，服务器就有危险，于是为了安全我们就要在登录上再加一把锁，那就是使用Google Authenticator（谷歌身份验证器）这个工具，在登录的时候进行一次验证，只有“验证通过了”+“密码正确”才能登陆服务器。 安装前准备1）关闭Selinux ：setenforce 02）安装依赖：yum -y install gcc make pam-devel libpng-devel libtool wget git3）添加阿里云epel 源： 1234RHEL 6/Centos 6wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.repoRHEL 7/Centos 7wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 4）安装Qrencode，谷歌身份验证器需要调用该程序生成二维码并显示：yum install -y qrencode 安装谷歌身份验证器这个时候很多教程会让你去执行git clone https://github.com/google/google-authenticator.git，然而现在这个git里面已经不再含有libpam这个文件夹了，下载下来是一个错误的包，那么这个时候你可以使用yum install google-authenticator，不过yum安装的身份验证器的版本很老，这个时候可以执行wget https://github.com/google/google-authenticator-libpam/archive/1.04.tar.gz。 下载下来1.0.4版本的然后拆包解压缩，里面是这样几个文件： 然后就./bootstrap.sh &amp;&amp; ./configure &amp;&amp; make &amp;&amp; make install进行编译和安装。 安装过程完毕之后，还要复制google身份验证器pam模块到系统下，命令是：cp /usr/local/lib/security/pam_google_authenticator.so /lib64/security/。 调整登陆方式1）编辑/etc/pam.d/sshd这个文件，我这个centos的版本是7.0的，里面的内容可能跟centos 6.x的优点不同，不过没关系，就需要插入黄色框内的auth required pam_google_authenticator.so，如图： 修改完毕之后，保存退出。 注意！修改了这步之后，服务器千万不能断开连接，否则再连是需要google验证码的，而我们现在还没有生成码，所以肯定是无法连接服务器，如果是云服务器，可以通过登陆控制台的方式把这个文件修改回来，如果是实体服务器，那就呵呵呵了。 2）编辑/etc/ssh/sshd_config，就修改一个地方：ChallengeResponseAuthentication yes3）保存退出之后，重启一下ssh服务： 12RHEL6 /Centos6：Service sshd restartRHEL7 /Centos7：Systemctl resart sshd 生成登陆验证码这次以root用户为例，那么切换成root用户执行下面的过程。1）执行google-authenticator，由于我们之前已经安装了qrencode，那么这个时候会生成一个超级超级巨大的二维码，给各位感受一下： 红色内容是生成的密钥，很重要。绿色的内容是备用的紧急救助码，紧急救助码就是当你无法获取认证码时（比如手机丢了），可以当做认证码来用，每用一个少一个，但其实可以手动添加的，建议如果 root 账户使用 Google Authenticator 的话一定要把紧急救助码另外保存一份。 1Do you want me to update your "/home/test/.google_authenticator" file? (y/n) y 是否更新用户的 Google Authenticator 配置文件，选择 y 才能使上面操作对当前用户生效，其实就是在对应用户的 Home 目录下生成了一个 .google_authenticator 文件，如果你想停用这个用户的 Google Authenticator 验证，只需要删除这个用户 Home 目录下的 .google_authenticator 文件就可以了。 1Do you want to disallow multiple uses of the same authentication token? This restricts you to one login about every 30s, but it increases your chances to notice or even prevent man-in-the-middle attacks (y/n) y 每次生成的认证码是否同时只允许一个人使用？这里选择 y。 1By default, tokens are good for 30 seconds. In order to compensate for possible time-skew between the client and the server, we allow an extra token before and after the current time. If you experience problems with poor time synchronization, you can increase the window from its default size of +-1min (window size of 3) to about +-4min (window size of 17 acceptable tokens). Do you want to do so? (y/n) n 是否增加时间误差？这里随便选择， ny都可以。 1If the computer that you are logging into isn't hardened against brute-force login attempts, you can enable rate-limiting for the authentication module. By default, this limits attackers to no more than 3 login attempts every 30s. Do you want to enable rate-limiting (y/n) y 是否启用次数限制？这里选择 y，默认每 30 秒最多尝试登录 3 次。 如果想要写成脚本的话，那么上面交互式的设置也可用通过参数一次性设置：google-authenticator -t -f -d -l test@chen.super -i MR.chen -r 3 -R 30 -W。 -I和-i是可以随便写的，但是-i后期可以改，-I不能改。 搭配手机端如果手机是ios，就去apple store里搜索“Google Authenticator”，如果是安卓，就去应用商店搜索“谷歌动态口令”。 安装完后，打开App，点击“开始设置”，选择“扫描条形码”扫描上面google-authenticator命令生成的二维码，或者是选择“输入密钥”，然后手机上就能看到对应的六位数认证码了。 最后一步，返回xshell，修改登陆方式，设置登陆方法为Keyboard Interactive，如图： 这个时候，推荐各位保留原有的ssh不要动，在另外一个xshell窗口登陆一下看看效果，如果正常的话，这个时候会看到系统会让你先输入一个Verification code。这个值就是手机里的那个六位数，然后再输入密码，只有两个都是正确的，才能登陆！ 至此整个配置完成，如果登陆时遇到问题，请查看日志文件/var/log/secure。 更改存储位置在生成二维码那一步的时候，如果你错过了记住密钥也不要怕，系统会自动把密钥和紧急救助码保存在~/.google_authenticator这个文件里。 如果想要改变密钥存储位置，请使用–secret参数:google-authenticator --secret=&quot;/文件路径/用户名&quot;。 然后更改/etc/pam.d/sshd内的路径配置:auth required pam_google_authenticator.so user=root secret=/PATH_FOLDER/${USER}。 上面那句话里“user=root” 用于强制PAM使用root用户权限来搜索文件。 另外请注意，由于我们当时切换成了root用户，所以密钥文件的所有者是root，生成文件的用户只能读取文件(chmod: 400)： 12chown root.root /PATH_FILE/SECRET_KEY_FILESchmod 400 /PATH_FILE/SECRET_KEY_FILES 使用chrome浏览器查看mfa如果你没有带手机，如何查看mfa呢？请使用chrome的插件http://gauth.apps.gbraad.nl/ 。 然后手动添加即可，但是要注意，这台电脑不能断网太久哦，不然就会自动删除。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记录一次处理https监听不正确的过程]]></title>
    <url>%2F2018%2F01%2F12%2F%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E5%A4%84%E7%90%86https%E7%9B%91%E5%90%AC%E4%B8%8D%E6%AD%A3%E7%A1%AE%E7%9A%84%E8%BF%87%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[今天开发反馈在测试金山云设备的时候遇到了这样的一个现象：123456wget https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 11:49:26-- https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 Resolving funchlscdn.lechange.cn... 120.92.158.134 Connecting to funchlscdn.lechange.cn|120.92.158.134|:443... connected. OpenSSL: error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol Unable to establish SSL connection. 爆“error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol”的错误，就是在当向只提供http的服务发送https请求造成的。 ping funchlscdn.lechange.cn，获得了这个域名对应的IP之后，返回到金山云的控制台查询这个IP，发现这个IP是一个负载均衡，但是这个负载均衡配置的时候对80端口是http协议，而对443端口还是http协议，于是更改成https，重新测试之后，发现错误变成了这样：123456[root@js-develop ~]# wget https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 16:08:15-- https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Resolving funchlscdn.lechange.cn... 120.92.158.134Connecting to funchlscdn.lechange.cn|120.92.158.134|:443... connected.HTTP request sent, awaiting response... 502 Bad Gateway2017-07-26 16:08:15 ERROR 502: Bad Gateway. 在浏览器打开效果如图： 502 Bad GatewayThe proxy server received an invalid response from an upstream server. KSYUN ELB 1.0.0 同时发现金山云负载均衡里对nginx的8000健康检查是“异常”。但是使用http访问却是可以的，效果如下：12345678910111213[root@js-develop ~]# wget http://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 15:31:55-- http://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Resolving funchlscdn.lechange.cn... 120.92.158.134Connecting to funchlscdn.lechange.cn|120.92.158.134|:80... connected.HTTP request sent, awaiting response... 302 FoundLocation: http://120.92.133.76:8090/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 [following]--2017-07-26 15:31:55-- http://120.92.133.76:8090/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Connecting to 120.92.133.76:8090... connected.HTTP request sent, awaiting response... 200 OKLength: 66 [application/x-mpegURL]Saving to: “dev_20170726085033_lpxh73ezzb92xxa8.m3u8”100%[========================================================================================================================================================&gt;] 66 --.-K/s in 0s 2017-07-26 15:31:55 (3.02 MB/s) - “dev_20170726085033_lpxh73ezzb92xxa8.m3u8” saved [66/66] 于是就叫来开发问一下http和https详细的流程，开发说在http里，设计路线如下：1http(80)-&gt;开发模块(9001) 而在https里，设计路线如下：1https(443)-&gt;nginx(8000)-&gt;开发模块(9001) 这时候就发现了问题，原来最早的时候金山云是没有配置https证书的，于是开发们就用nginx的8000端口去监听ssl这样达到https证书的效果，但是后来金山云控制台添加了https证书，就不再需要nginx去配置ssl证书了，再去https监听8000这一步也就是错误的了，于是在负载均衡那里改成了：1https(443)-&gt;开发模块(9001) 同时关闭了nginx，这时候再来测试一下https请求，就成功了！ 其实如果非要用nginx的ssl证书的话，那么的套路就是：开启nginx，但是在负载均衡那里使用tcp协议去监听nginx的8000端口，这样一样能达到效果。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>https</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Next主题添加音乐和将侧栏移动到左边]]></title>
    <url>%2F2018%2F01%2F12%2Fnext%E4%B8%BB%E9%A2%98%E6%B7%BB%E5%8A%A0%E9%9F%B3%E4%B9%90%E5%92%8C%E4%BE%A7%E6%A0%8F%E5%B7%A6%E7%A7%BB%2F</url>
    <content type="text"><![CDATA[玩Github博客也有一个多月的时间了，现在这个博客也被我折腾的有点样子了，目前博客里添加了如下功能：1.支持头像图片旋转，同时点击头像可以返回主页；2.背景图片随机出现，而且墙内用户也可以顺利访问；3.增加文章打分系统，觉得好可以给五星好评；4.开放评论系统，无需注册直接评论；5.添加了可视加载栏和公益404页面；6.添加桌面小宠物和访客统计；7.添加博客运行时间和代码橙色高亮； 目前欠缺的功能一个是“相册”，还有一个就是博客标题的加载方式希望更加高逼格。至于SEO和单独域名，我暂时还没有想去做，等将来再加上吧。而这篇文章里主要说的就是“博客添加音乐”和“侧栏左移”这两个事儿。 博客添加音乐Next主题添加网易云音乐不是一个很难的事儿，但是我发现对于非大陆的IP地址（比如我用的是公司VPN，香港IP），侧栏的网易云音乐就无法播放，而且打开博客页面就自动播放音乐这点对来访的用户来说，体验感觉是见仁见智。所以我打算把侧栏的网易云音乐撤掉，在“关于我”里单独放进音乐歌单。 若单独配置音乐同时不想被IP地址打扰的话可以使用由DIYgod所制作的APlayer。官方材料在这里：https://aplayer.js.org/docs/#/?id=options 。 要使用APlayer需要先在hexo根目录里安装插件：npm install aplayer --save 安装插件OK了后，具体在文章里添加的语法就是： 注意：如果lrc用的是这种URL形式，hexo g时请保持网络通畅，如果没有歌词，可以不用添加。 现在的世面上很少有在线提供歌曲MP3地址的网站了，很多都是下载mp3到本地，这里我推荐一个免费下载MP3的网站：https://www.tikitiki.cn 。里面有QQ音乐、网易云音乐和酷狗的资源，基本上大陆没有被封杀的艺人作品都能在里面找到（抱歉了，陈升先生和黄耀明先生）。然后再搭配七牛云，把下载的MP3和封面图片上传到七牛云存储里，然后搭配提供的外网域名就可以填写MP3地址和封面地址了。如图： 如果想做一个歌单，也很简单，如下：1234567891011121314151617181920212223&#123;% aplayerlist %&#125; &#123; "autoplay": false, "showlrc": 3, "mutex": true, "music": [ &#123; "title": "歌曲名", "author": "歌手名", "url": "https://具体地址.mp3", "pic": "https://封面图.jpg", "lrc": "https://歌词.lrc" #不愿意加歌词可以不写，注意逗号 &#125;, &#123; "title": "歌曲名", "author": "歌手名", "url": "https://具体地址.mp3", "pic": "https://封面图.jpg", "lrc": "https://歌词.lrc" &#125; ] &#125;&#123;% endaplayerlist %&#125; 不过我这个七牛云的账号比较挫，没有做https，只好用http了… 把侧栏移动到左边博客自从安装了宠物之后，发现小宠物与侧栏重叠，看上去感觉很不友好，但是很奇怪，默认的宠物即使调整了botton依旧无法移动，所以我就想那就把整个侧栏移动到了左边，但是发现更改next主题的_config.xml里的“sidebar的position属性”发现并没有效果，后来经过一顿查找，找到了改成左侧栏的方法(适用于next 5.1.3版本)。 首先，先更改\themes\next\source\css\_common\components\sidebar\sidebar.styl，把第三行的right改成left,如下：123.sidebar &#123; position: fixed; left: 0; 保存之后，打开\themes\next\source\js\src\motion.js，把101行和167行的paddingRight全改成paddingLeft,同时找到类似如下的代码，并替换成如下代码:123456789101112131415161718192021var sidebarToggleLine1st = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-first', status: &#123; arrow: &#123;width: '50%', rotateZ: '45deg', top: '2px', left: '5px'&#125;, close: &#123;width: '100%', rotateZ: '45deg', top: '5px', left: 0&#125; &#125;&#125;);var sidebarToggleLine2nd = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-middle', status: &#123; arrow: &#123;width: '90%'&#125;, close: &#123;opacity: 0&#125; &#125;&#125;);var sidebarToggleLine3rd = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-last', status: &#123; arrow: &#123;width: '50%', rotateZ: '-45deg', top: '-2px', left: '5px'&#125;, close: &#123;width: '100%', rotateZ: '-45deg', top: '-5px', left: 0&#125; &#125;&#125;); 保存完毕之后，hexo clean和hexo d -g。刷新一下页面，就大功告成了！ 参考资料https://reuixiy.github.io/technology/computer/computer-aided-art/2017/06/09/hexo-next-optimization.html#hcm=1515719347596232 （这篇文章强烈推荐！）http://www.lmnsyunhao.cn/2017/03/29/hexo-next-themes-left-sidebar/http://mashirosorata.vicp.io/HEXO-NEXT主题个性化配置.html]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
        <tag>Next</tag>
        <tag>博客美化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix监控ActiveMQ队列数以及结合Grafana展示]]></title>
    <url>%2F2018%2F01%2F11%2FZabbix%E7%9B%91%E6%8E%A7ActiveMQ%E9%98%9F%E5%88%97%E6%95%B0%E4%BB%A5%E5%8F%8A%E7%BB%93%E5%90%88Grafana%E5%B1%95%E7%A4%BA%2F</url>
    <content type="text"><![CDATA[在ZABBIX上监控MQ队列众所周知，Zabbix是可以自定义监控项的，那么就代表只要能获得到的数字都可以进入Zabbix的监控范围内。作为消息队列，Activemq里的“消息堆积数”是监控的重点项目之一。 获取消息堆积数并不是一个很难的事儿，浏览器里登陆MQ的web网页控制台，输入账号密码之后，在Queues的网页里就能看到如下的界面： 其中Pending Messages就是“等待消息”，Consumers是“消费者”，Enqueued是“入队”，Dequeued是“出队”。入队数=出队数+等待数。 现在我们要获取到图中的队列叫AggregateQueue里的那个23596，很简单，shell语句是： 1curl -s -u网站用户名:网站密码 http://网站外网IP地址:8161/admin/queues.jsp | grep -A 5 "具体的队列名&lt;/a&gt;&lt;/td&gt;"|awk -F '&lt;' '&#123;print $2&#125;'|sed 's/td&gt;//g'|head -2|tail -1 这里curl有一个-s的参数，不然会显示curl的状态。如图： 语句在此，写脚本就很easy了。不过我这里就直接监控具体数字了，没有写脚本，如果要写python脚本的话，我推荐各位移步：http://blog.51cto.com/sfzhang88/1316789 ，看一下这篇文章。 现在把这个监控项添加到具体的zabbix_agentd.conf里吧，具体添加过程可以参看 http://blog.51cto.com/chenx1242/1839829 ，由于是curl网站，那么直接把这个监控项加到Zabbix-server里就好，然后使用zabbix_get检查一下。有的zabbix 3.x里没有zabbix_get，安装zabbix_get方法：yum install zabbix-get.x86_64。 zabbix_get检查情况和具体的trigger情况如下： 配置Zabbix结合Grafana我使用的Grafana版本是4.3.2，下载地址：https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.3.2-1.x86_64.rpm ，下载完毕之后，直接yum install /路径/grafana-4.3.2-1.x86_64.rpm，由于Grafana使用的是AWS的云存储，可能在墙内的下载会比较吃力，有断开的情况就多试几次。话说Grafana的升级是比较频繁的，半年不到的时间升级了三次，现在最新版本已经是4.6.2。所以说这玩意，其实选择一个稳定的就好。 启动grafana的方法就是：systemctl start grafana-server.service，配置开机自启动的方法：chkconfig grafana-server on。然后在浏览器里输入grafana外网ip地址：3000就能看到grafana的界面，默认密码：admin/admin，grafana默认的日志存储路径是/var/log/grafana/。 Grafana与ZABBIX联系的插件下载方式：grafana-cli plugins install alexanderzobnin-zabbix-app，安装之后，重启一下grafana-server，在web界面就会看到插件已经成功安装，如图： 其他更多的插件下载可以在grafana的官方网站查看到：https://grafana.com/plugins ，用grafana-cli都能搞定，还是那话，墙里的同学速度要慢一点。 现在配置Zabbix作为Grafana的数据源，首选点击网站上面的红色漩涡标志，选择zabbix，点击Plugin Config，点击Enable，启动Zabbix插件。如图： 再次点击红色漩涡，这次选择Data Sources，点击Add data source，如果插件启动成功，那么在Type里是可以选择zabbix的，然后就是填各种东西，如图： 这里有一些要额外说明：1）url这个是zabbix的API地址http://ip/zabbix/api_jsonrpc.php，这个可以在zabbix服务端上可查找find / -name api_*.php；2）username和passwd是zabbix WEB界面的登录用户名和密码，有读的权限即可；3）alerting选择启动，min severity选择high； 然后点击save &amp; test，如果都正确的话，就会出现success，如图： 在Grafana展示趋势图点击左上方红色漩涡，Dashboards的地方点击+new，然后在小齿轮的地方选择Templating,如图： 在Templating里要建立4个模板，其中group的添加方法如下，如果Query正确的话，在点击Include All option的时候，就会有“组”显示出，而且和zabbix里完全一致： group添加完了，还有host、application、iteams，添加的大同小异，需要注意的是Query的不同：host的Query：$group.*application的Query: $group.$host.*iterm的Query:$group.$host.$application.* 以上四个template都搞定之后，应该是这个样子： 模板搞定了，下面就是图形展示，选择对应的hosts、application和items就自动有图像生成了！ 最后说一下页面自动刷新，点击右上角“Last 6 hours”, 在弹出的下拉框中，选择Time range下的Refreshing every选项，点击下拉框按钮，默认应该有“off”和“1m”两个选项。点击“1m” 然后Apply设置，即为每一分钟刷新一次数据的意思。设置成功后，在原来Last 6 hours的后面会出现Refresh every 1m的橙色文字！ 参考资料《实践MQ的小demo》http://www.jianshu.com/p/3a39c8dd4f29]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>zabbix</tag>
        <tag>grafana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Python使用yaml的几个例子]]></title>
    <url>%2F2018%2F01%2F11%2F%E5%9C%A8Python%E4%BD%BF%E7%94%A8yaml%E7%9A%84%E5%87%A0%E4%B8%AA%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[python版本：2.7.5安装方法：pip install PyYaml “把变量写进yaml做配置文件，然后python脚本从yaml文件里面取到变量”的方法最近是在python编程里比较流行的配置项方法。yaml更加易读，而且通过缩进表示结构，这一点与python不谋而合。 Yaml有四个比较常用的用法，分别是load()、dump()、load_all()、dump_all()。这篇文章主要就是了解一下这四个方法。 首先我们先写一个很简单的test.py： 12345678910111213# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlyaml_str = """name: Gakkiage: 29job: Actressrelationship: Wife""" aaa = yaml.load(yaml_str)print aaa 执行的话，看到的效果就是： 12[root@paas-online-crs-001 chentest]# python test.py &#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125; 这个aaa的类型是一个字典（dict），如果要得到里面那个”Gakki”，那么就是aaa[&#39;name&#39;]。通过load方法，一个字符串变成了一个字典。 现在把test.py换成如下： 123456789101112# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlyaml_dict = &#123;"name": "Gakki", "age": 29, "job": "Actress", "relationship": "Wife" &#125;aaa = yaml.dump(yaml_dict, default_flow_style=False)print aaaprint (type(aaa)) 执行后的效果如下： 123456[root@paas-online-crs-001 chentest]# python test.py age: 29job: Actressname: Gakkirelationship: Wife&lt;type 'str'&gt; 可见，通过dump方法，把一个dict变成了一个字符串。 现在写一个配置文件，假如它叫test.yaml: 1234- Gakki- 29 - Actress- Wife 再来一个test.py，内容如下: 1234567# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yaml aaa = yaml.load(file('test.yaml', 'r'))print aaaprint (type(aaa)) 执行这个test.py： 123[root@paas-online-crs-001 chentest]# python test.py ['Gakki', 29, 'Actress', 'Wife']&lt;type 'list'&gt; #得到了一个列表 如果把那个test.yaml升级成字典和列表的混合结构，如下： 1234567- name: Chris age: 29 job: OM Engineer- name: Gakki age: 29 job: Actress relationship: Wife 执行test.py的效果如下： 123[root@paas-online-crs-001 chentest]# python test.py [&#123;'job': 'OM Engineer', 'age': 29, 'name': 'Chris'&#125;, &#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125;]&lt;type 'list'&gt; 既然获得的结果是一个包含字典的列表，那么如果要获得“Gakki”就是aaa[1][&#39;name&#39;] 如果想要复制和引用，那么要用&amp;和*，比如把test.yaml改成这样： 12name: &amp;name Gakkiwife: *name 执行test.py的效果如下： 123[root@paas-online-crs-001 chentest]# python test.py &#123;'name': 'Gakki', 'wife': 'Gakki'&#125;&lt;type 'dict'&gt; 在同一个yaml文件中，可以用 — 来分段，这样可以将多个文档写在一个文件中： 123456789--- name: Chris age: 29 job: OM Engineer--- name: Gakki age: 29 job: Actress relationship: Wife 再写一个新的test.py如下: 123456# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlys = yaml.load_all(file('gakki.yaml', 'r')) #load_all() 方法会生成一个迭代器，可以用for输出出来for y in ys: print y 执行这个py的效果： 123[root@paas-online-crs-001 chentest]# python test.py &#123;'job': 'OM Engineer', 'age': 29, 'name': 'Chris'&#125;&#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125; 参考文档：https://huilansame.github.io/huilansame.github.io/archivers/recommond-case-file-type-yaml]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Zabbix去监控Redis]]></title>
    <url>%2F2018%2F01%2F10%2F%E4%BD%BF%E7%94%A8Zabbix%E5%8E%BB%E7%9B%91%E6%8E%A7Redis%2F</url>
    <content type="text"><![CDATA[了解Redis的info要获得Redis的当前情况，使用info命令即可。具体用法：redis-cli -h 127.0.0.1 -p 6379 -a redis_passwd info [参数] 。针对不同的参数就会看到具体的数字，如果没有带参数，那么就会把默认情况写出来，如果带上all参数，那么就会把所有情况都写出来。比如：redis-cli -h 127.0.0.1 -p 6379 -a redis_passwd info server，就会看到redis关于server的一些数据，如下：可以看出，从server里可以查询到的是版本号、pid号、配置文件路径等等东西。 如果参数是client，记录了是客户端的相关信息： 123456[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info clients# Clientsconnected_clients:64 #已连接客户端的数量（不包括通过从属服务器连接的客户端）client_longest_output_list:0 #当前连接的客户端当中，最长的输出列表client_biggest_input_buf:0 #当前连接的客户端当中，最大输入缓存blocked_clients:0 #正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量 如果参数是memory，记录的是内存的相关信息： 12345678910[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info memory# Memoryused_memory:2252984 #由 Redis 分配器分配的内存总量，以字节（byte）为单位used_memory_human:2.15M #上面的数字加上了单位used_memory_rss:9293824 #常驻集大小，即Redis已分配的内存总量。这个值和top、ps等命令的输出一致used_memory_peak:2607520 #Redis 的内存消耗峰值（以字节为单位）used_memory_peak_human:2.49M #上面的数字加上了单位used_memory_lua:33792 #Lua 引擎所使用的内存大小（以字节为单位）mem_fragmentation_ratio:4.13 #used_memory_rss 和 used_memory 之间的比率mem_allocator:jemalloc-3.2.0 #在编译时指定的，Redis所使用的内存分配器。可以是libc、jemalloc或者tcmalloc。 这里要注意！在理想情况下， used_memory_rss 的值应该只比 used_memory 稍微高一点儿（我这个机器就已经属于严重的级别了）。当 rss &gt; used ，且两者的值相差较大时，表示存在（内部或外部的）内存碎片。内存碎片的比率可以通过 mem_fragmentation_ratio 的值看出。当 used &gt; rss 时，表示 Redis 的部分内存被操作系统换出到交换空间了，在这种情况下，操作可能会产生明显的延迟。 如果参数是stats，那就是统计的相关信息： 12345678910111213141516[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info stats# Statstotal_connections_received:150383 #服务器已接受的连接请求数量total_commands_processed:500935 #服务器已执行的命令数量instantaneous_ops_per_sec:0 #服务器每秒钟执行的命令数量rejected_connections:0 #因为最大客户端数量限制而被拒绝的连接请求数量sync_full:0 sync_partial_ok:0 sync_partial_err:0 #查找数据库键成功的次数expired_keys:41 #因为过期而被自动删除的数据库键数量evicted_keys:0 #因为最大内存容量限制而被驱逐（evict）的键数量keyspace_hits:78121 #查找数据库键成功的次数keyspace_misses:56 #查找数据库键失败的次数pubsub_channels:0 #目前被订阅的频道数量pubsub_patterns:0 #目前被订阅的模式数量latest_fork_usec:878 #最近一次 fork() 操作耗费的微秒数 如果参数是CPU，那么就会返回CPU的相关信息： 123456[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info cpu# CPUused_cpu_sys:63.95 #Redis服务器耗费的系统CPUused_cpu_user:129.54 #Redis服务器耗费的用户CPU used_cpu_sys_children:1.70 #子进程耗费的系统CPUused_cpu_user_children:1.03 #子进程耗费的用户CPU 如果参数是keyspace，那么就会返回数据库相关的统计信息： 123[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info keyspace# Keyspacedb0:keys=262,expires=183,avg_ttl=284091259423 #据库的键数量、数据库设置有过期时间的key的数量（这个值减少是正常的） 除了以上之外其他还有更多信息，请移步：http://redisdoc.com/server/info.html 。感谢前人栽树！！！ 使用zabbix监控redis用zabbix监控redis是一个很简单的事儿，只需要把需要监控的数据提取出来即可。而提取数据的方法就是利用info去得到对应的数值。 首先先来一个判断redis服务器连接的脚本： 1234567891011[root@func-redis-001 ~]# cat check_redis.sh#这个脚本是用来zabbix监控自建redis的#!/bin/bashPORT='6379'PASSWD=‘REDIS密码’ STATUS_redis=$(redis-cli -h '127.0.0.1' -p $PORT -a $PASSWD ping)if [ "$STATUS_redis" == 'PONG' ];then echo '1'else echo '0'fi 然后更改zabbix_agentd.conf,如下： 12UserParameter=redis_status[*],redis-cli -h '127.0.0.1' -p $1 info | grep -w $2 | awk -F':' '&#123;print $NF&#125;'UserParameter=redis_ping,sudo sh /root/check_redis.sh 修改/etc/sudoers文件如下： 1234## Allow root to run any commands anywhereroot ALL=(ALL) ALLzabbix ALL=(ALL) NOPASSWD:ALL #这个是新增Defaults:zabbix !requiretty #这个是新增 保存之后，重启zabbix-agent服务，由于我这个redis是通过zabbix-proxy监控的，所以在zabbix-proxy一端用zabbix_get来查看结果： 然后在zabbix-proxy的模板里面添加一些需要监控的item即可，有必要的话可以设置trigger+action用来报警，如图： 最后就是grafana搞一个炫酷的图表来，如图： 最后一点，关于redis的内存优化，各位可以来看看：https://cachecloud.github.io/2017/02/16/Redis%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/ ，写的很全面了。还有zabbix各种模板整理，有需要的同学也可以去下载：https://monitoringartist.github.io/zabbix-searcher/ 。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过nginx配置修改网页cookie属性]]></title>
    <url>%2F2018%2F01%2F10%2F%E9%80%9A%E8%BF%87nginx%E9%85%8D%E7%BD%AE%E4%BF%AE%E6%94%B9%E7%BD%91%E9%A1%B5cookie%E5%B1%9E%E6%80%A7%2F</url>
    <content type="text"><![CDATA[需求与具体配置公司的电子商城在十九大等保安检时期被折腾出去，结果这几天又折腾回来了，据说还会是明年大数据研究院的主要开发项目。结果回来没几天被测试中心的人在cookie方面发现了几个问题，如下： cookie没有使用http-only； cookie没有携带secure属性； http头中需要配置“X-Frame-Options：SAMEORIGIN”； 以上这几点可以通过nginx的配置来轻松实现，具体方法就是在需要更改的网页server的配置里面添加下面几句话。如图： 123add_header Set-Cookie "HttpOnly";add_header Set-Cookie "Secure";add_header X-Frame-Options "SAMEORIGIN"; 然后保存配置文件，nginx -s reload平滑重启即可，通过chrome在目标网页里按下ctrl+shift+c，先选择好network，然后重新刷新一下界面，选择域名，对应域名下点击headers，就会看到cookie的配置情况，如图： 扩展内容看到配置已经生效。那么这几个配置主要是干什么的呢？其实主要都是防范XSS攻击（跨域脚本攻击）的。 Cookie的Secure属性，意味着保持Cookie通信只限于加密传输，指示浏览器仅仅在通过安全/加密连接才能使用该Cookie。如果一个Web服务器从一个非安全连接里设置了一个带有secure属性的Cookie，当Cookie被发送到客户端时，它仍然能通过中间人攻击来拦截。 Cookie的HttpOnly属性，指示浏览器不要在除HTTP（和HTTPS)请求之外暴露Cookie。一个有HttpOnly属性的Cookie，是不可以通过例如调用JavaScript(引用document.cookie)这种非HTTP方式来访问。因此，也不可能通过跨域脚本（一种非常普通的攻击技术）来偷走这种Cookie。 X-Frame-Options HTTP 响应头是用来给浏览器指示允许一个页面可否在frame, iframe或者object中展现的标记。网站可以使用此功能，来确保自己网站的内容没有被嵌到别人的网站中去，也从而避免了点击劫持 (clickjacking) 的攻击。它有三个可选择项： 123DENY：表示该页面不允许在 frame 中展示，即便是在相同域名的页面中嵌套也不允许；SAMEORIGIN：表示该页面可以在相同域名页面的 frame 中展示；ALLOW-FROM uri地址：表示该页面可以在指定来源的 frame 中展示； 如果设置为 DENY，不光在别人的网站 frame 嵌入时会无法加载，在同域名页面中同样会无法加载。另一方面，如果设置为 SAMEORIGIN，那么页面就可以在同域名页面的 frame 中嵌套。 这里还要额外注意一下！配置了Cookie的HttpOnly属性和Secure属性之后，如果测试中心的人使用的协议是http而不是https的话，会有“浏览器请求后端服务时header不会带上cookie参数”的现象，那是因为“由于secure属性的存在，导致浏览器在与服务器通信时不会使用该cookie”。这个时候就需要把secure=”true”这个配置去掉才可以达到正确测试的目的。 参考资料https://imququ.com/post/my-nginx-conf-for-security.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维技术</tag>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[django新增class的时候数据库格式出错]]></title>
    <url>%2F2018%2F01%2F10%2Fdjango%E6%96%B0%E5%A2%9Eclass%E7%9A%84%E6%97%B6%E5%80%99%E6%95%B0%E6%8D%AE%E5%BA%93%E6%A0%BC%E5%BC%8F%E5%87%BA%E9%94%99%2F</url>
    <content type="text"><![CDATA[这几天开发频繁要求查看生产环境zookeeper的配置，于是就想在django里添加一个新的栏，以文本的形式随时更新zookeeper的情况。 于是我就登陆了django，在model.py里添加一个新的class，如下： 12345678#建立杭州测试ZK配置class HZfunczk(models.Model): hzfunczk_remark = models.CharField(verbose_name='杭州测试ZK配置',max_length=50000,blank=true) hzfunczk_signer = models.CharField(verbose_name='登记人',max_length=30,default='system') hzfunczk_signtime = models.DateField(auto_now_add=True) def __unicode__(self): return self.domain_name 然后在django的目录下执行python manage.py makemigrations，这一步没问题，但是在执行python manage.py migrate的时候，就出现了下面的错误： 我开始认为是charfield写错了，应该写Textfield，于是更改了一下，但是保存之后，再执行python manage.py migrate还是出错。其实这个错误主要原因就是因为我那个50000设置错了，因为字段hzfunczk_remark定义的长度50000超出了mysql的varchar的最大长度21845（在utf8编码情况下）。于是我就在model.py里把这个长度改成20000，保存之后，还是执行到python manage.py migrate这一步，依旧爆上面的错误。于是我就干脆把这个class先删除掉，没想到都删除光了，还是在make的时候会爆错。 这就很奇怪了，我已经删掉了为啥还有这样的事儿？于是就干脆进入到数据库去看，由于我现在只知道列名叫hzfunczk_remark，所以我要根据这个列名去查它所在的表，maria反馈如下： 12MariaDB [abccs]&gt; select TABLE_SCHEMA, TABLE_NAME from information_schema.columns where COLUMN_NAME = 'hzfunczk_remark'; Empty set (0.02 sec) 好尴尬呀，数据库里压根就没有列名为“hzfunczk_remark”的表。然后由于python manage.py migrate报错，现在无法启动django。怎么办？ 遇到这种状况，就去django里的migrations文件夹，这个文件夹里有很多的以时间命名的py文件，它们记录着数据库的每一步操作，不过这里面的py还没有真正执行到数据库里，我找到当时添加class那个时间段的py文件，里面是这样的： 先把里面CharField改成TextField，然后把50000改成小于21845的就行了。如果你性子比较烈，那就干脆把这个文件以及之后产生的所有文件都删除掉。重新的去make。 如果还是实在不行，还有一个万不得已的办法，几乎所有的数据库错误都可以用这个方法解决：将migrations文件夹下的文件除了init.py全部删掉，然后将数据库drop掉，重新建数据库。然后make和migrate，就可以使用一个新的数据库（但愿你永远用不到这个方法）。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>django</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通道信息加密工具--Qtunnel]]></title>
    <url>%2F2018%2F01%2F10%2F%E9%80%9A%E9%81%93%E4%BF%A1%E6%81%AF%E5%8A%A0%E5%AF%86%E5%B7%A5%E5%85%B7-Qtunnel%2F</url>
    <content type="text"><![CDATA[前言数据库做异地容灾是一个很常见的现象，既然信息要跨地域传递，要么就很土豪的打通机房之间的链路或者动用VPN，要不然就不可避免的走公网网络传输信息。既然选择了公网，那么数据库的语句就很容易被人监听到，所以把那些明文加密是必不可少的环节。 mysql支持tls/ssl加密方法对信息进行加密，这个方法的配置也很简单，就是两边各加上一个nginx，一个是正向代理一个是反向代理，配上ssl证书，然后就像配置网站https协议那样，在nginx.conf里开启ssl监听即可。 但是这种方法有一点小问题，就是在进行SSL握手之前，mysql会发送Server Greeting和Login Request数据包，然后才有可能使用SSL握手。这样步骤就多了一步鉴权，对访问性能有所影响。所以这个时候，我选择了另一个用于加密client和server之间链路通信的工具—-Qtunnel，因为它直接加密，速度更快。 Git的地址在这里：https://github.com/arstercz/qtunnel ，感谢arstercz大神的再加工！ 上面说过了Qtunnel是不需要认证的，默认加密方法是RC4，以字节流的方式加密明文的每一个字节，而且密钥长度最长支持256位，可以很好的抵御暴力搜索密钥的攻击，总而言之，Qtunnel是一个轻量且快速的加解密工具，而且还可以搭配atlas等数据库中间件使用。 下载与准备由于Qtunnel是用go语言写的，所以需要先安装golang，centos服务器的yum安装方法如下: 12rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpmyum install -y golang go语言安装完毕之后，我们就git clone https://github.com/arstercz/qtunnel.git ，获得qtunnel文件夹，文件夹内容如下： make，如果没有任何报错，那么就是安装成功了，使用./bin/qtunnel -h语句验证一番： 本次实验的计划是这样的：用A机器访问B机器的mysql，并且插入数据，在B机器上的3306端口抓包，查看数据是否是明文；然后再在A机器和B机器上都安装qtunnel并且启动，然后重新插入数据，在B机器上的端口抓包，查看数据是否被加密。流程图如下： 实验开始A机器和B机器都是使用阿里云虚拟服务器，版本都是centos 6.4，现在我们的加密实验正式开始。 首先A和B机器上都不启动qtunnel，然后我们在A机器上登陆B机器的数据库，如果之前没有授权，那么授权语句是： GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;A机器的IP地址&#39; IDENTIFIED BY &#39;密码&#39; WITH GRANT OPTION; 登陆mysql之后，我们随意的插一个语句，然后通过抓包发现无论这个语句还是数据库的反馈都是以明文的形式呈现，如图： 这种让数据裸奔的行为无疑于找死，那么这个时候我们就要配置一下qtunnel，来看一下它的加密效果。 在A服务器上，我们设定qtunnel是客户端，手动建立一个conf文件，比如vim /etc/conn.conf，内容如下： 123456[client1]faddr = 10.252.215.108:3309 #这里是qtunnel客户端的IPbaddr = 10.175.193.239:3310 #这里是qtunnel服务端的IPcryptoMethod = rc4 #这里选用rc4的方式加密secret = 3301_test%Iad #rc4密钥，服务端的密码必须跟这个一致！clientmode = true #表示这端是客户端 然后使用./bin/qtunnel -conf=/etc/conn.conf -daemon -logto=syslog启动qtunnel，看一下进程和端口情况，如图： 在B服务器上，同样手动建立一个配置文件，假设也叫conn.conf，内容如下： 123456[server1]faddr = 10.175.193.239:3310 #这里是qtunnel服务端的IPbaddr = 10.175.193.239:3306 #这里是数据库的地址，由于在同一台机器上，所以地址一样cryptoMethod = rc4 secret = 3301_test%Iad #rc4密钥，跟client密钥一致clientmode = false #表示这是服务器端 也用同样的语句启动qtunnel，查看3310这个端口已经被监听了： 现在，我们在A服务器上来重新连接B数据库，但是要注意！这个时候mysql里的-h不能再是B的IP地址了，而是A的地址！因为qtunnel现在已经打通了一个通道，访问qtunnel的3310端口就等于是访问B数据库的3306端口（有点类似atlas的意思）。 连上之后，我们随意插入一些语句，看一下qtunnel的能力: 可见这个时候，抓包显示都是加密的文字了，实验成功！ 总结与参考资料总结一下：qtunnel采用rc4加密，在算法强度和速度方面是很好的选择，不会引起slave太大的延迟，对管理员或开发而言数据都是透明的（如果在上面的实验启动了qtunnel之后，不监听3310端口，而是监听3306端口，得到的依旧是明文），只是在两端传输的过程中增加了加解密处理。核心的业务(比如用户和充值)在做异地架构的时候可以考虑该方式增强数据的安全性。 《mysql使用ssl简析》：https://hsulei.com/2017/10/19/mysql%E4%BD%BF%E7%94%A8ssl%E7%AE%80%E6%9E%90/《使用ssl加密mysql 5.6的官方文档》：https://dev.mysql.com/doc/refman/5.6/en/encrypted-connections.html]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>加密技术</tag>
        <tag>Qtunnel</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix3.0搭配微信企业号报警]]></title>
    <url>%2F2018%2F01%2F10%2FZabbix3-0%E6%90%AD%E9%85%8D%E5%BE%AE%E4%BF%A1%E4%BC%81%E4%B8%9A%E5%8F%B7%E6%8A%A5%E8%AD%A6%2F</url>
    <content type="text"><![CDATA[Zabbix搭配微信企业号报警是一个很流行的手段，这里说一下如何配置。 准备工作建立一个企业号以及具体应用的链接在此：http://chenx1242.blog.51cto.com/10430133/1954634，里面写的都很明白了。 现在打开微信企业号的官方网站https://work.weixin.qq.com，然后扫描一下微信二维码登录到企业号的控制台。 在控制台网页里，需要查找几个元素，分别是CorpID、应用AgentId、应用Secret还有用户账号。 首先，在控制台里选择“我的企业”，然后就可以看见CorpID，如图： 然后点击“企业应用”，如果没有应用，那么就新建立一个应用。比如我已经建立了一个应用叫“zabbix告警”，那么应用AgentId和应用Secret就在如图的位置： 有了上面的CropID和Secret，就可以去验证一下accesstoken，登录http://qydev.weixin.qq.com/debug ，后在填入对应的CropID和Secret，看一下返回结果是否是“HTTP/1.0 200 OK”，如图： 在这个“zabbix告警”的应用里可见范围里添加对应需要通知的人，然后在“通讯录”里，找到对应的人，记录他们的账号，如图： 材料已经俱备完毕，现在需要做的是更改zabbix-server配置。 首先，在zabbix-server.conf里添加一句AlertScriptsPath=/usr/lib/zabbix/alertscripts，这是为了说明一下脚本所在的路径。当然，这个路径你可以自己更改，然后重启一下zabbix-server。 编写脚本cd /usr/lib/zabbix/alertscripts，在这个目录下我们要新写一个微信脚本，比如脚本名称叫wechat.py。 这个python脚本是需要requests模块的，所以需要先安装这个模块，安装方法如下： 12pip install requestspip install --upgrade requests 而python脚本内容如下，感谢https://github.com/X-Mars/Zabbix-Alert-WeChat/的脚本： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/usr/bin/python2.7#_*_coding:utf-8 _*_#this script is used for alarm by WECHATimport requests,sys,jsonimport urllib3urllib3.disable_warnings()reload(sys)sys.setdefaultencoding('utf-8')def GetToken(Corpid,Secret): Url = "https://qyapi.weixin.qq.com/cgi-bin/gettoken" Data = &#123; "corpid":Corpid, "corpsecret":Secret &#125; r = requests.get(url=Url,params=Data,verify=False) Token = r.json()['access_token'] return Token def SendMessage(Token,User,Agentid,Subject,Content): Url = "https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=%s" % Token Data = &#123; "touser": User, # 企业号中的用户帐号，在zabbix用户Media中配置，如果配置不正常，将按部门发送。 #"totag": Tagid, # 企业号中的部门id，群发时使用。 "msgtype": "text", # 消息类型。 "agentid": Agentid, # 企业号中的应用id。 "text": &#123; "content": Subject + '\n' + Content &#125;, "safe": "0" &#125; r = requests.post(url=Url,data=json.dumps(Data),verify=False) return r.text if __name__ == '__main__': User = sys.argv[1] # zabbix传过来的第一个参数 Subject = sys.argv[2] # zabbix传过来的第二个参数 Content = sys.argv[3] # zabbix传过来的第三个参数 Corpid = "这里填写Corpid" Secret = "这里填写Secret" Agentid = "这里填写应用的agentid" Token = GetToken(Corpid, Secret) Status = SendMessage(Token,User,Agentid,Subject,Content) print Status 脚本保存后，chown -R zabbix:zabbix wechat.py，然后小试一下，上面看到“Zabbix告警”这个微信应用里有一个用户账号叫ChenShuo，那么wechat.py执行语句是：python wechat.py ChenShuo 这个是标题 这里是正文！！ 然后看一下微信，如图： 正确出现了微信提示，可见这个脚本是OK的了。 配置zabbix现在我们要登录到zabbix网站，最上面的“Administration”里选择“Media types”，新建立一个Media type，如图： 保存之后，在“Administration”里选择“Users”，在Admin用户里点击“media”,把刚刚新增的“微信告警”这个media type添加进去，如图： 通知手段配置完毕，现在就是要在具体的Trigger上把微信告警这个新手段添加到active里。首先打开Configuration里的actions界面。此时假设现在有一个告警Trigger叫“模块发生了重启”，判断模块是否重启的依据就是pid值是否发生了变化。那么点击这个Trigger，在action里把“微信告警”添加到报警手段里，如图： 保存之后，整个的微信告警配置就完成了。为了验证配置是否生效，我冒死重启了一台生产环境的服务器，当然啦，好孩子千万不要效仿。 收到微信提示如图：不过考虑到微信告警可能会有所延迟，所以在这建议大家把告警阈值配置稍微早一点，避免“孩子死了奶来了”这种尴尬的情况。 参考资料http://www.yfshare.vip/2017/04/13/Zabbix%E4%B9%8B%E5%BE%AE%E4%BF%A1-Wechat-%E5%91%8A%E8%AD%A6/https://github.com/X-Mars/Zabbix-Alert-WeChat/]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>运维</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[自己动手搭建一个hexo博客demo]]></title>
    <url>%2F2018%2F01%2F10%2F%E8%87%AA%E5%B7%B1%E5%8A%A8%E6%89%8B%E6%90%AD%E5%BB%BA%E4%B8%80%E4%B8%AAhexo%E5%8D%9A%E5%AE%A2demo%2F</url>
    <content type="text"><![CDATA[曾几何时，自己动手做一个博客的想法愈加强烈，想在里面放一些更多除了技术之外的东西，比如烹饪的美食，比如PVP的视频，比如拍摄的照片，比如篮球足球的评论。在这种需求下，我从众多博客框架里面选择了hexo，原因就是“很多人都推荐hexo”….（囧）于是乎我在windows里搞一个，由于我在公司的网络是可以跨越长城的，所以搞github有一点天然的优势。而且github的博客不用花钱搞域名，他直接免费提供… 在搞github的时候墙裂推荐各位去用命令行，有linux的基本基础就可以很熟练的使用命令行搞github， 它的客户端真的不如命令行好用。 准备工作先去注册一个github，然后去https://git-scm.com 上下载一个最新的git windows的客户端，我下载的是2.15.1版本，如图： 下载完毕之后，就把这个exe文件安装，然后在“开始”里找到git再打开“Git Bash”，我的github账号是RorschachChan，电子邮件也已经配置过，所以现在就在这个bash窗口里写入如下语句： 12git config --global user.name "RorschachChan"git config --global user.email "chenx1242@163.com" 上面git config --global参数，表示你这台机器上所有的Git仓库都会使用这个配置。 再去https://nodejs.org/en/download/上根据自己windows的情况，下载最新的nodejs，下载完了之后就一路next，然后需要退出重进一下git bash，在bash的命令行里输入node -v，看到版本号就是OK，同时输入node，$会变成&gt;，然后输入.exit就可以退出返回到bash。 然后就是安装hexo，hexo的安装比较简单，就是在git bash里输入npm install -g hexo-cli和npm install -g hexo，然后需要等待一会，如果出现了npm ERR!不要怕，重新输入一次应该就会好了，安装完毕之后，输入hexo -v查看hexo的版本，如图： 然后建立一个github ssh密钥，在git bash里输入ssh-keygen -t rsa -C &quot;你的邮箱&quot;，然后告诉密钥生成的路径（下图黄框）以及会让你输入对应的口诀（红色箭头），这个口诀很重要，要妥善保存，如图： 这个密码会在你提交项目（hexo d）时使用，如果为空的话提交项目时则不用输入。这个设置是防止别人往你的项目里提交内容。这时候去C:\Users\33664\.ssh的路径里就会看到一对钥匙，id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。 来到github的个人配置里，选择SSH and GPG keys，然后输入title和id_rsa.pub的内容，点击add ssh key。如图：准备工作的最后一步，就是建立一个文件夹，我的文件夹建立在E盘下，名字就叫hexo。 开始搭建博客首先在git bash里进入/e/hexo，然后输入hexo init，这个命令是初始化命令，再输入hexo -g来生成静态文件，执行之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github上你的用户名.github.io的仓库上去的。然后可以输入hexo s来本地启动hexo，这个时候跑到浏览器里输入localhost:4000就会看到hexo博客最初的一个样子，如图： 这个默认的主题比较难看，我们去https://github.com/iissnan/hexo-theme-next下载最近一个比较火爆的主题next,并且把这个下载到hexo文件夹里的themes/next里，语句是：git clone https://github.com/iissnan/hexo-theme-next.git themes/next 然后打开hexo文件夹里的_config.xml，把原有的theme注释，换成新的next，注意，中间是有空格的！ 12#theme: landscapetheme: next 然后hexo clean和hexo g清除 Hexo 的缓存和重新生成静态文件，再次hexo s启动进程，来到浏览看一下发现博客的样子就变成下面的样子了： 这个看上去就简单大方很多了吧。 把博客上传到github现在有人问了，这个博客看上去好像很美，但是有两个致命的缺陷：第一，内容都是在我的windows里，如果我这个电脑坏了/出差/换新硬盘，那么如何保证我以前文件？第二，我启动进程需要执行 hexo -s，如果我电脑关机了，岂不是博客无法打开？ 需要解决就要把磁盘上的内容传递到github库里了，同时github是常开进程的，这样既可以更新我们的内容又不会关闭博客进程，除非github这个网站黄了。 先去github网站去建立一个库（repository），这里我直接选择了公共读，如图： 然后在hexo文件夹里面，修改一下_config.xml的几个地方： 1234567891011121314# Sitetitle: 石锤淡啤酒 #这个是网站在标签页的标题subtitle: 生活就是等待戈多 #这个是副标题description: 这里记录的不只有代码，还有生活和思想！ #这里也可以写网站的关键词，也可以矫情的写点别的author: Chris Chan #这个作者会在网页最下面显示language: zh-Hans #这里表示简体中文timezone:# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: git@github.com:RorschachChan/RorschachChan.github.io.git #这里写的就是刚刚申请的库名 branch: master 建立完库以及修改保存了_config.xml之后，我们执行一句hexo d部署命令，在执行的时候需要输入当时你建立id_rsa时候的口诀，刚刚申请的那个口诀不会这么快就忘了吧。 返回到github的网站就看到hexo里所有的内容都上传到了github网站里了，如图: 在浏览器里输入“https://你的用户名.github.io”，就看到了博客界面： 同理，如果你的github用户名是test，建立的是test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是http://test.github.io了，每一个github账户最多只能创建一个这样可以直接使用域名访问的仓库。 至此，建立一个博客demo就到此结束了！ 参考资料https://baoyuzhang.github.io/2017/04/28/【Hexo搭建独立博客全纪录】（一）使用Git和Github/https://github.com/iissnan/hexo-theme-nexthttp://opiece.me/2015/04/09/hexo-guide/http://shenzekun.cn/hexo的next主题个性化配置教程.html 强烈推荐这篇文章，可以让你把next主题的博客做的更加漂亮！]]></content>
      <categories>
        <category>博客搭建</category>
      </categories>
      <tags>
        <tag>github</tag>
        <tag>hexo</tag>
        <tag>博客搭建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Query String跟Arg的差异]]></title>
    <url>%2F2018%2F01%2F09%2FQuery-String%E8%B7%9Farg%E7%9A%84%E5%BC%82%E5%90%8C%2F</url>
    <content type="text"><![CDATA[前言与需求在https://rorschachchan.github.io/2018/01/09/记一次配置rewrite和return的经历/ 里记录了一次rewrite和return的故事，不过我当时在最后的return里是把域名给写死了：rewrite ^.*$ http://dvlshop.lechange.com/index.php/wap/$id$query last;。 现在新的需求又来了，说域名不要写死，http://dvlshop.lechange.com/index.php/这部分要跟整个uri的state部分保持一致。 于是我这里再把整个uri贴出来，辣一下各位的眼睛：http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp; #满足条件的话把这个改成+auto+scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 也就是说现在只需要变量state那点部分，那么这个时候就不能再使用$query_string了，要使用$arg。 $arg可以精确匹配变量，比如说我有一个参数（uri里？后面的那部分全叫参数）：&amp;p=你大爷&amp;q=你大娘，用$query_string和$arg就是获取所有，而使用$arg_p就是可以获取“你大爷”。 于是说动手就动手，把nginx.conf改成了：123456789101112131415161718location ~ .*\.php.*&#123; include php_fcgi.conf; include pathinfo.conf; set $flag "0"; if ( $args ~ "source_type=lc_app" ) &#123; set $flag "1"; &#125; if ( $args ~ "(.*)response_type(.*)" )&#123; set $Flag "$flag$flag"; set $id $1; set $query $2; &#125; if ($Flag = "11")&#123; set $flag "0"; return 301 $arg_state$id+auto+$query; &#125;&#125; 但是通过日志查看，发现$arg_state得到的是/http%3A%2F%2Fdvlshop.lechange.com%2Fproduct-79.html,这就很囧了，我希望获取http%3A%2F%2Fdvlshop.lechange.com%2Fproduct-79.html（不要前面的反斜杠）或者是/product-79.html（不要中间的网站）。这可怎么办？ 答案是，原生的nginx是做不到这一点，因为nginx不参与业务层逻辑方面的业务。如果说要达到改写的目的，就要搭配lua或者把nginx换成openresty。于是乎就让开发修改一下传递的state来达到目的。 扩展与补充看到这个结果突然让我想起来一道面试题，说开发有一个模块，同时这个模块会给nginx提供几个状态码，比如状态码是111，那就是代表OK，状态码不是111，那就是代表不OK，现在想写一个语句，如果nginx获得的状态码不是111，返回一个404的页面，怎么写？ 没错，答案也是“原生nginx写不了”，原因跟上面的一样，应用模块状态码是业务层的，nginx是http层的，不在一层压根就无法交流。 在这里也顺道补充一下“在浏览器中输入一个URL后都发生了什么？”，以下是一个大概流程： 浏览器向DNS服务器查找输入URL对应的IP地址； DNS服务器返回网站的IP地址； 浏览器根据IP地址与目标web服务器建立TCP连接； 发送HTTP请求； 服务器处理请求； 返回响应结果； 关闭TCP连接； 浏览器解析HTML； 浏览器布局渲染；]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次配置rewrite和return的经历]]></title>
    <url>%2F2018%2F01%2F09%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E9%85%8D%E7%BD%AErewrite%E5%92%8Creturn%E7%9A%84%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[前言与需求自动电商平台归属了大数据研究院之后，我又恢复了那个“把nginx当成爸爸”的日子。开发不断地提出了的要求，我一样一样的疲命应付，并且在应付后记录下来，就怕以后再遇到类似的问题。 这次的需求是一个跳转，满足某个条件之后把“http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp;scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 ”改成“http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;=code&amp;scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27” 具体条件是: 先判断是否有source_type=lc_app； 再判断是否有response_type； 如果以上两个都满足，将“response_type”改成“+auto+”； 各位看官，我理解你们此时不想继续看下去的心情，其实我当初看着那么一大坨uri心里也直犯闹，但是没办法，“食君之禄，分君之忧”，我只能耐着性子一个一个的拆开，还别说，拆开的话就清晰许多了，如下：http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp; #满足条件的话把这个改成+auto+scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 开始操作针对这次需求我的计划是这样的：把原地址看成”$1+ response_type +$2”这样的一个样式，确定$1和$2，然后rewrite成”$1+ +auto+ +$2”不就搞定了么？ 于是乎我就凭着我那二把刀的nginx技术开始动手。折腾了大约半个小时，拿出来这样一个配置： 123456789101112131415161718location ~ .*\.php.* &#123; include php_fcgi.conf; include pathinfo.conf; set $flag "0"; if ( $request_uri ~ "source_type=lc_app" ) &#123; set $flag "1"; &#125; if ( $request_uri ~ "(.*)response_type(.*)" )&#123; set $Flag "$flag$flag"; set $id $1; set $query $2; &#125; if ($Flag = "11")&#123; #注意这个地方是11 set $flag "0"; rewrite ^.*$ http://dvlshop.lechange.com/index.php/wap/$id$query last; #前面那一段是写死的 &#125; &#125; 但是很不幸，nginx -s reload之后的结果是“$1+$2+$1+ response_type +$2”的格式（地址太长太恶心了，我就不写了）。 然后在arstercz大神的指点下，把那句rewrite改成了return 301 http://dvlshop.lechange.com/index.php/wap/?$id$query;。就达到了效果。 原因确定后来追寻原因，原来是： rewrite后面接的$uri不需要$args，因为$args会被自动带过来。而return的则会丢失$args，需要手动补上$args。而我上面的$1,$2恰巧就是$args，所以用rewrite的话就会重复。举个例子，比如请求「http://localhost/?a=1」想被 301 到「https://localhost/?a=1?a=1」，要么 1234server &#123; listen 80; rewrite / https://$host$uri permanent;&#125; 要么就 1234server &#123; listen 80; return 301 https://$host$request_uri;&#125; 补充说明这里补充一下uri、request_uri、document_uri之间的区别： $request_uri: /stat.php?id=1585378&amp;web_id=1585378 $uri: /stat.php (不带？后面) $document_uri: /stat.php （与uri完全相同） 参考资料https://www.cnblogs.com/bigberg/p/7715020.htmlhttps://blog.csdn.net/yxl0011/article/details/72818409https://blog.csdn.net/aliencsdn/article/details/54668552]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux运维工程师面试题第一套]]></title>
    <url>%2F2018%2F01%2F04%2FLinux%E8%BF%90%E7%BB%B4%E5%B7%A5%E7%A8%8B%E5%B8%88%E9%9D%A2%E8%AF%95%E9%A2%98%E7%AC%AC%E4%B8%80%E5%A5%97%2F</url>
    <content type="text"><![CDATA[这套题的出处是http://blog.51cto.com/nolinux/1670406 ，看到了闲着没事周末就做一做，答案都是我自己在工作里得到的，不一定百分百准确，只是无聊的时候做做，现在拿出来跟各位分享一番。 1、请写出五种系统性能分析工具，并简述其作用和特点[我的答案] top、free、vmstat、iostat、perf等等等等，如果你想装逼，可以回答fio,blktrace，oprofile。具体的作用和特点这里不多说了，但是我着重要推荐vmstat，很实用很棒的一个命令。 2、请写出web服务器的调优要点[我的答案]以nginx为例，个人总结有如下几个要点：1）尽可能的少用http，因为http是有开销的；2）尽可能的使用CDN；3）添加Expire/Cache-Control头，这个头是缓存用的，可以缓存图片和flash那样不轻易更改的文件，减少访问时间；4）启动gzip压缩，这个没啥好说的了；5）尽可能少的重定向，能rewrite就不要return，我也知道return比rewrite好写，但是重定向是需要时间的，增加一次重定向就会多一次web需求；6）如果可以，把ajax也做缓存；7）减少dns查询，很多网页会有外站的广告，这些广告也是会启动dns查询的，所以如果不缺钱，减少这种广告；8）调好服务器里的TCP协议栈，这个无论是web服务器还是应用服务器都是必须的； 3、请写出你知道或使用过的nginx扩展模块（注意标注知道和使用）[我的答案] 随便说几个，这玩意到时候结合工作过的情况说说吧：Nginx负载均衡模块：nginx-upstream-fair非阻塞访问redis模块：redis2-nginx-module分布式图片实时动态压缩：ngx-fastdfs 4、请简述你了解的自动化配置管理工具特点和运行原理[我的答案]我用的最多的就是ansible和saltstack，这俩都是python的，对于我这个半路出家的更亲切。ansible基于SSH协议传输数据，不用装agent，配置比较简单，对windows支持惨不忍睹；saltstack使用消息队列zeroMQ传输数据，如果1000台以上的话它速度比ansible还要快,要安装agent，对windows支持同样惨不忍睹； 5、目前，有一个文件，内容如下： 172.16.100.1 172.16.100.2 172.16.100.3 172.16.100.4 请使用while和ssh命令，登录文件内的ip并执行hostname命令[我的答案]这个我还真没有什么思路，不过应该是跟“&lt;”输入重定向命令结合的一个脚本吧。PS,为啥不用ansible…哪怕pssh也可以啊！ 6、请使用awk命令将如下两份文件中名字相同的两行合并起来 A文件： 大广州 21岁 广州大 23岁 州广大 22岁 广州大 24岁 B文件： 广州大 男 大广州 男 州广大 男 广州大 男输出效果： 大广州 21岁 男[我的答案]awk ‘NR==FNR{a[$1]=$2}NR&gt;FNR{print $0,a[$1]}’ 第2个文件名 第1个文件名PS，做完这道题，我已经不认识“广”“州”这两个字了… 7、请使用绘图的方式简述TCP/IP三次握手和四次断开的交互过程[我的答案]这种图满大街都是了，我这个灵魂画师在这里就不污染各位的眼睛，不过这里推荐各位去看一篇文章：https://mp.weixin.qq.com/s?__biz=MjM5NzA1MTcyMA==&amp;mid=2651160450&amp;idx=2&amp;sn=1128438fa5287b6cee503880698642b2&amp;scene=21 对原理讲的浅显易懂。多说一句，网易招聘java的时候也问这个问题，不过他们问的是“为什么要三次握手？” 8、请根据你的理解，简述高可用服务体系的相关组件，并列举该组件的具体实现服务名字[我的答案] 我觉得这个题是要问一些架构上的东西，以我工作环境为例：统一配置:zookeeper、Consul、Etcd+Confd(这俩比较常见于动态管理nginx)前端展示:nginx消息队列:activemq、kafka读写分离中间件:atlas日志分析:elk 9、请根据你的理解，简述负载均衡的实现方式[我的答案]负载均衡主要分为两种，硬件（F5）和软件（NGINX、Haproxy、LVS），硬件效果比较牛逼，它是把4-7层的负载均衡功能做到一个硬件里面，但是价格昂贵最近用的越来越少了。软件的负载均衡又分两种，四层和七层：四层是在IP/TCP协议栈上把网络包的IP地址和端口进行修改，达到转发的目的；七层就是在应用层里把HTTP请求、URL等具体的应用数据发送到具体的服务器上。四层的效率比七层的高，四层一般安排在架构的前端，七层一般就是在具体服务器的前端。软件负载均衡比较常见的几个分配方式如下：轮询：访问请求依序分发给后端服务器；加权轮询：访问请求依序分发后端服务器，服务器权重越高被分发的几率也越大；最小连接数： 将访问请求分发给当前连接数最小的一台后端服务器，服务器权重越高被分发的几率也越大； 10、请根据你的理解，简述数据迁移工具和数据存储服务有哪些以及相关特点[我的答案]由于我公司主要都放在了阿里云，数据库用过的就这么几个:mysql、redis和elasticsearch。对于Storm和Hadoop这俩我还是初学者。mysql:关系型数据库elasticsearch:全文检索框架，这玩意逐渐向一个数据库靠拢了redis:键值储存数据库 mysql的数据迁移最常见的就是mysqldump，但是要注意使用不当会锁表，redis的数据迁移最稳妥的方法就是主从同步：在slave端启动redis，然后执行slaveof master机器IP地址 6379，然后使用info的时候查看master_link_status如果是up那就是OK了，再执行slaveof no one,提示OK就是OK了；Elasticsearch的数据迁移工具就是Elasticsearch-Exporter，不过我对它仅仅只是了解，用的并不多； 总结这套题不算难，方向是偏应用的，但是对云端服务的运维来说不算很友好，因为云厂商基本都把数据备份和数据迁移都做成自己的工具（比如阿里云的DTS），所以很多云服务的运维对这种东西了解不多。]]></content>
      <categories>
        <category>大牛之路</category>
      </categories>
      <tags>
        <tag>面试</tag>
        <tag>职场</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx动态编译新的模块]]></title>
    <url>%2F2018%2F01%2F03%2FNginx%E5%8A%A8%E6%80%81%E7%BC%96%E8%AF%91%E6%96%B0%E7%9A%84%E6%A8%A1%E5%9D%97%2F</url>
    <content type="text"><![CDATA[开始动手打算给电脑上的nginx添加一个当时没有编译安装的echo-nginx-module模块，这是一个第三方模块，要知道nginx要添加模块是需要重新编译的，这一点跟apache不同，apache是在配置文件里引用.so文件的。 首先先nginx -V，查看一下nginx已经编译的模块都有啥，如图： 于是我就git clone https://github.com/openresty/echo-nginx-module，但是发现竟然告诉我“git: command not found”。oh shit，原来这台nginx实验机器压根就没有装过git啊！而yum源里的软件基本上已经过时的太久了，就拿git来说吧，使用yum info git看到的版本是1.8.3.1。但是在https://github.com/git/git/releases 里可以看到，git的版本现在已经丧心病狂的到达了2.16的版本了。 那么我们先安装git!通过yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel和yum install gcc perl-ExtUtils-MakeMaker来安装依赖库。wget https://github.com/git/git/archive/v2.16.0-rc0.tar.gz来下载2.16的git保存到centos里。tar -xzvf v2.9.2.tar.gz -C /目标目录/，然后在目标目录里面执行make prefix=/usr/local/git all和make prefix=/usr/local/git install，编译过程可能会比较长，请耐心等待。 编译结束之后，echo &quot;export PATH=$PATH:/usr/local/git/bin&quot; &gt;&gt; /etc/bashrc，把git添加到环境变量，再source /etc/bashrc让它实时生效，最后再一次看看git --version，大功告成！ 编译新模块git搞定了之后，重新git clone https://github.com/openresty/echo-nginx-module，然后在nginx的configure文件夹里面，把echo-nginx-module模块添加上。命令如下：./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/root/pcre-8.41 --with-http_v2_module --add-module=/root/echo-nginx-module-0.61,我这里还附赠了一个“http_v2_module”。 configure完毕之后，去make一下就可以了，不要轻易make install，不然就是重新安装了。原来的nginx.conf等配置都没了。 养成替换nginx二进制文件的好习惯，如下： 12cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bakcp nginx编译目录/objs/nginx /usr/local/nginx/sbin/ 然后再打开看一下nginx -V]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[从vmstat命令里看服务器瓶颈]]></title>
    <url>%2F2018%2F01%2F03%2F%E4%BB%8Evmstat%E5%91%BD%E4%BB%A4%E9%87%8C%E7%9C%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%93%B6%E9%A2%88%2F</url>
    <content type="text"><![CDATA[这几天重新翻看基础知识，看到了vmstat，我认为它是一个非常优秀的命令,因为它包括了top和free，甚至还包含了一些io的信息，可以说是运维人员常备命令之一。常用方法：vmstat (-a) 多少秒刷一次 刷多少次。 对上面这个图来一个简单的解释： r: 运行队列中进程数量，这个值长期大于1就要判断是否需要增加CPU。b: 等待IO的进程数量 swpd: 使用虚拟内存大小(如果swpd的值不为0，但是SI，SO的值长期为0，这种情况不会影响系统性能）free: 空闲物理内存大小buff: 用作缓冲的内存大小cache: 用作缓存的内存大小(如果cache的值大的时候，说明cache处的文件数多，如果频繁访问到的文件都能被cache处，那么磁盘的读IO bi会非常小)inact: 非活跃内存大小（当使用-a选项时显示）active: 活跃的内存大小（当使用-a选项时显示） si: 每秒从交换区写到内存的大小，由磁盘调入内存so: 每秒写入交换区的内存大小，由内存调入磁盘注意：内存够用的时候，这2个值都是0，如果这2个值长期大于0时，系统性能会受到影响，磁盘IO和CPU资源都会被消耗。有些朋友看到空闲内存（free）很少的或接近于0时，就认为内存不够用了，不能光看这一点，还要结合si和so，如果free很少，但是si和so也很少（大多时候是0），那么不用担心，系统性能这时不会受到影响的。 bi: 每秒读取的块数bo: 每秒写入的块数注意：随机磁盘读写的时候，这2个值越大（如超出1024k)，能看到CPU在IO等待的值也会越大。 in: 每秒中断数，包括时钟中断。cs: 每秒上下文切换数。注意：上面2个值越大，会看到由内核消耗的CPU时间会越大。 us: 用户进程执行时间百分比(user time)注意： us的值比较高时，说明用户进程消耗的CPU时间多，但是如果长期超50%的使用，那么我们就该考虑优化程序算法或者进行加速。 sy: 内核系统进程执行时间百分比(system time)注意：sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因。 wa: IO等待时间百分比注意：wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。 id: 空闲时间百分比 最后总结：如果r经常大于4 ，且id经常少于40，表示cpu的负荷很重。如果bi，bo长期不等于0，表示内存不足。 r（运行队列）展示了正在执行和等待CPU资源的任务个数。当这个值超过了CPU数目，就会出现CPU瓶颈了。 CPU 100%并不能说明什么，Linux总是试图要CPU尽可能的繁忙，使得任务的吞吐量最大化。唯一能够确定CPU瓶颈的还是r（运行队列）的值。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>运维</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于阿里云CDN的两个故障解决]]></title>
    <url>%2F2017%2F12%2F28%2FCDN%E7%BD%91%E7%AB%99%E4%B8%80%E6%AC%A1%E6%89%93%E4%B8%8D%E5%BC%80%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[测试中心今天在测试时候发现了一个问题：官方的A网站做了域名跳转，跳转到阿里云CDN，但是在浏览器里输入A地址栏的时候，发现域名的确变成了CDN的域名，但是页面是403。 如图： 但是奇怪的是，再在浏览器点击一下回车，网页就神奇的打开了。 这个原因就是阿里云的CDN有一个“Refer防盗链”，需要在防盗链里面把A域名添加到白名单，这样的话就可以直接访问了。至于为什么第二次回车就可以访问，是因为那时候域名已经成CDN自己的域名了，当然可以访问。 但是这个防盗链也要注意！毕竟白/黑名单添加都是一个危险举动，一定三思后行。有可能你的css\js是用cdn加速的，一旦加上了白名单，可能css就会变得很难看。 不就之后，商城也下来一个需求，说公司有两个多年不用的域名B和C，打算废物利用，两个都要达到直接“跳转官网”的目的。 于是我就到阿里云域名管理的那里搜索一下，发现目前官网域名后端绑定的是一个CDN，于是也把域名B和域名C做一个CNAME到这个域名，不过登陆浏览器发现域名B和域名C都反馈502。 于是我就到电子商城后端的nginx.conf里查看，确认server_name字段没有写错，然后把域名B和域名C的CNAME直接改成了CDN的域名，再通过了dig确认。但是等于浏览器还是发现502。 最后找了阿里云的人了解，原来阿里云规定“一个CDN只能绑定一个域名，因为节点上没有那两个域名的配置，所以只要不符合节点上有配置文件信息的，全部502”。所以B和C是无法访问的。要解决这个问题有两招，1）把域名B和域名C直接A记录绑定CDN后面的SLB上，但是代价就是访问速度不如CDN快；2）重新购买两个CDN，都绑定SLB，然后把这两个CDN分别绑定到域名B和域名C上，代价是多收一点流量费…]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>CDN</tag>
        <tag>网站技术</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[screen的用法]]></title>
    <url>%2F2017%2F12%2F21%2Fscreen%E7%9A%84%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[很多时候在Linux要后台执行程序，都是使用“&amp;”，或者是nohup，不过这两个更多应用于临时的脚本。一个比较高科技的方法就是使用screen。 安装screen的方法很简单：yum install -y screen。 如果新建一个screen，就输入screen -S name，这样会新开一个窗口，然后执行命令。比如我要启动django，那么就输入python manage.py runserver 0.0.0.0:9000即可。 这个重开一个窗口，列出所有screen进程，就这样： 123[root@docker ~]# screen -lsThere are screens on: 3029.xiedi (Attached) 如果想链接上之前那个django，执行命令screen -r 3029即可。]]></content>
      <categories>
        <category>工作与技术</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>其他软件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pictest]]></title>
    <url>%2F2017%2F12%2F13%2Fpictest%2F</url>
    <content type="text"><![CDATA[这是一个我用来测试图片上传的文章 啊！五环，你比四环多一环！啊！五环，你比六环少一环！终于有一天，你会修到七环]]></content>
      <categories>
        <category>用来保护视力的图片</category>
      </categories>
      <tags>
        <tag>美女</tag>
        <tag>图片</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[这里记录的不只有代码，还有生活和思想！]]></title>
    <url>%2F2017%2F12%2F13%2F%E8%BF%99%E9%87%8C%E8%AE%B0%E5%BD%95%E7%9A%84%E4%B8%8D%E5%8F%AA%E6%9C%89%E4%BB%A3%E7%A0%81%EF%BC%8C%E8%BF%98%E6%9C%89%E7%94%9F%E6%B4%BB%E5%92%8C%E6%80%9D%E6%83%B3%EF%BC%81%2F</url>
    <content type="text"><![CDATA[var ap = new APlayer({ element: document.getElementById("aplayer1"), narrow: false, autoplay: false, showlrc: 0, music: { title: "一个人去旅行", author: "陈升", url: "http://p1x3hd2at.bkt.clouddn.com/一个人去旅行.mp3", pic: "http://p1x3hd2at.bkt.clouddn.com/五十米深蓝.jpg", } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 你说要一个人去旅行 但是归期却没有约定 亚得里亚海边风中的吉他声你说你带着苍白的回忆 却谢谢能与我相逢 我怕你在异乡夜里孤独醒来要拒绝两人单调的生活 想寻找自由 迷信了爱情 就迷失了我自己你就这样 离开吧 抛弃吧 他乡的旅人你就那样 离开吧 抛弃吧 一个人生活 你说要一个人去旅行 眼里藏着一朵乌云 知道你藏不住秘密 天空就会飘着雨你说你带着一本日记 却不想再拥有回忆 我怕你在异乡孤独的醒来要拒绝两人单调的生活 不想再随波逐流 迷信了孤独 就软弱的抛弃了我的等待 你就这样 离开吧 抛弃吧 他乡的旅人你就那样 离开吧 抛弃吧 让我孤独生活 你就这样 离开吧 抛弃我 孤独的旅人你就这样 离开我 抛弃我 让我孤独生活 我想要一个人去旅行 但愿归期会有约定 每个人都在问我 是否可以找到自由的你亚得里亚海边他乡的人和风中的吉他声 我怕你一个人在异乡孤独醒来我会带着你回来]]></content>
      <categories>
        <category>坠乱花天</category>
      </categories>
      <tags>
        <tag>音乐</tag>
        <tag>感悟</tag>
      </tags>
  </entry>
</search>
