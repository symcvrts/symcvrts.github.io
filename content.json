{"meta":{"title":"Chris Chan's BLOG","subtitle":"那些在阳光下挥洒青春的日子啊！","description":"生活就是等待戈多","author":"Chris Chan","url":"http://yoursite.com"},"pages":[{"title":"相册|苏幕遮","date":"2018-02-11T06:58:13.000Z","updated":"2018-02-11T08:59:16.949Z","comments":false,"path":"album/index.html","permalink":"http://yoursite.com/album/index.html","excerpt":"","text":".photo img{ border: 1px solid #999; height: 200px; width: 350px; } .photo li{ margin: 20px; float: left; list-style: none; } 喜欢的车 魔兽世界"},{"title":"","date":"2017-09-06T07:37:18.000Z","updated":"2018-01-09T06:45:46.132Z","comments":false,"path":"/404.html","permalink":"http://yoursite.com//404.html","excerpt":"","text":"&lt;!DOCTYPE HTML&gt;"},{"title":"对我有什么想说的","date":"2017-12-14T08:55:38.000Z","updated":"2017-12-14T08:56:41.508Z","comments":true,"path":"guestbook/index.html","permalink":"http://yoursite.com/guestbook/index.html","excerpt":"","text":""},{"title":"","date":"2018-02-12T16:49:27.638Z","updated":"2018-02-11T07:02:37.794Z","comments":true,"path":"album/tools.js","permalink":"http://yoursite.com/album/tools.js","excerpt":"","text":"const fs = require(\"fs\"); const path = \"../../photos\"; var qiniu = require(\"qiniu\"); //需要填写你的 Access Key 和 Secret Key qiniu.conf.ACCESS_KEY = 'WHg_aoZB61oK16ecGy2xv62UY_DPFYDSR_dJMF-Y'; qiniu.conf.SECRET_KEY = 'OxDBBVJ99v1vt8EKaV4T3Un7YPSSd5T0yV_LXr5K'; //要上传的空间 bucket = 'jichengtest'; //构建上传策略函数 function uptoken(bucket, key) { var putPolicy = new qiniu.rs.PutPolicy(bucket+\":\"+key); return putPolicy.token(); } //构造上传函数 function uploadFile(uptoken, key, localFile) { var extra = new qiniu.io.PutExtra(); qiniu.io.putFile(uptoken, key, localFile, extra, function(err, ret) { if(!err) { // 上传成功， 处理返回值 console.log('upload success : ',ret.hash, ret.key); } else { // 上传失败， 处理返回代码 console.log(err); } }); } /** * 读取文件后缀名称，并转化成小写 * @param file_name * @returns */ function getFilenameSuffix(file_name) { if(file_name=='.DS_Store'){ return '.DS_Store'; } if (file_name == null || file_name.length == 0) return null; var result = /\\.[^\\.]+/.exec(file_name); return result == null ? null : (result + \"\").toLowerCase(); } fs.readdir(path, function (err, files) { if (err) { return; } var arr = []; (function iterator(index) { if (index == files.length) { fs.writeFile(\"./output.json\", JSON.stringify(arr, null, \"\\t\")); return; } fs.stat(path + \"/\" + files[index], function (err, stats) { if (err) { return; } if (stats.isFile()) { var suffix = getFilenameSuffix(files[index]); if(!(suffix=='.js'|| suffix == '.DS_Store')){ //要上传文件的本地路径 filePath = path+'/'+files[index]; console.log('抓取到文件: '+files[index]); //上传到七牛后保存的文件名 key = files[index]; //生成上传 Token token = uptoken(bucket, key); // 异步执行 uploadFile(token, key, filePath); arr.push(files[index]); } } iterator(index + 1); }) }(0)); }); console.log(\"'output.json' file has been created successfully...\");"},{"title":"关于我","date":"2018-01-09T12:47:40.000Z","updated":"2020-01-22T01:47:30.288Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"欢迎你来到我的博客! 我叫Chris Chan,花名桃熙。目前生活在杭州，就职于阿里巴巴天猫供应链平台团队，职位是安全生产专家，啥都研究然后啥都不会… var options = {\"narrow\":false,\"autoplay\":false,\"showlrc\":0,\"mutex\":true,\"music\":[{\"title\":\"只要平凡（live)\",\"author\":\"刺猬乐队\",\"url\":\"http://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E5%8F%AA%E8%A6%81%E5%B9%B3%E5%87%A1(Live).mp3\",\"pic\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/bigband.png\"},{\"title\":\"咿呀呀(Live)\",\"author\":\"海龟先生&薛凯琪\",\"url\":\"http://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E5%92%BF%E5%91%80%E5%91%80(Live).mp3\",\"pic\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/bigband.png\"},{\"title\":\"莫欺少年穷(Live)\",\"author\":\"九连真人\",\"url\":\"http://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E8%8E%AB%E6%AC%BA%E5%B0%91%E5%B9%B4%E7%A9%B7(Live).mp3\",\"pic\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/bigband.png\"},{\"title\":\"GetFunky(Live)\",\"author\":\"click#15\",\"url\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/GetFunky(Live).mp3\",\"pic\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/bigband.png\"},{\"title\":\"一个人去旅行\",\"author\":\"陈升\",\"url\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E4%B8%80%E4%B8%AA%E4%BA%BA%E5%8E%BB%E6%97%85%E8%A1%8C.mp3\",\"pic\":\"http://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E9%99%88%E5%8D%87.jpg\"},{\"title\":\"十二种颜色\",\"author\":\"陈琳\",\"url\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E5%8D%81%E4%BA%8C%E7%A7%8D%E9%A2%9C%E8%89%B2.mp3\",\"pic\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E9%99%88%E7%90%B3.jpg\"},{\"title\":\"不要说谎\",\"author\":\"谢霆锋\",\"url\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E4%B8%8D%E8%A6%81%E8%AF%B4%E8%B0%8E.mp3\",\"pic\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E8%B0%A2%E9%9C%86%E9%94%8B.jpg\"},{\"title\":\"天煞孤星\",\"author\":\"谢霆锋\",\"url\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E5%A4%A9%E7%85%9E%E5%AD%A4%E6%98%9F.mp3\",\"pic\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E8%B0%A2%E9%9C%86%E9%94%8B.jpg\"},{\"title\":\"没有烟抽的日子\",\"author\":\"张雨生\",\"url\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E6%B2%A1%E6%9C%89%E7%83%9F%E6%8A%BD%E7%9A%84%E6%97%A5%E5%AD%90.mp3\",\"pic\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E5%BC%A0%E9%9B%A8%E7%94%9F.jpg\"},{\"title\":\"晚婚\",\"author\":\"李宗盛\",\"url\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E6%99%9A%E5%A9%9A.mp3\",\"pic\":\"https://img-baby.oss-cn-hangzhou.aliyuncs.com/JJFJJ/%E6%9D%8E%E5%AE%97%E7%9B%9B.jpg\"}]}; options.element = document.getElementById(\"aplayer2\"); var ap = new APlayer(options); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 习武之人有三个阶段：见自己，见天地，见众生。"}],"posts":[{"title":"2019年的个人读书总结","slug":"2019年的读书总结","date":"2020-02-03T15:03:22.000Z","updated":"2020-02-03T15:16:28.507Z","comments":true,"path":"2020/02/03/2019年的读书总结/","link":"","permalink":"http://yoursite.com/2020/02/03/2019年的读书总结/","excerpt":"","text":"整个2019年过去了，2020年也不算开了一个很好地头。于是这个年度回顾了也跟着来的晚了点。本文里就不扯那些事业上的进步blablabla的，重点说说我这一年读的书。 基督山伯爵说实话，这本书我是当爽文看的。金庸先生的《连城诀》应该参考了这本书，但是黑暗度有过之而不及。 我本身就读外国书不多，一大主要原因是外国人名太长，要是都是“汤姆”、“约翰”、“史蒂芬”这样的还好。偏偏这本法国书里很多人的姓都是四五个字的，不过幸好整套书看下来设计的人物不算多。人与人的关系还算捋得清。 度过这本书的人太多了，我也不多做什么分析。各种大神都已经分析烂了，我更想表达的是“复仇与创业一样，要保持热情和初心是挺难的”。 “等待与希望”，的确是对人来说很重要的两个事儿。厉害的人好像比普通的人就是多了那么一点点的耐心。 主角《主角》这本书我我看《圆桌派》的时候，王蒙老先生提到的，于是我就买了一本，《主角》是一本比较新的书，第一版是2018年1月。不过这部“茅盾文学奖”得主貌似并不受豆瓣青年的喜爱，我看了一下目前的得分是6.7分。在短评里很多人打出了三星以下的得分，我想主要原因就是作者把主人公忆秦娥写的太憋屈了，于是剧情党很是不满。 忆秦娥这个角色，让作者写的有点“小龙女+罗德曼”的味道，说她小龙女呢，是因为她长相美丽又不食人间烟火；说她罗德曼呢，是因为她跟罗德曼一样吗，靠磨炼术去逃避自己现实的不满。所以我想当作者安排她把处女之身给了刘红兵的时候，应该心里是比较波折的。其实我开始心里也是反对这门亲事，因为刘红兵虽然爹比较硬、家庭比较好、嘴巴会说，但是毕竟是一个毫无事业的人，而且性格也过于社会。但是作者这么安排我想也有他的良苦用心，第二部中期作者开始逐渐对刘红兵有了一些正面的描述，比如说他做了一手好面、人高马大、英俊帅气（就是后来被忆秦娥打掉一个门牙），追忆秦娥追了一年多，用物质砸，用手段哄，拿出了“烈女怕缠男、打死不退”的劲儿。而且也锲而不舍的描述他多么体贴入微：忆秦娥在中南海表演因为表演吹火而下场吐了一地，刘红兵二话不说直接脱了外套，用衣服把呕吐物包起来又把地面收拾了。这个细节的确把我打动了，换成我，我估计我就做不出来。 整本书看完忆秦娥除去了主角光环，她的人生和爱情悲剧成分居多，这跟她自己的成长经历有很大的关系，书里的安排也是符合现实的。她人生欲扬先抑，靠着一股痴劲儿遇到了不少好伯乐来提升她的技术。但是她毕竟不喜读书，遇事自己没主意，更多的时候只会“手背捂着嘴”，自己本来就傻，还不喜欢别人说她傻。早期米兰给她一个字典，后来秦八娃也让她去买书看，但是她更想睡觉。再加上性格自卑孤僻圈子小，封潇潇一出局，周围除了一个死缠烂打的刘红兵也就没有几个适龄男子了。不选他选谁？ 不过说实话啊，烈女与缠男的戏码，古往今来、艺术现实，基本都没有好结局，因为毕竟“强扭的瓜不甜”。缠男多半是图烈女的貌馋她的身子，他就是坚持100年也是图身子而不是特别图她的性格。一旦要了女子的身子，新建劲儿又过了，缠男自然就受不了烈女的脾气。忆秦娥是一个性冷淡，刘红兵出轨是再正常不过的安排。 诚然，同样是西北文学。《主角》的光辉跟《白鹿原》是没法比的。虽然故事基本都是发生在一个小圈子，但是《白鹿原》的故事背景太大了，而且达到了从小孔窥大局的高度。而《主角》重心更多是描写京剧这门艺术、新老剧的冲突和剧团内部争风吃醋的现象。 长夜难明这本书我好像一下午就读完了，它不算是一个推理小说，更多的是一部反腐小说，作者也下了一番功夫在故事的曲折性和现实的映射中找平衡。从故事情节来看，很棒，很悲壮，把正义与腐败的斗争写的很真实，尤其是江阳按下按钮抛出公寓闭眼等死那一段，可以说是写的非常有画面感，让人不禁激动落泪。有时候我也在反思：人们茶余饭后吹的那些正邪斗争的牛逼，真实情况里付出的代价太沉重了。 当全世界都在阻挠你做一个正确的事情，还能有几个人坚持下去呢？ 如果要说缺点，就是有些文笔比较粗糙和纸面化，感觉像是长篇纪实文学了。但是对司法体系和刑事程序的描写很真实。后来我也看了作者紫金陈的《谋杀官员》系列，个人最喜欢的是第一部徐策的故事。 中国14亿人口，每天出现的故事上千万。如果将来真的有一天取消了审查制度，我相信会有很多优秀感人的文艺作品问世的。 其他至于其他的一些书，比如《论人类不平等的发展》,《思考，快与慢》，《彷徨》这些的感受不太容易写出来，而且我要补充一句，都说鲁迅杂文写的牛逼，但是他写景也是一绝。","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"读书","slug":"读书","permalink":"http://yoursite.com/tags/读书/"}]},{"title":"Google SRE读后感","slug":"Google-SRE读后感","date":"2020-02-03T08:42:37.000Z","updated":"2020-02-03T10:23:04.644Z","comments":true,"path":"2020/02/03/Google-SRE读后感/","link":"","permalink":"http://yoursite.com/2020/02/03/Google-SRE读后感/","excerpt":"","text":"职业定义SRE是站点可靠性工程师，与运维不同之处是，运维更多是在别人开发好的系统上当流水线工人，而SRE需要自己开发系统，所以SRE需要有更加强的脚本开发技能，同时也要具备强有力的沟通能力、领导能力和丰富的排错经验。开发技能表现在需要开发一些工具帮助我们监控、事故追踪和压测。而沟通能力是因为我们需要经常与开发人员和产品经理交流，无论是优化环节还是故障排查环节。领导能力是建立在排错经验基础上的，当出现了线上故障，我们要第一时间的迅速定位故障点，同时领导整个团队高效解决故障。 注意！SRE并不负责部署，但是要负责发布！这里发布的概念要比部署大多了，虽然不负责机械化的部署操作，但是SRE更着眼于整个流程，而且更要有流程化思维。 SRE，我个人认为它是与用户站在同一个角度思考问题的，开发人员关注的是功能是否会实现，实现了那就OK了。而SRE关注的是用户用的爽不爽，若用户使用的时候出现了错误，那么SRE就要出场解决问题。 SRE也要注意推动问题解决，SRE不是server reboot engineering…重启大法虽然好，但是治标不治本。 平台稳定与SLO谷歌对系统稳定性有一个比较人性的看法：天底下没有100%不出故障的系统，出故障是正常情况，而如果判断一个系统的健康程度，主要看它是否满足预期的SLO。 SLO是一个重要概念,它中文意思是服务质量目标.服务的故障由于种种原因是无法避免的，每个服务的级别不同，不可能所有服务都是99.999999%，要针对业务的不通特性制定不同的SLO。如果是稳定性要求很高,即与客户有高强度的赔偿协议的服务,那么SLO的级别必须很高，那么付出的代价就是发布变动频率不高或者每一次发布都要严谨评审；而如果是相对冷门涟源的服务，那么SLO可以适度放低。 SLO的制定通常是产品经理、开发团队、SRE一起协商完成，大家根据业务的规模，产品特性，产品处于的阶段制定。当出现了“稳定”与“创新”的矛盾的时候，那么就要产品经理、开发团队、SRE再一次坐到一起修正SLO。 而年度总结的时候，是否满足SLO也是判断SRE的工作业绩的一个考核标准。 值班问题SRE有on-call制度的，即值班制度。这里的值班并不是广义的值班，而是在某个周期，某个成员会成为故障的第一接口人。这段时间里，这位同学保证内网VPN和工作电脑时刻在身边。值班范围可以先从一个小系统开始，然后随着对业务的熟悉而逐渐扩大。 值班同学切记不要搞“个人英雄主义”，该汇报汇报，该求助求助，同时其他同学也不可以“事不关己”的态度，同是一个团队的战友，“解决问题”是大家的共同责任。但是辩证法的看，如果平台太稳定，会导致on-call人员产生惰性，所以有些时候需要“人为制造麻烦”—-不断的演习； 但是总而言之，值班是一个很苦逼的工作，如何让值班变得轻松且成功，也是一个制度改进的问题。 故障排查不要一天到晚盯着“大屏”，而是编写合适的监控与报警规则，让我们能快速找到故障根源； 出故障第一时间先快速恢复（回滚、部分服务降级限流或者是其他方法），可以将流量转移到其他节点去，保留一台服务器作为事故现场，用于事后分析（这里可以看出虽然SRE不用实际手动去部署，但是有权利直接回滚） 故障排查不是一门玄学，平时经验积累是很重要的一环，经验的积累有助于在模糊不清的旁人描述中提高判断力，但是也要注意结合实际环境和最后一次改动，怀疑的范围逐渐缩小最后得到“真凶”。 事后总结要遵循“对事不对人”的原则，这样大家就不惧怕写事后总结了，而且会让事后总结质量提高，可以对新入职的同学有帮助； 结合实际的工作目标首要任务：有效性和覆盖率具体工作内容（☆越多代表优先级越高）：1.对现有的系统二次开发或者利用开源软件搭建环境，得到符合自己业务需要的监控系统（分布式，高可用），监控是SRE的眼睛；☆☆ 1.1 监控系统要从更高的服务质量和链路通讯层面告警，通过API或者是CURL等技术获取整体细节，但是也要能快速定位到具体的颗粒；1.2 告警分级系统，兼顾覆盖率的前提下要突出重点；1.3 准备一个文档，可以给开发或者其他同事讲述如何应对各种告警；1.4 即可以tcp又可以udp的探测系统；1.5 事故根源被跟踪恢复，可能还需要一个基线式的事故跟踪系统；2.需求预测与规划容量，一些大型促销时需要正确计算出扩容的规模；☆☆3.保障大促期间平台的正常运行，处理紧急运维事件，注意满足“1510法则”；☆☆☆4.建立一套完整的on-call值班机制；☆5.当熟悉了系统以及与开发人员交流增多的前提下，参与延迟优化和性能优化等工作；☆6.学习并参与全链路压测；☆☆7.参与各种演习，如故障演习，攻防演习等等，将平时演习得分提升上去；☆☆☆ 书中金句分享1.备份就像纳税一样，是一个服务需要持久而付出的代价，来保障其数据的可用性；2.失败是正常现象，没有100%正常的系统，但是要主动的去寻找失败的可能性；3.用排除法定位故障不是不可以，但是要快速定位，就要平时有对比环境是否一致性的习惯，这就是推动容器化的主要原因；4.SRE通过创造流程、实践以及工具，来提高软件的可靠性；5.一个需要人工阅读邮件和分析报警来决定目前是否需要采取某种行动的系统从本质上是错误的，没有不需要采取行动的警报，如果您遇到一个自己认为不需要执行操作的警报，您需要采用自动化的手段来修复该警报；6.不应该盲目的追求高可用性，从99.99% –&gt;99.999%付出的成本是巨大的，但是收益仅仅是0.009%而已。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"},{"name":"SRE","slug":"SRE","permalink":"http://yoursite.com/tags/SRE/"}]},{"title":"纪念我的姥姥","slug":"纪念我的姥姥","date":"2020-01-22T03:25:42.000Z","updated":"2020-01-22T14:13:45.616Z","comments":true,"path":"2020/01/22/纪念我的姥姥/","link":"","permalink":"http://yoursite.com/2020/01/22/纪念我的姥姥/","excerpt":"","text":"李惠中老人在2020年1月20日夜10点左右驾鹤西游，永远离开了这个世界，而她就是我的姥姥。 她这次意外是出于夜里上厕所自己不小心摔了一跤，导致胯部骨裂。医生检查后发现，年纪太大，骨质疏松已经很严重，所以不建议开刀做手术只能选择静养的保守治疗。随着这么一次折腾，她的各种并发症也一起并发了，元旦我回家看她的时候，甲亢已经很严重了，脖子胖胖的，摸上去软软的，同时还有肺炎，据说严重的时候整个人浮肿的厉害，手指头摸上去，很明显的感受得到老手皮下的液体。不过整个人是清醒的，头发又白又长又乱，眼袋很大，穿着毛衣，外面套着病号服，屁股下垫着成人尿不湿，她整个人木木的坐在被子里，呼噜呼噜的，医生嘱咐不能久坐，所以她更多的时间是平躺或者侧躺。我的几个姨姨和舅妈经也换着花样给她做点鸡蛋羹或者小米粥这样的东西给她喂饭。她食量忽高忽低，我第二次离开医院的时候，她状态很好，吃了一杯酸奶和一碗麦片。后来我到了杭州，听我妈说她的状态是往好转的，水肿消了不少而且甚至可以站起来了，只是不能走动。明明一切情况都是积极的，但是这个肺炎最后还是出现了情况恶化，夺走了她的生命。俗话说七十三八十四，我姥姥还是没有坚持过84这个坎。 我现在还记得姥姥家老房子的客厅结构，那是一个很小的客厅，没有阳台，窗户下面是暖气片，旁边就是一个木头的组合单人床，单人床对面是一个木头的青灰色大书桌，大书桌上有日历、座机电话和一个电视机。书桌上面有局部地方漆掉了，露出了里面的木头。单人床左边是一个长沙发，大约能并排坐下四个成年男子，沙发再左边又是一个单人床，这个单人床挨着墙壁，而墙里还嵌着一个柜子，里面放一些棉被枕头等东西。这个客厅在过年聚会的时候就会热闹，大人们在这里打麻将，小孩子这时候要不就是在单人床上七扭八歪的看电视，要不就是来回的从这个单人床跑跳到对面的单人床上，打打闹闹。 在我印象里，我姥姥并不是一个做饭的好手，她只会做一点简单的炒菜，以及大米饭炒鸡蛋，炖鸡炸鱼我个人是从来没见她做过。主要是她做的菜并不是很好看，所以每次我去她家都是猛劲儿吃蛋炒饭和熟食的。我姥爷走得早，我姥姥的房间在聚会散去之后就会显得很冷清，她自己也习惯了这种喧闹之后突然安静的日子，自己自有自己过的生活。我姥姥信佛，记得老房子里她的卧室还有一个挺大的佛台，供着瓷做的观音和小童子等摆件，佛台上还有一些附近寺里拿回来的经书和烛台。不过这些东西再在家之后好像就扔掉了。 除了信佛之外，我姥姥就没有别的什么业余生活了，她不怎么看书写字，看电视更多就是《西游记》这样的老片儿，朋友来往不算多，平常时候会自己下楼买菜或者遛弯，如果没什么事就早早上床睡了。如果子女忙工作没时间去看她的话，就这样从白天到黑夜，再由黑夜到第二个白天。为了怕她孤独，我的几个姨姨和舅舅也会抽时间过去跟她吃饭，顺便给她带点牛奶蔬菜等食物。姥姥说话很少，虽然到东北多年，但是一口的山西话还是很浓重。后来姥姥牙齿掉光，给她配了假牙，她也随身有一个小杯子，假牙不用了就泡进去。再后来她的耳朵也背了，但是她坚持不要带助听器，无论别人怎么劝。以至于后期跟她交流基本靠吼，打电话基本能累死一个人。也就这样，原本就不太与人交流的她更加沉默。她后来罗圈腿比较严重了，走路颤颤巍巍的，也偶有爬楼梯摔跤的经历，于是搬离了老房子去与我三姨同住。我去年春节回家的时候，全家去三姨家过年，看她自己在一个小屋里躺着，三姨给她调好IPAD，她就一集接着一集的看电视剧，有字幕和声音的帮助来了解剧情，以此来消磨时间。到了吃饭的时候，也是颤颤巍巍的走出来，在桌子边的角落吃点稀饭素菜，依旧不停的给我们小孩这些夹肉夹鸡蛋，或者一个劲儿的让我们喝雪碧可乐。她过年也会给我们这样的孙子辈准备红包，一笑起来，满脸的褶子更多了，一一分发给我们，哪怕我们都已经上班好几年了。 我姥姥是一个普普通通的石油工人家属，相比较我姥爷“郭老大”年轻时候的威风，她更多一种幕后后勤的角色。姥姥有七个子女，四女三男，其中有一个舅舅由于历史原因就一直在老家生活。那时候家里条件不算很好，我姥姥就这样坚持把这六个在身边的子女养大，并且安排他们一个一个都成了家，甚至有了我们这第三代。记得我大舅说过，在他年轻浪荡时，经常打个招呼就出门了，玩好了后再去朋友家喝酒喝通宵，当时没有什么通讯手段，我姥姥就一个一个朋友家的找过去，把醉酒的大舅找到。 我姥姥也有她自己的缺点，她有苏大强的那一面：偏心、固执、对弱者耍脾气对强者逃避。家里能长期忍受她脾气的人不多，除了我大姨也就是我三姨大舅一家了。她有一个弟弟，我叫舅老爷，俩人不知道怎么回事，突然就闹翻了，这一翻就翻了十多年。搞得现在子女往来都有点尴尬，我结婚的时候，舅老爷那边人也没有过来现场祝贺。但是身后第二天烧姥姥遗物的时候，舅老爷家来人悼念了。 今天已经是身后第三天了，我没有赶的回去，听几个已经到东北老家的弟弟说，一大早就出殡做了遗体告别，骨灰也暂放在殡仪馆百日。等头七的时候，我就要带着媳妇儿去给我姥姥磕头烧纸。 但是这几天我就一直在想，待我大年初二到了老家后，看到曾经总有一个人的那张床上空空如也，自己会是一个什么样的心情呢？那会是一种什么样的无奈失落和不适应？ 仁厚黑暗的地母呵，愿在你怀里永安她的灵魂！","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"心情","slug":"心情","permalink":"http://yoursite.com/tags/心情/"},{"name":"亲情","slug":"亲情","permalink":"http://yoursite.com/tags/亲情/"}]},{"title":"Python调用另一个py变量失败的问题","slug":"Python调用另一个py变量失败的问题","date":"2019-12-31T06:37:11.000Z","updated":"2020-01-06T06:43:30.000Z","comments":true,"path":"2019/12/31/Python调用另一个py变量失败的问题/","link":"","permalink":"http://yoursite.com/2019/12/31/Python调用另一个py变量失败的问题/","excerpt":"","text":"举个栗子我有两个文件，第一个文件a.py的内容如下： 1234567891011121314151617181920212223242526#!/usr/bin/env python# coding=utf-8CHOOSE = input (''' \\033[1;35m choose 1 or 2:\\033[0m 1)tom 2)jack''')a = 666b = \"bbb\"def f(): print(\"this is a test\") return \"function\"if __name__ == '__main__': if CHOOSE == '1': username = 'tom' print(username) elif CHOOSE == '2': username = 'jack' print(username) else: print('wrong choice,script is exit...') 拎一个脚本，b.py的内容如下： 123456789#!/usr/bin/env python# coding=utf-8import afrom a import b,f,CHOOSE,usernamea = a.af()print(b,a,CHOOSE,username) 可以看出b.py的内容就是调用同目录下a.py的变量，但是执行b.py是会报错的。 可见b.py已经成功读取到了b,f,CHOOSE这些变量，但是username却引入失败，为啥呢？ 因为a.py里有一个if __name__ == &#39;__main__&#39;，他的意思是当.py文件被直接运行时，if name == ‘main‘之下的代码块将被运行；当.py文件以模块形式被导入时，if name == ‘main‘之下的代码块不被运行。 举个例子解释一下：假设你是小明.py，在朋友眼中你是小明(name == ‘小明’), 你自己眼中你是你自己(name == ‘main‘)。 你编程很好, 朋友调你去帮他写程序(import 小明, 这时你在朋友眼中: name == ‘小明’),但你晚上也会打开xx网站, 做一些自己的事情(直接运行小明.py, name == ‘main‘)—摘自知乎网友回答。 既然知道了原因，解决方法也很简单：把a.py里的if __name__ == &#39;__main__&#39;段落拆掉，把相应内容改成一个函数，比如a.py改成如下的样子： 12345678910111213上面内容略def foo(CHOOSE): if CHOOSE == '1': username = 'tom' elif CHOOSE == '2': username = 'jack' else: username = None return username b.py改成如下样子(其他可读取的变量不考虑)： 123456789101112from a import fooCHOOSE = input (''' \\033[1;35m choose 1 or 2:\\033[0m 1)tom 2)jack''')username = foo(CHOOSE)if username: print(username)else: print('Wrong choice') 这样问题就解决了，记住if __name__ == &#39;__main__&#39;更适合放在脚本的入口点。 上面说了，if __name__ == &#39;__main__&#39;更适合放在脚本的入口点，到底哪个程序入口被选中，这取决于__name__的值，__name__是内置变量，可用于表示当前模块的名字。如果一个.py文件（模块）被直接运行时，则其没有包结构，其__name__值为__main__，即模块名为__main__。 所以，if __name__ == &#39;__main__&#39;的意思是：当.py文件被直接运行时，if __name__ == &#39;__main__&#39;之下的代码块将被运行；当.py文件以模块形式被导入时，if __name__ == &#39;__main__&#39;之下的代码块不被运行。 上面的话，可以做一个小实验来理解，我们在a.py里if __name__ == &#39;__main__&#39;之前加入print __name__，即将__name__打印出来，那么执行a.py会看到__name__输出是__main__。 但是此时a.py不动，直接执行b.py，会发现__name__变量值为b,不满足__name__==&quot;__main__&quot;的条件，因此，无法执行其后的代码: 参考资料https://zhuanlan.zhihu.com/p/34112508http://blog.konghy.cn/2017/04/24/python-entry-program/https://stackoverflow.com/questions/419163/what-does-if-name-main-dohttps://www.zhihu.com/question/49136398 （里面有很多例子）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Zabbix配置discovery主动发现ActiveMQ队列","slug":"Zabbix配置discovery主动发现ActiveMQ队列","date":"2019-12-19T11:44:02.000Z","updated":"2019-12-20T08:38:24.000Z","comments":true,"path":"2019/12/19/Zabbix配置discovery主动发现ActiveMQ队列/","link":"","permalink":"http://yoursite.com/2019/12/19/Zabbix配置discovery主动发现ActiveMQ队列/","excerpt":"","text":"快到年关了，领导大手一挥，要把线上环境切换新的VPC。既然要切VPC，就要与原有的VPC决裂，也要重新搭一套zabbix了，搭建activemq监控项就难免要监控各种队列，但是每个activemq里面的队列名又不同，一个一个特殊配置太头疼，于是就尝试使用主动发现来做，系统自己匹配队列。 后端脚本首先要先准备一个discover_mq.py，如下： 123456789101112131415# !/usr/bin/env python # -*- coding: utf-8 -*-# 用来获取当前mq的队列名try: import jsonexcept: import simplejson as jsonimport commands(status, output) = commands.getstatusoutput(\"\"\"curl -s -u 'mq前端页面账号:mq前端页面密码' http://127.0.0.1:8161/admin/queues.jsp|grep '&lt;/a&gt;&lt;/td&gt;'|awk -F'&lt;' '&#123;print $1&#125;'\"\"\")outputs = output.split('\\n')result = []for one in outputs: result.append(&#123;'&#123;#RESULT&#125;': one&#125;)print(json.dumps(&#123;'data':result&#125;,sort_keys=True,indent=4)) 这个脚本执行就可以获取当前所有的队列名，如图： 然后再准备一个monitor_mq.sh，如下： 12345678910111213141516171819#!/bin/sh# 获取每一个队列的入队、出队和积压量username=mq前端页面账号password=mq前端页面密码myip=$1queuename=$2mytype=$3case $&#123;mytype&#125; in Pending) curl -s -u \"$username:$password\" \"http://$&#123;myip&#125;:8161/admin/queues.jsp\"|grep \"^$&#123;queuename&#125;&lt;/a&gt;&lt;/td&gt;\" -A 5|sed -n '2p'|egrep -o '[0-9]+' ;; Enqueued) curl -s -u \"$username:$password\" \"http://$&#123;myip&#125;:8161/admin/queues.jsp\"|grep \"^$&#123;queuename&#125;&lt;/a&gt;&lt;/td&gt;\" -A 5|sed -n '4p'|egrep -o '[0-9]+' ;; Dequeued) curl -s -u \"$username:$password\" \"http://$&#123;myip&#125;:8161/admin/queues.jsp\"|grep \"^$&#123;queuename&#125;&lt;/a&gt;&lt;/td&gt;\" -A 5|sed -n '5p'|egrep -o '[0-9]+' ;;esac 然后就是准备zabbix的自定义监控项： 12UserParameter=activemq.discover, python /mnt/discover_mq.py #我放到/mnt目录下了UserParameter=activemq.check[*],sh /mnt/monitor_mq.sh $1 $2 $3 重启zabbix-agent，此时别忘了在/etc/sudoers添加上 12zabbix ALL=(root) NOPASSWD: /usr/bin/pythonDefaults:zabbix !requiretty 前端配置来到zabbix-server前端页面，先在对应的templates添加Discovery，如图： 点击Create discovery rule，创建一个规则： 然后创建3个item prototypes，每一个对应入队、出队、积压量，如图： 还可以针对积压量做一个Trigger prototypes的告警。 保存之后，整个主动发现就配置到整个Templates，我们可以抽查一个机器，看一下是否自动匹配到所有的队列： 大功告成，收工回家！","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"监控技术","slug":"监控技术","permalink":"http://yoursite.com/tags/监控技术/"},{"name":"Zabbix","slug":"Zabbix","permalink":"http://yoursite.com/tags/Zabbix/"}]},{"title":"美妙的东京八日游","slug":"美妙的东京八日游","date":"2019-12-03T15:24:27.000Z","updated":"2019-12-25T10:00:08.000Z","comments":true,"path":"2019/12/03/美妙的东京八日游/","link":"","permalink":"http://yoursite.com/2019/12/03/美妙的东京八日游/","excerpt":"","text":"9月份的时候，俺就跟媳妇琢磨想要一起休有薪假，原本打算去台湾转转，但是由于国家政策变化只能作罢，而我个人对韩国、老挝、柬埔寨也没啥感觉，于是选来选去还是决定二刷日本，不过这次目的地不再是大阪了，而是东京。 买了国航的票，一大早9点半从杭州坐机场大巴到浦东机场，当时上海正值国际进口博览会，刚入上海还要停车—所有人下车安检。之后顺利到达浦东机场，办理值机托运和出关手续之后，我和媳妇买了两个汉堡王套餐垫垫肚子。终于等到1点半起飞，4点抵达成田机场。 在日本办理入关的时候还有一个小插曲，我媳妇随身携带的布包里有飞机上吃剩的柚子和玉米，结果入关时被搜查犬盯上闻来闻去，然后与搜查犬一起的小姐姐就拿出一个纸片，上面有中文：“您的包裹里有食物，请配合我们检查”，于是我们就配合的检查了一下，检查完毕食物并没有没收照样还给了我们。插曲结束，跳上skyline直达东京市区，又买了东京3日地铁卡，然后按照google导航顺利找到酒店办理入住。 我们住的是平价酒店，在店员的指导下用机器checkin，到了房间里发现什么东西都很小，桌子小、卫生间小、浴缸小，除了大床剩下的基本能上墙的都上墙了。虽然小，但该有的都有，而且很整洁，很精致。我也人生第一次使用了他们的水冲屁屁马桶，那感觉还真有点“酸爽”。每天早上宾馆还有早餐，虽然免费的只有两个套餐，但是可颂抹黄油再配上一杯红茶还是挺好吃的。 我住的酒店位于茅长町。茅长町在当地是一个普通的住宅区，初到的那个晚上把行李放好之后，在酒店四处走了走，发现附近都是住宅区、小商店、写字楼、小公园，并没有什么景点。不过日本的街道很好玩，因为楼与楼很近，感觉就像迷宫一样，我就在各种小路里溜达探索，意外的发现了一个小神社，神社里还有人再出售神符。而且这个神社还挺有人气的，又一次我早上来溜达的时候，看到一个穿正装的女子前来拜祭，啪啪拍了两下手低头鞠躬，然后还往功德箱里面扔了几个硬币。估计这位妹子是去求职面试吧，希望自己能有一个好运气。 具体的行程表如下：11月9日 杭州东站—上海浦东机场—东京成田机场入关—茅长町酒店入住，周围小转11月10日 台场—自由女神–杜莎夫人蜡像馆–SEGA欢乐城—海贼王公园—东京塔观光11月11日 东京迪士尼海洋公园11月12日 东京国立博物馆—不忍池—秋叶原11月13日 雷门—浅草寺—上野动物园—茑屋书店（代官山店）11月14日 镰仓小町通—鹤岗八幡宫—镰仓高校打卡—歌舞伎町一番街11月15日 新宿买买买11月16日 东京成田机场买买买—上海浦东机场—杭州东站 东京迪士尼海洋公园东京迪士尼毫无疑问是本次东京之行的重头戏，非常值得独立出来说，它的篇幅也的确有点大。我们去的是迪士尼海洋园区。为了这趟迪士尼，本人着实下一番功夫：先去东京迪士尼的官网注册会员然后购买了门票并且打印出二维码。东京迪士尼跟上海的迪士尼不一样—FAST PASS卡不是用钱买的，而是需要抢的，如果不想自己掐着表在园区里跑来跑去，那么就需要下载两个app—Disney Resort和TDL/S时间： 但是这里要注意，只有日版的apple store才能下载到这俩个app，所以你需要用一个邮箱来申请一个日区的apple store账号，下载APP完毕之后，在Disney Resort需要登陆的也是你在东京迪士尼网络上注册买票的账号！这里是比较坑的一个地方。 这样在官网买了票，又准备了APP抢FAST PASS卡，带上几瓶水和简单的干粮。我和媳妇就一大早起床出发，直奔迪士尼海洋，到了园区拿了中文地图就方便多了，我俩足足玩了一整天，各种打卡拍照不亦乐乎。东京迪士尼我个人觉得必刷的几个项目： 百老汇演出，这个第一场是随便进的，强烈推荐去看！除了第一场剩余的都要抢票才可以； 玩具总动员，这个跟上海迪士尼不一样，比上海迪士尼的更好玩； 惊魂古塔，超级超级超级的跳楼机，我跟媳妇琢磨了许久，最后没敢上… 至于忿怒双神（过山车），飞跃地平线等项目也都很棒，但是跟上海迪士尼的差不太多，所以我强烈建议优先搞定上面三个。至于龟龟漫谈、神灯阿拉丁还有其他的部分项目，是有日语对白的，所以如果不懂日语就只能看个热闹。 迪士尼海洋馆是没有花车游行的，但是中午会有露天舞蹈演出，我们去的时候已经属于圣诞节期，所以NPC们穿的都是圣诞装束了。到了晚上八点半，园区中央同样会有游船表演和烟火，只不过规模没有旁边迪士尼主区那么大。虽然东京迪士尼相比较大阪的环球影城更加偏低龄化，但是也非常值得花一天去享受，里面的火鸡腿也很好吃！ 东京的文化东京国立博物馆是收费的，同样可以先在官网购买票，打印出票或保存二维码直接入门。我自己都没想到我花在东京国立博物馆的时间竟然比当时在大英博物馆的时间都要长，可能是因为国立博物馆主馆部分游客不多，许多展品可以一件一件的看过去，在这个空旷的展厅一个字一个字的读铂了金的佛经也是一个乐事。国立博物馆正馆里有一个特殊的小展厅，它里面每个月都会换国宝文物来展出，我去的时候正好是展出唐朝《群书治要》的手抄卷的一部分。 出了正馆，右手边就是东洋馆，不过先不急，天气特别好。我就在长凳上慢慢喝了一杯热咖啡，顺便晒晒太阳。东洋馆的“人，神，自然”特别展出给我留下的印象比较深刻—展厅中央是两具古尸，周围是各种公元前时代各种的祭品。人类本相通，无论什么种族肤色，都是从祭祀敬天慢慢的进化到娱己重我，那些静静躺着的文物也无声的证明这这段时光。在东洋馆3、4楼有较大的一片区域专门展出中国文物，有商朝的摇钱树、唐朝的器皿、宋朝的字画。底楼是展出波斯柬埔寨等国的文物，在展厅二楼中间可以掷骨算命和印章这样的小互动，免费玩一玩游戏还是蛮有意思的。 今年是日本新天皇上任，所以国立博物馆特意安排了奈良的正仓院举行特别展出，这次特别展出的招牌就是传世唯一唐朝五弦琵琶。果然那个琵琶附近全是人，排成队的流动。这次正仓院展出是额外收费的，而且只能凭借纸质票补差价，如果是电子票必须全额买，这一点比较坑。话说日本有很多老头老太太来逛博物院，一个个走的颤颤巍巍的。 除了博物馆，东京还有很多的美术馆，这里面我个人强烈推荐根津美术馆，它是一个私人收藏馆，整个园林的布置非常的考究，但是很遗憾，八天的时间里由于根津美术馆维修，我只能缘悭一面。后来我媳妇的闺蜜在12月初去了根津美术馆，媳妇闺蜜发微信说12月枫叶红了，整个根津美术馆特别漂亮和雅致，惊艳到她了。 东京的买说到买，东京有著名五大购物区—新宿、银座、池袋、涩谷、六本木。我俩行程里只安排了一天的购物，所以就在新宿泡了一整天。今年人民币贬值比较厉害，所以在东京购物相比较大陆，实惠的力度稍打折扣，不过还是比国内便宜很多，我买了一个加南大鹅的棉马夹，淘宝要4000，日本价格不到3100人民币。除此之外，买了三盒蒸汽眼罩。 江湖传言Adidas和North Face在日本都能买到特殊设计的服装，果然这两个品牌店在东京也是比较好找的。里面的款式也的确是国内专卖店没有的，看上去都很潮。不过很可惜，日本的男性普遍都是瘦身材，所以衣服最大码就是L码，对于我说来看到喜欢的衣服却没有XL码真是一个很痛苦的事情。 说完了买衣服再说说别的。台场商业中心是高达死忠粉必打卡的地方，中心门口的巨型高达已经足够吸睛，据说每天有两场灯光秀。而商场里最顶层有一半的空间是高达基地。这个简直可以称之为“高达博物馆”的地方里面有各式各样的高达手办，甚至可以自己DIY给高达配色和组装零部件。 如果你是NBA死忠粉，那么在台场商场的NBA店会看到许多NBA巨星的签名和球鞋，从飞人乔丹魔术师约翰逊鲨鱼奥尼尔再到艾弗森库里，中国长城姚主席的球衣也在展列柜里： 到了东京怎么能不去秋叶原？秋叶原以死宅的“圣域”而闻名，里面手办、游戏、漫画、写真、COSPLAY的衣服，无论是见过的没见过的，知道名的不知道名的，应有尽有。当然如果你乱走，也会有可能误入出售岛国爱情动作片和成人用品的地区，完全是意外之喜啊！ AKB48的剧场也位于秋叶原，如果你看过WorldOrder舞团的《Have a nice day》的MV，应该会对这里有点印象： 我是斋藤飞鸟的死宅粉，那么买一个我鸟的写真集也是早早就列入愿望list里的。而代官山的茑屋书店是一个很著名的书店，书店是全玻璃体，分三个部分，有露天楼梯相通，书店里出售书籍、影像、CD、文具、蓝牙音箱、车模乃至超市用具都有，甚至可以在里面边看书边吃饭。我在网上看它是一个东京少数的24小时店，甚至还提供住宿服务，不过我转了一圈并没有发现可以睡觉的地方… 东京的吃在东京吃东西很贵，我一个普通工薪族也没有安排特别高大上的东西。几天下来我个人觉得最好吃的就是在新宿店吃的“鸟贵族”，他们以烧鸟作为招牌菜。先叫上两杯梅子酒，吃上几串芝士鸡肉丸，我个人非常喜欢他们的天妇罗，炸的软软的，入口即。鸡皮盐味烤也不错，鸡皮烤得脆焦程度刚好，而且并不油腻。咬下去汁液在口腔中四溅，像盛开的烟花。再叫上一杯大扎啤，歇歇逛了一天的脚，感觉好极了。 在七里滨，我跟媳妇慕名来尝尝这里的bills—传说中最棒的早餐。我俩到达的时候已经是下午4点左右，已经开始排起了小队，但是队伍并不长。这里招牌的就是pancake，好吃到流泪，随着松饼温度而慢慢溶化的蜂蜜奶油，更增添香味。奶油让松饼入口即化，细细咀嚼后能够感受到淡淡的乳香，搭配上烤过的香蕉片，清爽甜蜜的美味让人难忘。虽然银座也有bills，但是七里滨的bills位于海边，当时正好是渐渐夕阳的时间段，在店里靠窗户的位置还能看着大海里一个一个冲浪结束返回的人，无敌的海景view。 在上野公园，正好有机会去尝了尝一兰拉面，一进店门机器投币下单，机器打印小票，每人单人隔间，把外套挂到身后的衣架上，小票放到小盘里按一下桌子上的按钮，就会从店员从帘子后面伸出手来把小票拿走，根据小票内容准备食物。如果想要多加一份面或者半份面也是在门口的机器上投币下单，然后重复的把票放到小盘里按按钮即可。豚骨拉面还是很好吃的，他家的绿茶豆腐也很棒，没有那么甜，绿茶味挺浓。 陈晓卿先生在《圆桌派》里说过：想了解一个城市，就一定要去它的菜市场，饱览里面的食材，饱尝各种美味。筑地市场现在也成了东京的一个景点，那是一个当地很有名的水产市场，很可惜它要搬走了，由于2020东京奥运会的缘故。 至于女仆咖啡店，老夫只是在秋叶原的街上遇到上穿羽绒服下穿短裙的卡哇伊妹子发传单，而没有亲身尝试。现在很多女仆咖啡店也开始对中国人做生意了，提供中文菜单，而且可以跟众多女仆妹子们一起嗨。秋叶原的女仆店价钱比新宿的女仆店要便宜一点，但是秋叶原的咖啡店玩法比较多，除了女仆还有三国系列，为什么会有三国设定？学赵子龙七进七出嘛？好吧，我承认我开车了… 东京的玩东京作为国际级别大都市，地标建筑很多，我们第一天晚上就去了东京塔。东京塔有一个网红拍摄地，就是在一个地下室的台阶上仰拍整个东京塔，我跟媳妇去的时候发现那里已经有不下50个人在排队拍照，有些是拍塔，有些是连塔带人一起拍。东京塔里吃的东西一般，但是海贼王主题乐园就在东京塔里，在网络上购票比现场买便宜，而且还可以买东京塔观光的联票。海贼王主题乐园的周边出售到没有什么特别新奇的，而且很多一看就是义乌小商品。但是里面的真人表演还是挺棒的，还原度挺高，每人还发一个荧光棒来配合演员唱歌，剧情是独立的内容。 出了海贼王我们就直接上塔观光，东京塔有两层用来观光，高度不同价钱自然也不同。其实在main deck里能看到东京大部分的市容风景，top deck风景更佳。虽然现在东京的晴空塔更新更高，但是在很多东京人的心中，东京塔还是有一个无法磨灭的地位在。 SEGA欢乐城其实就是一个超大的电子游戏机厅，除了常规的游戏机之外（不过我在东京的游戏机厅里没见过《拳皇》），里面也有一些全体作战的重量型主题游戏机，需要4~10人一起玩的。如果你日文读的能力差一点的话，可能有些地方就要乱按键，看看能不能瞎猫碰上死耗子了。 上野动物园跟不忍池都在东京国立博物馆旁边的上野公园里，我去的时候池塘的荷花已经败掉了，但是在上野动物园看到了著名的鲸头鹳，呆呆傻傻的，偶尔一张开翅膀惊得很多人欢呼。在动物园经常看到日本的老头老太太在笼子外无声的做手势，嘴巴里轻轻的呼唤着里面的动物，希望可以得到动物的注意而跑过来。除了鲸头鹳，上野动物园的镇馆之宝就是大熊猫了，毫无疑问，熊猫馆排队也是非常惊人的，我跟媳妇没有去凑这个热闹。 我们这次还抽出了一天的时间去镰仓，拜访了著名了镰仓高校车站。这个车站已经被众多《灌篮高手》的粉丝打卡，尤其是火车过站的时候，很多中国游客在狂热的拍照。车站往上走一点点就能看到镰仓高校，学校门口有一个告示牌：“请游客不要入内拍照”，可见这个学校虽然作为湘北高校的原型而红遍大江南北，但是也饱受游客骚扰之苦。 说完了健康的娱乐，再说一点不健康的…在上野公园出来的路边，我惊喜的发现了成人电影院（囧）。看广告应该是500日元可以看一小时，可以一直看到深夜，成人影院门口贴满热辣的马赛克海报以及门口也摆了一两个穿制服的塑料模特。我驻足一会，顶着被抓的风险，拍了几张照就离开了… 东京的人这此是我第二次来东京，觉得其实日本人还是很好分辨的。日本女人不用多说，妙龄少女打扮的很精致，贴假睫毛，牙齿又不算太整齐的话，那基本就是日本妹子了（甚至女厕所里会有梳妆台！别问我怎么知道的…）。而东京男人的体态特征也很明显，首先他们由于瘦，脸长且面部的棱角比较突出，而且感觉他们还都很喜欢鹰钩鼻，不知道是否有专门做这方面整容的医院。除了面部器官，头发也是识别东京男人的一个标志，很多年轻人都喜欢卷卷的头发，或长发或刘海，配上他们苗条的身材和不大的脸蛋，有些“花美男”的味道。 日本人超级能排队，当然据说他们心理对于“排队”也是拒绝的，但是身体却很诚实。上到美术馆下到拉面店，日本人在哪里都能排队。记得在迪士尼海洋，在环球喷泉最佳拍摄角度那里，日本人都会自发排队一个一个拍照…据说这是一种从众的体现。而且东京没有共享单车，因为几乎家家都有自行车，如果是住独栋的，院子里也会停一辆小排量的家用车。 日本的电车跟伦敦的一样，没有安检。站台非常干净，车厢里也是十分安静，很多人戴着口罩，不知道是遮住早起的倦容，还是藏着工作了一天的疲惫。刷手机，听歌，或者玩switch。看着车上的上班族，让我不自觉的想起日本综艺节目《让我去你家》里的一个一个小故事。想必国际大都市大抵都是这样，挤满了人，灯火辉煌的后面是一颗颗孤独的心。站在银座伊势丹的顶层，俯瞰这来往穿梭的人群车流，绝对是独一无二的景致。 上一次在大阪没有机会感受柏青哥，这次到了秋叶原也去转了一圈。发现里面各种柏青哥游戏机，小的是一个人玩的飞牌机，最大的有8个人一起玩的。在柏青哥店里，同样有吃有喝，排队等机器的话甚至可以看店家提供的杂志和漫画。店里20~80岁的各年龄层的男女顾客在这霹雳哗啦吵杂的声音里专注的盯着自己的屏幕消磨时间。有的人甚至旁边有一个小筐，筐里全是钢珠。但是柏青哥店并不是通宵营业，11点就关门了。 除了以上几点，东京给我更大的感触，就是虽然警车会在街上巡逻，但是生活中没有那么多的安检—-地铁没有，博物馆没有，甚至在机场也没有人来摸你检查有没有带违规东西。这一现象大陆几乎不可能，而对于我来说是很舒服的。 东京tips 从成田到东京市内可以坐skyliner，这个可以在网上直接订票，然后凭借二维码直接刷码入场。不过价钱有点小贵，但是车上很空； 东京迪士尼海洋馆没有漫威和星球大战的区域，也没有他们的周边卖； 宫崎骏美术馆需要至少提前一个月买票，如果实在没有票可以尝试去闲鱼购买，价钱比淘宝上便宜很多； 如果三年内两次入境日本，可以办理日本免签了； 8天很快就过去了，我这一次没有去的地方还很多：明治神宫、吉普力博物馆、晴空塔、棒球场、涩谷、池袋等等等等。但是整体玩下来，感觉到东京无愧于亚洲第一城市，繁华、奢靡、喧闹、庞大，这样的形容词来形容它的日和夜。静与杂，非常和谐的充斥在这座城市的24小时。对于日本来说，东京承担着“北京+上海”的职责。它在1945年被美军轰炸，而1964年就举办了东京奥运会，再生速度简直惊人！ 东京，是一个规则更加分明、细节更加发达的城市，但是这个城市里又容纳了各种各样的人和他们的文化，无论是奥特曼还是哥斯拉，火影忍者还是AKB48，每天发生着不同的故事，为这个城市增加了无限多的可能性。我这次仅仅是走马观花，东京给我的感觉就是这样一个干净、安全，人与人之间礼貌、尊重、信任的城市。作为一个游客，我还是想再玩一次！","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"旅游","slug":"旅游","permalink":"http://yoursite.com/tags/旅游/"},{"name":"日本","slug":"日本","permalink":"http://yoursite.com/tags/日本/"}]},{"title":"Zabbix添加多个微信告警渠道","slug":"Zabbix添加多个微信告警渠道","date":"2019-11-27T07:44:35.000Z","updated":"2019-11-27T13:01:04.000Z","comments":true,"path":"2019/11/27/Zabbix添加多个微信告警渠道/","link":"","permalink":"http://yoursite.com/2019/11/27/Zabbix添加多个微信告警渠道/","excerpt":"","text":"我们的zabbix监控项好几千个，这些告警都是使用同一个微信公众号的应用去报警，这样很多告警刷来刷去，就会把一些重要告警淹没。于是我们一方面做了更加详细的告警分级，而且也增加多个微信应用。让每个应用更加有针对性的告警，就不再大杂烩了，避免重要报警遗漏。 本文目的就是创建一个新的微信应用，专门用来告警这个Templates下的情况： 首先，先去微信企业号里创建一个新的应用，如图： 然后将原来zabbix-server上的wechat.py复制一份，比如叫proxysql-wechat.py，修改对应的corpsecret和agentid，改成新应用的。这个脚本可以去看https://rorschachchan.github.io/2018/01/10/Zabbix3-0%E6%90%AD%E9%85%8D%E5%BE%AE%E4%BF%A1%E4%BC%81%E4%B8%9A%E5%8F%B7%E6%8A%A5%E8%AD%A6/ 。 下面就来到zabbix server的Web端，首先Administrain---Media Types，增加一个新的告警媒介Proxysql-wechat，使用的脚本就是刚刚复制出来的proxysql-wechat.py： 然后再去Users里创建一个新的用户，因为原来的Administrator已经有了微信告警，所以要创建一个新的用户来专门接收proxysql-wechat.py的告警： 把它的media改成Proxysql-wechat： 下一步很容易遗忘，就是在Permissions里给这个用户对应的Templates下所涉及用户组的全部权限，当然，如果你胆子大（比如我），可以给这个用户Super权限： 告警人和告警路径已经搞定，下面就是要配置“什么样的告警才可以触发此微信应用，同时其他应用不要重复发信”。 来到Configuration---Actions，新创建一个triggers的action： 这里声明此action只会关注templates为”proxysql单独监控”的triggers情况。 在Operation details别忘了配置各个环节的Send to Users和Send only to： 保存之后，我们还要把原有的微信应用告警更改一下，如果不该的话，”proxysql单独监控”这个Templates触发了告警，两个微信应用都会告警，于是就把老的action改成如下： 此时触发一下”proxysql单独监控”这个Templates涉及的告警项，就会看到只发送了proxysql-wechat，而老的wechat媒介没有被触发。 微信也能正常收到信息： 总结一下：如果希望新增加一个报警途径，那么就新在后台创建脚本，然后在前台创建媒介，创建连接此媒介的用户，最后在告警action上配置正确的规则就OK了！","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"监控","slug":"监控","permalink":"http://yoursite.com/tags/监控/"},{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"}]},{"title":"解决Ssh时出现Connection closed by remote host的问题","slug":"Ssh时出现Bad-protocol-version-identification的坑","date":"2019-11-21T06:49:18.000Z","updated":"2019-11-21T08:08:04.000Z","comments":true,"path":"2019/11/21/Ssh时出现Bad-protocol-version-identification的坑/","link":"","permalink":"http://yoursite.com/2019/11/21/Ssh时出现Bad-protocol-version-identification的坑/","excerpt":"","text":"今天遇到一个超奇怪的现象：同一台服务器，有的可以ssh通，有的不可以ssh通。故障机器的ssh细节如下： 发现成功的服务器会持续到： 12debug1: Remote protocol version 2.0, remote software version OpenSSH_7.4debug1: match: OpenSSH_7.4 pat OpenSSH* 这一步，而失败的服务器会直接断开，并且爆ssh_exchange_identification: Connection closed by remote host的错误。 来到要连接的服务器上，查看/var/log/secure，发现每次失败的服务器每次发起ssh连接请求的时候，会有如下日志： 12Nov 19 15:56:26 iZuf6h1kfgutxc3el68z2lZ sshd[15096]: Bad protocol version identification '\\026\\003\\001' from X.X.X.X port 38966Nov 19 15:56:27 iZuf6h1kfgutxc3el68z2lZ sshd[15097]: Bad protocol version identification '\\026\\003\\001' from X.X.X.X port 38990 查了很多资料，基本都说请检查/etc/ssh/sshd_config、/etc/hosts.allow、/etc/hosts.deny、安全组和iptables。我把上面的文件在两台服务器都进行了对比，发现没有什么不同。 后来才发现这里有一个很深的坑，iptables -L的结果其实不一定是真的！最重要的是要看iptables-save的结果： 上面可见iptables -L返回的结果虽然是空的，但是iptables-save却是有内容的，怪不得连接不上。 如果要删除iptables-save这里的规则，直接service iptables stop即可。但是如果在启动iptables时有No config file的警告错误的话，任意添加一条策略，然后保存就能正常启动了： 12iptables -P OUTPUT ACCEPTservice iptables save","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"ssh","slug":"ssh","permalink":"http://yoursite.com/tags/ssh/"},{"name":"itables","slug":"itables","permalink":"http://yoursite.com/tags/itables/"}]},{"title":"Python从Mysql里获取值并且调用ansible批量执行的脚本","slug":"Python从Mysql里获取值并且调用ansible批量执行的脚本","date":"2019-11-20T11:17:34.000Z","updated":"2019-11-20T11:39:26.000Z","comments":true,"path":"2019/11/20/Python从Mysql里获取值并且调用ansible批量执行的脚本/","link":"","permalink":"http://yoursite.com/2019/11/20/Python从Mysql里获取值并且调用ansible批量执行的脚本/","excerpt":"","text":"我们的服务器资产信息都是在购买的时候就记录在mysql里的，表结构如图： 可见我们的服务器命名都是有标准的，即Ez4IP_地域缩写_模块名，如果有T就是测试环境没有T就是正式环境，现在就是要从mysql里取出来对应的值然后再由ansible 2.7批量执行命令，脚本如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166# !/usr/bin/env python# -*- coding:utf-8 -*-# 作者：ChrisChan# 用途：海外模块获取IP脚本，首先先从mysql数据库里获取对应IP，然后写上对应的命令，批量操作# 注意！这里写死了Ez4ip_XX_xx的格式，如果有需要则自己手动更改import pymysql, argparse, os, json, shutilfrom collections import namedtuplefrom ansible.parsing.dataloader import DataLoaderfrom ansible.vars.manager import VariableManagerfrom ansible.inventory.manager import InventoryManagerfrom ansible.playbook.play import Playfrom ansible.executor.playbook_executor import PlaybookExecutorfrom ansible.executor.task_queue_manager import TaskQueueManagerfrom ansible.plugins.callback import CallbackBaseimport ansible.constants as C# 命令行参数parser = argparse.ArgumentParser(description='本脚本先从mysql获取内网IP地址，然后回滚')parser.add_argument('-i', '--iii', metavar='目标模块名,如Ez4ip_FK_messagepushservice', required=True, dest='hosts', nargs='+', help='请必须输入一个模块名，不然无法执行数据库查询') # required表示此字段一定需要,nargs=’+’ 表示至少一个参数args = parser.parse_args()def checkSQL(i): # 使用cursor()方法获取操作游标 cursor = db.cursor() # SQL 查询语句 sql = \"select * from cloudresource_aws_instance where instance_name regexp '\" + i +\"' and project_name regexp 'ez4ip';\" try: cursor.execute(sql) results = cursor.fetchall() # 获取所有记录写到文件里，这个文件将来给ansible用 for row in results: instance_name = row[3] instance_innerip = row[4] print(\"instance_name=%s,instance_innerip=%s\" % (instance_name, instance_innerip)) f.write('\\n'+instance_innerip) except: print(\"出现错误，mysql无法获取到数据！\")class ResultCallback(CallbackBase): \"\"\" 重构ansible输出 \"\"\" def __init__(self, *args, **kwargs): super(ResultCallback, self).__init__(*args, **kwargs) self.host_ok = &#123;&#125; self.host_unreachable = &#123;&#125; self.host_failed = &#123;&#125; def v2_runner_on_ok(self, result, **kwargs): \"\"\"成功\"\"\" self.host_ok[result._host.name] = result._result[\"stdout\"] def v2_runner_on_unreachable(self, result, **kwargs): \"\"\"不可达\"\"\" self.host_unreachable[result._host.name] = result._result[\"msg\"] def v2_runner_on_failed(self, result, ignore_errors=False, **kwargs): \"\"\"失败\"\"\" self.host_failed[result._host.name] = result._result[\"stderr\"]def runner(ansible_host_path, module, args): \"\"\" 类似Ad-Hoc命令 :param ansible_host_path: 一个清单文件，一行一个ip就行 :param module: :param args: :return: \"\"\" Options = namedtuple('Options', ['connection', 'module_path', 'forks', 'private_key_file', 'remote_user', 'become', 'become_method', 'become_user', 'check', 'diff']) options = Options(connection='smart', module_path=None, forks=10, private_key_file=\"/root/.ssh/id_rsa\", # 你的私钥 remote_user=\"guest\", # 远程用户 become=True, become_method=\"sudo\", become_user=\"root\", # sudo的用户 check=False, diff=False) # 主要加载设置的变量 loader = DataLoader() # 一个密码参数，可以设置为None，默认即可，没什么影响，我用的是秘钥登录 passwords = dict(vault_pass='secret') # 结果回调 callback = ResultCallback() # 设置传入的机器清单 inventory = InventoryManager(loader=loader, sources=[ansible_host_path]) # 加载之前的变量 variable_manager = VariableManager(loader=loader, inventory=inventory) play_source = dict( name=\"Ansible Play\", hosts=\"all\", # all表示匹配清单所有机器，看源码发现的 gather_facts=\"no\", tasks=[ dict(action=dict(module=module, args=args), register='shell_out'), ] ) play = Play().load(play_source, variable_manager=variable_manager, loader=loader) tqm = None try: tqm = TaskQueueManager( inventory=inventory, variable_manager=variable_manager, loader=loader, options=options, passwords=passwords, stdout_callback=callback, ) result = tqm.run(play) finally: if tqm is not None: tqm.cleanup() shutil.rmtree(C.DEFAULT_LOCAL_TMP, True) # 重构输出 result_raw = &#123;'success': &#123;&#125;, 'failed': &#123;&#125;, 'unreachable': &#123;&#125;&#125; for host, result in callback.host_ok.items(): result_raw[\"success\"][host] = result for host, result in callback.host_unreachable.items(): result_raw['failed'][host] = result for host, result in callback.host_failed.items(): result_raw['unreachable'][host] = result return json.dumps(result_raw, indent=4)# 连接mysqldb = pymysql.connect(\"mysql连接地址\", \"mysql账号\", \"mysql密码\", \"database名称\")# 打开文件 f = open('/home/chens/instance.txt','a')# ansible文件所在的路径ansible_host_path = os.path.join(os.getcwd(), \"instance.txt\")try: for host in args.hosts: command = \"hostname &amp;&amp; date &amp;&amp; whoami\" module = host.split(\"_\",2)[2] print(\"输入的参数是：\" + host) print(\"对应的模块是：\" + module) chenchenchen = \"cd /opt/\" + module +\"/ &amp;&amp; ./stop.sh &amp;&amp; ./start.sh\" print (\"重启命令是：\" +chenchenchen) checkSQL(host)except Exception as e: print(\"ansible批量执行出现错误，请检查！\")# 关闭文件 f.close()# 关闭数据库连接 db.close()# 执行ansibledata = runner(ansible_host_path, \"shell\", command)print(data)os.remove(ansible_host_path) 执行效果如下： 上面的脚本里执行的是ansible语句，如果想要执行playbook，可以看一下https://blog.csdn.net/CCjedweat/article/details/88683152 这位大神的文章。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"python2","slug":"python2","permalink":"http://yoursite.com/tags/python2/"},{"name":"ansible api","slug":"ansible-api","permalink":"http://yoursite.com/tags/ansible-api/"}]},{"title":"AWS数据迁移到阿里云的一些坑","slug":"AWS配置的一些问题解决","date":"2019-11-07T09:16:29.000Z","updated":"2019-11-08T06:41:18.000Z","comments":true,"path":"2019/11/07/AWS配置的一些问题解决/","link":"","permalink":"http://yoursite.com/2019/11/07/AWS配置的一些问题解决/","excerpt":"","text":"最近在忙AWS迁移阿里云的事情，在这之中发现了也解决了很多坑，这里记录一下。 只读RDS修改配置组无效果我们这一次数据库的迁移是重点任务，考虑到AWS的源库都是无公网访问权限的，于是就创建一个有公网权限的只读库（read replica），然后在阿里云是用DTS，以这个只读库作为源库，然后进行数据的增量同步。这里有一点：“源库”的binlog必须是ROW模式，而默认的AWS创建的源库是MIX模式，于是就需要修改一下参数组（parameter group），将其改成ROW： 然后配置只读实例引用这个参数组，但是要等待参数组状态是（pending reboot），重启。 但是这里有一个大坑！那么就是read replica的Backup retention period值不可以是0，不然参数组即使重启了是不会生效的！ 当然直接使用DTS并不是一个好方案，因为即使是同一个可用区，比如都在法兰克福，但是不同厂商还是会有网络影响，所以更加推荐就是搭一个专线，然后走专线同步。而且DTS的时候，切忌目标库发生与源库不同的操作造成数据错乱，那样就前功尽弃了。 DTS的原理就是不断的读取binlog然后执行binlog，但是row模式的binlog特别巨大，再加上网络有波动或者源库有跟主库名称一样但是内容不一致的数据导致所有唯一主键都要报错一遍，那么延迟可能就是一辈子的事儿… 无公网ec2访问外网本次迁移数据除了mysql还有redis，但是AWS的redis也都是内网服务器，于是这样我们就做了外网NLB，在阿里云的redis上做主从配置，并且在阿里云的redis.conf里把主写成了NLB的域名，这里如果担心NLB域名后面的IP发生变化而故障，那么可以事先在aws里购买弹性IP，然后将域名绑定死对应的IP就不怕了。 但是如果想要返回来，让阿里云的redis做主，AWS这个无公网的ec2 redis做从的话，用外网NLB就不行了。不过AWS比较好，就是ec2虽然表面没有公网IP，但是它有一个隐藏的公网，比如我这个ec2: 可见它没有公网IP，但是在服务器里使用curl myip.ipip.net可以获取到它的公网出口IP： 将这个IP写到阿里云的安全组就可以在ec2这边访问到阿里云的公网了！ DMS白名单问题AWS的数据迁移叫DMS，这个地方也有一个坑，就是Replication instances的公网IP可能是不对的，如图： 我把图中的Public IP address填写到了阿里云对应数据库的白名单里但是test无法成功，后来改成0.0.0.0/0之后登陆上去一看，连接的IP并不是图中的IP，这真的是一个大坑！","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"aws","slug":"aws","permalink":"http://yoursite.com/tags/aws/"},{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"}]},{"title":"Alertmanager配置微信告警和钉钉告警","slug":"Alertmanager配置微信告警和钉钉告警","date":"2019-10-29T06:50:12.000Z","updated":"2019-10-31T11:53:36.000Z","comments":true,"path":"2019/10/29/Alertmanager配置微信告警和钉钉告警/","link":"","permalink":"http://yoursite.com/2019/10/29/Alertmanager配置微信告警和钉钉告警/","excerpt":"","text":"配置微信告警首先先去搞一个微信企业号，创建一个新的应用： 创建微信企业号的过程可以见https://rorschachchan.github.io/2018/01/10/Zabbix3-0%E6%90%AD%E9%85%8D%E5%BE%AE%E4%BF%A1%E4%BC%81%E4%B8%9A%E5%8F%B7%E6%8A%A5%E8%AD%A6/ 这篇文章。 来到prometheus服务器里，编辑alertmanager.yml如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445global: resolve_timeout: 5m smtp_smarthost: 'smtp.163.com:465' smtp_from: 'chenx1242@163.com' smtp_auth_username: 'chenx1242@163.com' smtp_auth_password: '邮箱密码' smtp_require_tls: false wechat_api_url: http://qyapi.weixin.qq.com/cgi-bin/ #这里是wechat对外接口templates: - './template/*.tmpl' # 模板的地址route: group_by: ['chentest'] group_wait: 10s group_interval: 30s repeat_interval: 30m receiver: 'GOOGLE-email' routes: # 这里做了一个路由 - receiver: 'wechat' group_wait: 30s # 这个路由会覆盖上面的值receivers:- name: 'GOOGLE-email' email_configs: - send_resolved: true to: 'chenshuo955@gmail.com' html: '&#123;&#123; template \"email.html\" . &#125;&#125;' headers: &#123; Subject: \"[WARN]Prometheus告警邮件\" &#125;- name: 'wechat' wechat_configs: - corp_id: 'XXXX' # 企业信息(\"我的企业\"---&gt;\"CorpID\"[在底部]) to_user: '@all' # 所有人就是@all，或者是指定人 agent_id: '1000003' # 企业微信(\"企业应用\"--&gt;\"自定应用\"[Prometheus]--&gt; \"AgentId\") api_secret: 'E8DR55yEDwp0E3d0mpjsdWdt0pFNF9i7kQPzFfsQVbI' # 企业微信(\"企业应用\"--&gt;\"自定应用\"[Prometheus]--&gt; \"Secret\") send_resolved: true #问题解决了要发信息 message: '&#123;&#123; template \"wechat.html\" . &#125;&#125;' # 指定模板inhibit_rules: - source_match: severity: 'critical' target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] 然后来到当前目录的/template/里创建wechat.tmpl，如下： 12345678910111213&#123;&#123; define \"wechat.html\" &#125;&#125; &#123;&#123; range .Alerts &#125;&#125; ========start========== 告警程序: prometheus_alert 告警级别: &#123;&#123; .Labels.severity &#125;&#125; 告警类型: &#123;&#123; .Labels.alertname &#125;&#125; 故障主机: &#123;&#123; .Labels.instance &#125;&#125; 告警主题: &#123;&#123; .Annotations.summary &#125;&#125; 告警详情: &#123;&#123; .Annotations.description &#125;&#125; 触发时间: &#123;&#123; .StartsAt.Format \"2019-01-01 01:01:01\" &#125;&#125; ========end========== &#123;&#123; end &#125;&#125;&#123;&#123; end &#125;&#125; 启动alertmanager，不就就可以在微信上看到信息了： 配置钉钉告警首先先创建钉钉机器人并且获取对应的token: 然后检查一下自己的golang版本，网络上流行的timonwong的webhook是不能用于1.13版本的，所以要安装1.11版本的golang。安装方法golang 1.11方法如下： 12wget https://studygolang.com/dl/golang/go1.11.linux-amd64.tar.gztar zxvf go1.11.linux-amd64.tar.gz -C /usr/local 修改/etc/profile,在文件末尾添加如下内容: 1234#go settingexport GOROOT=/usr/local/goexport GOPATH=/usr/local/gopathexport PATH=$PATH:$GOROOT/bin 执行source /etc/profile配置文件的环境变量立刻生效，此时在/usr/local/go/src路径下： 12345mkdir -pv github.com/timonwongcd github.com/timonwonggit clone https://github.com/timonwong/prometheus-webhook-dingtalk.gitcd prometheus-webhook-dingtalk/make 然后执行效果如下，同时/usr/local/go/src/github.com/timonwong/prometheus-webhook-dingtalk路径下多了一个prometheus-webhook-dingtalk： 然后在后台执行这个prometheus-webhook-dingtalk： 1nohup ./prometheus-webhook-dingtalk --ding.profile=\"chen_dingding=https://oapi.dingtalk.com/robot/send?access_token=XXXXX\" 2&gt;&amp;1 1&gt;dingding.log &amp; #创建一个频道chen_dingding 然后在alertmanager.yaml增加钉钉报警相关的信息： 123456789- receiver: 'dingding' group_wait: 30s match: go: gothreads- name: 'dingding' webhook_configs: - send_resolved: true url: http://localhost:8060/dingtalk/chens_dingding/send #这里频道要一致 然后重启Alarmmanager即可，一会就能收到报警： 至于这个钉钉与alertmanager的webhook勾连的细节，可以去看http://ylzheng.com/2018/03/01/alertmanager-webhook-dingtalk/ 。 参考资料https://www.cnblogs.com/xzkzzz/p/10211394.htmlhttps://github.com/prometheus/alertmanager/issues/1385https://blog.rj-bai.com/post/158.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"监控","slug":"监控","permalink":"http://yoursite.com/tags/监控/"},{"name":"Prometheus","slug":"Prometheus","permalink":"http://yoursite.com/tags/Prometheus/"}]},{"title":"Prometheus配置Alertmanager并实现邮箱告警","slug":"Prometheus增加告警和自定义监控项","date":"2019-10-12T02:59:31.000Z","updated":"2019-10-31T11:51:00.000Z","comments":true,"path":"2019/10/12/Prometheus增加告警和自定义监控项/","link":"","permalink":"http://yoursite.com/2019/10/12/Prometheus增加告警和自定义监控项/","excerpt":"","text":"添加告警配置在https://rorschachchan.github.io/2019/10/08/%E4%BD%BF%E7%94%A8Docker%E9%83%A8%E7%BD%B2Prometheus/ 里已经搭建好了Prometheus，当时是把主配置文件prometheus.yml写在了/mnt/promethues/server，然后挂载到相关容器里。现在也在相同目录里编写一个rules.yml，如下： 123456789101112131415161718192021groups:- name: example rules: # Alert for any instance that is unreachable for &gt;5 minutes. - alert: load15在告警! # 告警规则的名称 expr: node_load15&#123;group=\"server\",instance=\"172.31.0.85:9100\",job=\"server\"&#125; &gt; 0 #给予PromQL的表达式的告警触发条件 for: 1m #触发条件持续多久之后发送告警 labels: severity: node_load #自定义标签 annotations: #描述，这段信息会作为参数发送给Alertmanager summary: \"实例 &#123;&#123; $labels.instance &#125;&#125; 的load15大于 0\" description: \"&#123;&#123; $labels.instance &#125;&#125; of job &#123;&#123; $labels.job &#125;&#125; 值大于 0.\" # Alert for any instance that has a median request latency &gt;1s. - alert: gothreads过多啊！ expr: go_threads&#123;group=\"server\",instance=\"172.31.0.85:9100\",job=\"server\"&#125; &gt; 5 for: 1m annotations: summary: \"&#123;&#123; $labels.instance &#125;&#125;的gothreads过多\" description: \"&#123;&#123; $labels.instance &#125;&#125; has a high gotheads: (current value: &#123;&#123; $value &#125;&#125;s).\" 保存退出之后，在prometheus.yml里的rule_files字段做一下修改： 12rule_files: - 'rules.yml' #将刚刚编写的rules.yml结合进去 然后重启一下prometheus（如果不是容器部署的，就是killall -HUP prometheus），再去Prometheus的web界面，先是Status--Rules，看到我们的规则已经导入进去了，并且正常在运行： 再点击Alerts，就会看到目前告警处于pending，也就是说准备要告警了： 刷新一下，就看到状态已经变成了Firing，即告警了： 配置已经成功！不过不要过分激动，这个demo实在是太简单了，我们会在实际的工作里根据具体的场景增加一下难度。 安装Alertmanager目前我们已经配置了告警但是还没有配置发送通知，而实现发送通知就需要靠Alertmanager来完成。正常来说Alertmanager没必要跟Prometheus装在一起，只要他俩能正常通讯即可。但是我资源紧张，就安装到一台服务器里了，具体安装方法如下： 12345cd /mnt/ #我安装在mnt目录下wget https://github.com/prometheus/alertmanager/releases/download/v0.19.0/alertmanager-0.19.0.linux-amd64.tar.gztar -zxvf alertmanager-0.19.0.linux-amd64.tar.gzcd alertmanager-0.19.0.linux-amd64./alertmanager #这个是前台运行的 启动之后，发现9093和9094这两个端口开启了。此时我们再回到prometheus.yml，在最后添加如下内容，把Alertmanager配置到prometheus.yml中： 123456alerting: alertmanagers: - scheme: http static_configs: - targets: - \"172.31.0.85:9093\" #这个是Alertmanager所在的服务器IP地址 这个配置告诉Prometheus，当发生告警时，将告警信息发送到Alertmanager，Alertmanager的地址为http://172.31.0.85:9093。也可以使用命名行的方式指定Alertmanager： 1./prometheus -alertmanager.url=http://172.31.0.85:9093 此时我们登陆http://Alertmanager公网IP:9093/#/alerts，就会看到prometheus的alerts的内容出现在了Alertmanager里： 然后点击具体的告警项目，就会看到一些细节，比如我们在rules.yml里写的description和summary： 配置Alertmanager实现邮箱告警编辑alertmanager.yml如下： 123456789101112131415161718192021222324252627282930313233global: resolve_timeout: 5m smtp_smarthost: 'smtp.163.com:465' smtp_from: 'chenx1242@163.com' smtp_auth_username: 'chenx1242@163.com' smtp_auth_password: '这里邮箱的密码' smtp_require_tls: false #注意这个一定要写false，默认是true，若不改成false会有require_tls' is true (default) but \\\"smtp.qq.com:465\\\" does not advertise the STARTTLS extension#templates: # - './template/*.tmpl'# 所有报警信息进入后的根路由，用来设置报警的分发策略route: group_by: ['chentest'] # 这里的标签列表是接收到报警信息后的重新分组标签 group_wait: 10s # 第一次等待多久时间发送一组警报的通知 group_interval: 10s # 在发送新警报前的等待时间 repeat_interval: 1m # 如果一个报警信息已经发送成功了，等待'repeat_interval'时间来重新发送他们 receiver: 'GOOGLE-email' # 发送警报的接收者的名称，与receivers name的名称相同receivers:- name: 'GOOGLE-email' email_configs: # 邮箱配置 - send_resolved: true # 告警解决是否通知，默认是不通知 to: 'chenshuo955@gmail.com' #html: '&#123;&#123; template \"email.html\" . &#125;&#125;' #headers: &#123; Subject: \"[WARN] 报警邮件\"&#125; # 接收邮件的标题inhibit_rules: - source_match: severity: 'critical' target_match: severity: 'warning' equal: ['alertname', 'dev', 'instance'] Alertmanager检查配置文件的语句：./amtool check-config alertmanager.yml。如果出现SUCCESS即文件OK！ 默认Alertmanager的启动方式：./alertmanager --config.file=alertmanager.yml，不指定config.file则会去读取alertmanager.yml，不过我们还是用systemctl来启动，先编写 12345678[Unit]Description=alertmanager[Service]Restart=on-failureExecStart=/mnt/alertmanager-0.19.0.linux-amd64/alertmanager --config.file=/mnt/alertmanager-0.19.0.linux-amd64/alertmanager.yml[Install]WantedBy=multi-user.target 保存之后通过systemctl start alertmanager启动。既然是systemctl启动的进程，那么查看日志的方法就是sudo journalctl _PID=alertmanager进程号： 稍等一会，Gmail就会受到邮件，如图： 可见在告警邮件里是有在rules.yml配置的summary和description信息。 如果要用docker部署alertmanager的话，语句如下： 1234docker run --name alertmanager --rm -d \\-v /宿主机路径/alertmanager.yml:/etc/alertmanager/alertmanager.yml \\--net=host \\prom/alertmanager 为了方便，我们会配置一个模板，这样告警邮件看起来会更加直观，那么就在/mnt/alertmanager-0.19.0.linux-amd64目录下新建一个template文件夹，然后创建一个email.tmpl如下： 123456789101112131415161718&#123;&#123; define \"email.html\" &#125;&#125;&lt;table border=\"1\"&gt; &lt;tr&gt; &lt;td&gt;报警项&lt;/td&gt; &lt;td&gt;实例&lt;/td&gt; &lt;td&gt;报警阀值&lt;/td&gt; &lt;td&gt;开始时间&lt;/td&gt; &lt;/tr&gt; &#123;&#123; range $i, $alert := .Alerts &#125;&#125; &lt;tr&gt; &lt;td&gt;&#123;&#123; index $alert.Labels \"alertname\" &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; index $alert.Labels \"instance\" &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; index $alert.Annotations \"value\" &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; $alert.StartsAt &#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;&#123; end &#125;&#125;&lt;/table&gt;&#123;&#123; end &#125;&#125; 然后把上面alertmanager.yml里那几个#templates、#html、#headers的注释放开，重新启动alertmanager，一会就可以看到告警了： 可见模板已经配置上了。 故障排错Alertmanager前台启动后，会不停的刷如下的日志： 1level=error ts=2019-10-25T06:50:16.470Z caller=dispatch.go:266 component=dispatcher msg=\"Notify for alerts failed\" num_alerts=1 err=\"Post http://127.0.0.1:5001/: dial tcp 127.0.0.1:5001: connect: connection refused\" 这个的原因是alertmanager.yml默认情况下的配置是所有的告警都走一个叫web.hook的receiver，而这个receiver配置的就是本地5001端口，如下： 1234receivers:- name: 'web.hook' webhook_configs: - url: 'http://127.0.0.1:5001/' 所以这个报警可以无视掉，等你配置了正确的告警方式就解决掉这个问题了。 参考资料https://www.li-rui.top/2018/11/12/monitor/Prometheus%20Alertmanager%E4%BD%BF%E7%94%A8/https://www.qikqiak.com/post/alertmanager-of-prometheus-in-practice/https://www.aneasystone.com/archives/2018/11/prometheus-in-action.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"监控","slug":"监控","permalink":"http://yoursite.com/tags/监控/"},{"name":"Prometheus","slug":"Prometheus","permalink":"http://yoursite.com/tags/Prometheus/"}]},{"title":"国庆武汉长沙五日游","slug":"国庆武汉长沙六日游","date":"2019-10-11T13:37:19.000Z","updated":"2019-11-01T01:54:16.000Z","comments":true,"path":"2019/10/11/国庆武汉长沙六日游/","link":"","permalink":"http://yoursite.com/2019/10/11/国庆武汉长沙六日游/","excerpt":"","text":"终于到了国庆，俺跟媳妇趁着中秋苏州的余温，再次选择了出去旅游。原本我打算是去重庆的，但是媳妇已经去过了，于是就拍板这次国庆假期选择去武汉、长沙玩5天，10月2号出发，不耽误看国庆阅兵。 国庆的安排：10.2 下午7点在杭州东上车，大约11点到武汉站，打车去酒店，酒店周围吃吃夜宵10.3 黎黄陂路街头博物馆+古德寺庙+晴川阁+吉庆街+长江大桥轮渡10.4 黄鹤楼+辛亥革命纪念馆+湖北省博物馆+湖北省美术馆+粮道街+做了一个足浴歇歇脚10.5 汉街+万达，中午一点在武汉站上车，下午两点半到长沙南站，橘子洲头+太平老街+国金中心+黄兴广场10.6 湖南省博物馆+岳麓山，晚上7点长沙南上车返航 武汉的玩我住的酒店是洪山区中北路的万达商圈，出门就是汉街。汉街是一条很长的室外购物步行街，曾经跑男来这里做过节目。作为一条网红大街，整条街两侧各色商家开门营业—-摄影馆、书店、星巴克、小饭店、耐克阿迪优衣库、DQ、鸭脖子之类的。杜莎夫人的武汉店也在汉街上，150元一张成人票，由于我之前去过伦敦的杜莎夫人这次就没有去武汉馆了。 黎黄陂路街头博物馆其实就是一条老街，以宋庆龄故居开始往里走，那一片区域都是各帝国主义列强以前在武汉的租界，能看到有外国风格的老建筑，虽然那些建筑窗户和门都破破旧旧，跟宋庆龄故居对比强烈，但是经过100多年的风雨依旧屹立不倒，他们都已经被围墙围住打算重新修葺，围墙上被各种涂鸦，画的花里胡哨的。除了列强的建筑之外还有中共八七会议的旧址，现在已经被改成了一个小型的博物馆，毛主席著名的“枪杆子里夺政权”就是出自这次会议。在这样一条有历史痕迹的长街，还有不少的咖啡馆和猫舍营业，不少的女生在大街上自拍。街两侧的居民楼里还有老人居住，有卖包子的、有开小卖店的、有做针脚活的。走在这里还真有一种恍若隔世的感觉。 我去古德寺的时候正值寺庙要搬迁，入门要交6块钱的香火钱，然后进大门烧香拜拜。亲眼见到古德寺的一刹那还真有点蒙，因为它的造型简直就是一个教堂，而且它的部分尖塔顶还有十字架！ 古德寺四周是居民楼，寺里空地上有鸽子走来走去，花盆里有猫懒懒的睡觉，外形印度加波斯风的寺庙和大堂里的佛像搭配在一起，整个的气氛非常的祥和，不亏大隐隐于市这句话。可惜的是，10月初的时候，水池里的荷花已经败掉了。这个寺庙据说现在已经是一个尼姑庵。这座150年的历史的古刹，见证了武汉的50000多天的日日夜夜。它真的就像佛教一样的坚韧，屹立过那么多个是是非非，依旧对各路香客迎来送往。慈悲仁爱。 我没有去黄鹤楼，因为在网络上听到很多人以及周围朋友对黄鹤楼的吐槽。于是这次选择了晴川阁，第一它免费（囧），第二它是近距离看长江大桥的好地方，且与黄鹤楼隔江相望。晴川阁院里左手边是一个城墙，可以在城墙上看着下面车来车往，那里也是不少婚纱照的拍摄圣地，一对一对的新人穿着大红的服装风，扛个一把大伞搔首弄姿。 湖北省博物馆有两个镇馆之宝，一个是战国曾侯乙编钟，每天有固定时间会有工作人员表演；还有一个就是越王勾践的宝剑。这两个展厅的人是最多的，文物在展厅里静静的站立着，被一波又一波的游客检阅和拍照。武汉那两天气候太热，很多人都跑到博物馆去避暑，或盘腿坐或干脆躺着。湖北美术馆就在博物馆旁边，可以一波参观。 武汉的吃吉庆街的江小城是让我特别有印象的店，它的室内装修风格是武汉街头，对的，进了店门就好像到了老武汉的胡同，墙壁也上贴着各种小广告。 到了武汉怎能不吃鱼？毛主席写过“才饮长江水，又食武昌鱼”，正是因为这首诗，武昌鱼就成为了樊口鳊鱼的大众名。武汉除了鱼，就是热干面，豆皮、袁大头包子、排骨炖藕汤这些。除了以上这些，我还很喜欢武汉的毛豆，微微的一点辣，下酒挺好！ 武汉印象武汉给我的第一印象是天气真热人真多，我去户部巷的那天，屏幕显示整个户部巷有近20000人！更是让人觉得烦躁难耐，我买了一杯冰镇椰子汁，给媳妇买了一个网红冒烟冰淇淋，逛了一小会就觉得闷热的受不了。而在吉庆街街头大排档总会有一波带着乐器的中年大叔到各桌边演奏献唱，唱一次是否收费我并不了解。不过乐器花样倒是众多，古今中外一应俱全，从吉他到笛子。唱的歌曲嘛，无非就是《好运来》这样的大众歌曲。 坊间传闻武汉人因为靠江吃江，所以自古码头帮会众多，到了新社会也有一些好勇分子，不过大多数武汉民众都是遵纪守法的好市民，但是武汉人，无论男女的彪悍作风，直爽态度至今还是流传下来的，符合那句“天上九头鸟，地上湖北佬”的评价。武汉是一个基建狂魔，阮成发担任市长期间，从2009~2011年，城建投资超过了1500亿，但是武汉的确有效的建了地铁、修了高架，极大的缓解了市民出行的压力。不过话说回来，武汉的涝一直没有解决，在新闻上也能看到大雨天，武汉水过腰的照片，这是一个很严重的问题。 武汉市还有很多小景点，比如南洋大楼、瞿秋白故居、毛主席故居、陈潭秋烈士纪念馆、“汉阳造”纪念碑等等。现在的武汉被打造成了一个又红又专的城市，虽然当年国民党也在这里有过很大的动静，而且还一度被汪兆铭做了他的国民政府首都，但是武汉在中共革命历史上是有非常重要的意义的。武汉人说话有股子四川味，而且说活更“冲”，风风火火。可以说武汉话其实是四川话的“母版”，毕竟“两湖填四川”嘛。 长沙的玩从武汉到长沙并不算远，高铁90分钟就从湖北跑到了湖南。长沙不算是一个旅游城市，没有什么出众的景点。整个长沙最大的景点就是湖南省博物馆，而湖南省博物馆的镇馆之宝就是马王堆的辛追夫人全家的陪葬以及她本人的尸体。 除了湖南省博物馆还有岳麓山值得一去，爬上山还是比较累的，对于有运动癌的媳妇儿，我俩只能买车票上山，然后坐一个20分钟左右的缆车慢悠悠观景下来。山上的空气很棒，要进岳麓书院是要单独收费的。 至于橘子洲头就是在湘江那里的一个大公园而已，除了青年毛主席的头部雕塑没什么特别的。 长沙的吃长沙旅游业虽然比较贫乏，但是论吃就是顶级城市了。长沙的臭豆腐是当地一绝，走进太平老街，一股强烈的臭味迎面扑来，我估计如果贾谊在世还住在他那老宅，都能被熏死。 长沙的辣比武汉更甚，我在长沙两天，先后吃了么子烤肉、费大厨辣椒烧肉、易小厨辣椒炒肉等饭店。么子烤肉的烤五花肉和虾滑很棒！辣椒炒肉都差不多啦，还是比较下饭的，但是真的很辣，我不小心咬破一个辣椒籽，足足喝了两瓶水才把舌尖缓过来。 长沙印象长沙给我的第一印象就是贫富差距很大，破的地方很破，感觉有好大片楼拆了一半就烂在那里了，破破的在街道边无精打采的耸立着，有的甚至顶层都长半个人高的草。听人说这是因为长沙食物普遍都有辣和炸这两个风格，所以很多饮食的步行街看上去油腻腻脏乎乎，再加上我去那两天长沙天气并不晴朗，所以这种脏破让外人看来更加明显。 但是长沙高大上的地方又特别高级，比如国金中心，好几层楼，各种国际的奢侈品大牌都在里面有专卖店。国金中心斜对面就是黄兴广场，里面也是有吃有玩，各种champion店在大甩卖，广场的电子屏幕上甚至还有张艺兴的粉丝祝张艺兴生日快乐的滚动视频广告… 第二印象，长沙的乞丐真的很多。去湖南省博物馆的公交车下车到博物馆大门就趴着至少5位，残疾人、老年人、孤儿、母子、求学，各种各样的。据说早几年还有小孩抱腿的，不给钱就不撒手，给的不够也不撒手… 第三印象，打麻将真是当地人民喜闻乐见的休闲活动，胡同里的棋牌室基本爆满，不少人是老婆在隔壁商铺做饭，老公在店里打麻将。长沙夏天也是酷热难耐，不少长沙人会在游泳池里摆个桌子打几圈，这也是当地一大特色了。 一些tips 多带一点人民币现金，我去的时候长沙公交车恰巧不能刷支付宝的电子公交卡，所以还是人民币买单； 汉街商圈虽然明文规定是晚10点结束营业，但是其实很多店都是坚持到10点半左右，所以晚上还可以去在那里吃顿夜宵； 你如果用华为P30，是可以在晴川阁看到对面的黄鹤楼的细节的；","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"旅游","slug":"旅游","permalink":"http://yoursite.com/tags/旅游/"},{"name":"国庆","slug":"国庆","permalink":"http://yoursite.com/tags/国庆/"},{"name":"长沙","slug":"长沙","permalink":"http://yoursite.com/tags/长沙/"},{"name":"武汉","slug":"武汉","permalink":"http://yoursite.com/tags/武汉/"}]},{"title":"阿里云RDS的内存增高与临时表","slug":"阿里云RDS的内存增高的原因","date":"2019-10-11T07:33:07.000Z","updated":"2019-10-11T13:35:04.000Z","comments":true,"path":"2019/10/11/阿里云RDS的内存增高的原因/","link":"","permalink":"http://yoursite.com/2019/10/11/阿里云RDS的内存增高的原因/","excerpt":"","text":"正文mysql查看当前内存使用细节的语句是： 123show variables where variable_name in ('innodb_buffer_pool_size','innodb_log_buffer_size','innodb_additional_mem_pool_size','key_buffer_size','query_cache_size'); 大部分内存占用告警，都是因为buffer pool增长导致，而buffer pool的增长是正常的，如图： 如果说这个值高的令人发指（超过90%），那么基本就是两种可能： 当前session太多，show full processlist；看一下是不是有太多空闲的对话，如果有，酌情调整timeout断开； session不多，但是session里的私有内存占用过多，那么就要检查一下对应的sql语句，是不是语句里有大量的临时表、sort(排序)和join操作； 如何判断是否使用了临时表？使用explain查看执行的sql语句，在Extra列看到Using temporary就意味着使用了临时表。比如这个： 一般情况下，用到临时表就意味着性能较低。查看临时表大小的语句是show global variables like &#39;%table_size%&#39;;。 如果说某个SQL语句，它查询的内容非常的多（select *这种的），然后又对这个查询的内容进行了二次加工（sort或者join)就会生成一个巨大的临时表，那么内存可能就会放不下，导致mysql将这个表全部放到磁盘里，那么这样mysql的IO就会出现飙升、sql执行缓慢的现象。 查看临时表是在内存还是在磁盘上，可以通过show global status like &#39;%Created_tmp%&#39;;： 123456789MySQL [(none)]&gt; show global status like '%Created_tmp%';+-------------------------+-----------+| Variable_name | Value |+-------------------------+-----------+| Created_tmp_disk_tables | 53585768 | #服务器在磁盘上创建表（最初或通过转换内存中的表）| Created_tmp_files | 807803 || Created_tmp_tables | 167011673 | #服务器创建内部临时表（在内存或磁盘上）+-------------------------+-----------+3 rows in set (0.00 sec) 遇到这样的情况，建议是将原语句拆成两个sql，然后用in操作拼接。 最后结论，MYSQL在上线部署后，导致内存激增，请检查是否出现了临时表。临时表如果大出了指定范围，写入到磁盘里，就会导致IO上升，拖垮SQL执行速度。 补充在网站开发里，排序究竟是在程序(PHP)里排还是在数据库(mysql)里排？ 在 PHP 中执行排序更优的情况举例如下： 数据源不在MySQL中，存在硬盘、内存或者来自网络的请求等； 数据存在MySQL中，量不大，而且没有相应的索引，此时把数据取出来用PHP排序更快； 数据源来自于多个MySQL服务器，此时从多个MySQL中取出数据，然后在PHP中排序更快； 除了MySQL之外，存在其他数据源，比如硬盘、内存或者来自网络的请求等，此时不适合把这些数据存入MySQL后再排序。 必须在MySQL中排序的实例如下： MySQL中已经存在这个排序的索引； MySQL中数据量较大，而结果集需要其中很小的一个子集，比如1000000行数据，取TOP10； 对于一次排序、多次调用的情况，比如统计聚合的情形，可以提供给不同的服务使用，那么在MySQL中排序是首选的。另外，对于数据深度挖掘，通常做法是在应用层做完排序等复杂操作，把结果存入MySQL即可，便于多次使用。 不论数据源来自哪里，当数据量大到一定的规模后，由于占用内存的关系，不再适合PHP中排序了；此时把数据复制、导入或者存在MySQL，并用INDEX优化，是优于PHP的。不过，用Java，甚至C++ 来处理这类操作会更好。 结论：从网站整体考虑，就必须加入人力和成本的考虑。假如网站规模和负载较小，而人力有限（人数和能力都可能有限），此时在应用层（PHP）做排序要做不少开发和调试工作，耗费时间，得不偿失；不如在 DB 中处理，简单快速。对于大规模的网站，电力、服务器的费用很高，在系统架构上精打细算，可以节约大量的费用，是公司持续发展之必要；此时如果能在应用层 (PHP) 进行排序并满足业务需求，尽量在应用层进行。 参考资料https://dp.imysql.com:8080/node/97http://mysql.taobao.org/monthly/2019/04/01/http://blog.sae.sina.com.cn/archives/4096","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"阿里云","slug":"阿里云","permalink":"http://yoursite.com/tags/阿里云/"},{"name":"RDS","slug":"RDS","permalink":"http://yoursite.com/tags/RDS/"}]},{"title":"使用Docker部署Prometheus","slug":"使用Docker部署Prometheus","date":"2019-10-08T07:10:59.000Z","updated":"2019-10-31T10:04:30.000Z","comments":true,"path":"2019/10/08/使用Docker部署Prometheus/","link":"","permalink":"http://yoursite.com/2019/10/08/使用Docker部署Prometheus/","excerpt":"","text":"关于prometheus的基础内容，可以去看https://www.hi-linux.com/posts/25047.html 、https://yunlzheng.gitbook.io/prometheus-book/ 和https://www.ibm.com/developerworks/cn/cloud/library/cl-lo-prometheus-getting-started-and-practice/index.html 。 服务器说明：阿里云centos 7.6（内网IP：172.31.0.85） + docker 19.03.2 + git 1.8 + go 1.13 go的安装方法如下，国内可用： 123rpm --import https://mirror.go-repo.io/centos/RPM-GPG-KEY-GO-REPOcurl -s https://mirror.go-repo.io/centos/go-repo.repo | tee /etc/yum.repos.d/go-repo.repoyum install -y golang 部署Prometheus Server首先，创建一个普通用户，比如叫lcshop，然后gpasswd -a lcshop docker，把lcshop用户添加到docker组里。 然后在/mnt下创建promethues文件夹和子文件夹server，树形结构如下： 123456789[lcshop@lcshop-Prometheus mnt]$ tree.└── prometheus └── server ├── prometheus.yml └── rules.yml2 directories, 2 files[lcshop@lcshop-Prometheus mnt]$ 其中/mnt/promethues/server/prometheus.yml的内容是这样的： 123456789101112131415global: scrape_interval: 60s # 默认抓取间隔, 60秒向目标抓取一次数据。 external_labels: monitor: 'codelab-monitor'# 这里表示抓取对象的配置rule_files: #- 'prometheus.rules'scrape_configs: #这个配置是表示在这个配置内的时间序例，每一条都会自动添加上这个&#123;job_name:\"prometheus\"&#125;的标签 - job_name: 'prometheus' scrape_interval: 30s #重写了全局抓取间隔时间，由15秒重写成30秒 static_configs: - targets: ['localhost:9090'] labels: group: 'prometheus' 至于rules.yml暂时先为空，再把整个/mnt/promethues文件夹及内部所有文件所属组改成lcshop：docker，启动docker进程： 1docker run --name=prometheus -d -p 9090:9090 -v /mnt/prometheus/server/prometheus.yml:/etc/prometheus/prometheus.yml -v /mnt/prometheus/server/rules.yml:/etc/prometheus/rules.yml -v /etc/localtime:/etc/localtime:ro prom/prometheus:v2.7.2 --config.file=/etc/prometheus/prometheus.yml --web.enable-lifecycle 阿里云安全组放行9090端口，在浏览器使用外网IP:9090就会看到Prometheus的界面： 如果输入一些监控值，就会出现对应值的结果： 部署Prometheus metrics接口目前我们的server和grafana已经通了，但是仅仅是有一些无实际作用的指标，我们需要收集服务器的指标，收集指标的东西叫node-exporter。这是一个有点类似于zabbix-agent的东西，会帮你收集系统指标和一些软件运行的指标，把指标暴露出去。Prometheus官方是不推荐用Docker来运行 node_exporter的，因为Docker的文件系统和网络都有自己的namespace，收集的数据并不是宿主机真实的指标。所以我们这里还是用常规的方法，安装方法如下： 123456cd /usr/local/ &amp;&amp; mkdir node_exporter cd /usr/local/node_exporterwget https://github.com/prometheus/node_exporter/releases/download/v0.18.1/node_exporter-0.18.1.linux-amd64.tar.gztar -zxvf node_exporter-0.18.1.linux-amd64.tar.gzcd node_exporter-0.18.1.linux-amd64./node_exporter 这个启动是前台启动，监听9100端口。我们要改一下，改成systemctl启动，这样后台启动更好。创建/usr/lib/systemd/system/node_exporter.service如下： 1234567[Unit]Description=node_exporter[Service]Restart=on-failureExecStart=/usr/local/node_exporter/node_exporter-0.18.1.linux-amd64/node_exporter #这里填写的node_exporter 文件的全路径，不然无法启动[Install]WantedBy=multi-user.target 保存退出，systemctl daemon-reload之后再systemctl start node_exporter.service就启动了，然后可以curl http://localhost:9100/metrics查看一下是否正常获取服务器指标，如图： 确认可以正常获取到指标之后，就重新编写一下prometheus.yml: 12345678910111213141516171819202122global: scrape_interval: 60s # 默认抓取间隔, 60秒向目标抓取一次数据。 external_labels: monitor: 'codelab-monitor'# 这里表示抓取对象的配置rule_files: #- 'prometheus.rules'scrape_configs: #这个配置是表示在这个配置内的时间序例，每一条都会自动添加上这个&#123;job_name:\"prometheus\"&#125;的标签 - job_name: 'prometheus' scrape_interval: 30s #重写了全局抓取间隔时间，由15秒重写成30秒 static_configs: - targets: ['localhost:9090'] labels: group: 'prometheus' - job_name: 'server' scrape_interval: 30s static_configs: - targets: ['172.31.0.85:9100'] #本机IP labels: group: 'server' 然后重启prometheus容器，重新载入配置文件。然后在web端的Status -&gt; Targets可以看到添加的node-exporter： 保存之后，就可以在graph页面里查看一些指标。 Prometheus针对mysql、nginx、jmx都有官方的指标收集策略，感兴趣可以去看https://www.aneasystone.com/archives/2018/11/prometheus-in-action.html 。 接入GrafanaDocker部署Grafana的语句可见https://rorschachchan.github.io/2019/08/22/%E6%90%AD%E9%85%8DInfluxDB-CADvisor-Grafana%E7%BB%84%E5%90%88%E7%9B%91%E6%8E%A7Docker/ ，启动之后登录到grafana界面，在Data Source里选择Prometheus，然后就填写对应的url即可： 点击旁边的Dashboards，就会有三张模板，根据需要import。如果import了prometheus 2.0 stats，那么生成的格式就是这样的： 页面看上去还是挺有科技感的，保留这个骨架改一下里面具体的监控项就好了。 Prometheus的监控项跟zabbix的item不一样，它的监控项叫Element，格式是类似这样的： 1node_load15&#123;group=\"server\",instance=\"172.31.0.85:9100\",job=\"server\"&#125; 这个的意思就是172.31.0.85这个服务器的cpu 15分钟的负载。group、job、instance这些都是这个Element的标签。那么如何找到Element呢？在prometheus的web界面的graph里的console就能看到，如图： 然后在grafana页面在对应的表格里添加该element即可： 故障排错在go build的时候，可能会出现大陆特色错误： 1go: golang.org/x/sys@v0.0.0-20190927073244-c990c680b611: unrecognized import path \"golang.org/x/sys\" (https fetch: Get https://golang.org/x/sys?go-get=1: dial tcp 216.239.37.1:443: i/o timeout) 此时需要export GOPROXY=https://goproxy.io就OK，如图： 参考资料https://shockerli.net/post/go-get-golang-org-x-solution/https://www.aneasystone.com/archives/2018/11/prometheus-in-action.htmlhttps://blog.xizhibei.me/2017/08/06/monitoring-with-prometheus/https://yunlzheng.gitbook.io/prometheus-book/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"监控","slug":"监控","permalink":"http://yoursite.com/tags/监控/"},{"name":"Prometheus","slug":"Prometheus","permalink":"http://yoursite.com/tags/Prometheus/"},{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]},{"title":"Tomcat8配置apr","slug":"Tomcat8配置apr","date":"2019-09-30T02:06:35.000Z","updated":"2019-09-30T04:05:10.000Z","comments":true,"path":"2019/09/30/Tomcat8配置apr/","link":"","permalink":"http://yoursite.com/2019/09/30/Tomcat8配置apr/","excerpt":"","text":"基础知识开场先以一个面试题作为本文的开场白：tomcat与nginx都是Seb Server，他们有什么区别？首先先说明一下Tomcat更应该被叫做Web Container，当然它可以被认为是HTTP服务器，它的主要内容是处理动态请求，而nginx主要是用来处理静态请求。所以一般的设计都是把Nginx放在前端处理静态资源，如果有对应的Java编写的服务器端程序请求，则通过AJP转给后面的Tomcat、Jetty进行处理。 tomcat的部署首先先确认服务器是否有java，没有的话就yum install java-1.8.0-openjdk* -y，然后在/etc/profile最下面添加： 1234export JAVA_HOME=/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.222.b10-1.el7_7.x86_64export JRE_HOME=$JAVA_HOME/jreexport CLASSPATH=$JAVA_HOME/lib:$JRE_HOME/lib:$CLASSPATHexport PATH=$JAVA_HOME/bin:$JRE_HOME/bin:$PATH 然后source /etc/profile配置环境变量，然后开始安装。 123456mkdir /usr/local/tomcat #创建文件夹wget http://apache.fayea.com/tomcat/tomcat-8/v8.5.46/bin/apache-tomcat-8.5.46.tar.gz -P /usr/local/tomcat #直接下载tomcat8到目标文件夹cd /usr/local/tomcattar -zxvf apache-tomcat-8.5.46.tar.gz cd apache-tomcat-8.5.46/bin./catalina.sh start #.启动tomcat。使用./catalina.sh stop停止tomcat。 为了安全我们都会更改一下默认的8080端口，那么就修改apache-tomcat-8.5.46/conf/server.xml： 1234&lt;Connector port=\"33664\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" server=\"kan ni daye a kan\"/&gt; # 服务器信息，可以通过curl -I来查看 确保iptables和安全组放行33664端口之后，既可以在页面查看情况。 虽然现在程序已经正常启动了，但是还需要配置开机自启动和service控制开启关闭等其他工作。 首先要使用service命令控制tomcat启停，新编辑/etc/init.d/tomcat文件： 1234567891011121314151617181920212223#!/bin/bash# description: Tomcat8 Start Stop Restart# processname: tomcat8# chkconfig: 234 20 80CATALINA_HOME=/usr/local/tomcat/apache-tomcat-8.5.46case $1 in start) sh $CATALINA_HOME/bin/startup.sh ;; stop) sh $CATALINA_HOME/bin/shutdown.sh ;; restart) sh $CATALINA_HOME/bin/shutdown.sh sh $CATALINA_HOME/bin/startup.sh ;; *) echo 'please use : tomcat &#123;start | stop | restart&#125;' ;;esacexit 0 保存之后给予这个tomcat文件可执行权限，就可以通过service tomcat restart/stop/start来控制程序启停了。 开启自启动比较简单了：chkconfig --add tomcat &amp;&amp; chkconfig tomcat on。 基本上准备工作就到此为止了。 配置aprTomcat支持三种接收请求的处理方式：BIO（阻塞式）、NIO（非阻塞式）、APR（基于本地库）。采用APR是比较符合更高要求的场景，连接建立的速度会有50%～100%的提升。直接调用操作系统层果然神速啊，所以强烈推荐使用apr方式！而tomcat8默认情况下使用的是nio模式： apr模式本质是使用JNI技术调用操作系统IO接口，需要用到相关API的头文件，先yum install apr-devel openssl-devel gcc make -y安装相关依赖库。 然后在tomcat的bin文件夹下，会看到一个tomcat-native.tar.gz，解压之。然后在tomcat-native-1.2.23-src/native下执行./configure &amp;&amp; make &amp;&amp; make install安装。 安装完毕之后，返回到Tomcat的bin里编辑catalina.sh，在虚拟机启动参数JAVA_OPTS中添加java.library.path参数，指定apr库的路径： 1JAVA_OPTS=\"$JAVA_OPTS -Djava.library.path=/usr/local/apr/lib\" 再去tomcat的conf里server.xml修改一下： 12345&lt;Connector port=\"33664\" protocol=\"org.apache.coyote.http11.Http11AprProtocol\" connectionTimeout=\"20000\" redirectPort=\"8443\" maxThreads=\"800\" acceptCount=\"1000\" #这两个数在下面细说 server=\"kan ni daye a kan\"/&gt; 重启一下tomcat，就会看到现在使用的是apr模式了： 多tomcat负载均衡复制tomcat成多份，然后修改tomcat路径下/webapps/ROOT/index.jsp的内容作为标识，然后分别启动不同的端口，如： 12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!-- 1 默认8005改成8008 --&gt;&lt;Server port=\"8008\" shutdown=\"SHUTDOWN\"&gt; &lt;!-- 2 Http默认8080 改成自己喜欢的端口 --&gt; &lt;Connector port=\"第三个端口\" protocol=\"HTTP/1.1\" connectionTimeout=\"20000\" redirectPort=\"8443\" /&gt; &lt;!-- 3 AJP默认8009 改成8011 --&gt; &lt;Connector port=\"8011\" protocol=\"AJP/1.3\" redirectPort=\"8443\" /&gt; 启动之后，一个服务器里就运行了多个tomcat。然后修改nginx.conf： 12345678910111213141516171819http &#123; # 省略代码.... # 增加 upstream, 名称为 serverlist upstream serverlist&#123; server localhost:第一个端口 weight=1; # weigh表示权重，越大访问的机率越多 server localhost:第二个端口 weight=1; server localhost:第三个端口 weight=1; &#125; # 编辑 server &#123; listen 80; server_name www.yourdomian.com; location / &#123; # 这里使用定义 serverlist proxy_pass http://serverlist; &#125; 重新nginx就能通过你的域名进行访问了，多次刷新就可以看到网站显示是哪个tomcat的内容。 注意！强烈建议不要使用 Tomcat 的虚拟主机，推荐每个站点使用一个实例。即，可以启动多个 Tomcat，而不是启动一个 Tomcat 里面包含多个虚拟主机。因为 Tomcat是多线程，共享内存，任何一个虚拟主机中的应用崩溃，都会影响到所有应用程序。虽然采用多实例的方式会产生过多的开销，但至少保障了应用程序的隔离和安全。 运维注意点 不要使用root用户启动tomcat，Java程序与C程序不同。你使用什么用户启动Tomcat，那么Tomcat就会继承该所有者的权限。那么解决这个问题的办法： 12groupadd -g 80 daemonadduser -o --home /daemon --shell /sbin/nologin --uid 80 --gid 80 -c \"Web Server\" daemon #注意/sbin/nologin,意味着该用户不能登录，同时我也没有给它指定密码，这个用户只能用于启动tomcat 修改tomcat的conf里server.xml：关闭war自动部署unpackWARs=&quot;false&quot; autoDeploy=&quot;false&quot;，防止被植入木马等恶意程序； maxThreads：tomcat起动的最大线程数，即同时处理的任务个数，默认值为200；acceptCount：当tomcat起动的线程数达到最大时，接受排队的请求个数，默认值为100。这俩个值要根据业务合理分配，不是越大越好。一般来说acceptCount的配置是设置的跟maxThreads一样大； server.xml中定义了可以直接关闭Tomcat实例的管理端口。我们通过telnet连接上该端口之后，输入SHUTDOWN（此为默认关闭指令）即可关闭Tomcat实例（注意，此时虽然实例关闭了，但是进程还是存在的）。所以为了避免这样的情景，就把SHUTDOWN改成乱码： 1&lt;Server port=\"8005\" shutdown=\"9SDKJ29jksjf23sjf0LSDF92JKS9DKkjsd\"&gt; 参考资料https://lanjingling.github.io/2015/12/15/tomcat-redis-session/https://qq343509740.gitee.io/2018/07/24/Linux/CentOS/CentOS%207%20&amp;%20Tomcat%208%20%E5%AE%89%E8%A3%85%E4%B8%8E%E9%85%8D%E7%BD%AE/#%E6%B7%BB%E5%8A%A0%E9%85%8D%E7%BD%AEhttps://www.cnblogs.com/meetrice/p/5695127.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"java","slug":"java","permalink":"http://yoursite.com/tags/java/"},{"name":"tomcat","slug":"tomcat","permalink":"http://yoursite.com/tags/tomcat/"}]},{"title":"使用GTID主从同步阿里云RDS到自建Mysql","slug":"使用GTID备份阿里云RDS到自建MYSQL","date":"2019-09-26T03:42:09.000Z","updated":"2019-09-29T09:34:08.000Z","comments":true,"path":"2019/09/26/使用GTID备份阿里云RDS到自建MYSQL/","link":"","permalink":"http://yoursite.com/2019/09/26/使用GTID备份阿里云RDS到自建MYSQL/","excerpt":"","text":"基础概念传统的MYSQL主从就是主库每做一个操作会在binlog上做一个position，每做一个event就在binlog做一个起始编号、一个终止编号。然后主库把binlog传递给从库，然后从库根据这个binlog的pos值就按照顺序做一样的操作，达到两个数据库保持一致的目的。 GTID不用这个position的方式，而是用了全局事物标识，这个标识的格式是source_id:transaction_id，如3E11FA47-71CA-11E1-9E33-C80AA9429562:23： source_id即是server_uuid，在第一次启动时生成(函数 generate_server_uuid)，并持久化到DATADIR/auto.cnf文件里； transaction_id是顺序化的序列号(sequence number)，在每台 MySQL 服务器上都是从 1 开始自增长的序列，是事务的唯一标识； 它的主从过程是这样的：主库更新数据时，会在事务前产生GTID，连通sql记录到binlog日志中。从库的i/o线程将变更的binlog写入到relay log中,读取值是根据gitd_next变量，告诉从库下一个执行哪个GTID。从库的sql线程从relay log中获取GTID，然后对比从库的的binlog是否有记录。如果有记录，说明该GTID的事务已经执行，从库会忽略。如果没有记录，从库就会从relay log中执行该GTID的事务，并记录到从库binlog。在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有二级索引就用全部扫描。 也就是说，无论是级联情况，还是一主多从情况，都可以通过GTID自动找点儿，而无需像之前那样通过binlog和binlog_position找点儿了。更多GTID 原理的知识可以去查看：https://keithlan.github.io/2016/06/23/gtid/ 。 注意！由于RDS for MySQL 5.6版本引入了GTID特性，因此要求应用不能够在事务中创建和删除临时表。那么如何对待临时表？ 将SQL语句里的temporary table语句更改为table，使用普通表替代临时表，规避这个问题； 修改代码，将临时表的创建和删除操作放在事务外，并且保证会话的参数autocommit=1； 源RDS地址（内网）：rm-bp12k8yne0909uv68.mysql.rds.aliyuncs.com目标ECS地址（内网）：172.31.0.67 工具准备首先是现在ECS里安装mysql 5.6。由于centos 7默认安装的数据库是mariabd，所以使用tar.gz包安装。 12345wget -c \"http://dev.mysql.com/get/Downloads/MySQL-5.6/mysql-5.6.33-linux-glibc2.5-x86_64.tar.gz\"tar zxvf mysql-5.6.33-linux-glibc2.5-x86_64.tar.gz -C /usr/local/cd /usr/local &amp;&amp; ln -s mysql-5.6.33-linux-glibc2.5-x86_64 mysqlmkdir -p /home/mysql/datachown -R mysql.mysql /home/mysql &amp;&amp; chmod -R o=--- /home/mysql # chmod -o是其他以外的人 使用service mysqld start启动，再用mysql -u root -p登录进去，修改掉root的空密码： 123mysql&gt; update mysql.user set password=password('123123123') where user='root';Query OK, 4 rows affected (0.00 sec)Rows matched: 4 Changed: 4 Warnings: 0 要进行GTID，首先要确认阿里云RDS作为主库是否支持GTID，如图： 可见阿里云那一段是没问题的。 然后安装xtrabackup，由于我们是mysql 5.6，所以xtrabackup的版本是2.3： 12wget https://www.percona.com/downloads/XtraBackup/Percona-XtraBackup-2.3.5/binary/redhat/7/x86_64/percona-xtrabackup-2.3.5-1.el7.x86_64.rpmyum localinstall percona-xtrabackup-2.3.2-1.el7.x86_64.rpm 最后，检查RDS白名单，确保ECS与RDS可通。 具体操作登录阿里云的RDS控制台，选择对应的RDS之后，点击左侧栏的备份恢复，将最近的一次备份下载下来： 由于是内网，直接就复制内网地址，在ECS上执行如下操作： 12wget -c '&lt;数据备份文件外网下载地址&gt;' -O /home/mysql/shopoms.tar.gz #注意引号一定要带！tar -izxvf shopoms.tar.gz -C /home/mysql/shopoms #解压缩 解压缩完毕之后，打开/opt/shopoms看一下文件组成： 用xtrabackup工具恢复解压好的备份文件，于是innobackupex --defaults-file=/home/mysql/data/backup-my.cnf --apply-log /home/mysql/data。稍等一会，解压缩成功，备份一下backup-my.cnf，改名叫slave-oms.cnf： 123456789101112131415161718192021222324252627282930[mysqld]# from rds backup-my.cnfinnodb_checksum_algorithm=innodbinnodb_data_file_path=ibdata1:200M:autoextendinnodb_log_files_in_group=2innodb_log_file_size=524288000innodb_undo_directory=.innodb_undo_tablespaces=0# need for slave server-id = 666 # 从实例的id,不能与master的id相同port=3306master-info-repository = filerelay-log-info_repository = filebinlog-format = ROW # 这里必须是ROWskip-grant-tables ##忽略mysql权限问题，免密码直接登录# GTIDgtid-mode = ON # 打开了gtid模式enforce-gtid-consistency = truelog-bin = hostname-binrelay-log = /tmp/relay.log #注意这个文件要被mysql用户读取到，如果这里不设定对，就会有Slave failed to initialize relay log info structure from the repository的错误expire_logs_days=10 # 控制binlog日志文件保留时间max_binlog_size=100M replicate-ignore-db=mysql # 不需要同步的库 log-slave-updates=1# Recommended in standard MySQL setupsql_mode=NO_ENGINE_SUBSTITUTION,STRICT_TRANS_TABLES [mysqld_safe]log-error=/var/log/mysqld.logpid-file=/var/run/mysqld/mysqld.pidsocket = /tmp/mysql.sock 同时chown -R mysql:mysql /home/mysql/data修改文件属主，并确定文件所属为MySQL用户。然后执行/usr/local/mysql/bin/mysqld_safe --defaults-file=/home/mysql/data/slave-oms.cnf --user=mysql --basedir=/usr/local/mysql --datadir=/home/mysql/data &amp;启动mysql。如图： 然后使用root账号登陆该mysql： 添加主库信息： 12345mysql&gt; change master to -&gt; master_host='rm-bp12k8yne0909uv68.mysql.rds.aliyuncs.com', -&gt; master_user='oms',master_port=3306,master_password='对应密码', -&gt; master_auto_position=1;ERROR 1794 (HY000): Slave is not configured or failed to initialize properly. You must at least set --server-id to enable either a master or a slave. Additional error messages can be found in the MySQL error log. 原因是由于RDS的备份文件中包含了RDS的主从复制关系，需要把这些主从复制关系清理掉，清理方法： 12345mysql&gt; truncate table mysql.slave_relay_log_info;Query OK, 0 rows affected (0.14 sec)mysql&gt; truncate table mysql.slave_master_info;Query OK, 0 rows affected (0.03 sec) 重启mysql，注意！恢复完成的mysql.user是不包含rds中创建的用户的，需要重新创建： 1234567891011121314mysql&gt; delete from mysql.db where user&lt;&gt;'root' and char_length(user)&gt;0;Query OK, 10 rows affected (0.02 sec)mysql&gt; delete from mysql.tables_priv where user&lt;&gt;'root' and char_length(user)&gt;0;Query OK, 42 rows affected (0.00 sec)mysql&gt; flush privileges;Query OK, 0 rows affected (0.00 sec)mysql&gt; change master to -&gt; master_host='rm-bp12k8yne0909uv68.mysql.rds.aliyuncs.com', -&gt; master_user='oms',master_port=3306,master_password='对应密码', -&gt; master_auto_position=1;ERROR 1201 (HY000): Could not initialize master info structure; more error messages can be found in the MySQL error log 这里是因为在/home/mysql/data下有一个master.info，需要先删掉他，然后重新执行change master to ...就可以了，这期间不用停止mysql进程。 然后就是启动同步： 12345678mysql&gt; reset master;Query OK, 0 rows affected (0.03 sec)mysql&gt; reset slave;Query OK, 0 rows affected (0.00 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.04 sec) 使用show slave status\\G查看一下主从状态： 出现1236错误但是此时大概率应该出现了Last_IO_Error: Got fatal error 1236 from master when reading data from binary log: &#39;The slave is connecting using CHANGE MASTER TO MASTER_AUTO_POSITION = 1, but the master has purged binary logs containing GTIDs that the slave requires.&#39;这个错误，如图： 这里要先说两个概念： gtid_executed(global)：MySQL数据库已经执行过的Gtid事务，处于内存中。show master status/show slave status中的Executed_Gtid_Set也取自这里； gtid_purged(global)：由于binlog文件的删除(如purge binary logs或者超过expire_logs_days设置)已经丢失的Gtid事务，它是gtid_executed的子集； 明白了上面两个概念，我们再来回溯一下这个过程： 我们用RDS做的备份集来恢复出一个自建ECS的mysql实例； 启动主从同步； 从库在开始同步前,主库会依靠GTID来确认从库在开始同步以后, 能够把每一个主库上执行过的事务(包括slave的SQL Thread)都复现一次,最终保持和主库完全一致; 但是从库指定的GTID_PURGED并不等于主库的GTID_EXECUTED，为什么呢?因为主库多出来的这些gtid已经purge（丢失）掉了或者是新的从库未指定过GTID_PURGED； 出现1236的故障报错； 此时我们分别进入到主从mysql里，执行show global variables like &#39;%gtid%&#39;\\G，查询一下gtid_purged，如图： 我们先在主库上show global variables like &#39;GTID_EXECUTED&#39;;看一下效果： 1234567mysql&gt; show global variables like 'GTID_EXECUTED';+---------------+------------------------------------------------------------------------------------------------+| Variable_name | Value |+---------------+------------------------------------------------------------------------------------------------+| gtid_executed | 18e99fbf-5f38-11e8-8a6f-6c92bf21d8b5:1-1519695, 4ccd3917-5f58-11e8-8b41-7cd30adfe86a:1-9717278 |+---------------+------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 在从库上执行如下的内容： 123456789101112131415161718192021222324252627mysql&gt; stop slave;Query OK, 0 rows affected (0.01 sec)mysql&gt; reset master; # 这一步是为了把GTID_EXECUTED清空Query OK, 0 rows affected (0.03 sec)mysql&gt; show global variables like 'GTID_EXECUTED';+---------------+-------+| Variable_name | Value |+---------------+-------+| gtid_executed | |+---------------+-------+1 row in set (0.00 sec)mysql&gt; set global GTID_PURGED='18e99fbf-5f38-11e8-8a6f-6c92bf21d8b5:1-1519695,4ccd3917-5f58-11e8-8b41-7cd30adfe86a:1-9717278'; # 把主库的GTID_EXECUTED值填进来Query OK, 0 rows affected (0.03 sec)mysql&gt; show global variables like 'GTID_EXECUTED'; +---------------+------------------------------------------------------------------------------------------------+| Variable_name | Value |+---------------+------------------------------------------------------------------------------------------------+| gtid_executed | 18e99fbf-5f38-11e8-8a6f-6c92bf21d8b5:1-1519695, 4ccd3917-5f58-11e8-8b41-7cd30adfe86a:1-9717278 |+---------------+------------------------------------------------------------------------------------------------+1 row in set (0.00 sec)mysql&gt; start slave;Query OK, 0 rows affected (0.01 sec) 再次执行show slave status\\G，就好了： 由于mysql的配置文件没有规定readonly，所以我在从库也可以执行insert和update等写操作，但是是不会同步到主库的，而且还会由于主从数据不一致而报错。如果RDS不想要了，直接stop slave，把这个自建mysql当主库就行了。 参考资料https://www.cnblogs.com/weifeng1463/p/9678303.htmlhttps://misakatang.cn/2019/03/02/%E9%98%BF%E9%87%8C%E4%BA%91RDS%E9%80%BB%E8%BE%91%E5%A4%87%E4%BB%BD%E6%81%A2%E5%A4%8D%E4%B8%BB%E4%BB%8E/https://segmentfault.com/a/1190000015657340https://help.aliyun.com/knowledge_detail/41817.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"阿里云","slug":"阿里云","permalink":"http://yoursite.com/tags/阿里云/"},{"name":"mysql主从","slug":"mysql主从","permalink":"http://yoursite.com/tags/mysql主从/"},{"name":"gtid","slug":"gtid","permalink":"http://yoursite.com/tags/gtid/"}]},{"title":"中秋苏州游记","slug":"中秋苏州游记","date":"2019-09-23T01:52:01.000Z","updated":"2019-09-23T04:47:26.000Z","comments":true,"path":"2019/09/23/中秋苏州游记/","link":"","permalink":"http://yoursite.com/2019/09/23/中秋苏州游记/","excerpt":"","text":"我之前对苏州的认识并不多，仅仅是“上有天堂,下有苏杭”这样的一个模糊概念。但是一直以来对金庸先生笔下所描写的那个“姑苏”还是有些向往的，于是在这次中秋三天里，我跟媳妇就选择苏州作为度假点，好好的享受了一下这个吴城。 苏州的玩苏州论景点最出名的就是三兄弟—“苏州博物馆+忠王府+拙政园”,这三个地方不仅是苏州地标历史景点，而且地理位置还是在一起的。所以到了苏州的第一站，我们就满血冲了过去，苏州博物馆并不大，除了历史文物还有现代艺展，不到100分钟就能粗略浏览完毕。但是那里是著名的网红博物馆，里面到处都是摆造型拍照的女孩子。因为苏州博物馆的确设计的很漂亮，无论是展厅还是中庭，贝聿铭先生对空间的理解真是大师级别。苏州本身并不是一个尖顶建筑众多的城市，但是苏州博物馆是一个尖顶建筑，它整体但不高，天花棚通过条纹晒进阳光，让室内最大限度的透入自然光，使得墙面非常的好看。而且博物馆里的小窗户都是六边形的，可以通过窗看到院子里种的竹子、凉亭、小桥，古朴又不失现代感，更添一份宁静。在苏州博物馆，感受到里面意境和光影不仅仅是一个博物馆，更像是一个创意山水园。 苏州博物馆旁边就是忠王府，直接相通，他俩加上拙政园合起来就是天平天国忠王李秀成当年的府邸，忠王府也是迄今为止太平天国历史上保存的最好的建筑物了。一下子从苏州博物馆的艺术氛围跳到王府，画风的转变还是有点快。忠王府里面除了教堂、军事办公室、戏台、大厅和一架大炮之外，还收藏了一些太平天国的历史文物。 忠王府虽然是李秀成的，但是据说他自己却没有完全的住过，因为在同治二年冬（1863年12月），太平天国在苏州的地盘全面失守，当时忠王府的工程仍未完工，只是初具规模而已，李鸿章把忠王府为江苏巡抚行辕。这个建筑后来在1938年，被日本人当做了“江苏省维新政府”驻所。到了1946年，国立社会教育学院借作校舍，解放后收归国有。这幢建筑虽然几次易主，但是大体还算是平安的。相比较而言，它的第一任主人李秀成的命运要比它惨得多。 从忠王府出来，旁边就是拙政园了。我们同样是在公众号上买票，然后直接安检入门。拙政园就是一个超级大的园林，里面各种树木、池塘、长廊、小亭和假山。鸭子、金鱼在水里随便的游来游去，大片大片的荷叶慵懒的铺在水面上，充足的阳光穿过一层一层的叶子洒落在身上，把人晒得暖洋洋的。拙政园已经是苏州园林的代表，在那里转过之后，那么狮子林和留园等园林也就大同小异了。 拙政园离平江路就很近了。平江路作为了一个历史街区，感觉是一个修长的历史画卷。那里面不仅有很多网红店人满为患，还有许多笔直的小里巷，粉墙黛瓦，高低差参，栉比鳞次，有的宽仅一米，狭窄而幽深，空荡荡，看不到一个人。在这里不自觉就会把脚步放慢，一个店一个店慢慢的走过去，在商业化气息严重的今天，还是能感受一下老苏州的质朴。走到夕阳西下，我们花了80块坐了一次小船，摇船的大姐给我们唱了当地的小调—《小城故事多》、《秦淮景》、《四季歌》等等。船在水上，人在画中，小桥流水，倒映着斑驳旧影，垂柳依依，掩映着白墙黑瓦。悠悠水乡，多少沧桑，古朴幽静，船橹摇荡。这就是平江路的夜。 到了苏州，怎能不听评弹？有一句俗话叫做“宁愿听苏州人吵架，也不听宁波人说话”，用以形容苏州方言的动听。而且随着《都挺好》的热播，苏州平江路上大大小小的评弹店都是挂上了各种各样《都挺好》的因素。我选择了“琵琶语评弹茶座”，虽然店面不算太好找，但是里面却是人气爆棚。价钱很便宜，38块钱叫上一杯绿茶就可以在里面听上几段评弹，还可以有昆曲点播。听不懂苏州的吴侬软语不要怕，墙上有电子屏幕同步显示歌词。几曲咿咿呀呀下来，感觉自己被苏大强附体，不禁得摇头晃脑起来。 寒山寺也是一个苏州招牌景点，那句“姑苏城外寒山寺，夜半钟声到客船”俨然成了寒山寺的最好的宣传口号。那首诗也在寺里被至少几十个碑被各种历史名流篆刻。诗虽然流传千年，但是现在寒山寺的钟已经不再是当年的那口钟了，寒山寺还是保留着过年敲钟108下的习惯，为整个苏州辞旧迎新，祈祷平安。 寒山寺里就跟一般的寺院差不多，到没有什么特别。走了一圈，让我比较有印象的是寒拾殿。此殿位于藏经楼内，楼的屋脊上雕饰着《西游记》人物故事，是唐僧师徒自西天取得真经而归的形象。 第一天走完了苏州的古，回到民宿好好泡了脚休息一番。第二天驱车奔向金鸡湖开发区，去感受苏州的新。我们先后逛了苏州中心、东方之门和诚品书店。逛街本身只是例行打卡而已，毕竟苏州有的东西基本杭州都有。不过金鸡湖有直升飞机可以坐，860元一趟（2~4人），可以带你绕金鸡湖飞一圈，一趟下来大约需要20分钟，但是要很早的预约。夜生活的话，如果想去livehouse耍耍，那么观前街和十全街有酒吧可以满足需求，高中低档的一应俱全。 苏州的吃苏州的吃我并没有特别做攻略下功夫，按照随遇而安的心态，正餐都是在一般的店解决的。第一天到苏州后去琼琳阁吃了有名的焖肉面，晚上是在平江路靠路两边的小吃填饱肚子。第二天中午在苏州中心的南京大排档里尝了鸭血粉丝汤和烤鸭，晚上在石路的小郡肝钢管厂五号的串串店解决。至于最后一天中午，由于要玩VR，我们就在VR店附近的万达广场吃了汉拿山烤肉（囧，这顿饭一点都不苏州）。 苏州菜跟杭州菜对于东北出身的我来说，感觉师出一路，口味都是精致偏甜，里面的甜相比较用糖更多的是用酱。松鼠桂鱼和蟹黄豆腐基本是每一个苏州菜馆的菜单必备，如果觉得油腻再叫上一壶碧螺春刮刮油。相比较杭州羊肉的匮乏，苏州街边的藏书羊肉店是随处可见，里面羊肉汤羊肉饺子羊肉火锅各种吃法一应俱全。中秋时期还算是吃阳澄湖大闸蟹的季节，但是据说苏州的正餐里是不上大闸蟹的，因为一旦上了大闸蟹，大家的注意力都在拆蟹吃蟹上，宴会的气氛就会冷淡下来。至于小吃，我吃到了平江路的鸡脚旮旯的酱鸡爪，味道蛮好的，但是一定要带汤一起吃，没有汤的鸡爪子是没有灵魂的。除此之外，也吃到了哑巴生煎，感觉跟杭州的生煎味道差不多。 最后着重说一下石路上小郡肝钢管厂五区里面的土豆块，真是超级好吃，我后来在杭州的几家小郡肝找了一下都没有这个小菜。所以强烈推荐，到了苏州一定不要错过它！ 一点小tips 苏州的老城区是限号的，所以外地车辆在手机地图上应该提前设置好车牌，高德地图就直接把我们导航到了驳接车站那里； 从苏州北旅游换乘中心做免费车去苏州博物馆，但是最晚一趟车是5点半，所以超过这个点就只能打车回换乘中心了； 苏州博物馆、拙政园、狮子林等都可以在微信公众号上购票，由于苏州博物馆是免费的，所以推荐先拍下苏州博物馆的票，然后看一下拙政园的情况再买票，买票检查是需要身份证的； 平江路坐船，撑船大姐唱歌是要付费的，30一次； 苏州仅仅游玩了三天是不够的，我这一次的行程非常粗浅，并没有包括狮子林、虎丘、留园、苏州大学以及华谊兄弟乐园（能蹦极）等著名景点。但是这短短的两天时间却让我喜欢上了这个南方小城，它就像杭州的姐妹，既有温婉可人的一面也有工业发展的一面。最后就用刘以达的一首《我的天使》作为结局吧，这段歌词特别符合我这个初行者对苏州的印象： 12爱似浓郁咖啡 围裙除去 晚妆一卸拥抱一夜 以後百夜 亦暖些","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"旅游","slug":"旅游","permalink":"http://yoursite.com/tags/旅游/"},{"name":"苏州","slug":"苏州","permalink":"http://yoursite.com/tags/苏州/"}]},{"title":"Linux运维工程师笔试题第二十套","slug":"Linux运维工程师笔试题第二十套","date":"2019-09-16T08:10:28.000Z","updated":"2019-09-23T09:32:46.000Z","comments":true,"path":"2019/09/16/Linux运维工程师笔试题第二十套/","link":"","permalink":"http://yoursite.com/2019/09/16/Linux运维工程师笔试题第二十套/","excerpt":"","text":"试题正文 请解释Deployment、ReplicaSets、StatefulSets、Pod、Job、CronJob的不同用途Deployment的应用场景： 无状态的、轻量级应用StatefulSets的应用场景： 有状态的应用，每个节点有固定的的身份ID、Pod的启动有先后顺序、存储使用持久化存储卷（PV/PVC）；Deployment和Statefulset之间很显著的区别是deployment的pod名每次重启之后会变，而stateful不会变，另外statefuset的启动是有顺序的。Job的应用场景： 负责处理任务，即仅执行一次的任务，它保证批处理任务的一个或多个Pod成功结束；CronJob的应用场景: 在给定的时间点运行一个任务，也可以周期性地在给定时间点运行； Kubernetes 如何处理持久性？根据独立的存储系统如NFS、iSCSI、cephfs、glusterfs等，创建动态/静态PV，然后对应绑定PVC，然后在POD里使用PVC即可。 什么是sidecar容器？你能给出一个用例，说明你为什么要使用它么？将应用程序的功能划分为单独的进程可以被视为 Sidecar 容器。Sidecar的设计模式允许你为应用程序添加许多功能，而无需额外第三方组件的配置和代码。实际的应用场景是比如一些服务，还要搭配监控、日志、集中化配置和网络服务这样的附属服务的时候，就可以考虑用sidecar模式。 kubernetes包含几个组件。 各个组件的功能是什么。组件之间是如何交互的。k8s大致分为3个部分：Master节点、Node节点、应用。 Master节点提供集群的控制面板，其下组件有： 12345kube-apiserver 提供k8s的API调用服务。etcd 数据中心，存储集群的所有数据。kube-scheduler 调度器，负责给新创建的容器分配节点等。kube-controller-manager 控制管理器，负责监控和维护集群状态。cloud-controller-manager 是提供给第三方开发k8s特性的。 其中controller又包含： 1234Node Controller 报告节点健康状态。Replication Controller 维护rc的pod个数，pod挂掉又控制重启。Endpoints Controller 填充Endpoint对象，主要是给Service和Pod。Service Account &amp; Token Controllers 创建帐号和Token。 Node节点组件： 123kubelet 管理Pod里面的容器。kube-proxy 管理网络路由规则。container runtime 容器运行环境，如Docker等。 应用都是部署在kube-system这个命名空间下的。如： 1234DNS dns服务。Dashboard web管理界面。Container Resource Monitoring 容器资源管理和监控，如cAdvisor、Prometheus。Cluster-level Logging 日志收集分节点、集群、应用三种类型，可用elk或fluentd等。 k8s中的pod内几个容器之间的关系是什么。一个Pod是一组容器的集合，像豌豆荚于豌豆。提供容器间存储和网络的共享，和一系列运行规范。Pod里面的容器共享网络，因此可使用localhost通讯。由于也共享存储，所以可以使用IPC和共享内存进行通讯。 如何在 Kubernetes 中实现负载均衡？通过创建service来实现负载均衡，Service Cluster IP 是一个虚拟 IP，它与pod IP的映射关系是通过iptables，而且用的是使用类似轮询的负载均衡策略（iptables规则里有–probability 0.33332999982这样的标记）。 Deployment、Rc、Rs有什么区别。 其使用方式使用条件和原理是什么。Replication Controller是最早的部署、升级Pod的管理工具，他能保证pod的健康个数。Replication Set包含RC的所有功能，它比RC强的地方就是RC只支持等式的seletor，而RS的用法更丰富。Deployment比RS还高级，而且支持历史回溯、回滚、查看事件状态、暂停启动升级等功能，而且它支持两种升级方案：Recreate（全毁重建）、RollingUpdate（默认，逐步替换） Cgroup中的cpu有哪几种限制方式。Cgroup限制CPU的方式有三种：cpuset、cpuquota、cpushares，具体如下： 123cpuset隔离方式是以分配核心的方式进行资源隔离，可以提供的资源分配最小粒度是核心，不能提供更细粒度的资源隔离，但是隔离之后运算的相互影响最低。需要注意的是在服务器开启了超线程的情况下，要小心选择分配的核心，否则不同cgroup间的性能差距会比较大。cpuquota给我们提供了一种比cpuset可以更细粒度的分配资源的方式，并且保证了cgroup使用cpu比率的上限，相当于对cpu资源的硬限制。cpushares给我们提供了一种可以按权重比率弹性分配cpu时间资源的手段：当cpu空闲的时候，某一个要占用cpu的cgroup可以完全占用剩余cpu时间，充分利用资源。而当其他cgroup需要占用的时候，每个cgroup都能保证其最低占用时间比率，达到资源隔离的效果。 注意！Linux cgroup和Docker都将CPU核心数分成了1024个时间片（shares），而Kubernetes将它分成了1000个shares。所以有时候用docker inspect和kubectl查看有小小的误差。 k8s是如何使用实现request和limit的？CPU 资源限制和内存资源限制一样都是由cgroup控制 kubectl run这个命令敲下去会有什么过程？首先kubectl会先进行客户端验证的操作，kubectl run会自己判断创建的资源类型，比如当-–replicas=1的时候--restart=Never，那么生成的就是pod。如果有指定参数--generator，可以来部署其他多种资源类型。 然后通过apiVersion字段生成REST路径并且真正地发送HTTP请求。一旦请求发送到kube-apiserver之后获得成功的响应，kube-apiserver将对HTTP请求进行反序列化，然后利用得到的结果构建运行时对象的信息（有点像kubectl生成器的逆过程），并保存到etcd中。 此时Scheduler开始调度，第一轮算法是淘汰掉不满足pod需求的节点，第二轮算法是在符合要求的候选节点上进行优选，将结果打分。一旦找到了合适的节点，Scheduler就会创建一个Binding对象，该对象的Name和Uid与Pod相匹配，然后通过POST请求发送给apiserver。apiserver会把该资源与对应的node记录到etcd里。 Kubelet服务进程会根据度结果先创建pause容器，然后再进行业务Pod的创建。 参考资料https://juejin.im/post/5d28508ff265da1b7638ceeb （kubectl 创建 Pod 背后到底发生了什么？）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/tags/大牛之路/"}]},{"title":"解决Mysql的CPU过高的问题","slug":"解决Mysql的CPU过高的问题","date":"2019-09-11T13:29:58.000Z","updated":"2019-10-18T10:05:10.000Z","comments":true,"path":"2019/09/11/解决Mysql的CPU过高的问题/","link":"","permalink":"http://yoursite.com/2019/09/11/解决Mysql的CPU过高的问题/","excerpt":"","text":"正文今儿发现AWS有一个mysql5.6.40数据库从库（2核16G，最大IOPS 2000）的CPU很不正常，如图： 先查看了一下mysql的总体情况： 123456789Uptime: 10471685 Threads: 894 Questions: 58466385559 Slow queries: 2466 Opens: 321642 Flush tables: 1 Open tables: 2000 Queries per second avg: 5583.283 #Questions是已执行的由客户端发出的语句MySQL [easyip]&gt; show status where `variable_name` = 'Threads_running';+-----------------+-------+| Variable_name | Value |+-----------------+-------+| Threads_running | 2 |+-----------------+-------+1 row in set (0.00 sec) 跑到里用show full processlist一看，发现几乎都是sleep，只有偶尔才会刷出来一两条Query。 使用tcpdump -s 65535 -x -nn -q -tttt -c 500000 -i any port 3306 &gt; mysql.txt抓一个500M大小的包，然后wget percona.com/get/pt-query-digest和chmod u+x pt-query-digest来安装pt-query-digest，一会我们用它分析一下这个包。 插播一句，如果使用pt-query-digest的时候爆Can&#39;t locate Digest/MD5.pm in @INC这样的错误，请执行yum install perl-Digest-MD5.x86_64。 然后执行./pt-query-digest --type tcpdump --watch-server=&#39;mysql的IP地址:3306&#39; mysql.txt &gt;3306.log，打开这个3306.log一探究竟： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263# 91.2s user time, 4.1s system time, 38.76M rss, 203.35M vsz# Current date: Wed Sep 11 13:25:02 2019# Hostname: ip-10-10-153-64.eu-central-1.compute.internal# Files: mysql.txt# Overall: 107.03k total, 96 unique, 2.94k QPS, 2.89x concurrency ________# Time range: 2019-09-11 13:22:21.774093 to 13:22:58.211771# Attribute total min max avg 95% stddev median# ============ ======= ======= ======= ======= ======= ======= =======# Exec time 105s 0 73ms 984us 3ms 2ms 424us# Rows affecte 0 0 0 0 0 0 0# Query size 19.41M 18 1.59k 190.15 346.17 109.64 158.58# Warning coun 0 0 0 0 0 0 0# Profile# Rank Query ID Response time Calls R/Call V/M Item# ==== ============================= ============= ===== ====== ===== ====# 1 0x17439B73926DAFE4B1F7504E... 62.6518 59.5% 62408 0.0010 0.01 SELECT macuserinfo pcs_sys_user# 2 0x221ABFF7BE95D0B83774ECE7... 7.7099 7.3% 4374 0.0018 0.01 SELECT device_channel_config_info# 3 0x8D042CE60A67A30092CD7CFD... 6.9497 6.6% 4978 0.0014 0.01 SELECT push_client_info pcs_user_dev_link pcs_sys_user# 4 0xEBBF1DEAACA1353A4DD445F3... 4.5713 4.3% 3952 0.0012 0.00 SELECT pcs_adm_dev_storage_strategy# 5 0x49348052DEA8C471AD64477C... 4.1641 4.0% 5227 0.0008 0.00 SELECT pcs_user_dev_link pcs_sys_user# 6 0xF96D9A42E1EFE0A84717B273... 3.8453 3.7% 4970 0.0008 0.00 SELECT user_authorize_info# 7 0x40FC0DACAACA50F36466B100... 2.7108 2.6% 4132 0.0007 0.00 SELECT pcs_adm_dev_storage_strategy# 8 0x24A6818C09D884D5B2DD04FB... 2.2897 2.2% 2095 0.0011 0.01 SELECT device_config_info macuserinfo device_config_info# 9 0x6E5549936C772E40EBAE1FEE... 1.8566 1.8% 3355 0.0006 0.00 SELECT macinfo# 10 0x238C2BAB786EE59102CF0654... 1.7066 1.6% 2077 0.0008 0.01 SELECT pcs_user_dev_link pcs_sys_user# 11 0x327C32C0EBADC5D17957E04C... 0.9152 0.9% 1771 0.0005 0.00 SELECT device_config_info# 12 0x7190F54D663D68CFE1680408... 0.6966 0.7% 1021 0.0007 0.00 SELECT pcs_adm_dev_storage_strategy# MISC 0xMISC 5.2609 5.0% 6669 0.0008 0.0 &lt;84 ITEMS&gt;# Query 1: 2.71k QPS, 1.72x concurrency, ID 0x17439B73926DAFE4B1F7504E191657C8 at byte 287906107# This item is included in the report because it matches --limit.# Scores: V/M = 0.01# Time range: 2019-09-11 13:22:21.774093 to 13:22:58.211613# Attribute pct total min max avg 95% stddev median# ============ === ======= ======= ======= ======= ======= ======= =======# Count 58 62408# Exec time 59 63s 171us 69ms 1ms 3ms 2ms 424us# Rows affecte 0 0 0 0 0 0 0 0# Query size 50 9.88M 159 179 166.01 158.58 0.63 158.58# Warning coun 0 0 0 0 0 0 0 0# String:# Hosts 10.10.153.64# Query_time distribution# 1us# 10us# 100us ################################################################# 1ms ############## 10ms ## 100ms# 1s# 10s+# Tables# SHOW TABLE STATUS LIKE 'macuserinfo'\\G# SHOW CREATE TABLE `macuserinfo`\\G# SHOW TABLE STATUS LIKE 'pcs_sys_user'\\G# SHOW CREATE TABLE `pcs_sys_user`\\G# EXPLAIN /*!50100 PARTITIONS*/select b.id As user_id, b.PROJECT As project, a.user AS user from macuserinfo a, pcs_sys_user b where a.user=b.username and a.devsequence='4L05B49PAZE5806' limit 1;\\G# Query 2: 120.17 QPS, 0.21x concurrency, ID 0x221ABFF7BE95D0B83774ECE7A62FCB96 at byte 319100665......... 从文件里可以看出这个select语句在本次分析中总的时间占比高达60%，但是单次调用耗时极少，不过QPS（每秒执行的查询次数）却高达2.71k QPS，这个应该是CPU高的原因。 执行一下explain看一下： 然后有用show columns from pcs_sys_user;、show index from pcs_sys_user;和show columns from macuserinfo;、show index from macuserinfo;查看一下是否有漏建索引，发现没有，比如： 这种就是典型的“QPS高导致CPU使用率高”的场景：查询语句比较简单、执行效率高、SQL优化余地小。一般解决的方法就是从应用架构、实例规格等方面入手： 升级实例规格，增加CPU资源； 做了分库分表，将查询压力分担到多个RDS实例上； 使用批量操作，将多个操作合并为一次请求，但此种方式需要考虑是否可以一次批量的数据有多大，避免造成慢sql； 后续措施如上文所说，这个数据库里的sleep的进程也太多了，大量的sleep进程无法及时释放，也拖累系统性能，不过也不能把这个指设置的过小，否则可能会遭遇到MySQL has goneaway之类的问题，默认的等待时间是28000秒，如下： 1234567MySQL [easyip]&gt; show global variables like 'wait_timeout';+---------------+-------+| Variable_name | Value |+---------------+-------+| wait_timeout | 28800 |+---------------+-------+1 row in set (0.00 sec) 改成3600就够用了… 注意！本文中的例子里where条件是经常变化的，所以这种场合没有打开query_cache。对于经常修改的表，使用查询缓存可能会加大副本滞后，因为缓存已锁定且会频繁刷新。而对于查询数据比较静态、查询重复度高、查询结果集小于3MB的场景，才考虑开启查询缓存。 最后，本次故障排查感谢arstercz大神的鼎力相助！ 参考资料https://docs.aws.amazon.com/zh_cn/AmazonRDS/latest/UserGuide/CHAP_Troubleshooting.htmlhttps://aws.amazon.com/cn/blogs/china/pt-query-digest-rds-mysql-slow-searchnew/https://jin-yang.github.io/post/mysql-monitor.htmlhttps://tech.kujiale.com/shu-ju-ku-cpushi-yong-lu-100-pai-cha-ji/http://mysql.taobao.org/monthly/2015/05/02/ （强力推荐！）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/tags/AWS/"},{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"主从同步","slug":"主从同步","permalink":"http://yoursite.com/tags/主从同步/"}]},{"title":"K8s里pod的调度笔记","slug":"K8s里pod调度笔记","date":"2019-09-11T06:19:19.000Z","updated":"2019-09-17T13:40:52.000Z","comments":true,"path":"2019/09/11/K8s里pod调度笔记/","link":"","permalink":"http://yoursite.com/2019/09/11/K8s里pod调度笔记/","excerpt":"","text":"概述k8s里对pod的调度的过程简单说就是：当Scheduler通过API server的watch接口监听到新建Pod副本的信息后，它会检查所有符合该Pod要求的Node列表，开始执行Pod调度逻辑。调度成功后将Pod绑定到目标节点上，目标Node上的kubelet服务进程接管后继工作，负责Pod生命周期的后半生。同时Scheduler并将绑定信息传给API server写入etcd中。 Kubernetes Scheduler提供的调度流程分三步： 预选策略(predicate)：遍历nodelist，选择出符合要求的候选节点，Kubernetes内置了多种预选规则供用户选择。 优选策略(priority)：在选择出符合要求的候选节点中，采用优选规则计算出每个节点的积分，最后选择得分最高的。 选定(select)：如果最高得分有好几个节点，select就会从中随机选择一个节点。 而具体方案有以下几种：pod对pod：podAffinity和podantiAffinitypod对node：nodeName、nodeSelector、Taint和Toleration、nodeAffinity和nodeantiAffinity、DeamonSet 强指定nodeName先看一下当前node的情况： 最简单无脑的把pod分配到node上的方法就是nodeName，这个方法是不走schedule分配的，而是直接到对应的node上由kubelet创建pod，举个例子，写一个pod.yaml： 123456789101112131415apiVersion: v1kind: Podmetadata: labels: run: pod-manual-schedule namespace: default name: pod-manual-schedulespec: nodeName: \"node2\" #这里填写的是NAME段，指定这个pod去node2节点上 #nodeSelector: # cloudnil.com/role: dev #指定调度节点为带有label标记为：cloudnil.com/role=dev的node节点 #schedulerName: default-scheduler #调度器可以自己确定，一般来说这一行不写，即默认的那个调度器 containers: - name: my-pod image: nginx:1.11.9 kubectl apply -f pod.yaml之后，查看一下效果，果然分配到了node2上： kubectl delete -f 1.yaml删掉该pod。 跟nodeName差不多功效的是nodeSelector，只不过后者靠label而不是名字来给pod指定node。 但是要注意！！！如果在创建deployment/pod的时候指定了nodeName，那么k8s是不会做调度的，也就是说不管该node上的剩余资源是否满足request，都会硬往里塞。那么如果node上的剩余资源不足，就会发现pod处于outofcpu/outofmem。 亲和性nodeaffinity通过nodeAffinity调度pod就多了一丝动态选择的味道，不像nodeName那么死板了。首先kubectl label nodes node3 has-eip=yes先给node3打上has-eip=yes这样的label，然后写一个pod.yaml如下： 123456789101112131415161718192021apiVrsion: v1kind: Podmetadata: labels: run: node-affinity namespace: default name: node-affinityspec: containers: - name: my-pod image: nginx:1.11.9 imagePullPolicy: IfNotPresent affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: has-eip operator: In values: - \"yes\" kubectl apply -f pod.yaml之后，查看一下效果，果然分配到了node3上： 如果说就是不信邪，要把nodeAffinity和nodeName/nodeSelector一起用，而且还不是指向同一个node，那么这个pod就会调度失败，卡在Predicate MatchNodeSelector failed这个阶段。 谈谈topologyKey众所周知，为了照顾pod之间的超亲密关系，k8s还有一个podAffinity，比如一个yaml如下： 12345678910111213141516171819202122apiVersion: v1kind: Podmetadata: labels: run: pod-affinity namespace: default name: pod-affinityspec: containers: - name: my-pod image: nginx:1.11.9 imagePullPolicy: IfNotPresent affinity: podAffinity: requiredDuringSchedulingIgnoredDuringExecution: - labelSelector: matchExpressions: - key: run operator: In values: - \"node-affinity\" topologyKey: kubernetes.io/hostname 这里面有一个元素叫topologyKey，对它的讲解并不多，很多资料也是一句带过。我这里打算研究一番： topologyKey是拓扑域，即一个范围。这个范围可大可小，可以是地区、机房也可以是一个node。它实际对应的还是一个node的标签，也就是说，其实topologyKey就是用于筛选Node的。 结合我上面那个yaml，这个yaml意思就是要在default这个命名空间里创建一个叫pod-affinity的pod，它要求必须与run：node-affinity这样的pod在同一个node里，而且这个node还要有kubernetes.io/hostname这样的label。 那么如何判断一个node的label里有没有kubernetes.io/hostname？使用kubectl get nodes -o wide --show-labels 看一下： 可见图里三个node都有kubernetes.io/hostname，但是如何结合拓扑域呢？举个例子：Pod1在k8s.io/hostname=node1的Node上，Pod2在k8s.io/hostname=node2的Node上，Pod3在k8s.io/hostname=node1的Node上，则Pod2和Pod1、Pod3不在同一个拓扑域，而Pod1和Pod3在同一个拓扑域。 注意！原则上，topologyKey可以是任何合法的标签Key。但是出于性能和安全原因，对topologyKey有一些限制： 于亲和性和 requiredDuringSchedulingIgnoredDuringExecution的Pod反亲和性，topologyKey不能为空。 对于requiredDuringSchedulingIgnoredDuringExecution 的Pod反亲和性，引入LimitPodHardAntiAffinityTopology准入控制器来限制topologyKey只能是 kubernetes.io/hostname。如果要使用自定义拓扑域，则可以修改准入控制器，或者直接禁用它。 对于 preferredDuringSchedulingIgnoredDuringExecution 的Pod反亲和性，空的topologyKey 表示所有拓扑域。截止v1.12版本，所有拓扑域还只能是kubernetes.io/hostname、failure-domain.beta.kubernetes.io/zone和failure-domain.beta.kubernetes.io/region的组合。 除上述情况外，topologyKey可以是任何合法的标签key。 timeAdded的问题在Node的taint的配置里，可能会有timeAdded这样的字眼： 12345taints: - effect: NoSchedule key: dedicated timeAdded: null value: master 这个timeAdded是啥？很少有人介绍，就有人误认为效果是类似toleration里的tolerationSeconds，其实是不对的。 timeadded只有在effect:NoExecute里才有具体的值，其余时候都是null，这个字段的设计用途是：“考虑到不同的node可能时间不一致，如果k8s组件出现时间误差的时候，通过timeAdded + pod.tolerationSeconds小于等于time.Now来保证taint能成功的把pod转移到其他的node去”。 不过这个字段据说要慢慢被淘汰掉了，所以可以不用太关注它。 参考资料http://bazingafeng.com/2019/03/31/k8s-affinity-topologykey/https://github.com/kubernetes/kubernetes/issues/42394https://segmentfault.com/a/1190000018446858","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"http://yoursite.com/tags/k8s/"},{"name":"节点调度","slug":"节点调度","permalink":"http://yoursite.com/tags/节点调度/"}]},{"title":"Gitlab-runner实现跨服务器部署","slug":"Gitlab-runner实现跨服务器部署","date":"2019-08-26T13:26:36.000Z","updated":"2019-08-27T08:53:50.000Z","comments":true,"path":"2019/08/26/Gitlab-runner实现跨服务器部署/","link":"","permalink":"http://yoursite.com/2019/08/26/Gitlab-runner实现跨服务器部署/","excerpt":"","text":"环境描述本次试验的目的就是：业务模块服务器提交代码，触发流水线，gitlab-runner远程到该服务器进行操作。 gitlab-runner：172.16.194.01，容器安装，宿主机生成id_rsa；业务模块服务器：172.16.194.02；两个服务器相关端口已经打通。 配置变量.gitlab-ci.yml虽然是一个yaml格式的一个文件，但是script的内容其实就是一个shell脚本。既然是脚本，不可避免的要涉及到一些环境变量，而一些敏感的环境变量我们不推荐把它直接写进到gitlab-ci.yml里，比较好的方案是存储到gitlab里。 打开gitlab的web页面，点开对应的project—Settings—CI/CD—Variables，如图： 这里面存储的值比如DEPLOY_SERVER，对应的value就是172.16.194.02，即模块服务器的IP，保存之后，这样的环境变量不用在.gitlab-ci.yml里声明就可以直接通过$变量名的形式使用。 这里注意一下，SSH_PRIVATE_KEY对应的就是我们刚刚生成的那个宿主机的id_rsa内容，不是路径啊是整个文件的内容，我知道这个框很小，但是请放心，塞的进去。 完整gitlab-ci.yml现在在模块服务器的代码根目录做一个gitlab-ci.yml，主要目的就是让gitlab-runner在模块服务器的/tmp/test目录下生成一个111.txt文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647# 定义 stagesstages: - build - testbefore_script: - 'which ssh-agent || ( apt-get update -y &amp;&amp; apt-get install openssh-client -y )' - eval $(ssh-agent -s) # 清除一些系统中复制出现的换行符\\r，并重定向到/dev/null防止泄露 - echo \"$SSH_PRIVATE_KEY\" | tr -d '\\r' | ssh-add - &gt; /dev/null # 创建~/.ssh目录，并配置权限(非root运行的runner) - mkdir -p ~/.ssh - chmod 700 ~/.ssh - '[[ -f /.dockerenv ]] &amp;&amp; echo -e \"Host *\\n\\tStrictHostKeyChecking no\\n\\n\" &gt; ~/.ssh/config'after_script: - echo \"FINISH!!!\" # 也可以在这里指定环境变量，效果一样 variables: - IMAGE: java:latest - CONTAINER_NAME: daily_report_java - VERSION: \"1.8\" # 注意这里的双引号# 定义 job1job1: stage: test tags: - my-tag script: - echo \"I am job1\" - echo \"I am in test stage\" environment: name: production url: http://$DEPLOY_SERVER# 定义 job2job2: stage: build tags: - my-tag script: - echo \"I am job2\" - echo \"I am in build stage\" - echo $IMAGE:$VERSION - echo $CONTAINER_NAME - ssh root@$DEPLOY_SERVER \"cd /tmp/test &amp;&amp; echo '123123'&gt; 111.txt\" 这里说一下before_script段：第一行代码判断ssh-agent是否存在，不存在则下载；第二行执行ssh-agent；第三行将server端的私钥加入到ssh-agent的管理下；四、五行创建.ssh文件夹，并给予正确的权限。 还有before_script不是before-script，这样会被gitlab-runner当成一个job… 执行一下，来到web端可见job状态是OK： 点开build这个job，查看细节，可见文中的环境变量也被正确的读取了： 同时在模块服务器上的111.txt也生成了，实验成功！ 如果要使用ansible搭配批量部署，可以考虑让gitlab-runner去操作ansible服务器，然后在gitlab-ci.yml去调用ansible的脚本。 参考资料https://docs.gitlab.com/ee/ci/ssh_keys/https://wangjunming.com/Shi%20Yong%20gitlab%20CI%20CDJiang%20Cheng%20Xu%20Bu%20Shu%20Dao%20Yuan%20Cheng%20Fu%20Wu%20Qi.htmlhttps://zhuanlan.zhihu.com/p/51163261https://blog.51cto.com/11750513/2422946https://laogen.site/gitlab-ci/example-docker-ssh-deploy/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"gitlab-runner","slug":"gitlab-runner","permalink":"http://yoursite.com/tags/gitlab-runner/"},{"name":"CI/CD","slug":"CI-CD","permalink":"http://yoursite.com/tags/CI-CD/"}]},{"title":"搭配InfluxDB+CADvisor+Grafana组合监控Docker","slug":"搭配InfluxDB-CADvisor-Grafana组合监控Docker","date":"2019-08-22T07:29:24.000Z","updated":"2019-08-27T05:49:32.000Z","comments":true,"path":"2019/08/22/搭配InfluxDB-CADvisor-Grafana组合监控Docker/","link":"","permalink":"http://yoursite.com/2019/08/22/搭配InfluxDB-CADvisor-Grafana组合监控Docker/","excerpt":"","text":"环境说明InfluxDB和Grafana装在一起，IP是172.31.0.77，阿里云CENTOS 7。CADvisor装在172.16.0.195，同样是阿里云CENTOS 7。 思路就是CADvisor采集虚机里docker的指标，然后将值存入到InfluxDB，然后Grafana从InfluxDB取值展示。 部署influxDBinfluxDB如果用docker启动非常简单，语句如下： 1docker run -d -p 8083:8083 -p 8086:8086 --expose 8090 --expose 8099 --name influxsrv influxdb #使用官方镜像启动 启动之后，进入容器里，使用./usr/bin/influx -version查看当前版本是InfluxDB shell version: 1.7.7。 influxdb在1.1版本之后取消了web控制台，如果你还想使用web控制台的话，那就不要选择官方镜像，使用tutum/influxdb镜像，它是1.0版本的。 然后在命令框中创建数据库和用户： 123456789101112131415root@98d72bffb8cd:/usr/bin# ./influxConnected to http://localhost:8086 version 1.7.7InfluxDB shell version: 1.7.7&gt; show databases;name: databasesname----_internalCREATE DATABASE \"dockerdata\" #创建databasesCREATE USER monitor WITH PASSWORD '123456@qwe' #这里创建账户monitor和密码GRANT ALL PRIVILEGES ON \"dockerdata\" TO \"monitor\" #用户授权GRANT WRITE ON \"dockerdata\" TO \"monitor\"GRANT READ ON \"dockerdata\" TO \"monitor\" #授予读写权限DROP USER monitor #如果想删除用户，就用这个EXIT influxDB的语句比较讲究双引号和单引号，这一点跟mysql还是有点不同的，更多注册信息可以去看https://docs.influxdata.com/influxdb/v1.7/administration/authentication_and_authorization/ ，这里先暂时告于段落。 部署CADvisor首先先确定机器是否与InfluxDB的8086端口相通，确定之后，猫头鹰的部署语句如下： 1docker run -d --name=cadvisor -v /:/rootfs:ro -v /sys:/sys:ro -v /var/run:/var/run:rw -v /var/lib/docker/:/var/lib/docker:ro -p 8080:8080 google/cadvisor:latest -storage_driver=influxdb -storage_driver_db=dockerdata -storage_driver_host=172.31.0.77:8086 然后浏览器输入IP：8080就能打开猫头鹰的界面了，可以查看CADvisor搜集到当前服务器里所有docker。 点击对应的docker名称，就能看到详细监控信息。在docker run里我们设定了influxdb的数据库，到时候会把这些信息都保存到influxdb里的。 CADvisor采集的数据还是比较基本，具体信息如下： 部署Grafana部署gafana的语句如下： 1docker run -d --name grafana -p 3000:3000 -e INFLUXDB_HOST=localhost -e INFLUXDB_PORT=8086 -e INFLUXDB_NAME=dockerdata --link influxsrv:infx grafana/grafana 浏览器输入IP:3030登录grafana，默认账号密码是admin:admin，然后系统会通知我们先更改掉这个默认密码，于是换成新的。 点击add data source选择influxdb进行配置，如图： 然后点击save &amp; test，去dashboard里可以创建图表查看了！如图： 这个图看到并不连贯，可能是cadvisor采集的时候是有时间间隔的，于是我们需要将Min time interval改成1m，就会是一个流畅的曲线了。再把cadvisor里的其他有用信息都做成图表，如图： 需要注意的是，有可能select的数据，没能按照我们所预期的样子来进行展示，这个时候要考虑下，数据源内的数据是不是适合你选择的DashBoard类型，其他也就没什么问题了。 最后就是添加监控，我偷个懒把监控方式选择钉钉，验证一下监控OK！ 参考资料《容器云运维实战》 P268https://www.cnblogs.com/LUA123/p/9507029.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"监控","slug":"监控","permalink":"http://yoursite.com/tags/监控/"},{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"grafana","slug":"grafana","permalink":"http://yoursite.com/tags/grafana/"}]},{"title":"Gitlab搭配Gitlab-runner实现流水线自动化部署","slug":"Gitlab搭配Gitlab-runner实现流水自动化部署","date":"2019-08-21T13:06:35.000Z","updated":"2019-08-28T13:42:56.000Z","comments":true,"path":"2019/08/21/Gitlab搭配Gitlab-runner实现流水自动化部署/","link":"","permalink":"http://yoursite.com/2019/08/21/Gitlab搭配Gitlab-runner实现流水自动化部署/","excerpt":"","text":"最近跟开发研究给新业务搞一套完整的CI/CD流程，据说drone很猛，在github上势头很高。不过缺点也很明显：文档不全+错误提示不到位，于是还是选择了Gitlab，这次不同于以往的Gitlab+jenkins，而是采用了Gitlab+runner。 名词解释，我这里就不多说了，可以去看https://segmentfault.com/a/1190000007180257 ，讲解的很全。 环境介绍：阿里云Centos7 + Docker + Gitlab,gitlab里准备了一个测试用的project。 配置gitlab-runner很多地方都说gitlab-runner是一个比较吃内存的进程，而且处于安全角度考虑都很不推荐它跟gitlab装在一起，不过本文是展示测试而已，我手头也没有其他的服务器了，于是就先装在同一台服务器上。 用容器装gitlab-runner很简单，语句如下： 1234docker run -d --name gitlab-runner --restart always \\ -v /srv/gitlab-runner/config:/etc/gitlab-runner \\ -v /var/run/docker.sock:/var/run/docker.sock \\ gitlab/gitlab-runner:latest 如果你想玩骚的，可以通过一个存储卷容器来保存gitlab-runner的数据，语句如下： 123456789docker run -d --name gitlab-runner-config \\ -v /etc/gitlab-runner \\ busybox:latest \\ /bin/truedocker run -d --name gitlab-runner --restart always \\ -v /var/run/docker.sock:/var/run/docker.sock \\ --volumes-from gitlab-runner-config \\ gitlab/gitlab-runner:latest 此时docker ps -a情况如下: 来到gitlab的WEB页面，进入测试用的project，然后左侧栏里选择settings—-CI/CD—点击runner，就会看到配置的相关信息，如图： 保持这个界面不要动，我们返回命令行进入gitlab-runner容器里，需要把runner注册到我们的gitlab上，执行命令gitlab-runner register，然后就是如下交互对话： 12345678910111213141516root@4512a92c8cb2:/# gitlab-runner registerRuntime platform arch=amd64 os=linux pid=26 revision=de7731dd version=12.1.0Running in system-mode. Please enter the gitlab-ci coordinator URL (e.g. https://gitlab.com/): #这里输入gitlab的域名，如果不是域名就http://IP的形式http://GITLAB的IPPlease enter the gitlab-ci token for this runner:刚刚页面里的tokenPlease enter the gitlab-ci description for this runner: #这里写一个注释[4512a92c8cb2]: testPlease enter the gitlab-ci tags for this runner (comma separated):my-tag #打一个标签，注意这个标签不能乱写，下面会细说Registering runner... succeeded runner=fvyoASC8Please enter the executor: docker, parallels, virtualbox, kubernetes, custom, shell, ssh, docker+machine, docker-ssh+machine, docker-ssh:shell #选择执行方式，我写了shell，如果你写的是docker，那么会让你填写一个镜像地址，然后默认就会去拉这个镜像地址Runner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded! 返回gitlab的web页面刷新一下，就看到刚刚填写的runner已经成功注册上了，如图： 可以看到注释和tag，如果点击小锁头旁边的编辑按钮，就可以编辑刚才命令行里的配置，所以tag啥的写错了请放心。 如果说想要看到runner的一个概览，那么就点击gitlab上的小扳手，然后overview–runners即可，如图： 至此gitlab-runner已经配置完成！ 搭配GItLab CI要想在合并请求或者push的时候出发CI流水线，那么就在项目仓库的根目录添加.gitlab-ci.yml文件，for instance: 1234567891011121314151617181920212223242526272829303132333435363738394041stages: - test - build - deploy# 增加名为test-check的任务test-check: stage: test tags: # 指定使用有 my-tag 标签的runner运行该任务 - my-tag # 开始运行之前的操作 before_script: - echo 'runner begin...' script: - hostname &amp;&amp; date - whoami allow_failure: true #job失败了，pipline将会置绿或者置成功显示，可以继续往下走，但是commit页面或者job页面看到一条“CI build passed with warnings”的警告信息test-check2: stage: test tags: - my-tag2 script: - echo \"嘎嘎\" - echo \"哈哈哈哈哈\" - echo \"--------job2----------\" after_script: - echo \"FINISH!\"test-deploy: stage: deploy tags: - deploy environment: #这个环境设定主要是回滚的时候用得到 name: chentest url: https://test.example.com script: - echo \"部署啦！！\" - echo \"啦啦啦啦！\" - echo \"--------job3----------\" - echo \"finish\" &gt;&gt; /tmp/test.txt 然后触发一下git push，就会在gitlab的页面里看到commit:passed的绿色小勾，如图： 点击这个绿色小勾就能看到status下面的状态是passed，然后可以在pipiline里看到具体的流水线情况： 然后点击对应的job，就能看到了执行的详情，如图： 可以看到整个过程是在gitlab-runner这个容器里操作的，如果失败了也可以在这里查看具体的原因。注意！.gitlab-ci.yml的任何对文件操作都是在gitlab-runner这个容器内部进行的，而不是它所在的宿主机！也就是说在上面例子里job3最后的/tmp/test.txt是容器里的而不是宿主机的。 还有一个地方要注意，stage判断结果成功与否的标志是最后一个命令是否返回非零结果($?)，也就是说你的script内容是执行一个shell脚本，假如这个shell脚本中间有某些命令执行失败，但最后一个命令执行成功，stage最终结果也会是成功的。所以推荐shell命令行后面都加上|| { exit 1; }，这样可以避免坑。 .gitlab-ci.yml的语法非常丰富，详情可见官方文档https://docs.gitlab.com/ce/ci/yaml/README.html 或者是https://segmentfault.com/a/1190000010442764 ，已经总结的非常全面了。 高阶玩法上面只是gitlab-runner搭配cli的一个小小demo而已。在现实工作中，我们会创建很多个runner，然后给不同的runner分配各自的tag:编译、测试、打包和发布，然后在配合.gitlab-ci.yml文件操作。 如果想要jobs并发，先进入gitlab-runner容器里，将/etc/gitlab-runner/config.toml文件里的concurrent = 1酌情调大，重启容器生效。 如果说不想push都触发所有的jobs，而想要某个jobs在merge的时候才执行，可以在.gitlab-ci.yml里对应的job段落改成如下的格式： 1234567891011stage: buildscript: - xxxxxartifacts: paths: - xxxxxtags: - xxxxonly: #only后面可以跟分支或者标签 - /^issue-.*$/ # 该job将会只在issue-开头的refs下执行 - merge_requests # 只有merge才会触发！ 如果在触发流水线执行job的时候被提示：job is stuck check runners，那么请检查一下gitlab-ci.yml里是不是没有写明tag。 除了上面push/merge人为触发之外，gitlab还支持定时触发流水线作业。可以在web界面里的CI/CD—Schedules看到，如图： 参考资料https://triplecc.github.io/2018/06/23/2018-06-23-ji-gitlabcide-ci-shi-jian/http://jiangbai333.github.io/2018/10/30/gitlab-runner%E5%AE%89%E8%A3%85%E4%B8%8E%E4%BD%BF%E7%94%A8/http://walterinsh.github.io/2016/04/18/using-gitlab-ci.htmlhttps://www.chenshaowen.com/blog/gitlab-ci-configuring-runner.htmlhttps://zhuanlan.zhihu.com/p/33633217https://segmentfault.com/a/1190000011890710","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"自动化部署","slug":"自动化部署","permalink":"http://yoursite.com/tags/自动化部署/"},{"name":"gitlab","slug":"gitlab","permalink":"http://yoursite.com/tags/gitlab/"},{"name":"ci/cd","slug":"ci-cd","permalink":"http://yoursite.com/tags/ci-cd/"}]},{"title":"Nginx的allow、deny配置负载均衡真实IP的方法","slug":"Nginx的allow、deny配置负载均衡真实IP的方法","date":"2019-08-19T07:53:51.000Z","updated":"2019-08-26T05:56:12.000Z","comments":true,"path":"2019/08/19/Nginx的allow、deny配置负载均衡真实IP的方法/","link":"","permalink":"http://yoursite.com/2019/08/19/Nginx的allow、deny配置负载均衡真实IP的方法/","excerpt":"","text":"先说一下故事背景：nginx前端有一个阿里云SLB，然后外界从443进入SLB，SLB将流量转到nginx的80端口，同时80做了一个反向代理到同机器的8082端口服务。8082服务的配置文件如下： 但是这样的配置发现了一个问题：虽然已经allow 127.0.0.1，但是在浏览器里还是能正常打开/status界面，如图： 原因是deny和allow后面跟着的IP都是$remote_addr，而我这个环境里后端8082的服务，看到的$remote_addr就是127.0.0.1，所以才会出现这样子。那么如何解决呢？ 一般来说遇到这种有代理的情况，我们都是用http_x_forwarded_for来获取后端的真实IP，但是如何让deny和allow去搭配http_x_forwarded_for呢？用real_ip_header。 首先先nginx -V查看一下是否有--with-http_realip_module的模块，如果没有，那么需要重新编译nginx，如下： 12./configure --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-http_ssl_module --with-http_realip_module --with-http_addition_module --with-http_sub_module --with-http_dav_module --with-http_flv_module --with-http_mp4_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_random_index_module --with-http_secure_link_module --with-http_stub_status_module --with-http_auth_request_module --with-threads --with-stream --with-stream_ssl_module --with-mail --with-mail_ssl_module --with-file-aio --with-ipv6 --with-http_spdy_module --with-cc-opt='-O2 -g'make &amp;&amp; make install 然后将上面文件的status|ping那段location改成如下： 1234567891011location ~ ^/(status|ping)$ &#123; real_ip_header X-Forwarded-For; set_real_ip_from 0.0.0.0/0; real_ip_recursive on; allow 准许访问的IP地址1; allow 准许访问的IP地址2; allow 准许访问的IP地址3; deny all; fastcgi_pass 127.0.0.1:9000; include fastcgi.conf;&#125; 解释一下语法： real_ip_header X-Forwarded-For表示从哪个header头检索出要的IP地址； set_real_ip_from真实服务器上一级代理的IP地址或者IP段，不过经过我的反复试验，发现这个代理地址无法确定。不过我胆子大，写了0.0.0.0/0，这代表所有转发的IP都会被承认； real_ip_recursive的用途：递归的去除所配置中的可信IP，排除set_real_ip_from里面出现的IP。如果出现了未出现这些IP段的IP，那么这个IP将被认为是用户的IP； 重启nginx之后，就OK了。 不过问题还是有两个： http_x_forwarded_for是可以伪造的，因为这个值是通过获取HTTP头的X_FORWARDED_FOR属性取得，那有没有比它更准确的方法？ set_real_ip_from后面填写的IP究竟是不是http_x_forwarded_for多个IP后面的值？ https://blog.51cto.com/wks97/2084302","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"负载均衡","slug":"负载均衡","permalink":"http://yoursite.com/tags/负载均衡/"}]},{"title":"使用Shell做一个跳板机菜单","slug":"使用shell做一个跳板机菜单","date":"2019-08-06T13:12:19.000Z","updated":"2019-08-08T03:34:24.000Z","comments":true,"path":"2019/08/06/使用shell做一个跳板机菜单/","link":"","permalink":"http://yoursite.com/2019/08/06/使用shell做一个跳板机菜单/","excerpt":"","text":"跳板机虽然可以无密码登录，但是IP毕竟不好记，之前的方法就是在xshell做快速命令，可是后来IP越来越多，xshell界面弄得不太够用。于是就抽个空，做了一个ssh连接菜单，选择题总比填空题好嘛！ 执行效果如下： 脚本正文shell脚本如下： 12345678910111213141516171819202122232425262728#!/bin/bashclear#options=(\"Option 1\" \"Option 2\" \"Option 3\" \"Quit\")#select opt in \"$&#123;options[@]&#125;\"#quickssh是菜单文件，格式如下===&gt;ip:端口(用途)，比如：172.31.0.66:22(ec1)#若有新增服务器，直接添加/root/quickssh文件即可HOSTS=$(cat /root/quickssh|sort) #读取菜单NUM=$(cat /root/quickssh|wc -l)SSH=\"ssh -A -o ConnectTimeOut=5 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null\"user=rootusual_port=34872select line in $HOSTS ; do if [ $REPLY -le $NUM ] then echo \"$line 准备连接...\" ip=$(echo $line |cut -d ':' -f 1) unusual_port=$(echo $line | awk '&#123;split($0,a,\"[:(]\");print a[2]&#125;') port=$&#123;unusual_port:-$usual_port&#125; echo ip是：$ip echo port是: $port $SSH -p $port \"$user@$ip\" xit 0 else echo \"请输入一个正确的序号：\" fidone 这里使用了$(a:-b)给变量预赋值：若a为空或者null，则得到的是b。但是要注意这里面的a如果是变量的话，前面是不能加$的，会爆格式错误。把执行脚本命令做成alias写进~/.bashrc里，再source ~/.bashrc，以后就快速调用，更加方便。 这个脚本还有可以改进的地方，就是不只是输入序号，还可以通过输入服务器名称快速找到目标服务器，这样达到更高效！ 不过如果服务器过多，还是推荐用mysql来记录。 参考资料https://liam.page/2016/11/08/Shell-variable-reference-and-string-cut-off/https://blog.csdn.net/x1269778817/article/details/46535729","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"ssh","slug":"ssh","permalink":"http://yoursite.com/tags/ssh/"},{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}]},{"title":"Ansible-playbook批量更改sudoers文件里的NOPASSWD:ALL","slug":"Ansible-playbook批量更改sudoers文件里的NOPASSWD-ALL","date":"2019-08-02T02:29:39.000Z","updated":"2019-09-12T09:17:34.000Z","comments":true,"path":"2019/08/02/Ansible-playbook批量更改sudoers文件里的NOPASSWD-ALL/","link":"","permalink":"http://yoursite.com/2019/08/02/Ansible-playbook批量更改sudoers文件里的NOPASSWD-ALL/","excerpt":"","text":"由于我们有海外业务，于是就要接受GDPR检查，在检查里有一项就是要求不可以在/etc/sudoers文件里配置普通用户 ALL=(root) NOPASSWD:ALL这一项，要根据实际需要缩小范围，于是就要用ansible-playbook去批量修改这个问题。 获取AWS的外网IPAWS的EC2控制台跟阿里云不一样，不提供一个类似excel表格来获取当前区域内所有云服务器的资料。于是只能通过API获取，不过好在AWS的python SDK比较简单。 首先先pip install boto3和pip install awscli。然后再命令行执行aws configure，分别输入自己的AK、SK以及其他资料如下： 1234AWS Access Key ID [None]: 你的AKAWS Secret Access Key [None]: 你的SKDefault region name [None]: 对应区域 详情可见：https://docs.aws.amazon.com/general/latest/gr/rande.htmlDefault output format [None]: json #建议选择json 然后就会在/root/.aws（普通用户就会在/homt/用户名/）下看到config和credentials，这里面就是你刚刚输入的内容。 获取所有running状态的ec2的内网IP地址的脚本如下： 123456789101112131415import boto3def main(): ec2 = boto3.resource('ec2') instances = ec2.instances.filter( Filters=[&#123;'Name': 'instance-state-name', 'Values': ['running']&#125;] ) for instance in instances: print(instance.private_ip_address) # 获取内网IP地址 print(instance.public_ip_address) # 获取公网IP地址 print(instance.tags) #服务器名称if __name__ == '__main__': main() 简单的一匹。 编写play-book获取到了该区域所有的服务器内网IP之后，先在vim状态下使用:g/^172./d，把老网段的服务器(172开头)的IP过滤掉。然后编写playbook，如下： 12345678910111213141516171819202122232425- hosts: all #默认执行hosts里的所有IP remote_user: root any_errors_fatal: no gather_facts: no #不采集对方机器的数据，提高执行速度 serial: - 5 #5台机器一组 tasks: - name: judge NOPASSWD:ALL shell: grep \"zabbix ALL=(root) NOPASSWD\" /etc/sudoers ignore_errors: True register: result - name: change lineinfile: dest: /etc/sudoers state: present regexp: '^zabbix ' line: 'zabbix ALL=(root) NOPASSWD: /usr/bin/python' when: result.stdout.find(\"NOPASSWD:ALL\") != -1 - name: del lineinfile: dest: /etc/sudoers state: absent regexp: 'NOPASSWD:ALL$' # 将所有NOPASSWD:ALL结尾的字段删除 这里有一点要注意，如果使用shell去用sed -i写的话，那么面临一个很尬的境地：ansible-playbook对冒号空格的搭配默认会识别成key:value的形式。 比如说，在shell里使用sed -i &#39;s/NOPASSWD:ALL/NOPASSWD: \\/usr\\/bin\\/python/g&#39; /etc/sudoers是OK的，但是在shell就会爆格式错误，然后执意要走shell的话，就会可能掉入嵌套地狱… 如果想要在文件后追加多行ansible里的lineinfile模块是常见的修改文件内容的模块，但是如果要在文件末尾追加多行内容，一般人可能会想到使用with_items搭配lineinfile做循环。其实在ansible 2+的版本有一个更加优雅的方法：blockinfile，写法如下： 123456789tasks: - name: addApollo blockinfile: | dest=/tmp/chenprofile #目标文件 backup=yes content=\"export public_cloud_config_host=apollo.imou.com export public_cloud_config_port=28080 export public_cloud_config_group=default export public_cloud_config_namespace=imou.commonsource.mysql,imou.commonsource.cs,imou.commonsource.redis,imou.commonsource.mq,imou.commonsource.lb,imou.saascommonconfig,imou.originalcommonconfig,application\" 然后去对应的文件就能看到结果，但是要注意，这里使用等号，而不是冒号，用冒号会报错，可能是ansible的一个小bug。 补充 如果发现本机已经安装了awscli，但是爆错aws: command not found，检查一下python的virtualenv环境是否正确； 如果目标机器不在默认的inventory文件里被设置，可以通过加逗号的方式被ansible识别，比如ansible all -i 172.16.1.7, -m ping； 如果playbook想指定其他inventory文件，使用-i参数；","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://yoursite.com/tags/ansible/"},{"name":"AWS","slug":"AWS","permalink":"http://yoursite.com/tags/AWS/"}]},{"title":"Python3从jenkins爬取连接并且上传到文件服务器的脚本","slug":"Python3从jenkins爬取连接并且上传到文件服务器的脚本","date":"2019-07-31T02:24:58.000Z","updated":"2019-07-31T06:53:46.000Z","comments":true,"path":"2019/07/31/Python3从jenkins爬取连接并且上传到文件服务器的脚本/","link":"","permalink":"http://yoursite.com/2019/07/31/Python3从jenkins爬取连接并且上传到文件服务器的脚本/","excerpt":"","text":"以前部署的流程是这样的：开发给运维一个jenkins地址，运维在桌面打开jenkins页面下载zip包，然后Xftp传递到nfs共享挂载盘里。不过我们现在开发都把模块的名字取得特别长而且易混（天才一般的取名方式），最重要的是遇到大型上线，jenkins里会有N多个zip包，如图： 这样一个一个点下来，连点十多下然后再上传的行为不仅蠢还很容易遗漏，于是就写一个脚本来解决这个问题，实现“一键传包”。脚本如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112# !/usr/bin/env python # -*- coding:utf-8 -*-# 作者：ChrisChan# 用途：爬取jenkins网页的所有的zip连接，下载完毕之后上传到文件服务器里，脚本需要安装paramiko,tqdm和BeautifulSoupimport osimport reimport requestsfrom bs4 import BeautifulSoupfrom tqdm import tqdmimport paramikoimport datetimezip_url = []zip_name = []folder_path = r'F:/Jenkins/'if os.path.exists(folder_path) == False: # 判断文件夹是否已经存在 os.makedirs(folder_path) # 创建文件夹 print(\"jenkins文件夹已经创建完毕！\")BASE_URL = input(\"请输入jenkins网址：\") # 由于input输入http地址自带超链接，回车就直接弹开网页，所以url末尾是以 空格 结束if BASE_URL.endswith('/ '): url = str.rstrip(BASE_URL) + \"artifact/artifacts/Modules/\" # 去掉末尾空格else: url = str.rstrip(BASE_URL) + \"/artifact/artifacts/Modules/\" # 补全print(\"准备去\",url,\"里下载所有的zip文件\")# 爬取页面所有的zip地址page = requests.get(url).textpagesoup = BeautifulSoup(page,'lxml')for link in pagesoup.find_all(name='a',attrs=&#123;\"href\":re.compile(r'.zip$')&#125;): # 获取所有zip结尾的，如果是开头就是^ zipname = link.get('href') zip_url.append(url + zipname) zip_name.append(zipname)#print(zip_url) # 得到完整的zip包下载链接zip_dict = dict(zip(zip_name, zip_url)) #把下载包名和链接做成字典if (\"./*zip*/Modules.zip\") in zip_dict.keys(): # 判断字典里是否存在这个元素 zip_dict.pop(\"./*zip*/Modules.zip\") print(\"该页面有 %s 个zip文件：\" % len(zip_dict))else: print(\"该页面有 %s 个zip文件：\" % len(zip_dict))# 下载文件def downloadFile(name,file_url): resp = requests.get(url=file_url, stream=True) content_size = int(resp.headers['Content-Length']) / 1024 with open(folder_path+name, \"wb\") as f: print(\"安装包整个大小是：\", content_size, 'k，开始下载...') for data in tqdm(iterable=resp.iter_content(1024), total=content_size, unit='k', desc=name): #使用tqdm做了一个进度条 try: f.write(data) except Exception as e: print(repr(e)) print('\\r\\n' + name + \"已经下载完毕！\")# 上传到share盘def uploadFile(_localDir, _remoteDir): _localDir = folder_path _remoteDir = remote_path try: t = paramiko.Transport((hostIP, port)) # 这里一定是双括号！ t.connect(username=username, password=password) sftp = paramiko.SFTPClient.from_transport(t) print('现在开始上传文件到/share/bag %s ' % datetime.datetime.now()) for root, dirs, files in os.walk(_localDir): # 相对与_localDir的路径 remoteRoot = root.replace(\"\\\\\", \"/\") # 文件名，不包括路径 for filespath in files: local_file = os.path.join(root, filespath) remote_file = remote_path + \"/\" + filespath remote_file = remote_file.replace(\"//\", \"/\") try: sftp.put(local_file, remote_file) except Exception as e: sftp.mkdir(os.path.split(remote_file)[0]) sftp.put(local_file, remote_file) print(\"%s 上传成功！远程地址是 %s \" % (local_file, remote_file)) for name in dirs: remoteDir = _remoteDir + \"/\" + remoteRoot + \"/\" + name remoteDir = remoteDir.replace(\"//\", \"/\") print(\"remoteDir \", remoteDir) try: sftp.mkdir(remoteDir) print(\"mkdir path %s\" % remoteDir) except Exception as e: pass print('文件已经全部上传完毕！ %s ' % datetime.datetime.now()) t.close() except Exception as e: print(e)if __name__ == '__main__': for item in zip_dict: if item: downloadFile(item, zip_dict[item]) else: print(\"文件不存在，无法下载！\") hostIP = \"文件服务器的外网IP\" port = 目标端口 username = \"连接账号\" password = \"连接密码\" remote_path = \"远程路径\" # 这里注意文件夹权限 uploadFile(folder_path, remote_path) 执行效果如下： 脚本可以改进的几个地方： 使用多进程，提高下载和上传效率； 不使用服务器，而是本地将文件上传到云存储，然后在部署的时候，模块服务器通过内网下载对应的zip包或者在dockerfile里就可以直接ADD 云存储路径； 服务器或者是oss信息，单独保存在配置文件里，然后使用configparser方法读取出来；","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python3","slug":"python3","permalink":"http://yoursite.com/tags/python3/"},{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"}]},{"title":"使用Rancher搭配Harbor部署Kafka集群","slug":"使用Rancher搭配Harbor部署Kafka","date":"2019-07-25T08:20:19.000Z","updated":"2019-08-14T03:32:12.000Z","comments":true,"path":"2019/07/25/使用Rancher搭配Harbor部署Kafka/","link":"","permalink":"http://yoursite.com/2019/07/25/使用Rancher搭配Harbor部署Kafka/","excerpt":"","text":"准备工作Kafka是没有一个官方的镜像的，但是有一个star比较高的个人镜像，是wurstmeister/kafka，更新的也比较频繁，所以我们就选择这个镜像：docker pull wurstmeister/kafka。而kafka启动依赖zookeeper，于是我们还需要docker pull digitalwonderland/zookeeper，然后把他俩都上传到自建的harbor仓库里。 在部署的时候，rancher会去harbor里拉取镜像，但是harbor的私有仓是需要账号密码鉴权的，于是我们就要在rancher的界面点击集群—&gt;执行kubectl命令行，然后输入对应的内容： 其中secret-name：secret的名称，namespace：命名空间，docker-server：Harbor仓库地址，docker-username：Harbor仓库登录账号，docker-password：Harbor仓库登录密码，docker-email：邮件地址。 执行之后，三个worker就应该可以登录到harbor仓库里了。 部署zookeeper现在我们开始部署zookeeper，首先来到项目/命名空间，在Default这个项目里新建一个命名空间，比如叫shop。 然后点击集群的下拉菜单，选择default: 点击部署服务，填写一些基本资料： 然后点击启动，就完事了！但是不要高兴太久，发现pod有错误，是处于Unavailable的状态： 来到worker里，kubectl get pods --namespace=shop查看一下这几个pod的状态： 竟然是ImagePullBackOff？那么除了网络问题外，就是：镜像tag不正确、镜像不存在（或者是在另一个仓库）、Kubernetes没有权限去拉那个镜像。使用kubectl describe pod 对应pod名 --namespace=shop查看细节，果然被拒绝了： 后来发现犯了两个错误，第一我把secret的namespace写到了default这个namespace里，结果部署是在shop这个namespace里；第二使用kubectl get secret secret-name -o yaml以及echo &quot;秘钥&quot; | base64 --decode发现，我的harbor IP写错了，在secret里写的是内网IP，结果在部署的时候，镜像填写的是外网IP，更改过来之后，就OK了！ 如果习惯使用yaml的方式去部署的话，可以直接在工作负载的地方点击导入yaml： 然后复制进如下的yaml: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495kind: DeploymentapiVersion: extensions/v1beta1metadata: name: zookeeper-deployment-1spec: replicas: 1 selector: matchLabels: app: zookeeper-1 name: zookeeper-1 template: metadata: labels: app: zookeeper-1 name: zookeeper-1 spec: containers: - name: zoo1 image: digitalwonderland/zookeeper imagePullPolicy: IfNotPresent ports: - containerPort: 2181 env: - name: ZOOKEEPER_ID value: &quot;1&quot; - name: ZOOKEEPER_SERVER_1 value: zoo1 - name: ZOOKEEPER_SERVER_2 value: zoo2 - name: ZOOKEEPER_SERVER_3 value: zoo3---kind: DeploymentapiVersion: extensions/v1beta1metadata: name: zookeeper-deployment-2spec: replicas: 1 selector: matchLabels: app: zookeeper-2 name: zookeeper-2 template: metadata: labels: app: zookeeper-2 name: zookeeper-2 spec: containers: - name: zoo2 image: digitalwonderland/zookeeper imagePullPolicy: IfNotPresent ports: - containerPort: 2181 env: - name: ZOOKEEPER_ID value: &quot;2&quot; - name: ZOOKEEPER_SERVER_1 value: zoo1 - name: ZOOKEEPER_SERVER_2 value: zoo2 - name: ZOOKEEPER_SERVER_3 value: zoo3---kind: DeploymentapiVersion: extensions/v1beta1metadata: name: zookeeper-deployment-3spec: replicas: 1 selector: matchLabels: app: zookeeper-3 name: zookeeper-3 template: metadata: labels: app: zookeeper-3 name: zookeeper-3 spec: containers: - name: zoo3 image: digitalwonderland/zookeeper imagePullPolicy: IfNotPresent ports: - containerPort: 2181 env: - name: ZOOKEEPER_ID value: &quot;3&quot; - name: ZOOKEEPER_SERVER_1 value: zoo1 - name: ZOOKEEPER_SERVER_2 value: zoo2 - name: ZOOKEEPER_SERVER_3 value: zoo3 点击提交之后，上面三个deployment就生成了，去任意的一台worker服务器里使用for i in pod的名称后缀; do kubectl exec zookeeper-$i --namespace=shop /bin/bash /opt/zookeeper/bin/zkServer.sh status ; done获得结果如下： zk的角色都已经分配好了，至此zookeeper集群搭建完毕！ 部署kafka还是在这个集群里，点击上面菜单栏的服务发现，再点击旁边的导入yaml，复制粘贴如下的yaml内容： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950apiVersion: v1kind: Servicemetadata: name: kafka-service-1 labels: app: kafka-service-1spec: type: NodePort ports: - port: 9092 name: kafka-service-1 targetPort: 9092 nodePort: 30901 protocol: TCP selector: app: kafka-service-1---apiVersion: v1kind: Servicemetadata: name: kafka-service-2 labels: app: kafka-service-2spec: type: NodePort ports: - port: 9092 name: kafka-service-2 targetPort: 9092 nodePort: 30902 protocol: TCP selector: app: kafka-service-2---apiVersion: v1kind: Servicemetadata: name: kafka-service-3 labels: app: kafka-service-3spec: type: NodePort ports: - port: 9092 name: kafka-service-3 targetPort: 9092 nodePort: 30903 protocol: TCP selector: app: kafka-service-3 然后再返回工作负载里，同样进入导入yaml，输入如下yaml: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394kind: DeploymentapiVersion: extensions/v1beta1metadata: name: kafka-deployment-1spec: replicas: 1 selector: matchLabels: name: kafka-service-1 template: metadata: labels: name: kafka-service-1 app: kafka-service-1 spec: containers: - name: kafka-1 image: wurstmeister/kafka imagePullPolicy: IfNotPresent ports: - containerPort: 9092 env: - name: KAFKA_ADVERTISED_PORT value: \"9092\" - name: KAFKA_ADVERTISED_HOST_NAME value: [kafka-service1的clusterIP] - name: KAFKA_ZOOKEEPER_CONNECT value: zoo1:2181,zoo2:2181,zoo3:2181 - name: KAFKA_BROKER_ID value: \"1\" - name: KAFKA_CREATE_TOPICS value: mytopic:2:1---kind: DeploymentapiVersion: extensions/v1beta1metadata: name: kafka-deployment-2spec: replicas: 1 selector: matchLabels: name: kafka-service-2 template: metadata: labels: name: kafka-service-2 app: kafka-service-2 spec: containers: - name: kafka-2 image: wurstmeister/kafka imagePullPolicy: IfNotPresent ports: - containerPort: 9092 env: - name: KAFKA_ADVERTISED_PORT value: \"9092\" - name: KAFKA_ADVERTISED_HOST_NAME value: [kafka-service2的clusterIP] - name: KAFKA_ZOOKEEPER_CONNECT value: zoo1:2181,zoo2:2181,zoo3:2181 - name: KAFKA_BROKER_ID value: \"2\"---kind: DeploymentapiVersion: extensions/v1beta1metadata: name: kafka-deployment-3spec: replicas: 1 selector: matchLabels: name: kafka-service-3 template: metadata: labels: name: kafka-service-3 app: kafka-service-3 spec: containers: - name: kafka-3 image: wurstmeister/kafka imagePullPolicy: IfNotPresent ports: - containerPort: 9092 env: - name: KAFKA_ADVERTISED_PORT value: \"9092\" - name: KAFKA_ADVERTISED_HOST_NAME value: [kafka-service3的clusterIP] - name: KAFKA_ZOOKEEPER_CONNECT value: zoo1:2181,zoo2:2181,zoo3:2181 - name: KAFKA_BROKER_ID value: \"3\" 然后就会生成kafka了！我个人还是很喜欢用yaml去生成服务的。 如果发现导入yaml界面卡死了，极有可能是yaml格式有问题。点击取消修改错误再提交即可。 验证kafka部署完了还要验证的，首先来到workers里，先使用kubectl get service --all-namespaces获取kafka的CLUSTER-IP。如下： 然后再kubectl exec -it kafkapod名称 /bin/bash --namespace=shop进入到跟刚才记录IP不一样的kafka里，先cd opt/kafka/bin，然后kafka-console-producer.sh --broker-list 任意kafka的CLUSTER-IP:9092 --topic test。此时打开另一个xshell窗口，同样随机进入一个kafka的pod里，也是到opt/kafka/bin下之后，执行kafka-console-consumer.sh --bootstrap-server 另一个kafka的CLUSTER-IP:9092 --topic test --from-beginning，此时在原先窗口里输入字符，可以在第二个窗口里看到，这样就算OK了！如图： 部署kafka-manager开发又提出了需求，希望安装一个kafka的可视化插件，提高办公效率。于是我就选择了kafka-manager作为插件，yaml内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758apiVersion: v1kind: Servicemetadata: name: kafka-manager labels: app: kafka-managerspec: type: NodePort ports: - name: kafka port: 9000 targetPort: 9000 nodePort: 30900 selector: app: kafka-manager---apiVersion: apps/v1kind: Deploymentmetadata: name: kafka-manager labels: app: kafka-managerspec: replicas: 1 selector: matchLabels: app: kafka-manager template: metadata: labels: app: kafka-manager spec: containers: - name: kafka-manager image: zenko/kafka-manager:1.3.3.22 imagePullPolicy: IfNotPresent ports: - name: kafka-manager containerPort: 9000 protocol: TCP env: - name: ZK_HOSTS value: \"[zookeeper的IP]:2181\" livenessProbe: httpGet: path: /api/health port: kafka-manager readinessProbe: httpGet: path: /api/health port: kafka-manager resources: limits: cpu: 500m memory: 512Mi requests: cpu: 250m memory: 256Mi 同样在工作负载—导入yaml里粘贴上面的yaml之后，执行一下就会看到kafka-manager的deployment生成了，如图： 在阿里云SLB里配置对应的端口，然后在浏览器里就可以访问了，如图： 参考资料https://o-my-chenjian.com/2017/04/11/Deploy-Kafka-And-ZP-With-K8s/http://blog.yuandingit.com/2019/03/26/Practice-of-Business-Containerization-Transformation-(3)/https://www.cnblogs.com/00986014w/p/9561901.html （文中yaml的作者）https://k8smeetup.github.io/docs/tutorials/stateful-application/zookeeper/http://www.mydlq.club/article/29/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"http://yoursite.com/tags/k8s/"},{"name":"rancher","slug":"rancher","permalink":"http://yoursite.com/tags/rancher/"},{"name":"harbor","slug":"harbor","permalink":"http://yoursite.com/tags/harbor/"},{"name":"kafka","slug":"kafka","permalink":"http://yoursite.com/tags/kafka/"}]},{"title":"使用Rancher2.1部署k8s集群","slug":"使用Rancher2-1部署k8s","date":"2019-07-25T03:03:04.000Z","updated":"2019-09-29T07:13:44.000Z","comments":true,"path":"2019/07/25/使用Rancher2-1部署k8s/","link":"","permalink":"http://yoursite.com/2019/07/25/使用Rancher2-1部署k8s/","excerpt":"","text":"rancher是个啥？Rancher是一个开源的企业级全栈化容器部署及管理平台。简单的说，就是一个可以让你通过web界面管理docker容器的平台。定位上和K8s比较接近，都是通过web界面赋予完全的docker服务编排功能。而且它自带账户权限。相比K8s没有账号管理rancher自带账号权限体系。账号可以独立创建，也可以很方便地接入ldap等账号体系，对于公司使用是一大利器。 还有一个最牛逼的就是它有一个应用商店，并且可以做到配置自用的应用商店，部署服务，很快就能搞定！ 所以说在k8s势不可挡的今天，学习一下rancher还是很有必要的。哪怕你领导担心它搞不定线上业务，拿来给测试环境部署也好啊！具体rancher的优点和不足可以去看 https://blog.csdn.net/CSDN_duomaomao/article/details/78029800 。 安装rancher以及创建k8s集群安装rancher的方法非常简单： 12345docker run -d --restart=unless-stopped \\ --name rancher-managment \\ -p 8080:80 -p 8443:443 \\ -v /rancher/data:/var/lib/rancher \\ rancher/rancher:latest 参数--restart=unless-stopped的意思是在容器退出时总是重启容器，但是不考虑在Docker守护进程启动时就已经停止了的容器。 然后确认一下防火墙是否对外开放了8443和8080端口，打开浏览器输入IP:8443就会看到rancher的样子，自带中文版，就问你感动不感动？ 然后准备三台服务器，资料如下： 123名称：k8s-001 IP：\"172.20.52.12\" 角色：etcd+control+worker名称：k8s-002 IP：\"172.20.52.11\" 角色：worker名称：k8s-003 IP：\"172.20.52.10\" 角色：worker 以上服务器系统均为centos7，而且与rancher网络的8443和8080端口互通。为了路径相同，个人建议在rancher买一个大一点的高效云盘，然后让这三个worker都挂载这个云盘，这样的话启动容器的时候，数据都持久化保存在云盘里。 回到rancher页面，点击添加集群，选择CUSTOM，然后给集群起个名儿，如果有其他的rancher成员可以管理或者访问这个集群就编辑一下成员角色，默认情况下是安装k8s-1.11版本。然后点击下一步： 下一步很重要了，先在第一台172.20.52.12上勾选所有的角色以及输入对应IP，然后会web页面下面生成一个命令，将这个命令在172.20.52.12上执行一下，瞬间它就会尝试去注册到rancher： 如果注册不成功，web提示[etcd]Pulling image [rancher/coreos-etcd:v3.12.18] on host XXX的话，那么还要去该服务器上手动docker pull rancher/coreos-etcd:v3.12.18一下，不久之后就会看到主机被成功注册到rancher上： 点击主机，能看到一点CPU和内存的细节： 安装kuberctl使用rancher部署的k8s集群是没有自带kuberctl命令的，只能通过rancher页面的执行kubectl命令行来操作，若需要worker里使用kubectl，那就得手动安装，过程如下： 12345curl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl #国内可以正常打开，表怕chmod +x kubectlsudo mv ./kubectl /usr/local/bin/kubectlecho \"source &lt;(kubectl completion bash)\" &gt;&gt; ~/.bash_profile # 增加自动补全功能 kubectl version 此时得到的结果应该是： 如果执行的结果是： 12/usr/local/bin/kubectl: line 1: syntax error near unexpected token `&lt;'/usr/local/bin/kubectl: line 1: `&lt;?xml version='1.0' encoding='UTF-8'?&gt;&lt;Error&gt;&lt;Code&gt;NoSuchKey&lt;/Code&gt;&lt;Message&gt;The specified key does not exist.&lt;/Message&gt;&lt;Details&gt;No such object: kubernetes-release/release//bin/linux/amd64/kubectl&lt;/Details&gt;&lt;/Error&gt;' 那么很有可能是你的kubectl没有下载完全，这个文件应该是41M左右的，大于小于都不对！ 返回到rancher的集群页面，点击kubeconfig文件，将里面的内容复制到~/.kube/config里（没有就创建一个），保存退出之后，重开一个终端就能正常使用了，如图： 清理节点当你不想要一个node的时候，一定要清理干净，不然在新加node的时候就会出现：[etcd] Etcd Cluster is not healthy的错误。清理节点的方法语句如下： 1234567891011121314151617181920212223242526# 停止服务systemctl disable kubelet.servicesystemctl disable kube-scheduler.servicesystemctl disable kube-proxy.servicesystemctl disable kube-controller-manager.servicesystemctl disable kube-apiserver.service systemctl stop kubelet.servicesystemctl stop kube-scheduler.servicesystemctl stop kube-proxy.servicesystemctl stop kube-controller-manager.servicesystemctl stop kube-apiserver.service # 删除所有容器docker rm -f $(docker ps -qa) # 删除所有容器卷docker volume rm $(docker volume ls -q) # 卸载mount目录for mount in $(mount | grep tmpfs | grep '/var/lib/kubelet' | awk '&#123; print $3 &#125;') /var/lib/kubelet /var/lib/rancher; do umount $mount; done# 备份目录mv /etc/kubernetes /etc/kubernetes-bak-$(date +\"%Y%m%d%H%M\")mv /var/lib/etcd /var/lib/etcd-bak-$(date +\"%Y%m%d%H%M\")mv /var/lib/rancher /var/lib/rancher-bak-$(date +\"%Y%m%d%H%M\") node上的重要数据，已经要备份好！ 其他问题如果node是集群，那么把web的语句复制到node的命令行执行后却迟迟不见注册成功，那么可以点击高级选项，然后输入内网IP和名称，如图： 如果在node上执行kubectl version的时候报错：Unable to connect to the server: x509: certificate signed by unknown authority，原因可以看https://www.cnrancher.com/docs/rancher/v2.x/cn/configuration/admin-settings/custom-ca-root-certificate/ 。不过不知道是我姿势不对还是怎么的，我按照官方文档操作没有成功，这样可以在rancher的执行语句里添加--no-cacerts，如下： 12345docker run -d --restart=unless-stopped \\ --name rancher-managment \\ -p 8080:80 -p 8443:443 \\ -v /rancher/data:/var/lib/rancher/ \\ rancher/rancher:latest --no-cacerts 这样就可以解决了。 参考资料https://www.cnblogs.com/horizonli/p/10572834.htmlhttps://systemoutprint.github.io/kubernetes/2018/07/19/kubernetes%E9%9B%86%E7%BE%A4%E7%97%9B%E8%8B%A6%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"http://yoursite.com/tags/k8s/"},{"name":"云原生","slug":"云原生","permalink":"http://yoursite.com/tags/云原生/"},{"name":"rancher","slug":"rancher","permalink":"http://yoursite.com/tags/rancher/"}]},{"title":"在Docker里使用s6-svscan做进程守护","slug":"在Docker里使用runit监控服务状态","date":"2019-07-23T02:29:22.000Z","updated":"2019-07-23T09:21:02.000Z","comments":true,"path":"2019/07/23/在Docker里使用runit监控服务状态/","link":"","permalink":"http://yoursite.com/2019/07/23/在Docker里使用runit监控服务状态/","excerpt":"","text":"为什么要用s6容器的哲学就是“容器里最好只有一个模块”，也就是常说的容器即进程（one process per container）。但是现在这个哲学有所动摇，很多人认为容器即服务（one thing per container），毕竟总有些特殊场景我们需要在一个docker里安装多个模块。容器虽然可以在docker run的时候可以指定--restart=always，但是这个并不能对pid不为1的进程起到看门狗的作用，如果pid不为1的进程crash了，那么就不会重启而出现故障了。于是需要一个真正的看门狗来重启这个服务。可用于docker的看门狗品种有很多，详情可见 https://www.iamle.com/archives/tag/runit 这篇文章。我在那篇文章里选择了s6。虽然听说有赞在生产环境里已经用了runit，但是我搞了一天都没有搞明白runit怎么用，而且关于runit的资料都是2017年之前的，就放弃了… 首先先在/opt/service里准备两个服务，分别是app1和app2，在各自的文件家里分别创建run和finish两个文件，结构如下： 12345678910[root@func-lcshop-Harbor opt]# tree service/service/├── app1│ ├── finish│ └── run└── app2 ├── finish └── run2 directories, 4 files 这个run文件就是进程的启动文件，app1/run内容如下： 123456789101112[root@func-lcshop-Harbor app1]# cat run #!/bin/bashecho \"Started APP1 service...\"for i in &#123;1..3&#125;do echo \"这里是第一个程序！\" sleep 1doneecho \"Oh no!我嗝屁了...\" &gt;&amp;2 #3秒就死掉exit 1 而app2/run的内容如下： 123456789101112#!/bin/bashecho \"Started app2 service...\"for i in &#123;1..3000&#125; #这里懒，就直接写了3000秒do echo \"这是第二个程序！\" #这里做了区分 date sleep 1doneecho \"Oh no!我嗝屁了...\" &gt;&amp;2exit 1 我上面主要是为了模拟程序挂掉的场景，实际run脚本应该是长时间运行的。 而finish的作用主要是执行程序退出后的操作，也就是run结束后的操作。这里要注意！因为s6会自动重启run脚本，如果在finish里也写了启动run脚本，那么就会有两个run脚本运行！ app1/finish内容如下： 123#!/bin/bashecho \"app1 挂掉啦！...\"echo \"app1 restart ok!\" 然后我们准备一个dockerfile，如下： 1234FROM ubuntuADD https://github.com/just-containers/s6-overlay/releases/download/v1.21.8.0/s6-overlay-amd64.tar.gz /tmp/ #这个网站可能链接比较慢，所以推荐先下载然后COPY到容器里RUN tar xzf /tmp/s6-overlay-amd64.tar.gz -C / #解压缩到根目录下CMD [\"/bin/s6-svscan\",\"/opt/service\"] #/opt/service就是app1和app2的路径 执行docker build -t=&quot;s6:0.1&quot; .创建镜像，再使用docker run -it --name s6demo -v /opt/service:/opt/service s6:0.1启动这个s6demo的容器，在容器启动时就会发现s6会扫描/opt/service文件夹，执行对应的run脚本，当run脚本意外退出时，s6会自动重启，如图： 参考资料https://github.com/just-containers/s6-overlay#the-docker-wayhttps://sourcediver.org/blog/2014/11/17/using-runit-in-a-docker-container/https://segmentfault.com/a/1190000006644578https://it.ismy.fun/2018/03/09/runit-example/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"s6-svscan","slug":"s6-svscan","permalink":"http://yoursite.com/tags/s6-svscan/"}]},{"title":"python3监控https证书过期时间","slug":"python3监控https证书过期时间","date":"2019-07-17T11:43:40.000Z","updated":"2019-07-19T06:30:24.000Z","comments":true,"path":"2019/07/17/python3监控https证书过期时间/","link":"","permalink":"http://yoursite.com/2019/07/17/python3监控https证书过期时间/","excerpt":"","text":"上周日，我们的一个https证书到期了，结果运维没有事前检查到，导致服务中断，于是赶紧亡羊补牢一个python3的脚本： 123456789101112131415161718192021222324# !/usr/bin/env python # -*- coding:utf-8 -*-# 作者：ChrisChan# 用途：获取https证书的过期时间，需要先执行pip3 install pyopensslfrom urllib3.contrib import pyopenssl as reqsfrom datetime import datetime# 公网验证cert = reqs.OpenSSL.crypto.load_certificate(reqs.OpenSSL.crypto.FILETYPE_PEM, reqs.ssl.get_server_certificate(('cn.imoulife.com', 443)))notafter = datetime.strptime(cert.get_notAfter().decode()[0:-1], '%Y%m%d%H%M%S') #获取到的时间戳格式是ans.1的，需要转换remain_days = notafter - datetime.now() # 用证书到期时间减去当前时间print(remain_days.days)# 离线验证from OpenSSL import cryptocert_file = 'F:\\\\crt文件的路径\\\\mycert.crt'cert2 = crypto.load_certificate(crypto.FILETYPE_PEM, open(cert_file).read())cert2.get_version()subject = cert2.get_subject()subject.get_components()print(\"域名是：\",subject.CN)print(\"终止的时间戳是：\",cert2.get_notAfter()) pyopenssl可以给与我们的https信息非常的丰富，除了到期时间之外，还有如下几个常用项： get_subject()：返回证书域名 get_version()：返回证书版本 get_issuer()：证书颁发机构 更多信息可以去看 https://www.pyopenssl.org/en/stable/index.html 官网介绍。 进一步加工后的脚本是: 123456789101112131415161718192021222324252627# !/usr/bin/env python # -*- coding:utf-8 -*-import argparsefrom urllib3.contrib import pyopenssl as reqsfrom datetime import datetime# 命令行参数parser = argparse.ArgumentParser(description='本脚本获取https证书到期时间')parser.add_argument('-w', '--www', metavar='https网站,如cn.imoulife.com', required=True, dest='sites', nargs='+', help='请一定要输入监控的https网站') # required表示此字段一定需要,nargs=’+’ 表&gt;示至少一个参数args = parser.parse_args()# 公网验证def get_notafter(www): cert = reqs.OpenSSL.crypto.load_certificate(reqs.OpenSSL.crypto.FILETYPE_PEM, reqs.ssl.get_server_certificate((www, 443))) notafter = datetime.strptime(cert.get_notAfter().decode()[0:-1], '%Y%m%d%H%M%S') remain_days = notafter - datetime.now() # 用证书到期时间减去当前时间 print(www,\"证书到期天数是：\",remain_days.days)# 输出结果try: for site in args.sites: get_notafter(site)except Exception as e: print(\"出现错误，请检查域名是否正确或者可达性！\") 执行效果如下： shell脚本http://noops.me/?p=945 这个小米的运维网站分享一个非常不错的shell脚本来监控证书，脚本如下： 1234567891011121314151617181920#! /bin/sh host=$1port=$2end_date=`openssl s_client -host $host -port $port -showcerts &lt;/dev/null 2&gt;/dev/null | sed -n '/BEGIN CERTIFICATE/,/END CERT/p' | openssl x509 -text 2&gt;/dev/null | sed -n 's/ *Not After : *//p'`# openssl 检验和验证SSL证书。# &lt;/dev/null 定向标准输入，防止交互式程序Hang。从/dev/null 读时，直接读出0 。# sed -n 和p 一起使用，仅显示匹配到的部分。 //,// 区间匹配。# openssl x509 -text 解码证书信息，包含证书的有效期。 if [ -n \"$end_date\" ]then end_date_seconds=`date '+%s' --date \"$end_date\"`# date指令format字符串时间。 now_seconds=`date '+%s'` echo \"($end_date_seconds-$now_seconds)/24/3600\" | bcfi 上面那个有两个小地方可以改进下：echo “HOST: test.com /r/n GET / HTTP/1.1″|openssl s_client -connect test.com:443 这样可以增加速度，因为openssl s_client只负责链接，后面是请求内容如果不输入的话就是等待超时，时间会很长。而且增加一个参数-servername可一直开启TLS SNI support，可以检测一个ip多个证书的情况。 其他监控证书的网站如果不想用脚本监控可以用第三方网站监控，下面这三个网站方法都一样：就是填入自己的邮箱注册账户，然后在页面输入自己要监控的域名，然后会给你一个剩余时间，如果快到期了就会给你发邮件通知，这三个网站分别是： letsmonitor.org 每小时检测一次，但是发送告警邮件只有一次 certificatemonitor.org 非常简单，只能443端口，一共会发9次邮件通知 https://keychest.net/ 它支持api，邮件每周一次发送，比较好 详情可见https://www.sooele.com/2784.html 。 参考资料https://flyhigher.top/develop/755.htmlhttps://blog.skk.moe/post/checkssl-status/https://blog.csdn.net/tzdjzs/article/details/28124609https://www.conum.cn/program/python/241.html （pyopenssl的介绍）https://python3-cookbook.readthedocs.io/zh_CN/latest/c13/p03_parsing_command_line_options.html (python命令行参数)","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python3","slug":"python3","permalink":"http://yoursite.com/tags/python3/"},{"name":"https证书","slug":"https证书","permalink":"http://yoursite.com/tags/https证书/"}]},{"title":"使用centos7部署Harbor私有仓库","slug":"使用Debian9部署Harbor私有仓库","date":"2019-07-15T07:48:36.000Z","updated":"2019-08-13T06:50:08.000Z","comments":true,"path":"2019/07/15/使用Debian9部署Harbor私有仓库/","link":"","permalink":"http://yoursite.com/2019/07/15/使用Debian9部署Harbor私有仓库/","excerpt":"","text":"安装过程首先，我当你在centos7上已经装好了docker，如图： harbor官方更推荐使用docker-compose(1.18.0+)来配合安装，于是乎我们要安装一下docker-compose，如下： 12345curl -L https://github.com/docker/compose/releases/download/1.24.1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose#这一步国内的服务器可能会比较费时间chmod +x /usr/local/bin/docker-compose[root@func-lcshop-Harbor ~]# docker-compose -vdocker-compose version 1.24.1, build 4667896b 然后下载离线的harbor1.8安装包： 12wget https://storage.googleapis.com/harbor-releases/release-1.8.0/harbor-offline-installer-v1.8.2-rc1.tgztar -zxvf harbor-offline-installer-v1.8.2-rc1.tgz 进入harbor的文件夹去修改一下harbor.yml，将hostname改成服务器的外网地址，不过不想要默认的80端口，同时可以加上端口号，如下： 文件下面还有一个harbor_admin_password，这个是登录页面的初始密码。注意！密码不可以有!和@，不然命令行会报错！而且这个密码只能是第一次登陆可用，如果要改然后执行./install.sh，如下： 安装完毕了之后，看一下机器里生成了很多docker容器： 再去浏览器打开ip:端口就能看到harbor的页面，是不是超简单？ 如果想要更换端口，在修改完harbor.yml之后，执行如下才会生效： 123docker-compose down -v./preparedocker-compose up -d 修改密码？假设我们已经修改了密码，并且重启了docker-compose，此时用命令行的方式访问harbor镜像库（推荐使用--password-stdin方法而不是在命令行里直接输入密码，先创建一个/root/.harborpwd文件，里面写入harbor.yml的harbor_admin_password），使用docker login -u admin --password-stdin harbor外网IP &lt; /root/.harborpwd试试，竟然返回unauthorized: authentication required这个错误！为什么呢？因为上面说了harbor_admin_password里的密码只能第一次使用，之后改密码了是不能通过harbor.yml修改的。 那么应该如何修改密码？需要进到harbor的数据库里。现在新的harbor数据库默认是postgresql，所以那些重置mysql密码的文章可以直接略过了。 具体修改的方法如下： 1234567891011121314[root@func-lcshop-Harbor ~]# docker exec -it harbor-db /bin/bash #先登录到db容器里root [ / ]# psql -h postgresql -d postgres -U postgres #这里需要输入配置文件里db密码，默认的是root123Password for user postgres: psql (9.6.10)Type \"help\" for help.postgres=# \\c registryYou are now connected to database \"registry\" as user \"postgres\".registry=# select * from harbor_user; user_id | username | email | password | realname | comment | deleted | reset_uuid | salt | sysadmin_flag | creation_time | update_time ---------+------------+-------------------------+----------------------------------+----------------+----------------+---------+------------+----------------------------------+---------------+----------------------------+---------------------------- 2 | anonymous | anonymous@example.com | | anonymous user | anonymous user | t | | | f | 2019-07-23 14:17:32.288001 | 2019-07-23 14:17:32.288001 1 | admin | admin@example.com | a71a7d0df981a61cbb53a97ed8d78f3e | system admin | admin user | f | | ah3fdh5b7yxepalg9z45bu8zb36sszmr | t | 2019-07-23 14:17:32.288001 | 2019-07-24 04:05:31.260468(3 rows) harbor采用的加密方式叫PBKDF2，在国外挺流行的，在国内用的人还不多。如果对这个比较感兴趣的可以去看 http://phantom0301.cc/2017/02/08/harborpass/ 这个文章，里面还有一个python2的脚本来帮助生成密码。 如果想改回默认的harbor12345，就在postgresql里执行update harbor_user set password=&#39;a71a7d0df981a61cbb53a97ed8d78f3e&#39;, salt=&#39;ah3fdh5b7yxepalg9z45bu8zb36sszmr&#39; where username=&#39;admin&#39;;即可，不过我更推荐换一个新的密码，同时 update harbor_user set username=&#39;其他用户名&#39; where user_id=1;，这样把admin也给改掉。 退出harbor-db容器，再新建/etc/docker/daemon.json，里面内容如下： 123&#123;\"insecure-registries\" : [\"Harbor外网IP地址\"]&#125; 保存退出并且重启docker之后，此时就可以在命令行尝试登陆harbor了，如图： 图中的WARNING意思是密码会以一个比较简单的加密方式保存在/root/.docker/config.json里，如果你有好的习惯，每次都会logout的话，那么这个文件还是会自动删除掉这个密码的。 如果想要给harbor开启ldap，请看https://github.com/goharbor/harbor/blob/master/docs/configure_user_settings.md 。 上传镜像整个镜像上传的过程如下： 1234docker login -u admin --password-stdin harbor外网IP &lt; /root/.harborpwd #登录docker tag [ImageId] harbor外网IP/repository名/具体镜像名:版本号 #打一个tagdocker pull harbor外网IP/repository名/具体镜像名:版本 #推送docker rmi harbor外网IP/repository名/具体镜像名:版本 #这一步是删除tag repository名这个要在harbor上事前生成，不然无法push，会报错：denied: requested access to the resource is denied。上传上去的镜像会保存在/data/registry/docker/registry/v2/repositories/这个路径下，所以如果是有很多个镜像，建议/data盘买大一点。 注意！如果出现了网页可以登录但是docker login无法登录的情况，请去检查harbor.yml里的hostname与实际docker login的域名是否保持一致，https访问是否也一致。 配置https和高可用方案其实在harbor.yml下面就已经有配置https的地方，但是官方的建议是不要在Harbor上启用https，而是在将Harbor放置到一个SLB的后边，配置SLB的端口转发进行访问。或者是再装一个nginx，进行nginx的端口转发。具体配置这里就不写了。 如果想做一个HA方案的话，可以按照如下的方式构建一个（主从模式真的很不靠谱）： 负载均衡同时还要承担健康检查的任务，而Redis用于数据的缓存和消息队列的实现，MySQL存储用户信息和仓库信息，云存储用来存储Docker镜像。 配置阿里云OSS做后端存储参考资料https://youendless.com/post/docker_login_pass/https://blog.51cto.com/lzlutao/2388635https://blog.frognew.com/2017/06/install-harbor.html （这个版本已经比较老了，只能参考）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"私有仓库","slug":"私有仓库","permalink":"http://yoursite.com/tags/私有仓库/"}]},{"title":"這些年被Ainge拆毀的塞爾提克","slug":"這些年被Ainge拆毀的塞爾提克","date":"2019-07-11T13:28:58.000Z","updated":"2019-07-11T13:58:38.000Z","comments":true,"path":"2019/07/11/這些年被Ainge拆毀的塞爾提克/","link":"","permalink":"http://yoursite.com/2019/07/11/這些年被Ainge拆毀的塞爾提克/","excerpt":"","text":"原作者：老溫隨筆 2019年選秀會上塞爾提克將替補中鋒Aron Baynes打包送往太陽隊，如果加上成為自由球員且可能一去不回頭的Kyrie Irving、Al Horford、Terry Rozier，以及成為自由球員但完全沒有續約消息的Daniel Theis，塞爾提克頓時成了沒有控衛、沒有中鋒，加上本來就沒有大前鋒的詭異陣容。這支一年前還誓言爭奪總冠軍的球隊，在幾天之內就變得連自家球迷都不認識的模樣。 自從2013年7月12日總管Danny Ainge正式將Kevin Garnett、Paul Pierce與Jason Terry打包送往籃網隊交換包含數個首輪選秀權的包裹後，短短六年裡塞爾提克在Ainge不斷的交易洗資產與總教練Brad Stevens的堅持不擺爛的兩極風格下意外地兩度打入東區冠軍賽，一年前甚至僅一場之差就足以重返總冠軍賽，讓塞爾提克成為聯盟裡最炙手可熱的球隊。 但是就在短短的一年裡，塞爾提克問鼎準後勇士時期王座的希望破滅。隨著球季中一波波的脫序演出，無論是場後Irving、Marcus Morris在媒體前的狂飆或是場上直接發洩不滿的舉動，連過去十幾年來幾乎沒有異音的波士頓媒體都逐漸脫離過往照著球隊餵養訊息過日子的生態，不斷的向這些球員發出怒火。當塞爾提克在東區第二輪以近乎毫無抵抗力的方式慘敗給公鹿隊，宛如1983年的悲劇重演的情節似乎也注定了這支完全不符內外期望的塞爾提克即將面對的悲慘未來。 歷史的借鏡1983年球季結束後的第22天，原本以為自己地位依然穩固的總教練Bill Fitch意外得知一向力挺自己的老闆Harry Mangurian即將出售持股，三天後，在鬥爭中贏得勝利的總裁Red Auerbach正式重新掌握球隊，在眾叛親離下，Fitch只能黯然宣布下台。除了失去老闆Mangurian的力挺外，另一個壓垮Fitch的原因是成為自由球員的明星前鋒Kevin McHale表明不願意再替Fitch打球，而陣中除了Larry Bird以外的球員無論老少也都投下反對票。 故事的最後在老闆Mangurian用智力退試圖搶親的尼克隊讓McHale續留下獲得圓滿的結局。塞爾提克重新成為Auerbach的大家庭，孚眾望的助理教練K.C. Jones扶正成為總教練，McHale如願逼走了Fitch並重返球隊，Mangurian也成功地在八月將球隊賣給Dan Gaston。 重新站起的塞爾提克很快地在1984年東區冠軍賽裡以4：1淘汰了公鹿隊，報了一箭之仇，並在總冠軍賽裡擊敗了湖人隊拿下總冠軍。 也許，可以說當1983年Red Auerbach剷除球隊內部不安的因子Fitch後，這支球隊就獲得初步的止血，並在交易Dennis Johnson完成對湖人與公鹿部屬後重新回到正軌。 跟1983年相近的是2019年的塞爾提克也有一個最後近乎公認的麻煩人物Kyrie Irving，而球季結束後這個麻煩人物也近乎確定離隊。問題在於當你的麻煩人物是個總教練或是行政人員時，下手清除膿包並不會對球隊實力傷筋動骨，但當你的問題人物是個球員時，除非能夠以對等交易的方式進行，否則終將註定會折損球隊的實力。 而現在的塞爾提克問題更加複雜，因為Irving不僅是位球員，還是這支球隊最好的球員，也注定了這將會是一個難捱的暑假，即使，這個結果在兩年前其實就已經可以預知。 從Irving幾乎確定轉隊開始，對塞爾提克不利的消息就接踵而來。原本球團即使沒有Irving都想促成的Anthony Davis交易在經紀人Rich Paul出面喝止，湖人隊一口氣比照籃網隊加碼數個首輪選秀權下成了泡影。眼看著死敵日漸茁壯，當家中鋒Al Hoford宣布跳脫合約後因為換約談判觸礁而可能他去的消息傳出，不僅成了壓垮塞爾提克球迷希望的最後一根稻草，也意味著從2013年開始的重建畫下句點。 不要懷疑，無論是對波士頓這座體育城市，或是對塞爾提克而言，重建成功的標準只有一個：總冠軍。 有趣的是Horford離隊消息傳出後，塞爾提克向上交易第四順位、交易Bradley Beal或是Mike Conley等謠言開始大舉出籠，過去一年完全沒有動作的總裁Ainge也開始再度活躍。更在選秀會上送出了剛執行合約的Baynes，一瞬間，反手大力清除薪資的塞爾提克從原本沒有薪資空間變成了有開出頂薪的能力。 一年前還是眾人捧的塞爾提克在一年後不但牆倒眾人推，而且很有可能成為一支完全不同的球隊。 塞爾提克的東區冠軍賽魔咒如果檢視Danny Ainge的掌舵紀錄，會發現打入東區冠軍賽往往不是美好未來的起點，反而可能是旅程的終點。更可以發現當Ainge與背後的老闆們覺得球隊無法跨越高牆時做出的選擇幾乎都是整組拆掉重建，只是過去三次都是Ainge主動按下重建鈕，只有這一次是Ainge首度因為球員背離而被迫重建。 塞爾提克的未來尚在未定之天，過去一年的安定終究只是這十七年來的意外，但如果回顧過去三次的解體，除了第二回因為Garnett與Pierce逐漸衰老外，另外兩次主力都正當盛年，解體後的結果都讓球隊跌入更深的深淵，特別是剛打出生涯最佳成績的Isaiah Thomas與Jae Crowder被打包送往騎士交換Irving更是導致當前的大挫敗。 被拆毀的2002年塞爾提克只是當年Ainge接手後如何一手拆掉2002年打入東區冠軍賽的塞爾提克，已經沒有太多人記憶，如果經歷過那一段歷史，也許對現在塞爾提克的一片混亂就不會那麼意外，因為這曾經是身為塞爾提克球迷的日常。 當時塞爾提克的老闆傳承到Gaston家族的第二代Paul Gaston，跟熱愛籃球的老爸不同，Paul Gaston只是因為繼承了老爸的遺產而成為球隊的老闆，儘管球隊戰績跌落谷底，但因為NBA持續成長讓塞爾提克的價值也持續成長，於是覺得這是門好生意的Paul Gaston願意繼續經營下去。雖然Auerbach依然在球團裡擔任精神領袖的總裁一職保持門面，但Paul Gaston卻對剛退役的八零年代明星球員有諸多提防，例如一直被認為總有一天會回到波士頓承繼Auerbach衣缽的Larry Bird就始終被以顧問之名給晾在一旁，1993年就開始擔任助理教練的Dennis Johnson也始終無緣扶正。 當接掌國王的王子始終避免被有人望的王子所取代下，其他八零年代的球星如Ainge、McHale就更沒有插手機會，而先後轉戰太陽隊與灰狼隊。這層緊張關係終於在1997年塞爾提克手握兩張樂透籤，有高達19.9%的機率抽到Tim Duncan而爆開。 當規劃NBA史上第一個公然輸球拚選秀的總管M.L. Carr功成身退後，能夠指導Duncan的總管兼總教練空缺成了聯盟最搶手的工作，當時最熱門的人選除了老字號的名帥Larry Brown外，就屬Larry Bird的呼聲最高。 但最後，Paul Gaston宣布由畢業自麻州大，帶領Providence College打入NCAA四強賽，與波士頓有強烈地緣關係的Kentucky大學總教練Rick Pitino接手總教練，並明升暗降Auerbach到副董事長。雖然記者會上Pitino表示會考慮接手塞爾提克是在接到Bird的詢問電話之後，並表示希望Bird能夠考慮留在球團內協助，但此時的Bird也已經接到家鄉印第安那溜馬隊的總教練職缺探詢，只是基於禮貌不便在老東家宣布新任總教練時確定接任。 Pitino的塞爾提克總教練任期最後證明是場災難，但他帶來的首席助理教練Jim O’Brien擔任代理總教練時卻成功帶領以Antoine Walker與Paul Pierce為首的年輕球員在剩餘球季打出剛好五成勝率，第一個完整球季更寫下49勝33敗成績，不但重返季後賽並就此一路打到東區冠軍賽，距離上回Bird帶領球隊打入東冠已經間隔了十四年之久。 這個球季也是Walker成功洗白的一年。 Walker是M.L. Carr在1996年所選，隔年在大學恩師Pitino的全力支持下刷出了22.4分、10.2籃板與3.3助攻的成績，加上球隊從聯盟底部回升到36勝46敗，讓Walker成功入選了明星賽替補。只是少年得志加上教練團沒有強加約束，其實Pitino也約束不住已經在NBA混了一季，跟許多老將廝混養出一堆壞毛病的Walker。他囂張的態度惹惱了波士頓記者，不但給了他Employee #8的綽號，也成了媒體發洩不滿的稻草人，讓Walker在波士頓的名聲始終欠佳。 這局勢在O’Brien接手後開始轉變。Pitino在塞爾提克失敗最大的原因與Fitch相當接近，同為大學教練出身的兩人在球隊裡人緣極差，Pitino更刻意維持大學籃壇以總教練為首的金字塔結構，讓自己與球員之間的隔閡頗深，即使是大學子弟兵如Walker、Ron Mercer、Walter McCarty也難以直接與總教練接觸，所有的事情都靠居間扮演傳達與協調者的O’Brien傳遞，因此當O’Brien接手後很快地就讓球員團結一致的以季後賽為目標，雖然最後無緣，但O’Brien代理時帶隊打出24勝24敗已經是McHale退休後最佳的教練成績，也讓他獲得真除成為正式的塞爾提克總教練。 O’Brien除了改變總教練高高在上的姿態外，最重要的轉變是讓Walker、Pierce成為球隊決策的一環，無形中也讓球員與教練團間的隔閡消失。被賦予重任的Walker改變過去被媒體貼上的標籤，在暑假裡邀請隊友一起練球，到西岸跟Pierce練球，更把場上表現的機會讓給Pierce，自己扮演助攻的配角，這些都讓Walker的好感度快速累積。 最關鍵的還是Walker在2002年東區冠軍賽第三戰回到波士頓主場時展現的領導力。在前三節結束時塞爾提克大幅落後21分，鏡頭前只見到Walker在板凳上激動地對Pierce比手畫腳，第四節裡Pierce用單節獨得19分的表現幫助塞爾提克演出大逆轉，這也是塞爾提克脫離黑暗時期的象徵。 但沒人想到這也是塞爾提克的轉捩點。 將塞爾提克當作是一門生意的Paul Gaston在球隊重返季後賽價值快速上升後終於開啟了交易模式，並成功地在2002年9月將球隊易手給目前以Wyc Grousbeck家族為首的團隊。雖然新老闆沒有立刻撤換球團制服組，但懸而未決的總管人選卻在季後賽時傳出了可能人選，因此當2002-03季後賽塞爾提克在第二輪再次遭遇籃網隊時，所有媒體的焦點都落在可能接手籃球事務的Ainge身上。離開太陽隊教職後的Ainge轉任電視球評，他對於塞爾提克的過度依賴三分投射的打球方式多所評論，特別是對Walker的投籃選擇更是不假辭色，當傳出他可能接掌球隊時，預期他可能將全隊拆解的傳聞也開始在市場上流傳，讓原本就無力防守Jason Kidd的塞爾提克更加無助。球團最後確認人選消息傳出的時間剛好在第三戰前，在人心浮動下，整個第三戰完全失焦，塞爾提克也以76：94慘敗收場，最後慘遭橫掃。 只是諷刺的是Ainge在1988-89球季之所以被賣走，除了年輕最有交易價值外，他與新任總教練Jimmy Rogers交惡也是原因之一，而交惡的原因就是因為Ainge糟糕的三分投籃選擇。 O’Brien跨越時代的戰術思維如果回顧當時的塞爾提克打法，O’Brien有許多跨越時代的想法。最知名的是2002-03球季塞爾提克以2155次三分球出手成為NBA史上第一支單季三分球出手次數突破2000次球隊，而且要到兩年後NBA才開始穩定有球隊單季出手突破2000次，可說是當前三分熱潮的真正開端。更重要的是O’Brien不僅僅是讓球員多投三分球，他也要求球隊減少在中距離的出手，同時大幅增加球隊在兩側底角的三分球出手次數。 對比另一個底角出手次數較多的國王隊，兩隊的投籃分布截然不同，這說明了O’Brien的塞爾提克在整個投籃的思維領先當代甚多，以致於無法讓當時的媒體所理解。 雖然塞爾提克本身角落三分球出手只占全隊三分球出手的23%在聯盟裡屬於後段，但總出手逼近500次，僅略低於剛好突破500次的馬刺隊（註），這數字比次高球隊多出超過30次。如果認為這數字只是單純因為O’Brien增加三分投射而來，那就大錯特錯，因為這是本季新任湖人隊總教練Frank Vogel在塞爾提克擔任數據影像分析師時所得出來的結論，讓O’Brien有了理論基礎，設計出這套以三分球取代命中率低的中距離，同時利用兩側底角距離較短的特性來增加威脅力的基本打法，而這正是現在NBA的主流思維。 最明顯的例子是小前鋒Eric Williams。1995年入隊的他常跟Walker一起在禁區內攪和，但被Pitino賣往金塊隊後卻因為受傷導致爆發力與敏捷性大幅衰退，重新被賣回塞爾提克後轉型成了防守大鎖，原本不出手三分球的他也開始嘗試在外圍接應。從2001-02球季開始Williams的角落三分球比重就在七成以上，2002-03球季的數據雖然稍降，但也有65.5%的出手比重是在兩側底角。同樣的情況也發生在Walter McCarty身上，2002-03球季有50.4%的出手在兩側底角，這個策略讓塞爾提克能夠利用雙槍的切入破壞力製造外圍空檔，也能夠讓進攻能力較弱的防守組球員在場上能利用較短三分距離有了牽制效果，讓對手不能肆意的內縮防線包夾雙槍。 （註）馬刺隊的數字是因為Bruce Bowen有79.3%的三分球出手都在角落，一個人就出手超過一百八十次。 因此，帳面上看塞爾提克的天份在雙槍之後有明顯的落差，但這支球隊卻能夠很有效率的贏球。2002-03球季戰績之所以不進反退，一個極大的原因是Paul Gaston為了規避豪華稅且讓球隊賣相好看而刻意控制薪資，因此讓成為自由球員的Rodney Rogers以微幅增加的三年九百萬美金合約轉投死敵籃網隊。這筆薪水如果加上豪華稅將讓Gaston付出接近兩千萬美金，使得他堅持不肯放行。 Rodney Rogers的重要性在於他是塞爾提克攻守兩端所缺乏的關鍵人物。雖然資料上名列前鋒，但六呎七吋有235磅重的他能夠在防守時對抗對手的大前鋒甚至中鋒，進攻端更因為他每場出手3.5次命中率高達41.1%的三分球，讓對手不得不將長人拉至外圍防守Rogers，因此成了O’Brien調度上的活棋。 換言之，在2001-02球季O’Brien在交易大限換入Rogers後，O’Brien就已經當現今最熱門的衍生四號甚至外線中鋒的概念運用在Rogers身上，Walker、Pierce、Williams搭配Rogers，或是將Williams換成McCarty的四小前鋒是O’Brien即常使用的陣容，這也是當年O’Brien跨越時代的戰術思維。 換入Rogers後，塞爾提克的勝率從原本的56.3%攀升至66.7%，只差一勝就跨入五十勝俱樂部，少了Rogers讓O’Brien的攻守體系缺了一角，而在當年，這樣能夠投三分又能夠扛住對手中鋒的替代品幾乎沒有。 當Ainge確定接手，拆解陣容就成了時間早晚的問題。除了原本就對塞爾提克的打法與組隊方式非常有意見外，球隊薪資已經因為雙槍的兩張頂薪合約而捉襟見肘也是另一個因素。 交易1：送出Daris Songaila从国王得到Bandon Hunter和Orien Greene Ainge在五月九日第三戰時上任，很快的就在一個多月後的選秀會上大展身手。Ainge用2002年第50順位的Darius Songalia為籌碼向國王隊換來2003年與2005年的兩個二輪選秀。這筆交易據稱是Songalia的經紀人Mark Bartelstein拜託Ainge把自己客戶交易到有較多上場機會的球隊，只是當時的國王隊正當盛年，特別是前場的深度與高度俱佳，實在很難讓人信服Songalia能有更好的機會。 Songalia獲選後在夏季聯盟登場時展現了相當好的球賽解讀能力，以及非常靈巧的雙手，因此儘管體能遠遠不及NBA水準，接下來幾年一直都是堪用替補。 幾天後的選秀會上，Ainge用剛交易來的第二輪第56順位選了他選秀生涯最愛的類型：六呎七吋260磅重的矮胖型長人Brandon Hunter，但Hunter也跟大多數他選的矮胖型長人一樣沒有太多作用。而2005年的二輪成了第53順位，Ainge挑選了六呎四吋的得分後衛Orien Greene，只打了一年就被揮棄。 Ainge用生涯出賽495場平均6.9分、3.4籃板的堪用替補，換了兩個福袋。 交易2：送出Troy Bell和Dahntay Jones从灰熊得到Marcus Banks和Kendrick Perkins 這筆交易只是Ainge瘋狂交易的開端，選秀會上他又用第16順位的Troy Bell與第20順位的Dahntay Jones跟前灰熊隊交換了第13順位的Marcus Banks與第27順位的Kendrick Perkins。這筆交易引起不少反彈，因為Bell是本地Boston College出品的後衛，是BC隊史上的得分王，不過只出賽六場就從聯盟中消失。Jones雖然沒有太突出表現，但至少在聯盟裡打滾了十三個球季，2015-16在騎士隊拿到了一枚戒指。 Banks是Ainge非常喜愛的控衛類型，六呎二吋高的小後衛，沒有外線可言，速度飛快，往後每幾年他就會在選秀會上挑上一個或交易來一個，近期的代表人物是Demetrius Jackson。 選秀後Banks參加了暑假在UMass Boston舉行的Shaw’s夏季聯盟。UMass Boston的校區在波士頓南邊，突出在大西洋中的小半島，校園裡的甘迺迪總統圖書館襯映著大西洋在炎夏下極美。當時UMass Boston的體育館是一般小型學校的規模，座椅是從兩側拉出來的活動式座椅，兩年的經驗累積下來習慣坐在第二或第三層的位置，這位置大致就是球員眼睛高度左右，可以清楚看到球員切入後眼光的移動，是判斷球員場上閱讀能力最好的角度。第一場只見場上的Banks速度飛快但運球不甚靈光，因此快速推進時得要聚精會神地盯住球瘋狂地往前快跑，也導致當他快速移動時的視角極窄，幾乎只有正前方的傳球視角，看完一場之後就知道這個第13順位打注定要打水漂。 Banks從來沒有成為Ainge口中的控球後衛，在2006年成為交易中的配菜，只在隊史留下5.3分、2.0助攻完全不及格的成績。 Perkins應該是交易裡知名度最高的球員，在今年的諸多紛擾裡是對Irving最不假辭色的退休球員，他是2014-15球季Irving在騎士隊的隊友。雖然是末代高中棄學生，Perkins是少數近乎沒有進攻技巧的高中棄學生，生涯前兩個球季幾乎沒有上場機會。身體十分鈍重，直到第三個球季才逐漸開竅，最後在Garnett入隊後成為禁區的防守核心。 也許，可以說Perkins救了這筆交易，但這筆交易最可悲的地方也在於Perkins救了這筆交易。 交易3：送出JR Bremer、Bruno Sundov和Ryan Gomes从骑士队得到了Jumaine Jones 一個月後，Ainge又做出了另一筆交易，將六月底剛轉換為保證約的第二年控衛J.R. Bremer與六月底選擇執行球員選擇權的替補中鋒Bruno Sundov以及2005年第二輪打包送往騎士隊，用先簽後換的方式換回了小前鋒Jumaine Jones。Jones在騎士的兩個球季有9.0分、5.6籃板，被認為能升級塞爾提克在鋒線的深度，但在入隊後Jones卻沒有辦法獲得出場時間，只上場42場，留下2.2分、1.6籃板就在隔年被送往湖人隊。 Bremer是總管Chris Wallace在沙裡掏金的結果。出身St. Bonaventure University，大四有24.6分與3.1助攻，雖然在2002年選秀會上未受青睞，但在Shaw’s裡以大膽投射與防守贏得球隊青睞，成功入隊。開季後從替補打起，由於塞爾提克此時的控衛工作相對單純，運過半場後就交由雙槍處理，主要工作是擔任外圍接應的狙擊手，勇於出手的Bremer因此有許多發揮空間，更在一月取代老將Tony Delk成為球隊的先發控球，直到季末為了準備季後賽才再度由Delk先發。擔任先發的41場比賽裡Bremer有平均11.2分、3.5助攻的成績，同時有37.2%的三分球命中率。 Sundov是小牛隊1998年選秀會第二輪第35順位，七呎二吋的瘦長型克羅埃西亞中鋒。高中在麻州就讀，一直被認為是有潛力的攻擊型長人，但生涯前四年沒有太多表現機會，因此2002年暑假被Wallace以底薪簽下，但在26場比賽裡也只交出1.2分、1.1籃板的成績。 交易4：送出Antoine Walker和Tony Delk从小牛队得到Raef LaFrentz、Chris Mills、Jiri Welsch和Delonte West Ainge接掌球隊後所有媒體最關注的就是主將Walker的去留，接手一周Ainge就約談Walker討論未來合作。結束後Ainge對媒體說著：「我跟Walker談過，並告訴他我對他在這個暑假的期望，以及對新球季訓練營前的準備，這就是我們的計劃，繼續邁步向前。」 只是這個保證並沒有持續太久，10月20日，塞爾提克突然宣布將Walker、Delk打包送往小牛隊交換Pierce的大學隊友Raef LaFrentz，一對搖擺人Chris Mills與Jiri Welsch以及2004年的首輪選秀權。這筆交易幾乎毫無預警，因為前一天環球報隨隊記者Shira Springer還煞有其事地認真討論著塞爾提克開季的球員陣容，而Walker是她筆下的篤定人選。 交易一出，波士頓環球報的神級專欄作家傾巢而出。由最資深也是知名Walker厭惡者Bob Ryan寫體育版刊頭，包括現在還在執筆的Jackie MacMullan、長年隨隊記者Peter May與現役隨隊記者Springer都寫了文章討論。帳面上Ainge的理由是不久後即將成為自由球員的Walker在延長合約談判上堅不讓步，高達一千六百萬美金的頂薪年薪讓球團無力負擔，又擔心會在未來失去他而一無所有，於是做出了交易的抉擇。 看過這個，應該就不會意外Ainge如何處理Isaiah Thomas。 Delk是Walker的肯大隊友，也是聯盟有名的板凳好手，在前主控Kenny Anderson離隊後就是塞爾提克實際上的控球後衛。在塞爾提克兩季裡Delk練出了一手穩定的三分球，成為重要的外線射手，有39.5%的三分準度，同時一雙長臂也是球隊重要的後場防守者。 小牛隊提出的包裹裡，Mills曾經在1997年暑假與Pitino簽下合約，但球季還沒開打就被打包送往尼克隊交換包含McCarty在內的包裹。這次再度重返波士頓沒想到歷史又再度重演，因為受傷一直無法上場的Mills在隔年交易大限時又被放上交易桌上，數據上連一場替塞爾提克出賽的紀錄都未曾留下。Ainge利用Mills的六百六十萬美金合約做為幫助其他球隊平衡薪資的重要籌碼，終於在與老鷹、活塞的三方交易中扮演重要角色，讓活塞順利從老鷹處換得Rasheed Wallace，幫助活塞拿下2004年總冠軍。交易中塞爾提克另外送出控衛Mike James，換回另一個近似的控衛Chucky Atkins以及老將Lindsey Hunter與2004年首輪選秀權，James與Atkins這對戰力毫無幫助的互換也讓人開了眼界。 Welsch是相當有靈性的搖擺人，入隊後第一年有9.2分、3.7籃板與2.3助攻的成績，同時有38.1%的三分球命中率。不過2005年的交易大限Welsch又被打包送往騎士隊交換2007年的首輪選秀權。 這筆交易裡的主角LaFrentz是1998年選秀會的第三順位，但生涯卻一直為膝蓋傷勢所苦，始終沒能有所表現。小牛隊在2002年的交易大限換入了LaFrentz，並在球季結束後與他簽下一紙七年七千萬美金的肥約。儘管LaFrentz在小牛隊的一年多裡只有9.7分、5.5籃板的不及格成績，為了賣掉Walker的Ainge還是毅然決然地接手他剩下來六年長約，成了許多人批評的把柄。交易後LaFrentz依然因為膝傷所苦，表現並不穩定，最後終於在12月12日接受膝蓋手術而宣告球季提前結束，生涯在塞爾提克三季只有9.2分、5.8籃板。 面對媒體不斷的詢問Walker的私人恩怨說，Ainge只能不斷的否認，強調時間將會證明一切。不管是真心還是推託之詞，Ainge倒是不能說完全在說謊，因為2005年交易Welsch的同一天，他又將一年多前說毫無續約希望的Walker從老鷹隊給換了回來，目的是替塞爾提克爭取季後賽的機會。就這樣，Walker與LaFrentz一起在季後賽裡出戰，但塞爾提克打滿七場後敗在溜馬隊的手下。 球季結束後，Ainge又再一次將Walker打包以先簽後換的方式送往熱火隊，讓Walker成為第一個拿下冠軍的球員。 看到Walker這樣賣出去又買回來又賣出去，以及LaFrentz的數據，Ainge急於做出這筆交易是不是有個人恩怨也許見仁見智，但賠上了塞爾提克兩個球季這點卻是毫無爭議的事情。 交易5：送出Tony Battie、Kedrick Brown、Kedrick Brown从骑士队得到Ricky Davis、Chris Mihm、Michael Stewart和Ryan Gomes 送走了Walker讓塞爾提克全隊士氣低迷，也讓全隊更加人心惶惶，誰也不知道自己的明天在哪裡。就在LaFrentz倒下的幾天後，Ainge又再一次做出交易，這次把中鋒Tony Battie、前鋒Williams與體能絕佳的搖擺人Kedrick Brown給送往騎士隊，交換中鋒Chris Mihm、Michael Stewart、搖擺人Ricky Davis與2005年的第二輪選秀權。 這一筆交易等於將塞爾提克上季除了Pierce、McCarty之外的主力正式全部出清，也把在球隊資歷最久的Williams再次推出球隊。 雖然是2000年的第七順位，但Chris Mihm始終只有替補中鋒的資質，球隊的先發中鋒依然是1997年第57順位由超音速所選，但在小聯盟裡浮沉三年，直到2000年才被塞爾提克看上帶入NBA的Mark Blount擔綱。 Michael Stewart綽號Yogi (Bear)，是六呎十吋的火鍋中鋒，但菜鳥球季在國王繳出4.6分、2.4阻攻之後就因為毫無節制的犯規而被各隊冷凍。在塞爾提克的一季裡只有平均0.3分、0.1阻攻的成績，0.8次的犯規換算成36分鐘將高達6.6次，一年後就從聯盟中消失。 這次交易中的主角Davis可說是Ainge早期交易史裡少數成功的球員，三個球季中留下16.2分、3.7籃板與3.4助攻，成為這幾個球季裡Pierce最主要的助拳者。2002-03球季Davis在幾乎無人的騎士隊裡成為第一主將，在有大量出手機會下繳出平均20.6分、4.9籃板與5.5助攻的全方位成績（Jones也是在這季打出成績）。只是在LeBron James入隊後，Davis就成了礙眼的存在，最後成了騎士隊出清的對象。Davis有得分能力也有外線準度，防守的態度也比在騎士隊時好上許多，但他始終不是一個能夠幫助球隊更上層樓的球員，各方面雜而不精，也因為功能與Pierce重疊性遠高於Walker，讓他的發揮空間受到壓縮。 2006年一月底Davis又跟Blount、Banks一起被打包送往灰狼隊，交換1998年狀元Michael Olowokandi、Wally Szczerbiak、Dwayne Jones與2009首輪選秀權。 1998年選秀會上的兩大長人Olowokandi與LaFrentz都在Ainge主政下來到了塞爾提克，但結果卻與選秀會上同樣悲慘。 塞爾提克送出的Williams是1995年首輪第14順位的新秀，跟1996年第六順位的Walker是一起度過黑暗歲月的夥伴，也是Walker在球隊裡最好的朋友。年輕時是宛如豺狼般的蠻幹型小前鋒，受傷後失去爆發力導致進攻能力大幅衰退，但原本不在意防守的他卻專注在防守上，負責防守對手最難纏的搖擺人，讓雙槍能夠減輕防守負擔，是個工作態度與團隊精神俱佳的自家球員。 經過這幾年，也該知道Ainge最不在乎的就是這些非關天賦的正面特質。 Williams是Walker最好的朋友，而Battie則是Pierce最好的朋友。當Pierce在2001年開季前於Buzz Club遇刺時，緊急抱著Pierce穿過Stuart Street到對街的新英格蘭醫療中心求助，保住Pierce一命的隊友正是Battie。 Buzz Club的位置在中國城與劇院區之間，雖然出事後沒多久Buzz Club就已經歇業，但原址一直都在經營夜店或是酒吧，並不是外界想像的是非之地。十多年前習慣將車停在Buzz Club旁大空地開設的停車場，每天那裏就不斷的玩著大型移車遊戲，現在停車場已經杳無蹤跡成了高樓大廈，但夜店依舊在。 Battie是1997年第五順位，1998-99球季開始前被賣到塞爾提克交換被Pitino打入冷宮的中鋒Travis Knight。Battie有六呎十一吋高230磅重，瘦長的體型讓他的防守能力一直被外界所忽略，但他在塞爾提克的生涯裡有平均1.1次的阻攻，是塞爾提克賴以為生的防守核心。O’Brien接手後特別替Battie設計一套在前防守的系統，利用他的一雙長手臂來騷擾對手後衛將球送往禁區的路徑。如果對手將球轉移到側翼，Battie可以利用自身敏捷性繼續保持在前防守，或是立刻轉換成傳統的防守位置。這一套防守有效的箝制對手將球送到中鋒的機會，再搭配Walker在後方的包夾，就曾經成功地限制住湖人隊當家中鋒Shaq O’Neal在禁區的威脅力。 跟受傷後的Williams或是沒有驚人天賦的Battie不同，2001年第11順位的Kedrick Brown則有讓人過目不忘的驚人天賦，那兩年在Shaw’s裡Brown幾乎快超過籃框的實戰扣籃動作至今依然震撼。但Brown始終沒有辦法把自己的天賦幻化成實際數據，二年制學院出身而成為樂透新秀的他缺少如Pierce一般苦練而來的下球技巧，這讓他無法利用切入來發揮自己的體能天賦，也沒有發展出足夠穩定的三分投射能力，加上個性缺少在NBA成功所必需的強大企圖心，讓他一直都沒能達到天賦體能所該有的表現，這也讓他在離隊後不久就從NBA消失。 Ainge主政下最糟糕的一點是2003年暑假剛開始，塞爾提克就製作了Tony Delk、Tony Battie的非正式版球衣，然後某些通路還買得到Kendrick Brown的球衣，買了之後，這些球員就通通被賣掉，於是通路賣不掉的球衣就瘋狂大拍賣。 連這都要坑殺球迷。 交易後的塞爾提克真的有不平庸？Ainger接手後改變了這個球隊的諸多面向，這一季塞爾提克的三分球出手數陡降至1599次，總教練O’Brien在季中終於難以忍受而宣布辭職，塞爾提克在代理總教練John Carroll努力團結球員下勉強以東區第八打入季後賽，但被Larry Bird擔任總管，Rick Carlisle擔任總教練的溜馬隊輕鬆橫掃出局。 那幾年的塞爾提克除了大量的三分球外，最著名的就是瘋狂不要命的防守態度，Williams、Battie、McCarty、Delk等防守組球員正是執行這套防守的核心人物，也是塞爾提克能夠逆勢獲勝的關鍵。 經過這幾年，也該知道Ainge對這些與天賦無關的事情一點也不在乎。 從五月九日上任到十二月十五日，Ainge花了七個多月的時間就送走了上一季名單中的七名球員，讓這隻曾經打入2002年東區冠軍賽的塞爾提克完全崩解，留在名單中的Vin Baker因為酗酒問題而在2004年二月被球隊解約，Tommy Heinsohn的愛將McCarty則在2005年交易大限前被送往太陽隊交換2007年的第二輪選秀權，被好友形容是被遺忘在孤島上的Pierce則熬過了地獄般的重建歲月拿下2008年總冠軍，但也在2013年被賣往籃網隊。 這七個月的跳樓大拍賣裡包含選秀會共有五筆交易，Ainge送出了十位球員與一枚二輪選秀權，收進了十一位球員、兩枚首輪與三枚二輪選秀權，已經展露出他喜歡收集選秀權的習性。在Ainge送出的十位球員裡有入選明星賽的Walker與球隊主力Delk、Williams、Battie以及年輕的Bremer，換進來的球員除了Davis外只有Welsch勉強對球隊有些助益。 這五筆交易後，Ainge在接下來到2007年選秀會交易Ray Allen前又發動了十二筆交易，不斷的將手上的球員洗成另一批球員，雖然因此累積了許多爛合約作為交易的資產，也累積了許多選秀權幻化為新秀，也讓這些年輕球員累積了許多壞習慣，導致塞爾提克的戰績不斷下滑，2006-07球季僅有24勝58敗，讓好不容易走出九零年代中黑暗時期的球迷又墜入無底深淵之中，也讓Pierce終於決定向球隊發出最後通牒，也才在2007年暑假有GAP的誕生。 這七個月的時間裡，展現了Ainge的許多特質，例如不計代價地送走自家球員，這在2013年拍賣GAP之後也有相同的舉動，只是這次Ainge很幸運地在大拍賣中分別與2014與2015年換到了Jae Crowder與Isaiah Thomas，並用他們帶領著一批浪人打入季後賽，再吸引Al Horford加盟終於再次打入東區冠軍賽。 但就像2002年的塞爾提克，奮戰不懈的態度與打死不退的防守在Ainge與老闆群的眼裡完全無法與天賦相提並論，最後終於參與許多人口中「就算再一百次也會選擇交易」的捨Thomas、Crowder就Irving的交易。 另一個不同處是Ainge對於自己挑選的球員有相當偏好，因此2003年的重建中毫無顧忌地拍賣除了Pierce之外的球員，而2017年則送走了自己在交易中挖掘的Thomas與Crowder，而留下自己挑選的Jaylen Brown、Jayson Tatum等年輕球員。 2003與2017的塞爾提克如果沒有拆散是否能拿下總冠軍？這問題誰也沒有答案，只能說如果留下核心繼續努力，也許有一拚的機會。當時絕大多數人都覺得這兩支球隊完全沒有機會，但這些人中又有一部分覺得有了Irving之後就有機會至少打入總冠軍賽。歷史打了這些人兩次巴掌，第一次是Irving、Gordon Hayward受傷後反而再次打入東區冠軍賽直到第七戰才落敗。第二次則是有了健康的Irving反而讓球隊分崩離析，不但離總冠軍更為遙遠，還成為眾人的笑柄。 也許關鍵就在對核心的認知，2017年與2018年兩度打入東區冠軍的原因不是因為Tatum或是Brown或是Horford，而是Thomas與Crowder入隊後帶給這支球隊的態度，打死不退的防守與永遠不放棄的精神，讓所有球員緊緊的團結在一起。而Ainge與背後的老闆們則認為關鍵因素在自己的眼光挑選了Tatum、Brown等人，因此一貫認為更高的天分與更多的明星就能打造出真正的冠軍球隊，而放任Irving恣意而為，最後摧毀了球隊。 兩年過去了，牆倒眾人推，Irving已經成了媒體棄兒，大多數人都已經忘了自己當時對這筆交易的喜悅以及本能覺得身高、天賦就是一切的迷思，當然，更沒有多少人記得十七年前那一連串交易所造成的夢靨。 Ainge與Auerbach的差異Hoop雜誌最後的2019年六月號裡，紀念John Havlicek的文章最後引用了Hondo自傳裡對1976年冠軍隊的描述，這不僅說明了為何Auerbach執政時期的塞爾提克即使又老又傷還是能夠笑傲江湖，也說明了為何有數位頂薪球員又有滿滿天賦的2019塞爾提克最後會落得樹倒猢猻散的下場。 「塞爾提克又再次拿下冠軍，我很確信聯盟裡很多球員不懂為何我們能屢屢奪冠，1975-76球季的塞爾提克是隊史上最脆弱的一隊，也是那四年裡最不強勢的一隊，卻拿下最後勝利。我們的紙上陣容不是聯盟最佳，而是由一群角色球員所組成的球隊，然而，在季後賽裡我們每個人都非常有效的扮演自己的角色。」 謹以此文，替這些年劃下一個句點。","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"nba","slug":"nba","permalink":"http://yoursite.com/tags/nba/"}]},{"title":"Root用户删除文件爆Permission denied","slug":"Root用户删除文件爆Permission-denied","date":"2019-07-11T12:31:18.000Z","updated":"2019-07-11T12:55:54.000Z","comments":true,"path":"2019/07/11/Root用户删除文件爆Permission-denied/","link":"","permalink":"http://yoursite.com/2019/07/11/Root用户删除文件爆Permission-denied/","excerpt":"","text":"今天在一台服务器上使用useradd创建用户，竟然爆Permission denied，我靠，我明明是root，竟然没有权限增加新用户，如图： 此时注意到下面还有一句话：useradd: cannot lock /etc/passwd; try again later。于是怀疑到可能在/etc/下有一个文件把passwd锁住了。搜索一番，发现了.pwd.lock这个文件，但是发现这个文件不能删除和改名，如图： 此时的我觉得root身份受到了很大的冒犯，怎么还有这种鬼现象？突然想到，可能这个锁文件被人给chattr修改了，于是使用lsattr查看这个文件，发现就剩下一个e属性了： 12[root@ip-172-31-7-167 etc]# lsattr .pwd.lock -------------e- .pwd.lock e属性是不能用chattr -e删除的，而且也是一个很普通的属性，那么问题出在哪呢？ 在/etc/下执行lsattr -R -a递归的查看所有文件（包含隐藏文件），发现原来当初是把整个/etc/文件夹加了i，如图： 于是就在/etc/路径下使用chattr -i .破掉了i属性，此时再次尝试删除lock锁文件，终于删除掉，并且成功创建了用户，如图：","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"lsattr","slug":"lsattr","permalink":"http://yoursite.com/tags/lsattr/"}]},{"title":"使用pycurl来模拟curl效果","slug":"使用pycurl来模拟curl效果","date":"2019-07-11T01:58:12.000Z","updated":"2019-07-11T12:58:16.000Z","comments":true,"path":"2019/07/11/使用pycurl来模拟curl效果/","link":"","permalink":"http://yoursite.com/2019/07/11/使用pycurl来模拟curl效果/","excerpt":"","text":"安装centos下安装pycurl，如果直接使用pip install pycurl的话，可能会有ERROR: Command &quot;python setup.py egg_info&quot; failed with error code 1 in /tmp/pip-install-hb0k0rkr/pycurl/的错误，那么需要先安装一下yum install python-devel curl-devel就解决问题了。 如果是windows下安装pycurl就比较麻烦一点，需要先pip install wheel安装wheel，然后去http://www.lfd.uci.edu/~gohlke/pythonlibs/ 下载对应python版本的编译包到本地，然后在cmd命令行里pip install 对应的.whl就好了。但是注意http://www.lfd.uci.edu/~gohlke/pythonlibs/ 是需要翻墙登录的。 python3脚本pycurl的常用的常量列表可以看一下https://izsk.me/2017/12/27/%E4%BD%BF%E7%94%A8python%E5%BA%93pycurl%E6%9D%A5%E6%A3%80%E6%B5%8Bweb%E6%9C%8D%E5%8A%A1%E8%B4%A8%E9%87%8F/ 这个文章，我这里就直接写一下我的脚本： 123456789101112131415161718192021import pycurlimport sysc = pycurl.Curl()url = 'http://X.X.X.X:对应端口号'c.setopt(c.URL, url)c.setopt(c.HEADER, True)c.setopt(pycurl.CONNECTTIMEOUT, 5) # 连接的等待时间，设置为0则不等待c.setopt(pycurl.TIMEOUT, 5) # 请求超时时间c.getinfo(pycurl.HTTP_CODE) # 返回的HTTP状态码#c.setopt(c.POST,1) #是否是post，默认是gettry: c.perform() #提交请求except Exception as e: print(\"连接异常！\" + str(e)) c.close() sys.exit()HTTP_CODE = c.getinfo(c.HTTP_CODE) #获取 HTTP 状态码print('HTTP状态码: %s' %(HTTP_CODE))c.close() 不过pycurl有两个缺点，第一,整个请求头都会输出；第二,无法摘取到http协议版本号。 GO脚本如果是想用go语言来实现curl效果，脚本如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package mainimport ( \"fmt\" \"github.com/mikemintang/go-curl\")func main() &#123; url := \"http://目标路径:目标端口\" headers := map[string]string&#123; \"User-Agent\": \"Sublime\", \"Authorization\": \"Bearer access_token\", \"Content-Type\": \"application/json\", &#125; cookies := map[string]string&#123; \"userId\": \"12\", \"loginTime\": \"15045682199\", &#125; queries := map[string]string&#123; \"page\": \"2\", \"act\": \"update\", &#125; postData := map[string]interface&#123;&#125;&#123; \"name\": \"mike\", \"age\": 24, \"interests\": []string&#123;\"basketball\", \"reading\", \"coding\"&#125;, \"isAdmin\": true, &#125; // 链式操作 req := curl.NewRequest() resp, err := req. SetUrl(url). SetHeaders(headers). SetCookies(cookies). SetQueries(queries). SetPostData(postData). Post() if err != nil &#123; fmt.Println(err) &#125; else &#123; if resp.IsOk() &#123; fmt.Println(resp.Body) &#125; else &#123; fmt.Println(resp.Raw) &#125; &#125;&#125; 上述脚本执行效果： 参考资料http://pycurl.io/docs/latest/index.html (官方文档)https://www.twilio.com/blog/2016/12/http-requests-in-python-3.htmlhttps://stackoverflow.com/questions/472179/how-to-read-the-header-with-pycurl","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"curl","slug":"curl","permalink":"http://yoursite.com/tags/curl/"},{"name":"端口探测","slug":"端口探测","permalink":"http://yoursite.com/tags/端口探测/"}]},{"title":"Nginx使用proxy_pass里的坑","slug":"Nginx使用proxy-pass里的坑","date":"2019-07-08T07:47:57.000Z","updated":"2019-07-10T03:46:14.000Z","comments":true,"path":"2019/07/08/Nginx使用proxy-pass里的坑/","link":"","permalink":"http://yoursite.com/2019/07/08/Nginx使用proxy-pass里的坑/","excerpt":"","text":"第一坑我们有一个后台服务A，架构是这样： 1管理员 ====&gt; nginx ====&gt; AWS的云服务器（服务A） 此时在nginx上做了一个proxy_pass的转发，如下： 12345678 server &#123; listen 8081; server_name xxx.com; location / &#123; proxy_pass aws云服务器的IP地址:对应端口; &#125;&#125; 一直用的挺好，但是后来这个服务业务量上来了，就扩了一台机器，也部署了A服务，然后在前面加上了一个ELB做最小连接数分配，如图： 123 AWS的云服务器1（服务A）管理员 ====&gt; nginx ===&gt; ELB ===&gt; AWS的云服务器2（服务A） 此时修改了一下proxy_pass的配置： 12345678 server &#123; listen 8081; server_name xxx.com; location / &#123; proxy_pass http://aws的ELB域名地址:对应端口; &#125;&#125; 当时是好使的，但是第二天就不好使了，nginx调用结果是502 Bad Gateway，当时是分别curl路径然后又抓包，一路十三招查下来也没什么头绪。后来发现原来proxy_pass后面如果接的是域名地址的话，那么Nginx会在每次启动和重载设置时，使用DNS将域名解析为IP地址缓存下来，并在之后一直使用这个IP！只有通过nginx -s reload这样的重启才会强制刷新IP，所以当时在nginx上抓包发现跳转的IP其实并不存在。由于在AWS中ELB的内网域名对应的IP并不是一直不变的，这才导致了上面的问题。 新更改的配置如下： 1234567891011server &#123; listen 80; server_name xxx.xxx.net; resolver DNS服务器地址 valid=30s; #resolver 是 DNS 服务器地址, valid 设定 DNS 刷新频率 set $service_lb aws的ELB域名地址; location / &#123; proxy_pass http://$service_lb; #若有路径的必要，就加上$request_uri &#125;&#125; 需要特别注意的一点是set语句不能写到 location 里面，否则不会生效。 第二坑proxy_pass这个配置对相对路径和绝对路径也有很有讲究，比如： 123location /proxy/ &#123; proxy_pass http://10.0.0.1:8080/; #这里以/结尾 &#125; 当访问 http://127.0.0.1/proxy/a/b/c.txt 时，nginx匹配到/proxy/路径，把请求转发给10.0.0.1:8080服务，实际请求代理服务器的路径为http://10.0.0.1:8080/a/b/c.txt（不带location目录）。 如果是这么写的： 123location /proxy/ &#123; proxy_pass http://10.0.0.1:8080; #这里没有以/结尾 &#125; 当访问 http://127.0.0.1/proxy/a/b/c.txt 时，nginx匹配到/proxy/路径，把请求转发给10.0.0.1:8080服务，实际请求代理服务器的路径为http://10.0.0.1:8080/proxy/a/b/c.txt（带location目录），此时nginx会把匹配的proxy也代理给代理服务器。 proxy_pass后面接多一级路径的情况跟上面一致。 补充一个$host 400错误的故障400这个状态码是Bad Request，基本上就是请求header或者是cookie有问题，而请求header的问题要么是头过大要么是头没有。在HTTP/1.0里不支持Host请求头的，而在HTTP/1.1中，Host请求头部必须存在,否则会返回400 Bad Request。如果请求的URI不包含所请求服务的主机名，则必须为Host头字段指定一个空值。 nginx如果配置了$http_host变量做反向代理时，后端真实的服务器是需要知道请求的host头，而$http_host的值是’’，所以会触发400这个错误。这个情况就需要用$hosts来替代$http_host。 也就是说：proxy_set_header Host $host这一行的作用是把原http请求的Header中的Host字段也放到转发的请求里。如果不加这一行的话，nginx转发的请求header里就不会有Host字段，而服务器是靠这个Host值来区分你请求的是哪个域名的资源的。 还有一种400的情况：如果是GET请求没问题，而POST请求返回400错误，那么可能是websocket配置成了全局单独配置websocket的地址即可。 参考资料https://www.jibing57.com/2018/11/27/nginx-with-dynamic-upstreams-to-ELB/http://www.syyong.com/net/Using-nginx-s-proxy_pass-function-to-do-domain-name-forwarding-causes-an-accident.htmlhttps://blog.nswebfrog.com/2018/09/09/nginx-proxypass-dns/https://www.jianshu.com/p/b113bd14f584https://www.cnblogs.com/woshimrf/p/nginx-proxy-rewrite-url.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"proxy_pass","slug":"proxy-pass","permalink":"http://yoursite.com/tags/proxy-pass/"}]},{"title":"Intellij Idea配置GO调用本地包","slug":"Intellij-Idea配置GO调用本地包","date":"2019-07-05T07:56:16.000Z","updated":"2019-07-08T13:04:44.000Z","comments":true,"path":"2019/07/05/Intellij-Idea配置GO调用本地包/","link":"","permalink":"http://yoursite.com/2019/07/05/Intellij-Idea配置GO调用本地包/","excerpt":"","text":"go代码里使用import去导入包文件，比如常见的import fmt，这个命令实际上导入的就是GOROOT\\src\\fmt。但是当遇到需要导入本地包的时候，就需要配置一下。 我windows里的go脚本文件夹是E:\\github\\GoeveryDay，现在在这个文件夹里创建src\\chentest\\，然后在src\\下面创建一个chenchen.go，在chentest\\下创建testtest.go，如图： 而chenchen.go的内容如下： 123456789101112131415package mainimport ( \"chentest\" \"fmt\")func main()&#123; chentest.XXX() var s1 chentest.Player s1.Name = \"iverson\" s1.Number = 3 s1.Team = \"76ers\" fmt.Println(s1)&#125; 现在需要让chenchen.go能成功调用到chentest.go里的XXX函数，如果此时在chenchen.go里直接import testtest.go所在文件夹是会报错的，错误提示是Cannot resolve file ‘testtest.go所在文件夹’，这是因为程序在运行时先去GOROOT去搜索导入包，然后去GOPATH寻找导入包，最后在当前项目模块下寻找导入包，如果三个都找不到就会报错。 可见在idea中默认不支持直接导入本地Golang包，那么解决该问题的关键是明白GOROOT和GOPATH的作用，根据官方文档的解释GOPATH的主要作用是存放文件以便Golang程序编译时可以进行搜索引用，GOPATH可以设置一个值或多个值，多个值之间以分号隔开。很明显只要我们将本地Golang加入到GOPATH中即可在IDEA中正常运行该程序。 那么先File--Settings--Languages &amp; Frameworks--Go--GOPATH，在project GOPATH里添加E:\\github\\GoeveryDay这个总的文件路径，如图： apply保存即可，记住这里不能填E:\\github\\GoeveryDay\\src，因为系统会自带src目录，如图： 此时再执行就得到正确结果了！如图： 但是要注意，要使用本地包函数、结构体、结构体的成员，首字母必须是大写！如果首字母是小写是私有的，即不可见的，只能在同一个包里使用。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"},{"name":"intellij idea","slug":"intellij-idea","permalink":"http://yoursite.com/tags/intellij-idea/"}]},{"title":"Golang的切片学习笔记","slug":"Golang的切片学习笔记","date":"2019-07-03T08:27:49.000Z","updated":"2019-07-04T12:20:00.000Z","comments":true,"path":"2019/07/03/Golang的切片学习笔记/","link":"","permalink":"http://yoursite.com/2019/07/03/Golang的切片学习笔记/","excerpt":"","text":"与python对比初开始接触golang的slice，感觉跟python的slice有点像，但也有几个比较明显的区别： python中的slice是在原有基础上拷贝一份。go中的slice则是指向生成它的数组/切片(切片和数组共用同一片内存)，切最长长度不会超限； go的切片，其成员是相同类型的，python的列表和元组则不限制类型； 对于[a:b]这种切片操作，go的a、b两个参数不能是负数，python可以是负数，此时就相当于从末尾往前数； 对于[a:b:c]这种切片操作，go的c表示的是容量；而python的c表示的是步长。 判断切片相等比较两个切片是否相等，除了循环遍历还有一个reflect方法： 12345678910111213141516171819package mainimport ( \"fmt\" \"reflect\")func bijiao(b,c []int) bool&#123; return reflect.DeepEqual(b,c)&#125;func main()&#123; b := []int&#123;&#125; //他俩是一回事 c :=make([]int,0,0) var d []int //d跟b、c不是一回事 fmt.Println(bijiao(b,c)) fmt.Println(bijiao(d,c)) fmt.Println(d) fmt.Println(c)&#125; copy的问题go的copy是拷贝对应的位置，而不是全拷贝，也就是说如果是让一个空切片作为目的切片，那得到了新切片就是空切片，如果是让一个空切片做源切片，那么得到的新切片与目的切片一致。 判断字符串的几种情况用一个例子说明： 12345678910111213141516package mainimport (\"fmt\"\"strings\")func main() &#123; var str string = \"This is an example of a string.\" //定义变量 fmt.Printf(\"T/F? Does the string \\\"%s\\\" have prefix %s? \", str, \"Th\") fmt.Printf(\"%t\\n\", strings.HasPrefix(str, \"Th\")) fmt.Printf(\"%t\\n\", strings.HasSuffix(str,\"ing\")) fmt.Println(strings.Contains(str,\"an\")) //目标变量是否含有an fmt.Println(strings.ContainsAny(str,\"axwq\")) //目标变量是否含有“axwq”里的任意一个 fmt.Println(strings.Count(str, \"s\")) //目标变量里有多少个s&#125; 如果要获取汉字字符串的汉字数，可以使用utf8.RuneCountInString(s)。 参考资料https://studygolang.com/articles/12944 （判断相等的deepequal）https://studygolang.com/articles/5769 （golang中strings包用法）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"golang","slug":"golang","permalink":"http://yoursite.com/tags/golang/"},{"name":"基础知识","slug":"基础知识","permalink":"http://yoursite.com/tags/基础知识/"}]},{"title":"一个Go语言按行读取文件的脚本","slug":"Go语言flag包学习","date":"2019-07-02T02:56:00.000Z","updated":"2019-07-02T13:21:34.000Z","comments":true,"path":"2019/07/02/Go语言flag包学习/","link":"","permalink":"http://yoursite.com/2019/07/02/Go语言flag包学习/","excerpt":"","text":"脚本内容假设我有一个文件111.txt，内容如下： 现在需要读取这个111.txt，并将文件里的数值，然后组合成一个数列，再写入到222.txt里。写了一个go脚本flagtest.go，内容如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091package mainimport ( \"bufio\" \"flag\" \"fmt\" \"io\" \"os\" \"strconv\")var infile *string = flag.String(\"i\",\"infile\",\"file contains vales for sorting\") //flag 包中，定义的指令以指针类型返回var outfile *string = flag.String(\"o\",\"outfile\",\"file to receive sorted values\")func readValues(infile string)(values []int,err error)&#123; file, err := os.Open(infile) if err != nil&#123; fmt.Println(\"failed to open this file:\",infile) return &#125; defer file.Close() //资源释放,关闭文件句柄 //file.Close()不会触发panic，会先判断file == nil //defer 除了最后执行之外还有一个重要的特性：即便函数抛出了异常，也会被执行的。 这样就不会因程序出现了错误，而导致资源不会释放了 br := bufio.NewReader(file) //读缓冲区 values = make([]int,0) //空切片 for &#123; line,isPrefix,err1 := br.ReadLine() if err1 != nil&#123; if err1 != io.EOF &#123; err = err1 &#125; break &#125; if isPrefix &#123; fmt.Println(\"A too long line,seems unexpected.\") return &#125; str := string(line) //转换字符数组成字符串 value,err1 := strconv.Atoi(str) if err1 != nil &#123; err = err1 return &#125; values = append(values,value) &#125; fmt.Println(values) return&#125;func writeVaules(values []int, outfile string) error&#123; file, err := os.Create(outfile) if err != nil&#123; fmt.Println(\"创建文件失败！\",outfile) return err &#125; defer file.Close() for _,value := range values &#123; //第一个是下标，第二个是元素 str := strconv.Itoa(value) //int到string file.WriteString(str + \"\\n\") //如果是windows文件，那就是\\r\\n &#125; return nil&#125;func main()&#123; flag.Parse() if infile != nil&#123; fmt.Println(\"infile =\",*infile,\"outfile =\",*outfile) &#125; values,err := readValues(*infile) if err == nil&#123; fmt.Println(\"原文件的内容是:\", values) fmt.Println(\"现在开始录入到新文件里...\") writeVaules(values, *outfile) &#125; else &#123; fmt.Println(err) &#125;&#125; 执行效果如下： 新的知识点！ bufio.NewReader的返回值里line和err不可能同时非nil。 string方法会自动识别\\n和\\t等通配符。 reader.ReadBytes（&quot;\\n&quot;)这个方法可以将字符串按\\n分割，然后取第一部分。 读取一行，通常会选择ReadBytes或ReadString。不过，正常人的思维，应该用ReadLine，只是不明白为啥ReadLine的实现不是通过ReadBytes，然后清除掉行尾的\\n（或\\r\\n），它现在的实现，用不好会出现意想不到的问题，比如丢数据。个人建议可以这么实现读取一行： 12line, err := reader.ReadBytes('\\n')line := bytes.TrimRight(line, \"\\r\\n\") 这样既读取了一行，也去掉了行尾结束符（当然，如果你希望留下行尾结束符，只用ReadBytes即可）。 参考资料https://segmentfault.com/a/1190000014935402http://qefee.com/2014/02/02/go%E8%AF%AD%E8%A8%80%E7%9A%84flag%E5%8C%85%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B/ (flag各种用法集合）http://fuxiaohei.me/2015/12/9/mistake-in-bufio-reader.html （bufio.reader的坑）https://github.com/ma6174/blog/issues/10 （bufio.reader的坑2）https://studygolang.com/articles/5932 （go使用Defer的几个场景）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"go","slug":"go","permalink":"http://yoursite.com/tags/go/"}]},{"title":"Linux运维工程师笔试题第十九套","slug":"Linux运维工程师笔试题第十九套","date":"2019-07-01T02:31:06.000Z","updated":"2019-09-23T08:06:20.000Z","comments":true,"path":"2019/07/01/Linux运维工程师笔试题第十九套/","link":"","permalink":"http://yoursite.com/2019/07/01/Linux运维工程师笔试题第十九套/","excerpt":"","text":"试题内容 简述一下客户端请求网页里a.css的过程。 HTTP 协议中与缓存相关的HTTP Header有哪些?见https://segmentfault.com/a/1190000014445687?utm_source=index-hottest/*&amp;^%$ 这篇文章吧。 SQL语句：update apps set ID=&quot;12345&quot; and NAME=&quot;李四&quot; where ID=&quot;100001&quot; and NAME=&quot;张三&quot;的执行结果是什么？为什么会有这个结果？ mysql官方要求以逗号分隔的col_name=value列表，如果是and的话，题目中的句子实际执行效果是update apps set ID=（&quot;12345&quot; and NAME=&quot;李四&quot;） where ID=&quot;11111&quot; and NAME=&quot;张三&quot;，即括号里的是一个逻辑表达式，但是由于NAME是等于张三而不是李四，于是就等于ID=&quot;12345&quot; and False，即False，在mysql里False等于0。所以出现了这个情况。 接上题，如果要正确达到目的应该怎么写？正确写法是：update apps set ID=&quot;12345&quot;，NAME=&quot;李四&quot; where ID=&quot;100001&quot; and NAME=&quot;张三&quot;，这样才能达到同时修改两个列的目的。 POST和GET的区别见https://www.cnblogs.com/logsharing/p/8448446.html 这篇文章吧。 如何保证用户鉴权过程是安全的？用户在网页输入用户名A和密码B，对“A+B+有规律的字符串”进行加密得到C，将A和C传递给服务器。由于A是明文的，服务器可根据A去数据库里得到相应的密码B，也用同样的步骤生成D，比较C和D是否相同即可。 Lunix如何查看某个进程的线程？两种方法：1）ps -T -p pid，返回的结果里spid就是线程号2）top -H -p pid3）pstree -p 进程用户名 | grep 进程名，ps -Lf 进程名，pstack 进程名 数据库事务隔离级别数据库事务的隔离级别有4个，由低到高依次为Read uncommitted(读未提交） 、Read committed（读提交，SQL和ORACLE的默认规则） 、Repeatable read（重复读，MYSQL默认的） 、Serializable（序列化，效率低但是最准确） ，这四个级别可以逐个解决脏读、不可重复读、幻读这几类问题。 将软连接的原文件删除，能否编辑此软连接？会有什么现象？可以通过echo命令编辑此软连接，结果生成名跟原文件一样的文件，inode也一样，但是文件内容已经是echo的新内容了。 如何识别此文件是硬链接？使用ll -hit查看文件，如果索引数不是1就是硬链接。 数据库延迟同步的语句是什么？一般来说为了防止数据库误操作，都会给一个异地备份数据库配置延迟同步功能，语句如下： 123mysql&gt;stop slave;mysql&gt;CHANGE MASTER TO MASTER_DELAY = 1800；单位为秒mysql&gt;start slave; SQL语句执行很慢的原因都有什么？见https://zhuanlan.zhihu.com/p/62941196 这篇文章。 什么场景会造成CPU低而负载确很高呢？造成这种现象的原因是：等待磁盘I/O完成的进程过多，导致进程队列长度过大，但是cpu运行的进程却很少，这样就体现到负载过大了，cpu使用率低。具体表现有以下场景：场景一：磁盘读写请求过多就会导致大量I/O等待：上面说过，cpu的工作效率要高于磁盘，而进程在cpu上面运行需要访问磁盘文件，这个时候cpu会向内核发起调用文件的请求，让内核去磁盘取文件，这个时候会切换到其他进程或者空闲，这个任务就会转换为不可中断睡眠状态。当这种读写请求过多就会导致不可中断睡眠状态的进程过多，从而导致负载高，cpu低的情况。 场景二：MySQL中存在没有索引的语句或存在死锁等情况：我们都知道MySQL的数据是存储在硬盘中，如果需要进行sql查询，需要先把数据从磁盘加载到内存中。当在数据特别大的时候，如果执行的sql语句没有索引，就会造成扫描表的行数过大导致I/O阻塞，或者是语句中存在死锁，也会造成I/O阻塞，从而导致不可中断睡眠进程过多，导致负载过大。具体解决方法可以在MySQL中运行show full processlist命令查看线程等待情况，把其中的语句拿出来进行优化。 场景三：外接硬盘故障，常见有挂了NFS，但是NFS server故障：比如我们的系统挂载了外接硬盘如NFS共享存储，经常会有大量的读写请求去访问NFS存储的文件，如果这个时候NFS Server故障，那么就会导致进程读写请求一直获取不到资源，从而进程一直是不可中断状态，造成负载很高。 为什么普通用户没有/etc/passwd的写权限，可以修改用户密码?这是应为passwd命令的权限是-rwsr-xr-x. 1 root root，其中这个s的意思是被赋予了SetUID权限，即passwd命令执行时是以root身份执行的，即可以更改密码的原因。参考资料https://github.com/kaiye/kaiye.github.com/issues/3https://tech.meituan.com/2014/08/20/innodb-lock.html （Innodb中的事务隔离级别和锁的关系）https://segmentfault.com/a/1190000020459073 （CPU 使用率低高负载的原因）","categories":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/categories/大牛之路/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"http网络","slug":"http网络","permalink":"http://yoursite.com/tags/http网络/"}]},{"title":"Proxysql添加后端SSL加密","slug":"Proxysql添加后端SSL加密","date":"2019-06-28T02:45:53.000Z","updated":"2019-10-14T06:22:06.000Z","comments":true,"path":"2019/06/28/Proxysql添加后端SSL加密/","link":"","permalink":"http://yoursite.com/2019/06/28/Proxysql添加后端SSL加密/","excerpt":"","text":"配置阿里云安全部门最近放出了新需求，要数据库流量实现内网加密。即mysql&lt;-----&gt;proxysql之间是加密的，这里记录整个配置过程，安装部分可以移步去看 https://rorschachchan.github.io/2019/05/31/%E8%AE%B0%E5%BD%95%E9%83%A8%E7%BD%B2ProxySql%E7%9A%84%E8%BF%87%E7%A8%8B/ 这篇文章。 首先登陆阿里云控制台RDS，选择对应的数据库—数据安全性—SSL，点击开通，如图： 注意！此项举动会重启数据库，所以线上环境请慎重！ 在配置的时候，同时下载CA证书，上传到proxysql所在的服务器的/var/lib/proxysql/里。解压缩之，发现压缩包里是三个文件，如图： 我们主要用的是ApsaraDB-CA-Chain.pem这个文件（如果是读写库，那么这个pem的文件是一模一样的）。 如果数据库开通ssl成功，那么在阿里云的控制台上是显示为“已开通”，在mysql命令行里使用show global variables like &#39;%ssl%&#39;;查看如下： 登录proxysql，查看当前链接mysql情况，如图： 发现里面的use_ssl是0，所以update mysql_servers set use_ssl=1;将他们改成1。 然后set mysql-ssl_p2s_ca = &#39;/var/lib/proxysql/ApsaraDB-CA-Chain.pem&#39;;设定CA证书所在路径。随后就是load mysql variables to runtime;和save mysql variables to disk;，保存之后使用select * from runtime_global_variables;查看： 验证的方法也很简单，在对应数据库里操作的同时tcpdump -s 0 -i any -v port 3306 -w /root/test.pcap 抓一下包看一下里面的内容是否加密了就行。 补充：虽然SSL方式使得安全性提高了，但是相对地使得QPS也降低23%左右。所以要谨慎选择： 对于非常敏感核心的数据，或者QPS本来就不高的核心数据，可以采用SSL方式保障数据安全性； 对于采用短链接、要求高性能的应用，或者不产生核心敏感数据的应用，性能和可用性才是首要，建议不要采用SSL方式； 配置AWS首先去https://docs.aws.amazon.com/zh_cn/AmazonRDS/latest/UserGuide/UsingWithRDS.SSL.html ，里下载 https://s3.amazonaws.com/rds-downloads/rds-combined-ca-bundle.pem 这个文件，同样上传到服务器里，在proxysql添加路径和配置。 AWS与阿里云不同的地方是，AWS可以针对某个用户开启SSL的，这需要用命令行登录RDS数据库，使用命令GRANT USAGE ON *.* TO &#39;对应用户名&#39;@&#39;%&#39; REQUIRE SSL;（MYSQL 5.6）开启加密，如果想取消掉，就是GRANT USAGE ON *.* TO &#39;对应用户名&#39;@&#39;%&#39; REQUIRE NONE;。 更多信息可以去看：https://docs.aws.amazon.com/zh_cn/AmazonRDS/latest/UserGuide/CHAP_MySQL.html#MySQL.Concepts.SSLSupport 。 参考资料https://github.com/sysown/proxysql/wiki/SSL-Supporthttps://googlebaba.io/mysqlcookbook/7.aboutssl.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"读写分离","slug":"读写分离","permalink":"http://yoursite.com/tags/读写分离/"},{"name":"proxysql","slug":"proxysql","permalink":"http://yoursite.com/tags/proxysql/"},{"name":"ssl加密","slug":"ssl加密","permalink":"http://yoursite.com/tags/ssl加密/"}]},{"title":"Ansible-Playbook判断进程是否存在","slug":"Ansible-Playbook判断进程是否存在","date":"2019-06-27T13:57:14.000Z","updated":"2019-09-04T08:19:46.000Z","comments":true,"path":"2019/06/27/Ansible-Playbook判断进程是否存在/","link":"","permalink":"http://yoursite.com/2019/06/27/Ansible-Playbook判断进程是否存在/","excerpt":"","text":"正文部署有一个需求，要将所有的模块服务器里添加一个叫agentmizar的日志采集模块。但是有一些服务器提前有部署过，那么判断一下如果服务器里有此进程就跳过，如果没有此进程就传包并修改配置文件然后启动。 与playbook搭配的yaml内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950- hosts: all #默认执行hosts里的所有IP remote_user: root any_errors_fatal: no gather_facts: no #不采集对方机器的数据，提高执行速度 serial: - 5 #5台机器一组 tasks: - name: judge agent process is exits shell: ps -aux | grep agent ignore_errors: True #如果命令执行不成功，即 echo $?不为0，则在其语句后面的ansible语句不会被执行，导致整个程序中止。 register: result - name: agent is running shell: echo \"agent is running\" when: result.stdout.find('agent.conf') != -1 - name: agent dir is exits shell: ls /opt/agentmizar ignore_errors: True register: dirresult - name: copy packages copy: src: /tmp/agentmizar.zip dest: /opt owner: root when: dirresult is failed #如果文件夹存在就是dirresult is succeeded - name: unzip agentmizar unarchive: #如果你并不喜欢用unzip的话，那么可以shell:unzip -o 对应.zip的方式来达到不用输入y的效果，但是更推荐用unarchive #extra_opts: -j #将zip里的所有递归文件都放到本目录 src: /opt/agentmizar.zip dest: /opt remote_src: yes when: result.stdout.find('agent.conf') == -1 - name: backup old and unpack new package shell: cp -rf /opt/build/* /opt/ #由于zip包也解压缩出来是一个build文件夹，需要再扒一层 when: result.stdout.find('agent.conf') == -1 - name: update agent.conf lineinfile: dest: /opt/agentmizar/agent.conf regexp: \"kafka = 192.168.0.1:9092,192.168.0.2:9092,192.168.0.3:9092\" #修改配置文件 line: \"kafka = 172.0.10.1:9092\" when: result.stdout.find('agent.conf') == -1 - name: start agentmizar shell: cd /opt/agentmizar/ &amp;&amp; /bin/bash /opt/agentmizar/start_agent.sh when: result.stdout.find('agent.conf') == -1 这个yaml，我执行ps -aux | grep agent，并将结果存储到result这个register里。然后从register里去find关键字agent.conf，如果不存在就返回-1，那么可以判断当前机器里没有agentmizar进程。 如果说进程是一个守护进程，那么在判断进程（比如是systemctl status apache2）是否存在可以这么写： 1234567891011121314- name: Check if Apache is running command: systemctl status apache2 ignore_errors: yes changed_when: false register: service_apache_status- name: Report status of Apache fail: msg: | Service apache2 is not running. Output of `systemctl status apache2`: &#123;&#123; service_apache_status.stdout &#125;&#125; &#123;&#123; service_apache_status.stderr &#125;&#125; when: service_apache_status | failed 注意！如果when条件判断句中有变量的话要将用（）来括变量，如下： 12when: ansible_default_ipv4.address == &#123;&#123; ETCD_NODE03 &#125;&#125; #错误写法when: ansible_default_ipv4.address == (ETCD_NODE03) #正确写法 再注意！register变量的命名不能用-（中横线），比如dev-sda6_result，则会被解析成sda6_result，dev会被丢掉！ yum一次性安装多个模块的问题新版本的ansible-playbook已经不支持在yum安装多个模块里使用的方式了，也就是说 1234567tasks- name: 安装最新版本的命令yum: name=&#123;&#123; item &#125;&#125; state=latestwith_items: - unzip - psmisc - java-1.8.0-openjdk* 这么写在老版本还OK，但是在2.8以后，还这么写就会有错误：[DEPRECATION WARNING]: Invoking &quot;yum&quot; only once while using a loop via squash_actions is deprecated. Instead of using a loop to supply multiple items and specifying name: &quot;&quot;, please use name: [&#39;unzip&#39;, &#39;psmisc&#39;, &#39;java-1.8.0-openjdk*&#39;] and remove the loop. This feature will be removed in version 2.11. Deprecation warnings can be disabled by setting deprecation_warnings=False in ansible.cfg.要改成如下： 12345678tasks: - name: 安装最新版本的命令yum: state: latest name: - unzip - psmisc - java-1.8.0-openjdk* 如何在task之间传递变量某个变量想从一个task给另一个，可以按照如下的方式写： 12345678910---- hosts: all gather_facts: no tasks: - name: register vars shell: hostname register: info - name: display vars debug: msg=\"&#123;&#123;info.stdout&#125;&#125;\" 第一个shell执行完后，使用register获取数据到info里，info是一个key value字典，debug输出info.stdout的具体内容。 参考资料https://www.ibm.com/developerworks/cn/linux/1608_lih_ansible/index.htmlhttps://blog.51cto.com/liuzhengwei521/1962382 （条件判断）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://yoursite.com/tags/ansible/"},{"name":"批量部署","slug":"批量部署","permalink":"http://yoursite.com/tags/批量部署/"}]},{"title":"Python端口探测脚本","slug":"Python端口探测脚本","date":"2019-06-25T14:22:23.000Z","updated":"2019-06-26T03:55:32.000Z","comments":true,"path":"2019/06/25/Python端口探测脚本/","link":"","permalink":"http://yoursite.com/2019/06/25/Python端口探测脚本/","excerpt":"","text":"有一个模块最近总是假死，假死的现象就是进程还在但是端口（9030端口）已经不工作了。于是就需要写一个端口探测脚本，发现该端口一旦无法正常收到信息，就重启此模块。 由于此模块是一个五台机器的集群，我这次没有在五台机器都跑一样的脚本，而是在一个可以免密码ssh到他们的机器上写了一个脚本，让这个机器去探测对应的端口。模式如图： 先创建一个detect.conf如下，他的格式是yaml，所以不要用tab用空格： 1234567891011121314151617181920--- Name: localhost IP: 127.0.0.1 Port: 9030--- Name: mrs-05 IP: 10.0.1.14 Port: 9030--- Name: mrs-04 IP: 10.0.1.13 Port: 9030--- Name: mrs-03 IP: 10.0.1.12 Port: 9030--- Name: mrs-02 IP: 10.0.1.11 Port: 9030 脚本detect.py内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950# !/usr/bin/env python # -*- coding:utf-8 -*-# 作者：ChrisChan# 用途：Python3.6脚本，检测IP端口连接是否正常,建议放在单独的机器里进行端口扫描，此脚本需要搭配同目录下的detect.conf使用。# 请先pip install PyYaml,pip install paramikoimport socketimport paramikoimport yaml# ssh秘钥地址key_filename = \"秘钥地址,即id_rsa\"# 重启进程命令command = \"具体的进程启动命令\"def is_open(ip, port): s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) try: s.connect((ip, int(port))) s.shutdown(2) return True except: return Falsedef ssh(ip): ssh = paramiko.SSHClient() ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) try: ssh.connect(ip, 22, \"appuser\", key_filename=key_filename) #这里写死了22端口和appuser用户 except FileNotFoundError as e: print('私钥文件不存在！') except AuthenticationException as e: print('私钥不正确，请检查对应用户或私钥内容！') else: stdin, stdout, stderr = ssh.exec_command(command) print(stdout.readlines()) finally: ssh.close()if __name__ == '__main__': input = open('detect.conf', 'r') # 这里是pyyaml 5.1的新格式 ys = yaml.load_all(input, Loader=yaml.FullLoader) for y in ys: host = y[\"IP\"] #从yaml里取值 port = y[\"Port\"] if is_open(host, port): print(y[\"Name\"] + \" is OK\") else: print(y[\"Name\"] + \" is NO\") ssh(host) print(\"Process is started!\") 内网探测效果还不错，如果时间耗时比较长，就放弃for循环，走多进程路线更佳！","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python3","slug":"python3","permalink":"http://yoursite.com/tags/python3/"}]},{"title":"使用Alpine当基础镜像的坑","slug":"使用Alpine当基础镜像的坑","date":"2019-06-24T09:09:32.000Z","updated":"2019-06-26T14:42:00.000Z","comments":true,"path":"2019/06/24/使用Alpine当基础镜像的坑/","link":"","permalink":"http://yoursite.com/2019/06/24/使用Alpine当基础镜像的坑/","excerpt":"","text":"踩坑正文今天部署开发要上一个新模块，此模块已经通过golang编译好的，而且在本地机器可以正常启动，现在需要将其容器化—-制作一个镜像，然后在根据这个镜像启动程序。 本着基础镜像最小的原则，就选择了alpine:latest。先创建一个干净的alpine镜像挂载模块所在的文件夹，然后docker exec进去执行启动脚本。发现启动脚本里涉及到了cpulimit、rpm、ps -p、 sudo等alpine非自带命令所以无法启动。alpine安装模块的命令即非yum又非apt-get，而是apk add，于是在Dockerfile里添加一句： 1RUN apk add cpulimit &amp;&amp; apk add rpm &amp;&amp; apk add sudo &amp;&amp; apk --update add procps 新镜像制作完毕，进去启动还是失败。具体表现是./启动脚本的时候报&quot;no such file or directory&quot;，开始我以为是因为alpine没有/bin/bash的缘故，把所有的shebang都改成了/bin/sh。但是发现启动的时候报格式错误，我想到这是一个go编译好的脚本，那么./就应该可以直接启动的。后来在https://github.com/gin-gonic/gin/issues/1178 里查到原来alpine里是没有稳定的libc，所以还要添加libc6-compat和libstdc++。 在镜像里apk add libc6-compat &amp;&amp; apk add libstdc++之后，发现启动脚本还有这样一句话： 1echo './core_%e.%p' | sudo tee /proc/sys/kernel/core_pattern 这个命令是无法执行的，因为docker里/proc/sys/kernel/core_pattern是只读文件，自然无法进行修改。但是宿主机上的这个文件是root用户可以修改的。这可怎么办？ 我开始想既然宿主机的/proc/sys/kernel/core_pattern可以修改，那么就把宿主机的/proc/sys/kernel/core_pattern挂载给镜像不就得了？但是在执行的时候会报错：cannot be mounted because it is located inside “/proc”，因为Docker不允许在proc目录下随意挂文件，如果你有信心可以通过修改docker的源码来实现挂载的效果。 但是我觉得还是沉稳为上，于是就想出一个办法：在docker run的时候添加--privileged，这样容器获得了额外的特权可以对系统变量的值进行修改。但是要注意如果容器发生了重启，那么值会恢复成原样，即无法持久化。不过在启动脚本里已经有了echo语句，这样每一次执行启动脚本都会更改/proc/sys/kernel/core_pattern，于是就不用太担心这个问题了。 最后完整的Dockerfile如下： 1234567FROM alpine:latestMAINTAINER ChrisChan &lt;33664@dahuatech.com&gt;RUN apk update &amp;&amp; apk add libc6-compat &amp;&amp; apk add libstdc++ &amp;&amp; apk add cpulimit &amp;&amp; apk add rpm &amp;&amp; apk add sudo &amp;&amp; apk --update add procpsRUN mkdir -p /mnt/agentmizar #agentmizar这个就是工作的模块名WORKDIR /mnt/agentmizar #设定工作目录CMD [\"sh\", \"control\", \"start\"] #启动之 创建完镜像之后，启动语句如下： 1docker run --name 容器名 -dit -v /opt/:/opt/:ro -v /etc/localtime:/etc/localtime:ro --privileged 镜像名 #别忘了对准时间 补充一句，最后镜像大小不到50MB。 参考资料https://blog.csdn.net/qq_41980563/article/details/88876874https://serverfault.com/questions/883625/alpine-shell-cant-find-file-in-dockerhttps://sq.163yun.com/blog/article/155817999160799232","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"Golang","slug":"Golang","permalink":"http://yoursite.com/tags/Golang/"}]},{"title":"研究一下Zabbix 3.4的服务主动发现功能","slug":"研究一下Zabbix-3-4的服务主动发现功能","date":"2019-06-21T09:24:11.000Z","updated":"2019-06-24T03:02:12.000Z","comments":true,"path":"2019/06/21/研究一下Zabbix-3-4的服务主动发现功能/","link":"","permalink":"http://yoursite.com/2019/06/21/研究一下Zabbix-3-4的服务主动发现功能/","excerpt":"","text":"我所在组一直以来对不同服务的监控方针是：针对不同的服务（比如nginx,tomcat,mysql等等）创建不同的template，然后将这个template应用于对应的服务器上，在每一个template里添加具体的item和trigger。今天尝试一下全新的自动发现Low-level discovery（LLD）。 LLD对返回的内容有一个json格式，这个json格式必须要被zabbix-server识别。所以我们需要准备一个脚本，脚本的结果就是生成这个json。本文zabbix-server和zabbix-agent的版本都是3.4.15。 服务器内部操作首先在被监控服务器里，创建一个脚本/etc/zabbix/script/discovery_services.sh，内容如下： 1234567891011121314151617181920#!/bin/bashproarray=($(find /var/run/ -name \"*.pid\"|egrep -v '(rpc|php_daemon|haldaemon|irqbalance|console-kit-daemon)' |awk -F'/' '&#123;print $NF&#125;'|awk -F'.' '&#123;print $1&#125;')) # 排除不监控的服务length=$&#123;#proarray[@]&#125; #$&#123;#var&#125;是用来取长度printf \"&#123;\\n\"printf '\\t'\"\\\"data\\\":[\"printf \"\\t\"printf '\\n\\t\\t&#123;'printf \"\\\"&#123;#PRO_NAME&#125;\\\":\\\"iptables\\\"&#125;\" #必须要添加的iptablesprintf \",\"for ((i=0;i&lt;$length;i++))do printf '\\n\\t\\t&#123;' printf \"\\\"&#123;#PRO_NAME&#125;\\\":\\\"$&#123;proarray[$i]&#125;\\\"&#125;\" #for循环取每一项 if [ $i -lt $[$length-1] ];then printf ',' fidoneprintf \"\\n\\t]\\n\"printf \"&#125;\\n\" 这里我们设定将所有的进程文件的pid统一放到/var/run下，这样能取到所有进程的文件。脚本里的{PRO_NAME}这个就是自动发现规则中的宏变量，另外这个脚本返回的是符合zabbix-server的json格式。如图： 同时在加上一个判断进程是否运行的脚本/etc/zabbix/script/program_status.sh，内容如下： 1234567891011121314151617#!/bin/bashprocjetName=\"$&#123;1:-NULL&#125;\"LOCK_PATH=\"/var/lock/subsys\" RUN_PATH=\"/var/run\"ret_ok=1ret_critical=3ret_unknown=4if [[ $&#123;procjetName&#125; == \"NULL\" ]] ; then echo $&#123;ret_unknown&#125;fiif [ -f \"$&#123;LOCK_PATH&#125;/$&#123;procjetName&#125;\" ] || [ -f \"$&#123;RUN_PATH&#125;/$&#123;procjetName&#125;.pid\" ] || [ -f \"$&#123;RUN_PATH&#125;/$&#123;procjetName&#125;/$&#123;procjetName&#125;.pid\" ] ; then echo $&#123;ret_ok&#125;else echo $&#123;ret_critical&#125;fi 这个脚本的结果就是：服务若存在就返回1，否则返回3。如图： 然后在zabbix_agentd.conf里添加两个items，如下： 12UserParameter=services.scan,/bin/bash /etc/zabbix/script/discovery_services.shUserParameter=services.status[*],/bin/bash /etc/zabbix/script/program_status.sh $1 服务端操作到此结束。 WEB端操作添加自动发现规则与添加item很相似，先configuation—templates—create template: 在新生成的“服务进程自动发现”的template里添加Discovery rules，设定Key是Services.scan如下： 上面那个Services.scan到时候要写到zabbix-agent.conf里的，切记保持一模一样。然后在点击Filters标签页，如下： 此处的{PRO_NAME}就是我们的脚本返回的变量，保存之。然后创建一个item prototypes，如图： 此处需要注意的$1和键值是我们之前定义的，也即是服务名，保存之。 然后创建一个trigger prototype，如图： 图中的解释器是： 1(&#123;auto Service discovery:services.status[&#123;#PRO_NAME&#125;].last()&#125;&lt;&gt;1) and (&#123;auto Service discovery:services.status[&#123;#PRO_NAME&#125;].last(,1h)&#125;=1) 这句话的意思是“最后状态不是1同时一小时前的状态是1”的服务出现了问题会发生报警，这主要是因为当启动一些临时进程，比如yum，当yum完毕了之后，进程就不存在了，那么如果只是通过判断进程数的话，就会报yum is down。 至此web端配置结束。 错误解决如果web界面出现了Value should be a JSON object.的错误，如图： 跑到zabbix-server去zabbix-get一下发现有错误： 将mdadm这个文件夹改成755即可。回到web页面查看一下latest data: 参考资料https://www.zabbix.com/documentation/3.4/zh/manual/discovery/low_level_discoveryhttps://www.xiaomastack.com/2015/07/04/zabbix-auto-tcp-port/https://www.cnblogs.com/fengbohello/p/5954895.html （Linux Shell 截取字符串）http://caosiyang.github.io/2017/03/06/zabbix-get-value-error/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"监控","slug":"监控","permalink":"http://yoursite.com/tags/监控/"},{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"}]},{"title":"网易雷火运维面试全纪录","slug":"网易雷火运维面试记录","date":"2019-06-20T06:12:57.000Z","updated":"2019-09-23T03:59:46.000Z","comments":true,"path":"2019/06/20/网易雷火运维面试记录/","link":"","permalink":"http://yoursite.com/2019/06/20/网易雷火运维面试记录/","excerpt":"","text":"电话一面 都搞过什么linux的发行版，区别是啥？ 为什么云服务器普遍不装swap？ 1小内存主机由于内存不足导致持续swapping后会严重影响存储设备的IO性能。其实如果需要使用swap的话，主机性能也已经是烂的一塌糊涂，根本不能满足使用了，建议增加内存为上。 localhost与127.0.0.1的区别 1localhost（local）是不经网卡传输！这点很重要，它不受网络防火墙和网卡相关的的限制。127.0.0.1是通过网卡传输，依赖网卡，并受到网络防火墙和网卡相关的限制。 iptables的四表五链是啥？ 出现延迟都有原因？ 如何把数据库恢复到指定时刻？ 你从业以来参与的比较大的故障是什么？怎么解决的？ 如果要大量insert数据到数据库，有什么优化的方法？ 123451)一条SQL语句插入多条数据:比如一次insert插入多个values，INSERT INTO `insert_table` (`datetime`, `uid`, `content`, `type`) VALUES ('0', 'userid_0', 'content_0', 0), ('1', 'userid_1', 'content_1', 1);这样的好处是减少binlog和innodb的日质量，降低了日志刷盘的频率提高效率，同时减少了网络传输的IO，这个优化效果特别明显；2）把多一个insert写成一个事务，进行一个insert操作时，MySQL内部会建立一个事务，在事务内才进行真正插入处理操作。通过使用事务可以减少创建事务的消耗，所有插入都在执行后才进行提交操作；3）数据按照主键有序插入，因为数据库插入时，需要维护索引数据，无序的记录会增大维护索引的成本，不过这个方法提高的并不明显；4）以上方法综合使用； 电话二面 介绍一下你自己 使用docker遇到了什么坑？ docker的网络模式有哪些？为什么不能选hosts？ 服务器调整进程优先级的命令是啥？ 123456789一般来说微服务（即一个云服务器只跑一个进程）的场景来说，这个问题很少遇到，但是实际很多公司是一个服务器（比如80核160G）跑多个进程，那么对后台的程序有优先级限制就要使用`nice`命令。Linux系统中，进程有-19到19这39个优先级。-19最优先，19最不优先。进程的默认优先级为0。如果希望将进程调整为最优先，则将进程的nice值设置为-19；如果希望进程最不优先，占用最少的系统CPU时间，则将其设置为19。修改已经存在的进程的优先级将PID为1799的进程优先级设置为最低（19）：renice 19 1799将PID为1799的进程优先级设置为最高（-19）：renice -19 1799新建进程并设置优先级nice -19 tar zcf pack.tar.gz documents #这里-19并不是最高优先级，而是最低优先级，要设定最高优先级是--19 python的==和is有什么不同？ 1is比较的是id是不是一样，==比较的是值是不是一样。 如何删除某文件下所有名称带有空格的文件？ 12可以通过转义符，或者获取文件的inode，根据inode删除对应的文件:find -inum 编号 -delete比如想rm文件名为“my file”的文件可以用rm my\\ file ansibleplaybook的回滚方法？ 如果nginx的server设置了add header，同时子location也设置了add header，那么会有什么现象？ 如何判断查询是否用到了索引？ 12使用explain，如果type类型是all就是没有用到索引，如果是其他具体类型就是用到了索引。索引依次从好到差：system，const，eq_ref，ref，fulltext，ref_or_null，unique_subquery，index_subquery，range，index_merge，index，ALL，除了all之外，其他的type都可以使用到索引，除了index_merge之外，其他的type只可以用到一个索引。 现场技术一面 写一下Python序列循环移位的方法，原来是[1,2,3,4,5,6]，变成[3,4,5,6,1,2]，任意语言都可以。 1234使用切片，简单易理解，速度最快，可同时实现循环左移（k&gt;0）和右移（k&lt;0）。def demo(lst, k): return lst[k:] + lst[:k] 你们平时备份mysql使用什么方法？为什么用这个开源软件？ 服务器你们是如何初始化的？ 简单的介绍一下python的生成器？ 如果发现慢sql你怎么排查？ 发现java服务出现了CPU飙升的现象，怎么排查？ 除了代码问题之外，都有哪些情况会导致CPU 100%？ 都做过什么优化？（主动运维方向） 剩下的就是一些流程性的问题了。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/tags/大牛之路/"},{"name":"面试","slug":"面试","permalink":"http://yoursite.com/tags/面试/"}]},{"title":"XtraBackup的安装和使用","slug":"XtraBackup的安装和使用","date":"2019-06-17T02:37:56.000Z","updated":"2019-09-26T07:07:04.000Z","comments":true,"path":"2019/06/17/XtraBackup的安装和使用/","link":"","permalink":"http://yoursite.com/2019/06/17/XtraBackup的安装和使用/","excerpt":"","text":"XtraBackup是数据库物理备份工具，是阿里云RDS备份数据库的组件。它的优点是热备而且速度快，效率比mysqldump不知道高到哪里去了。它的备份原理如下: innobackupex首先会启动一个xtrabackup_log后台检测的进程，实时检测mysql的redo log的变化，一旦发现redo有新的日志写入，立刻将日志写入到日志文件xtrabackup_log中。 物理拷贝innodb的数据文件和系统表空间文件idbdata1到对应的以默认时间戳为备份目录的地方 复制结束后，执行flush table with read lock操作进行全库锁表准备备份非InnoDB文件 复制.frm .myd .myi等非InnoDB引擎文件 查看binary log 的位置 解锁unlock tables 停止xtrabackup_log进程 安装与全量备份先去https://www.percona.com/downloads/Percona-XtraBackup-2.4/LATEST/ 下载2.4版本的XtraBackup，虽然最新的版本是8.0.6，但是据说它只支持mysql8.0和percona8.0… 安装步骤如下： 12345678910[root@share ~]# yum install -y cmake libaio-devel[root@share ~]# yum install glibc glibc-devel glibc-static perl-Digest-MD5 perl-DBD-MySQL -y [root@share ~]# wget ftp://rpmfind.net/linux/atrpms/el6-x86_64/atrpms/stable/libev-4.04-2.el6.x86_64.rpm [root@share ~]# rpm -ivh libev-4.04-2.el6.x86_64.rpm #xtrabackup安装依赖libev.so.4()(64bit) [root@share ~]# rpm -ivh percona-xtrabackup-24-2.4.14-1.el6.x86_64.rpm warning: percona-xtrabackup-24-2.4.14-1.el6.x86_64.rpm: Header V4 RSA/SHA256 Signature, key ID 8507efa5: NOKEYPreparing... ################################# [100%]Updating / installing... 1:percona-xtrabackup-24-2.4.14-1.el################################# [100%][root@share ~]# 安装完毕之后，就可以innobackupex --host=127.0.0.1 --user=root --password=数据库密码 --defaults-file=/etc/mysql/my.cnf /备份的文件夹名来备份数据库。同时备份结束之后会生成一个LSN号，在增量备份时候，就只备份大于此号的数据页。 如果有了备份文件想要全量恢复的话，就是如下操作： 1234567scp -r /backup/备份文件夹/ 另一个mysqlIP:/backup/ #先将本机的备份文件夹拷贝到其他服务器里去innobackupex --apply-log --use-memory=1G /backup/备份文件夹/ #在新的mysql里进行数据的准备工作，这一步用来合成可用的数据，--use-memory根据实际情况指定systemctl stop mariadbrm -rf /var/lib/mysql/* #停止当前进程，并且删除数据目录和对应日志innobackupex --datadir=/var/lib/mysql --copy-back /backup/备份文件夹/ #将准备好的数据还原到对应目录里chown -R mysql: /var/lib/mysql/ #将文件夹属主和组都更改成mysqlsystemctl start mariadb #重启进程 增量备份与恢复增量备份的前提是全量备份，假设我们已经进行了全量备份。增量备份过程如下： 12345678910innobackupex -p数据库密码 --incremental /全量备份文件夹 --incremental-basedir=/backup/增量备份文件夹1/ #与全量备份文件夹相比，进行增量备份scp -r /backup/* 另一个mysqlIP:/backup/ #传递给另个mysql里innobackupex --apply-log --redo-only --use-memory=1G /backup/全量备份文件夹/ #先对最早的全量备份进行恢复innobackupex --apply-log --redo-only --use-memory=1G /backup/全量备份文件夹/ --incremental-dir=/backup/增量备份文件夹1 #在之前全量备份的基础上合并一波增量备份systemctl stop mariadbrm -rf /var/lib/mysql/* #停止当前进程，并且删除数据目录和对应日志innobackupex --datadir=/var/lib/mysql --copy-back /backup/备份文件夹/ #将准备好的数据还原到对应目录里chown -R mysql: /var/lib/mysql/ #将文件夹属主和组都更改成mysqlsystemctl start mariadb #重启进程 查看是否是增量备份还是全量备份，可以通过xtrabackup_checkpoints文件里的backup_type字段：full-prepared是全量备份、incremental是增量备份。 这里有一个坑，就是备份和恢复的时候使用的xtrabackup的版本要保持一致，如果不一致，就会有Failed to connect to MySQL server to detect version.的错误。如果出现了错误，就要根据mysql版本在原有命令后添加--ibbackup xtrabackup_版本号，比如我的mysql是5.6版本的，那么语句就是innobackupex --use-memory=1G --apply-log /data/back --ibbackup xtrabackup_56 。 Mysql如何恢复到任意时间点众所周知，mysql的更新操作（UPDATE）是“先备份再覆盖”的一个过程，那备份在哪里呢?buffer。 但是这个瞬间就会出现buffer的数据页与磁盘的数据页内容不一致，这时的buffer的数据页叫dirty page。如果此时出现了mysql非正常宕机，就会出现“数据并没有同步到磁盘文件中，而且已经从内存里出来了”的现象，即数据丢失。 为了解决这个现象，就在buffer的dirty page变更结束之后，把相应修改记录记录到redo log里。如果在发现有数据丢失的现象，可以通过redo log回溯。更多内容可以看https://mp.weixin.qq.com/s?__biz=MjM5NjMyMjUzNg==&amp;mid=2448131616&amp;idx=1&amp;sn=5af80b03adef5846b7dc51015d99f7e7&amp;scene=0#wechat_redirect&amp;rd2werd=1#wechat_redirect 这篇文章。 整理一下mysql里更新语句的内幕： 系统当取到一个UPDATE语句的时候，会先通过主键找到该行，判断此行是否在buffer里，如果在就直接返回给执行器，如果不在就先从磁盘拷贝一份到内存里，在内存里对数据进行修改，此时生成了dirty page，同时也将这个操作记录更新到redo log里，redo log处于prepare状态（mysql生成xid)，通知执行器可以提交覆盖磁盘（这是一个事务）。然后执行器先生成这个操作的bin log（mysql是日志先行的设计），然后再执行覆盖的操作（将xid写进bin log)，至此更新完成。 假设此时mysql出现了非正常宕机，那么先找一下有没有之前的xtrabackup等工具保留的备份，如果有当日的备份，再结合bin log可以恢复一个临时表。然后扫描最后一个bin log，提取出xid。重做检查点以后的redo log，搜集处于prepare阶段的事务链表，将事务的xid与bin log中的xid对比。若存在，说明事务记录到bin log成功，只是最终未commit成功，可以直接提交，否则就回滚。 参考文档http://mysql.taobao.org/monthly/2016/03/07/http://mysql.taobao.org/monthly/2018/02/05/https://mp.weixin.qq.com/s?__biz=MjM5NjMyMjUzNg==&amp;mid=2448131616&amp;idx=1&amp;sn=5af80b03adef5846b7dc51015d99f7e7&amp;scene=0#wechat_redirect&amp;rd2werd=1#wechat_redirecthttps://help.aliyun.com/knowledge_detail/41738.html?spm=a2c4g.11186631.2.4.2b9d6998v5nwaK","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"数据备份","slug":"数据备份","permalink":"http://yoursite.com/tags/数据备份/"}]},{"title":"记录一次优化前端docker的过程","slug":"记录一次优化前端docker的过程","date":"2019-06-12T07:48:42.000Z","updated":"2019-06-12T13:35:12.000Z","comments":true,"path":"2019/06/12/记录一次优化前端docker的过程/","link":"","permalink":"http://yoursite.com/2019/06/12/记录一次优化前端docker的过程/","excerpt":"","text":"最初优化前端node项目一直以来虽然是容器部署，但是是很粗糙的形式—每次更新的过程给各位感受一下： 1先在宿主机里去项目文件夹里执行`git pull`，然后 docker exec -it 容器名 /bin/bash 进入到对应容器里，然后执行`pm2 flush`、`npm run build`和`pm2 reload 0`。 这种拿docker做虚拟机的行为实在是让人“叔可忍婶不可忍”。于是就要改变一下这个思路，重写一个dockerfile，内容如下： 12345678FROM keymetrics/pm2:latest-alpineMAINTAINER ChrisChan &lt;chen_shuo@dahuatech.com&gt;WORKDIR /var/www/node/shopFrontCOPY shopFront/ . #由于上面已经指定了WORKDIR的地址，所以COPY/ADD/RUN等命令的相对路径都是WORKDIR的路径，所以这里是.RUN git pull &amp;&amp; npm run buildEXPOSE 3000 #暴露3000端口CMD [ \"pm2\", \"start\", \"npm\"] 然后docker build -t=&quot;ecnode：0.1&quot; .生成镜像，docker run --name ECNODE -it -p 33664:3000 ecnode:0.1启动叫ECNODE的容器，发现服务站不住，启动完了后就死了。其实这里不能用pm2 start npm这种启动方法，应该用pm2-docker start XXX.js作为CMD，这样才能在后台站住。效果如图： 继续折腾上面这个dockerfile打成镜像的时间总共是165秒，如图： 分析一下发现时间大量的消耗在npm run build和COPY这两个步骤上了，因为dockerfile所在的文件夹shopFront/(项目文件夹）里包括node_modules，这个文件夹大小是220M左右，复制肯定比较消耗时间。于是我尝试换了一个Dockerfile写法： 1234567891011FROM keymetrics/pm2:latest-alpineMAINTAINER ChrisChan &lt;33664@dahuatech.com&gt;RUN mkdir -p /var/www/node/shopFrontWORKDIR /var/www/node/shopFront #设定工作目录COPY package.json . #package.json要跟dockerfile在同一个文件夹下RUN npm install COPY shopFront/ . #再将其他的内容拷贝过去RUN git pullEXPOSE 3000CMD [ \"pm2-docker\", \"start\", \"server.js\"] 执行之后效果如图： 妈的，时间反而多了20秒。不过这样文件夹里就不用带着node_modules，因为npm install会生成一个node_modules。不过这个0.2镜像比之前的多不到100M。所以看来看去还是0.1更划算。 补充一下：docker ps -a --no-trunc是查看docker ps完全命令，有的时候COMMAND显示不全就用它。 参考资料https://pm2.io/doc/zh/runtime/integration/docker/#%E8%AE%BE%E7%BD%AE%E4%B8%80%E4%B8%AAdocker%E6%96%87%E4%BB%B6https://mp.weixin.qq.com/s?__biz=MzA5OTAyNzQ2OA==&amp;mid=2649700687&amp;idx=1&amp;sn=a656b7c7fdacc1b3df97c1d2630e50d9&amp;scene=21#wechat_redirecthttps://stackoverflow.com/questions/35774714/how-to-cache-the-run-npm-install-instruction-when-docker-build-a-dockerfile","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"前端node","slug":"前端node","permalink":"http://yoursite.com/tags/前端node/"},{"name":"前端pm2","slug":"前端pm2","permalink":"http://yoursite.com/tags/前端pm2/"}]},{"title":"使用Zabbix监控logstash","slug":"使用zabbix监控logstash","date":"2019-06-11T07:04:28.000Z","updated":"2019-06-11T12:54:14.000Z","comments":true,"path":"2019/06/11/使用zabbix监控logstash/","link":"","permalink":"http://yoursite.com/2019/06/11/使用zabbix监控logstash/","excerpt":"","text":"配置过程logstash常规的监控项可以去移步 https://github.com/fredprod/logstash-zabbix ，有模板有脚本，可以说是非常全面、服务到家了。 本文主要是要监控logstash的tps，先说一下tps的定义：它是Transactions Per Second（每秒传输的事物处理个数），即服务器每秒处理的事务数。TPS包括一条消息入和一条消息出，加上一次用户数据库访问。我们从TPS里反馈出logstash的实时工作状态。 首先先要安装logstash-output-zabbix，安装方法很简单：在logstash/bin目录下执行./logstash-plugin install logstash-output-zabbix，如图： 然后在启动logstash对应的conf文件里，新增如下的配置： 12345678910111213141516171819202122232425262728input &#123; ...&#125;filter &#123; ...原有配置略 metrics &#123; meter =&gt; \"events\" #这里统计经过filter的事件 add_tag =&gt; \"metric\" add_field =&gt; &#123;\"[@metadata][zabbix_key]\" =&gt; \"logstash_events\"&#125; #zabbix item的key，这个要和zabbix-server的配置一致 add_field =&gt; &#123; \"[@metadata][zabbix_host]\" =&gt; \"被监控机器名\" &#125; #zabbix写入的主机 flush_interval =&gt; 30 #设定写入频率，我这里是30秒一次 &#125; &#125; output &#123; ...原有配置略 if \"metric\" in [tags] &#123; zabbix &#123; zabbix_server_host =&gt; \"172.31.0.77\" #这里是zabbix-server的地址 zabbix_host =&gt; \"[@metadata][zabbix_host]\" zabbix_key =&gt; \"[@metadata][zabbix_key]\" zabbix_value =&gt; \"[events][count]\" #[events][count] 是事件统计数据， &#125; &#125; 保存之后，来到zabbix-server的web端，新增一个items，如下： 注意！这个items的类型是zabbix-trapper（Zabbix采集器）！同时设定Preprocessing steps为simple change。 然后重启logstash即可。重启之后，如果出现了如下的错误： 12[2019-06-11T15:53:33,789][WARN ][logstash.outputs.zabbix ] Zabbix server at ZABBIXIP地址 rejected all items sent. &#123;:zabbix_host=&gt;\"被监控机器名\"&#125;[2019-06-11T15:53:43,797][WARN ][logstash.outputs.zabbix ] Zabbix server at ZABBIXIP地址 rejected all items sent. &#123;:zabbix_host=&gt;\"被监控机器名\"&#125; 检查一下zabbix_key、zabbix_host是否与zabbix-server网页端配置的完全一致，而且zabbix_value也最好不要是具体值，[events][count]就可以了。 然后在zabbix-server端就可以看到tps结果了： 使用systemctl启动logstash我这个logstash是tar包安装的，每一次杀死启动都是敲命令，看上去很挫，于是就要转成systemctl的方式。首先先创建logstash用户和用户组，确认logstash用户在logstash用户组里。然后需要改几个地方： 先去pipelines.yml里修改path.config: “/logstash路径/config/*.conf”，改成实际的配置文件。然后再在同文件夹的startup.options里修改 123LS_HOME=/usr/share/logstash-6.2.3 项目目录LS_SETTINGS_DIR=\"$LS_HOME/config\"LS_OPTS=\"--path.settings $&#123;LS_SETTINGS_DIR&#125;\" 再logstash安装路径下执行./bin/system-install /logstash安装路径/config/startup.options systemd。一会就能看到一个成功的字样，去/etc/systemd/system/logstash.service目录可以看到配置文件。此时就是可使用systemctl enable/start/stop/restart logstash.service来操作了！ 参考资料https://www.zabbix.com/cn/integrations/logstashhttps://notes-by-yangjinjie.readthedocs.io/zh_CN/latest/service/elk/08-logstash-output-zabbix.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"elk","slug":"elk","permalink":"http://yoursite.com/tags/elk/"},{"name":"tps","slug":"tps","permalink":"http://yoursite.com/tags/tps/"}]},{"title":"搭建V2Ray服务端搭配Shadowrocket使用","slug":"搭建V2Ray服务端搭配Shadowrocket使用","date":"2019-06-10T12:17:49.000Z","updated":"2019-06-11T02:54:30.000Z","comments":true,"path":"2019/06/10/搭建V2Ray服务端搭配Shadowrocket使用/","link":"","permalink":"http://yoursite.com/2019/06/10/搭建V2Ray服务端搭配Shadowrocket使用/","excerpt":"","text":"搭建服务端由于今年是“六四事件”三十周年，从6月1号开始，大陆范围内铺天盖地的封网行动开始了。记得今年两会期间，也有短暂的封网，只不过那次是封端口，这次就比较狠了，直接被GFW封IP（即国内ISP无法访问服务器，但是国外的IP可以正常访问）。 没有外网的日子真是难受哇，经过这两天的研究，我终于再次成功使用AWS（为什么不用阿里云，人家也要吃饭的嘛）搭建了梯子客户端。这次不再用shadowsocks了，而改用了v2ray。 首先在AWS加拿大区域买了一个centos7，配置好秘钥和基本信息，然后ssh登录，开始搭建v2ray服务端。步骤如下： 1234567891011sudo yum -y install wgetsudo yum install -y zip unzipwget https://install.direct/go.shsudo bash go.sh ## 启动sudo systemctl start v2ray## 停止sudo systemctl stop v2ray## 重启sudo systemctl restart v2ray 然后sudo cat /etc/v2ray/config.json，查看一下当前开启的端口号，返回aws控制台在对应的安全组里放开此端口号，可以跑到别的服务器上去telnet试一下，通了就是OK！ 配置shadowrocketsv2ray默认用的是vmess协议，由于我的iphone里只有白色的小火箭。所以就要改一下配置文件，在/etc/v2ray/config.json配置文件新增一个协议： 1234567891011\"inboundDetour\": [&#123; \"protocol\": \"shadowsocks\", \"port\": 443, #对应的端口 \"settings\": &#123; \"method\": \"aes-256-cfb\", \"password\": \"加密密码\", \"udp\": false &#125;&#125;], 这样就可以让V2Ray支持Shadowsocks协议。不过这里要注意，此时shadowrockets不应该填写v2ray的端口而是填写443这个端口，所以别忘了把这个端口加入到安全组里。 套一个CDN在V2Ray前套一个CDN，可以让防火请不会那么快的发觉你的真实IP。原理说起来很简单：先在服务器上用v2ray伪装成一个网站，再用CDN中转，那么，你的流量就是这样传递的： 于是我选择了使用阿里云的CDN，由于我的IP是加拿大的，所以选择了全球加速。配置好源站信息后，再去申请一个域名，把CNAME复制进去即可。这时候在手机的shodowrocket里，服务器信息就直接写刚刚申请的域名（不是CNAME），端口写80就行，测试一晚，看看阿里云的CDN会不会出事… 参考资料https://www.4spaces.org/digitalocean-build-v2ray-0-1/?replytocom=593#respondhttps://www.rultr.com/tutorials/proxy/2580.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"翻墙","slug":"翻墙","permalink":"http://yoursite.com/tags/翻墙/"},{"name":"v2ray","slug":"v2ray","permalink":"http://yoursite.com/tags/v2ray/"},{"name":"ssr","slug":"ssr","permalink":"http://yoursite.com/tags/ssr/"}]},{"title":"调整Django使其可以上传大文件和多文件","slug":"调整Django使其可以上传大文件和多文件","date":"2019-06-06T06:16:24.000Z","updated":"2019-06-06T08:51:28.000Z","comments":true,"path":"2019/06/06/调整Django使其可以上传大文件和多文件/","link":"","permalink":"http://yoursite.com/2019/06/06/调整Django使其可以上传大文件和多文件/","excerpt":"","text":"更改上传文件大小限制我的django上传文件工具代码是https://rorschachchan.github.io/2018/12/19/Django实现图片上传/ 这么写的，但是发现再上传大的图片（7M左右的GIF图片）时，出现了413的错误提示： 我上传的方法request.FILES.getlist，但是文件的体积太大了，所有就有这样的错误。去django的官方文档https://docs.djangoproject.com/en/2.2/ref/settings/#file-upload-max-memory-size 查了一下： 原来django默认的上传文件大小是2.5M，小于2.5M时，会放在InMemoryFileUploadFile（内存里面）对象里面；大于2.5M时，会放在TemporaryFileUploadFile（磁盘文件）里面。于是我们就要更改一下这个大小，改成25M。这个要谨慎使用，小心内存溢出。 打开settings.py，增加一句 12FILE_UPLOAD_MAX_MEMORY_SIZE = 26214400 #上传文件大小，改成25MDATA_UPLOAD_MAX_MEMORY_SIZE = 26214400 #上传数据大小，也改成了25M 保存之后，django会自动重启，再次尝试传输单个大文件，应该就会成功了。 其实这个改动不仅仅是单个文件小于25M，假如是批量上传，所选的文件加起来总量小于25M都可以一并传上去了。 参考资料https://stackoverflow.com/questions/55190498/413-payload-too-large-on-django-serverhttps://github.com/django/django/blob/master/django/conf/global_settings.py#L297","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://yoursite.com/tags/Django/"},{"name":"文件上传","slug":"文件上传","permalink":"http://yoursite.com/tags/文件上传/"}]},{"title":"记录部署ProxySql的过程","slug":"记录部署ProxySql的过程","date":"2019-05-31T03:12:05.000Z","updated":"2019-12-02T03:57:38.000Z","comments":true,"path":"2019/05/31/记录部署ProxySql的过程/","link":"","permalink":"http://yoursite.com/2019/05/31/记录部署ProxySql的过程/","excerpt":"","text":"安装与启动先去https://github.com/sysown/proxysql/releases 下载稳定版本 ，我是下载的proxysql-2.0.4-1-centos7.x86_64.rpm，然后rpm -ivh proxysql-2.0.4-1-centos7.x86_64.rpm，如果出现了如下错误： 1234[root@dvlshop-proxysql-001 ~]# rpm -ivh proxysql-2.0.4-1-centos7.x86_64.rpm error: Failed dependencies: perl(DBD::mysql) is needed by proxysql-2.0.4-1.x86_64 perl(DBI) is needed by proxysql-2.0.4-1.x86_64 就执行一下yum install -y perl-IO-Socket-SSL perl-DBD-MySQL就可以了。 安装成功之后，启动的命令是service proxysql start： 12345[root@dvlshop-proxysql-001 ~]# service proxysql startStarting ProxySQL: 2019-05-31 11:23:10 [INFO] Using config file /etc/proxysql.cnf2019-05-31 11:23:10 [INFO] No SSL keys/certificates found in datadir (/var/lib/proxysql). Generating new keys/certificates.DONE![root@dvlshop-proxysql-001 ~]# 启动完毕就可以使用初始命令mysql -uadmin -padmin -h 127.0.0.1 -P 6032来登录proxysql了，如图： 补充一下：proxysql的默认管理端口是6032，客户端服务端口是6033。默认的用户名密码都是admin，可以在配置文件里看到。 再说一下各个重要文件的位置：proxysql的静态配置文件是/etc/proxysql.cnf(只在第一次启动的时候有用，后续所有的配置修改都是对SQLite数据库操作，并且不会更新到proxysql.cnf文件中。)，日志文件是/var/lib/proxysql/proxysql.log，SQLITE的数据文件是/var/lib/proxysql/proxysql.db。 基本概念与之前的中间件atlas不同，配置ProxySQL是基于sql命令的方式完成的，而且配置完成之后直接应用无需重启。怎么做到这个的呢？是因为ProxySQL的三层管理配置设计： runtime：运行中使用的配置文件，这些表的数据库无法直接修改，只能从其他层级load加载。这一份配置会直接影响到生产环境的，所以要将配置加载进RUNTIME层时需要三思而行； memory：提供用户动态修改配置文件，它是我们修改proxysql的唯一正常入口。一般来说在修改一个配置时，首先修改Memory层，确认无误后再接入RUNTIME层，最后持久化到DISK和CONFIG FILE层。也就是说memeory层里面的配置随便改，不影响生产，也不影响磁盘中保存的数据。 disk：将修改的配置保存到磁盘SQLit表中（即：proxysql.db），DISK/CONFIG FILE层表示持久存储的那份配置，持久层对应的磁盘文件是$(DATADIR)/proxysql.db，在重启ProxySQL的时候，会从proxysql.db文件中加载信息。即如果不持久化下来，重启后，配置都将丢失。 config：一般不使用它（即：proxysql.cnf） 再重复一遍：proxysql分为三个级别，RUNTIME是即时生效的，MEMORY是保存在内存中但并不立即生效的，DISK|CONFIG FILE是持久化或写在配置文件中的。修改的配置都是在memory层。可以load到runtime，使配置在不用重启proxysql的情况下也可以生效，也可以save到disk，将对配置的修改持久化！如图： 这三个级别的配置文件互不干扰，在某个层级修改了配置文件，想要加载或保存到另一个层级，需要额外的LOAD或SAVE操作：”LOAD xx_config FROM xx_level | LOAD xx_config TO xx_level | SAVE xx_config TO xx_level | SAVE xx_config FROM xx_level”等等。 由此可见，如果想要更改proxysql的初始账号密码以及端口，改了/etc/proxysql.cnf是没用的，应该通过sql命令行进入到proxysql里，先查看global_variables这个表： 要修改表里的内容才算是真正的修改了配置文件！于是想要在admin:admin的基础上添加一个lcshop:lcshop2019这个用户同时把登录端口改成127.0.0.1:6969，那么语句如下： 1234update global_variables set variable_value = 'admin:admin;lcshop:lcshop2019' where variable_name = 'admin-admin_credentials';update global_variables set variable_value = '127.0.0.1:6969' where variable_name = 'admin-mysql_ifaces'; #登录proxysql的管理端口是6969了LOAD MYSQL SERVERS TO RUNTIME; #常用，让修改的配置生效SAVE MYSQL SERVERS TO DISK; #常用，将修改的配置持久化 此时就是使用新账号和新端口访问proxysql管理界面了！如图： 跟mysql一样，如果你想查看历史命令记录，cat ~/mysql_history即可。 具体配置假设我有一组阿里云RDS数据库，主库的内网地址是rm-bp1el471x0ltbg402.mysql.rds.aliyuncs.com，从库的内网地址是rr-bp10ki29n7n8z0ex0.mysql.rds.aliyuncs.com，端口皆3306，并且将这台proxysql的IP地址添加到双方的白名单里。 首先先把两个mysql信息插入到mysql_servers，如下： 123456789101112MySQL [(none)]&gt; insert into mysql_servers(hostgroup_id,hostname,port) values(10,'rm-bp1el471x0ltbg402.mysql.rds.aliyuncs.com',3306); #10表示写组，为20表示读组。Query OK, 1 row affected (0.01 sec)MySQL [(none)]&gt; insert into mysql_servers(hostgroup_id,hostname,port) values(20,'rr-bp10ki29n7n8z0ex0.mysql.rds.aliyuncs.com',3306);Query OK, 1 row affected (0.00 sec)MySQL [(none)]&gt; select * from mysql_servers;+--------------+---------------------------------------------+------+-----------+--------+--------+-------------+-----------------+---------------------+---------+----------------+---------+| hostgroup_id | hostname | port | gtid_port | status | weight | compression | max_connections | max_replication_lag | use_ssl | max_latency_ms | comment |+--------------+---------------------------------------------+------+-----------+--------+--------+-------------+-----------------+---------------------+---------+----------------+---------+| 10 | rm-bp1el471x0ltbg402.mysql.rds.aliyuncs.com | 3306 | 0 | ONLINE | 1 | 0 | 1000 | 0 | 0 | 0 | || 20 | rr-bp10ki29n7n8z0ex0.mysql.rds.aliyuncs.com | 3306 | 0 | ONLINE | 1 | 0 | 1000 | 0 | 0 | 0 | |+--------------+---------------------------------------------+------+-----------+--------+--------+-------------+-----------------+---------------------+---------+----------------+---------+2 rows in set (0.00 sec) 然后还要在阿里云的RDS控制台上创建两个用户，一个是监控用户sqlmonitor，一个是普通的进程用户proxysql。先将进程用户proxysql添加到mysql_users这个表里 1234567891011MySQL [(none)]&gt; INSERT INTO mysql_users(username,password,default_hostgroup) VALUES ('proxysql','这里是账号对应的密码',10);MySQL [(none)]&gt; select * from mysql_users;+----------+--------------------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+---------+| username | password | active | use_ssl | default_hostgroup | default_schema | schema_locked | transaction_persistent | fast_forward | backend | frontend | max_connections | comment |+----------+--------------------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+---------+| proxysql | 这里是账号对应的密码| 1 | 0 | 10 | NULL | 0 | 1 | 0 | 1 | 1 | 10000 | |+----------+--------------------+--------+---------+-------------------+----------------+---------------+------------------------+--------------+---------+----------+-----------------+---------+1 row in set (0.00 sec) LOAD MYSQL USERS TO RUNTIME;SAVE MYSQL USERS TO DISK; 这里说一下default_hostgroup，它的意思是“这个用户的请求没有匹配到规则时，默认发到这个hostgroup，默认0”，由于我们上面设定10是写组，所以这里写成10。 这里默认保存的密码是明文的，如果想保存加密后的密码，可以先去mysql的界面里进行加密，比如： 123456MySQL [(none)]&gt; select PASSWORD('114514');+-------------------------------------------+| PASSWORD('114514') |+-------------------------------------------+| *D9050F2D99C3DDD8138912B7BDF8F4BACBE3A8E7 |+-------------------------------------------+ 然后用这个密码输入，比如：insert into mysql_users(username,password,active,default_hostgroup) values (&#39;proxysql2&#39;,&#39;*D9050F2D99C3DDD8138912B7BDF8F4BACBE3A8E7&#39;,1,20);。注意！mysql_users的username是不能重复的。 确认一下账号已经正确连接： 12345678910MySQL [(none)]&gt; select * from mysql_server_connect_log;+---------------------------------------------+------+------------------+-------------------------+---------------+| hostname | port | time_start_us | connect_success_time_us | connect_error |+---------------------------------------------+------+------------------+-------------------------+---------------+| rm-bp1el471x0ltbg402.mysql.rds.aliyuncs.com | 3306 | 1559649241943118 | 8607 | NULL || rr-bp10ki29n7n8z0ex0.mysql.rds.aliyuncs.com | 3306 | 1559649242748088 | 1291 | NULL || rr-bp10ki29n7n8z0ex0.mysql.rds.aliyuncs.com | 3306 | 1559649301943192 | 1396 | NULL || rm-bp1el471x0ltbg402.mysql.rds.aliyuncs.com | 3306 | 1559649302760022 | 7218 | NULL |+---------------------------------------------+------+------------------+-------------------------+---------------+4 rows in set (0.00 sec) 发现connect_error为空，而且connect_success_time_us有值可见已经成功连接了。如果connect_error有具体的错误，那么就可以根据错误来修改。 然后添加sqlmonitor用户，它主要是用来健康监测： 123456set mysql-monitor_username='sqlmonitor';set mysql-monitor_password='对应的密码';#或者是UPDATE global_variables SET variable_value='monitor' WHERE variable_name='sqlmonitor';#UPDATE global_variables SET variable_value='unixfbi' WHERE variable_name='对应的密码'; LOAD MYSQL VARIABLES TO RUNTIME; #别忘了让修改的配置生效SAVE MYSQL VARIABLES TO DISK; #将修改的配置持久化 此时在另外一个xshell对话框窗口尝试一下使用proxysql连接数据库，使用mysql -h127.0.0.1 -P6033 -uproxysql -p效果如图： 已经成功的通过proxysql来访问到数据库了！ 验证读写分离首先在proxysql账号下创建一个tables： 然后往里面随机插入三条数据： 123INSERT INTO players ( name, team, num ) VALUES ( \"Jordan\", \"Bulls\" , 23);INSERT INTO players ( name, team, num ) VALUES ( \"Kobe\", \"Lakers\" , 24);INSERT INTO players ( name, team, num ) VALUES ( \"Duncan\", \"Spurs\" , 21); 查看数据如下： 此时新开一个xshell窗口登录proxysql的管理端，select * from stats_mysql_query_digest;查看语句细节如下： 发现所有的语句的hostgroup都是10，也就是我们上面设定的写库，即读库并没有承担起读的作用。这是为什么呢？因为proxysql还需要设定路由。于是我们添加两个路由： 1234insert into mysql_query_rules(rule_id,active,match_digest,destination_hostgroup,apply)values(1,1,'^SELECT.*FOR UPDATE$',10,1);insert into mysql_query_rules(rule_id,active,match_digest,destination_hostgroup,apply)values(2,1,'^SELECT',20,1);load mysql query rules to runtime; #生效save mysql query rules to disk; #持久化 如图： 加上这几句话的含义是：1.将select语句全部路由至hostgroup_id=20的组(也就是读组)； 2.但是select * from tb for update这样的语句是修改数据的，所以需要单独定义，将它路由至hostgroup_id=10的组(也就是写组)； 3.其他没有被规则匹配到的组将会被路由至用户默认的组(mysql_users表中的default_hostgroup) 然后我们返回到mysql，再插入几句数据，再重新打开select * from stats_mysql_query_digest;，发现符合标准的select都落到了hostgroup是20的mysql上了，测试读写分离成功，如图： 最后补充几个常用的语句： 12345678910111213141516select hostgroup_id, hostname, status from runtime_mysql_servers; #查看在用的mysql状态select * from mysql_server_ping_log; #查看mysql的连接情况select * from stats_mysql_query_rules; #查看路由规则命中情况load mysql users to runtime;load mysql servers to runtime;load mysql query rules to runtime;load mysql variables to runtime;load admin variables to runtime;#load进runtime，是配置生效save mysql users to disk;save mysql servers to disk;save mysql query rules to disk;save mysql variables to disk;save admin variables to disk;#save到磁盘(/var/lib/proxysql/proxysql.db)中，永久保存配置 参考资料https://github.com/sysown/ProxySQLhttps://arstercz.com/proxysql-%E4%BB%8B%E7%BB%8D%E5%8F%8A%E6%B5%8B%E8%AF%95%E4%BD%BF%E7%94%A8/http://seanlook.com/2017/04/10/mysql-proxysql-install-config/ （具体各表的信息可以看这个）https://www.cnblogs.com/kevingrace/p/10329714.html （墙裂推荐！mysql 5.7的主从同步也有）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"读写分离","slug":"读写分离","permalink":"http://yoursite.com/tags/读写分离/"},{"name":"proxysql","slug":"proxysql","permalink":"http://yoursite.com/tags/proxysql/"}]},{"title":"Gitlab配置ssh，实现秘钥上传下载代码","slug":"Gitlab配置ssh，实现秘钥上传下载代码","date":"2019-05-21T09:28:26.000Z","updated":"2019-05-21T13:03:28.000Z","comments":true,"path":"2019/05/21/Gitlab配置ssh，实现秘钥上传下载代码/","link":"","permalink":"http://yoursite.com/2019/05/21/Gitlab配置ssh，实现秘钥上传下载代码/","excerpt":"","text":"常规配置gitlab配置ssh比较简单，在代码机上使用ssh-keygen -t rsa -C &quot;你的邮箱&quot;制作id_rsa和id_rsa.pub，然后来到gitlab的web页面，settings—ssh keys,把id_rsa.pub拷贝进去，然后点击Add key: 然后返回到代码机器上，再对应的代码目录里使用git remote -v查看一下当前的方式，如果不是git的话，通过git remote set-url origin git@你的project地址修改，然后再试一下 ssh -T git@&quot;你的gitlab服务器地址&quot;是否会出现welcome，如果可以的话，那么就可以通过ssh的方式下载上传代码以及git clone 对应的project了。 容器配置但是现在很多人都用容器部署gitlab，而且在部署的时候除了指定80，443端口的映射，还制定了22端口的映射。比如我的这个gitlab容器的启动命令就是： 1docker run --detach --hostname 外网IP --publish 443:443 --publish 80:80 --publish 2222:22 --name gitlab --restart always gitlab/gitlab-ce:latest 可见我把宿主机的2222端口对应给了gitlab容器。那么像上面的方法肯定不会成功，这里就需要我们修改一处地方。 首先进入容器，然后修改gitlab.rb文件，这个文件在容器里有很多，我这个镜像里的gitlab.rb是/etc/gitlab/gitlab.rb，然后把gitlab_rails[&#39;gitlab_shell_ssh_port&#39;]改成2222并且去掉注释，如图： 然后gitlab-ctl restart重启之，重启完毕之后，在代码机上测试一下ssh： 可以已经连通，修改一下remote master地址之后，就可以直接上传了：","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"容器","slug":"容器","permalink":"http://yoursite.com/tags/容器/"},{"name":"gitlab","slug":"gitlab","permalink":"http://yoursite.com/tags/gitlab/"},{"name":"ssh keys","slug":"ssh-keys","permalink":"http://yoursite.com/tags/ssh-keys/"}]},{"title":"摆弄摆弄iptables","slug":"摆弄摆弄iptables","date":"2019-05-20T09:06:14.000Z","updated":"2019-05-21T03:21:30.000Z","comments":true,"path":"2019/05/20/摆弄摆弄iptables/","link":"","permalink":"http://yoursite.com/2019/05/20/摆弄摆弄iptables/","excerpt":"","text":"作为一名运维人员，安全是第一任务，那么某些高机密web网页限制IP访问是必做的环节，当然如果使用阿里云的“安全组”可以让这一切变的简单和直观。不过有时候，一个安全组里面有多个服务，不同的服务使用同一个端口（比如都是443），有些443要对所有人开放，有的443只能对公司的IP开放，那么如果不想重新收拾安全组的话，就干脆用iptables。 普通的iptables常用的iptables规则如下： 1234567iptables -nvL #详细查看当前iptables情况iptables -I INPUT -p tcp --dport 8701 -j DROP #所有来访问8701端口的请求都作废iptables -I INPUT -s 60.191.94.118 -p tcp --dport 8070 -j ACCEPT #只准许60.191.94.118这个IP访问8070端口iptables -t nat -I PREROUTING 1 -s 120.92.136.159/32 -p tcp -m tcp --dport 6379 -j DNAT --to-destination 100.99.231.81:6379 #准许120.92.136.159的6379信息转发到100.99.231.81的6379里iptables -A OUTPUT -p tcp -m tcp --dport 61616 -j DROP #将61616端口的报文抛弃iptables -D INPUT 1 #删除INPUT表里的第一规则iptables -L FORWARD --line-numbers #展现规则序号，-D删除的行号就是这里的序号 如果不小心配错的规则比较多，不愿意一个一个删除，可以执行service iptables restart直接恢复。 容器的iptables现在容器化横行，但是我们也要限制IP来访问容器的端口，但是如果像上面那样的话，是无法成功的。对于容器，为了避免您的规则被docker破坏,请使用DOCKER-USER链，比如有个容器已经做了3306端口与宿主机的3306端口互通，那么配置如下规则： 123iptables -A DOCKER-USER -i eth0 -s 1.1.1.1 -p tcp -m conntrack --ctorigdstport 3306 -j ACCEPTiptables -A DOCKER-USER -i eth0 -s 2.2.2.2 -p tcp -m conntrack --ctorigdstport 3306 -j ACCEPTiptables -A DOCKER-USER -i eth0 -p tcp -m conntrack --ctorigdstport 3306 -j DROP 执行的效果就是只能1.1.1.1和2.2.2.2来访问该服务器的3306端口，其余IP一律drop掉。这里也要注意输入的顺序，因为iptables执行是从上往下的。 RETURN的问题如果上面的规则如果变成了这样： 1234iptables -A DOCKER-USER -p all -j RETURNiptables -A DOCKER-USER -i eth0 -s 1.1.1.1 -p tcp -m conntrack --ctorigdstport 3306 -j ACCEPTiptables -A DOCKER-USER -i eth0 -s 2.2.2.2 -p tcp -m conntrack --ctorigdstport 3306 -j ACCEPTiptables -A DOCKER-USER -i eth0 -p tcp -m conntrack --ctorigdstport 3306 -j DROP 会不会达不到预期的要求？答曰不一定，在我这个例子里结果就是任何人都可以访问容器的3306端口。因为return退出的是当前CHIAN：如果当前CHIAN是别的CHAIN调用的子CHIAN（从一个CHAIN里可以jump到另一个CHAIN, jump到的那个CHAIN是子CHAIN），那么返回到调用点下一条规则处开始执行，如果当前CHIAN不是子CHAIN，那么就以默认策略执行。iptables -nvL看一下当前iptables的情况： 可以看出DOCKER-USER这个链是1 references，即它被一个默认链调用，被哪个默认链呢？FORWARD，当DOCKER-USER RETURN的时候回返回到FORWARD链里然后走下一个规则，而下一个规则是什么呢？是 17893K 5610M ACCEPT all -- * docker0 0.0.0.0/0 0.0.0.0/0 ctstate RELATED,ESTABLISHED 所以所有人都可以访问这个3306了。 没有DOCKER-USER？DOCKER-USER这个链是Docker比较新的版本加上的，例子里的docker版本是version 18.06.1-ce, build e68fc7a。但是如果docker比较老的话，是不会默认生成这个链的，比如： 这种情况要么乖乖的升级docker，要么可以自定义创建iptables链。比如我们创建一个链，链名叫GITLAB，只让公司内部网络（115.200.239.106）访问GITLAB。 首先先iptables -N GITLAB，创建该链。然后iptables -I GITLAB -p tcp --dport 443 -j DROP和iptables -I GITLAB -s 115.200.239.106 -j ACCEPT创建给GITLAB链里添加两个访问规则达到只有指定IP访问443端口的目的。但是此时这个GITLAB链没有被任何任何默认链引用，所以即使配了规则也是无法匹配到任何报文的，所以我们要把它与FORWARD链链接起来，准许443端口可以转发，命令是iptables -I FORWARD -p https --dport 443 -j GITLAB，如图： 去浏览器里或者curl一下验证，的确只能指定IP才能访问GITLAB主页。不过，你以为现在就完事了么？非也，因为gitlab默认是通过https的形式拉取代码的，所以你还要把所有的代码服务器IP也要写进iptables里。 参考资料https://docs.docker.com/network/iptables/https://www.frozentux.net/iptables-tutorial/cn/iptables-tutorial-cn-1.1.19.htmlhttp://kuntsung.blogspot.com/2012/10/iptables.htmlhttps://www.zsythink.net/archives/1625","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"容器","slug":"容器","permalink":"http://yoursite.com/tags/容器/"},{"name":"iptables","slug":"iptables","permalink":"http://yoursite.com/tags/iptables/"}]},{"title":"配置Intellij IDEA进行高效率运维开发","slug":"配置intellij-IDEA让运维开发更高效率","date":"2019-05-14T08:58:50.000Z","updated":"2019-05-20T14:17:06.000Z","comments":true,"path":"2019/05/14/配置intellij-IDEA让运维开发更高效率/","link":"","permalink":"http://yoursite.com/2019/05/14/配置intellij-IDEA让运维开发更高效率/","excerpt":"","text":"以前我写python用的是pycharm2018，但是发现我的pycharm里没有go插件，脱机安装也报错，于是乎我就干脆下载了一个interllij IDEA2019，打算把python、go、yaml文件都用它来编辑和管理。 配置python开发环境首先先去File–Settings–Plugins搜索python，下载对应插件，下载完毕之后需要重启IDE，重启完毕之后，File--New--Module--Python，选择对应的SDK即可。 若需要添加样式，还是在File–Settings–Editer–File and Code Templates里找到python script，增添文件的通用版面即可，如图： 输出结果换行也很简单，在File–Settings–Editer–Console里，勾选Use soft wraps in console即可，如图： 如果控制每行的长度，修改Console commands history size即可。 配置go开发环境首先安装go语言，配置好GOROOT和GOPATH，然后去File–Settings–Plugins搜索go，下载对应插件，下载完毕之后需要重启IDE，重启完毕之后，在File--Settings--Languages &amp; Frameworks里选择Go，配置好GOROOT和GOPATH。注意，GOPATH填的是Go的src文件地址。保存之后，就可以正常启动go文件了。 配置k8s yaml开发环境首先先去File–Settings–Plugins搜索yaml和kubernetes，下载对应的插件之后，直接创建新的project，就会自动补齐，如图： 调节字体大小调节菜单等字体大小：File--Settings--Appearance &amp; Behavior--Appearance--Use custom font(Size)，如图： 调节代码的字体大小：File--Settings--Font--Size，如图： 配置与远程服务器同步写完了代码，总不能lrzsz的去上传到服务器里，我们要用一个优雅的方式去达到这个目的，首先在顶级菜单里选择Tools--Deployment--Configuration，点击+创建一个新的链接： 检查可以成功连接到远程服务器之后，保存此链接。右键点击文件，选择Deployment---Upload to XXX，然后就可以看到上传成功。 最后，分享两个比较柔和的xshell配色方案： 1234567891011121314151617181920212223[Solarized Dark]text(bold)=839496magenta(bold)=6c71c4text=839496white(bold)=fdf6e3green=859900red(bold)=cb4b16green(bold)=586e75black(bold)=073642red=dc322fblue=268bd2black=002b36blue(bold)=839496yellow(bold)=657b83cyan(bold)=93a1a1yellow=b58900magenta=dd3682background=042028white=eee8d5cyan=2aa198[Names]count=1name0=Solarized Dark 将文件命名为solarized-dark.xcs文件，在xshell配色方案中导入该文件即可。颜色对比如下： 第二个方案如下： 1234567891011121314151617181920212223[mycolor]text(bold)=e9e9e9magenta(bold)=ff00fftext=00ff80white(bold)=fdf6e3green=80ff00red(bold)=ff0000green(bold)=3c5a38black(bold)=808080red=ff4500blue=00bfffblack=000000blue(bold)=1e90ffyellow(bold)=ffff00cyan(bold)=00ffffyellow=c0c000magenta=c000c0background=042028white=c0c0c0cyan=00c0c0[Names]count=1name0=mycolor 将此文件保存较mycolor.xcs，然后同上面一样导入即可。如果想要xshell自动加载此配色，需要将上面里所有mycolor改名叫Xterm，并且删除掉原有的Xterm配色方案，重启Xshell即看到效果。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"intellij idea","slug":"intellij-idea","permalink":"http://yoursite.com/tags/intellij-idea/"}]},{"title":"使用Python GUI去将本地文件上传阿里云OSS","slug":"使用Python-GUI去将本地文件上传阿里云OSS","date":"2019-05-13T11:51:31.000Z","updated":"2019-05-21T03:24:14.000Z","comments":true,"path":"2019/05/13/使用Python-GUI去将本地文件上传阿里云OSS/","link":"","permalink":"http://yoursite.com/2019/05/13/使用Python-GUI去将本地文件上传阿里云OSS/","excerpt":"","text":"前端同事会甩过来一个zip包，然后我们需要将其解压，然后上传到阿里云OSS里对应的目录，为了提高效率，就用python 3写了一个GUI，如图： 具体代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980#!/usr/bin/env python # -*- coding:utf-8 -*-# 作者：ChrisChan# 用途：使用GUI上传阿里云OSSimport tkinter as tkimport tkinter.ttk as ttkfrom tkinter import messagebox # 弹窗# from tkinter import filedialog # 选择单独文件from tkinter.filedialog import askdirectory # 选择文件夹import oss2,os,sys,zipfile,time #引入zipfile解压window = tk.Tk()window.title(\"将桌面文件上传到阿里云国内线上OSS\") # 窗体的标题def confirm(): result = messagebox.askokcancel(\"请确认\", '''本地文件是：%s,对应OSS路径是：%s''' % (filename,region1.get())) # 前面是弹窗主题，后面是弹窗内容 Des_path = region1.get() fileroot = filename.split('.zip')[0] #获取文件路径，不含.zip后缀 print(\"上传zip包路径是:%s\" % fileroot) # 获取要上传的文件路径 print(\"要解压的zip包名是:%s\" % filename) print(\"目标路径是:%s\" % Des_path) # 获取目的完整路径 if result is True: ak = \"账号ak\" sk = \"账号sk\" # 秘钥 auth = oss2.Auth(ak, sk) # 鉴权 ossBucket = oss2.Bucket(auth, 'http://oss-cn-hangzhou.aliyuncs.com',Des_path) # 定义ossBucket date = time.strftime(\"%Y-%m-%d\", time.localtime()) #获取今天日期 #解压缩zip包 zFile = zipfile.ZipFile(filename, \"r\") for fileM in zFile.namelist(): zFile.extract(fileM, \"D:\\OSSback\") zFile.close() # 文件夹上传 def uploadFile(file): remoteName = file.replace(fileroot,'').replace('\\\\','/')[1:] # 将“/”去掉 print('uploading...', file, 'remoteName:', remoteName) result = ossBucket.put_object_from_file(remoteName, file) print('http status: &#123;0&#125;'.format(result.status)) def list(dir): fs = os.listdir(dir) for f in fs: file = dir+\"\\\\\"+f if os.path.isdir(file): list(file) else: uploadFile(file) list(fileroot) # 开始上传 print(\"目标文件夹里所有文件上传完毕！\") #zip包改名 os.rename(filename,filename + date) #按日期重命名def chooseZip(): global filename filename = tk.filedialog.askopenfilename() # 选择单独的文件 if filename != '': lb.config(text=\"您选择的文件是：\" + filename) else: lb.config(text=\"您没有选择任何文件\")lb = tk.Label(window, text='')lb.grid(row=0, column=1, sticky=tk.W, padx=10, pady=5)btn = tk.Button(window, text=\"选择要上传的文件\", command=chooseZip)btn.grid(row=0, column=0, sticky=tk.E, padx=10, pady=5)lb2 = tk.Label(window, text='请选择上传地址')lb2.grid(row=2, column=0, sticky=tk.W, padx=10, pady=5)number = tk.StringVar()region1 = ttk.Combobox(window,width=35,textvariable=number,state='readonly') #下拉列表设置成为只读模式region1['values'] = ('resource-public/lccms','resource-public/phoneAlarm','resource-public/lcview','resource-public/webFront/annualReport','resource-public/webFront/cancellation','resource-public/webFront/deviceShare','resource-public/webFront/discoverNews','resource-public/webFront/timeAlbum','resource-public/chenchenchen') #下拉列表里面具体的元素region1.grid(row=2,column=1)region1.current(0)tk.Button(window, text='上传', width=10, command=confirm).grid(row=3, column=0, sticky=tk.W, padx=10, pady=5)tk.Button(window, text='退出', width=10, command=window.quit).grid(row=3, column=1, sticky=tk.E, padx=10, pady=5)tk.mainloop() 整个过程还是出现一个gui界面，然后传入zip包，然后将其在源目录下解压缩，并且上传到选择的OSS路径里，上传成功后将原zip改名已做备份。 最后吐槽一下，阿里云OSS的SDK里是没有文件改名的功能，只能复制一份然后靠上传新的顶替掉原来老的内容，这样很不友善…所以我才选择将zip包保留在本地。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python3","slug":"python3","permalink":"http://yoursite.com/tags/python3/"},{"name":"阿里云OSS","slug":"阿里云OSS","permalink":"http://yoursite.com/tags/阿里云OSS/"},{"name":"gui","slug":"gui","permalink":"http://yoursite.com/tags/gui/"}]},{"title":"使用Python GUI去创建阿里云负载均衡","slug":"使用python-GUI去创建阿里云负载均衡","date":"2019-05-07T06:17:04.000Z","updated":"2019-05-16T06:29:28.000Z","comments":true,"path":"2019/05/07/使用python-GUI去创建阿里云负载均衡/","link":"","permalink":"http://yoursite.com/2019/05/07/使用python-GUI去创建阿里云负载均衡/","excerpt":"","text":"前言最近闲来无事研究了一下python3的gui，就用最基础的tkinter去做了一个购买阿里云负载均衡的脚本，先看一下效果： 点击“确认”按钮之后，就会出现这样一个谈话框： 确认参数完毕之后，若点击取消则返回上一层页面修改，如果点击确认则进行购买。 这个脚本需要的基础知识可以去看一下莫烦大大的tkinter教学系列，地址是https://morvanzhou.github.io/tutorials/python-basic/tkinter/ ，B站有全部的视频，不到10分钟一节课，还是很棒的。 脚本正文脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137#!/usr/bin/env python # -*- coding:utf-8 -*-#作者：ChrisChan#用途：py3脚本，使用GUI购买阿里云SLB脚本import tkinter as tkimport tkinter.ttk as ttk #下拉式菜单from tkinter import messagebox #弹窗from aliyunsdkcore.client import AcsClientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionfrom aliyunsdkslb.request.v20140515.CreateLoadBalancerRequest import CreateLoadBalancerRequest#秘钥集合aksk_A = [\"第一个账号的ak\",\"第一个账号的sk\"]aksk_B = [\"第2个账号的ak\",\"第2个账号的sk\"]aksk_C = [\"第3个账号的ak\",\"第3个账号的sk\"]#创建一个类可以建立负载均衡class CreateSlb(object): def __init__(self,ak,sk,domain): self.ak = ak self.sk = sk self.domain = domain def create(self,name,nettype): client = AcsClient(self.ak,self.sk,self.domain) request = CreateLoadBalancerRequest() request.set_accept_format('json') request.set_LoadBalancerSpec(\"slb.s1.small\") #这里是负载均衡的规格， request.set_LoadBalancerName(name) request.set_AddressType(nettype) response = client.do_action_with_exception(request) print(str(response, encoding='utf-8'))window = tk.Tk() #建立一个窗体window.title(\"购买阿里云负载均衡\") #窗体的标题Label1 = tk.Label(window, text='请输入负载均衡名称:').grid(row=0, column=0)v1 = tk.StringVar()e1 = tk.Entry(window, textvariable=v1)e1.grid(row=0,column=1,padx=10,pady=5) # 设置输入框显示的位置，以及长和宽属性l = tk.Label(window,bg=\"yellow\",width=20,text=\"默认值是1\")l.grid(row=1,column=1,padx=10,pady=5)parameter1 = tk.StringVar()l1 = tk.Label(window,bg='pink',width=20,height=5,text=\"请选择对应的阿里云账号\")l1.grid(row=2,column=1,rowspan=3,padx=10,pady=5)parameter2 = tk.StringVar()l2 = tk.Label(window,bg='yellow',width=20,text=\"请选择实例所在的地域\")l2.grid(row=5,column=1,padx=10,pady=5)parameter3 = tk.StringVar()l3 = tk.Label(window,bg='green',width=20,height=3,text=\"请选择网络类型\")l3.grid(row=10,column=1,rowspan=2,padx=10,pady=5)def clickMe(): result = messagebox.askokcancel(\"请确认\", ''' 负载均衡名称是：%s,对应账号是：%s,所在区域是：%s,网络类型是：%s ''' % (v1.get(),parameter1.get(),region1.get(),parameter3.get())) #前面是弹窗主题，后面是弹窗内容 name = v1.get() nettype = parameter3.get() domain = region1.get() account = parameter1.get() print(\"负载均衡名称是：%s\" % name) # 获取用户输入的信息 print(\"所在区域是：%s\" % domain) print(\"对应账号是：%s\" % account) print(\"网络类型是：%s\" % nettype) if result is True: if account == \"A\": ak = aksk_A[0] sk = aksk_A[1] getSLB = CreateSlb(ak,sk,domain) #将类实例化 getSLB.create(name,nettype) #执行购买函数 elif account == \"B\": ak = aksk_B[0] sk = aksk_B[1] getSLB = CreateSlb(ak, sk, domain) # 将类实例化 getSLB.create(name,nettype) #执行购买函数 else: ak = aksk_C[0] sk = aksk_C[1] getSLB = CreateSlb(ak, sk, domain) # 将类实例化 getSLB.create(name,nettype) #执行购买函数 print(\"购买完毕！\") else: passdef print_selection(v): l.config(text=\"当前选择的值是：\" + v) #V就是传入值也是获取的长度def get_env(): l1.config(text=\"你选择了\"+parameter1.get()) #使用config功能去改变原有l的参数,把text变成了提取var1里的值 #print(parameter1.get())def get_region(): l2.config(text=\"你选择了\"+region1.get()) #print(parameter2.get())def get_network(): l3.config(text=\"你选择了\"+parameter3.get()) #print(parameter3.get())#选择环境env1 = tk.Radiobutton(window,text=\"第一个账号\",variable=parameter1,value='A',command=get_env)env2 = tk.Radiobutton(window,text=\"第2个账号\",variable=parameter1,value='B',command=get_env)env3 = tk.Radiobutton(window,text=\"第3个账号\",variable=parameter1,value='C',command=get_env)env1.grid(row=2, column=0, padx=10, pady=5)env2.grid(row=3, column=0, padx=10, pady=5)env3.grid(row=4, column=0, padx=10, pady=5)#选择地域，使用下拉列表number = tk.StringVar()region1 = ttk.Combobox(window,width=12,textvariable=number,state='readonly') #加入readonly，使下拉列表设置成为只读模式region1['values'] = (\"cn-hangzhou\",\"cn-shenzhen\",\"eu-central-1\",\"ap-southeast-1\",\"cn-hongkong\") #下拉列表里面具体的元素region1.grid(row=5,column=0)region1.current(0)#选择内/外网network1 = tk.Radiobutton(window,text=\"内网\",variable=parameter3,value='intranet',command=get_network)network2 = tk.Radiobutton(window,text=\"外网\",variable=parameter3,value='internet',command=get_network)network1.grid(row=10, column=0, padx=10, pady=5)network2.grid(row=11, column=0, padx=10, pady=5)#尺度区间s = tk.Scale(window,label=\"想要多少台?\",from_=1,to=20,orient=tk.HORIZONTAL,resolution=1,command=print_selection) #HORIZONTAL横向,length的单位是像素,resolution单位是取小数还是取整s.grid(row=1, column=0, padx=10, pady=5) #提交按钮action = tk.Button(window, text='确认提交',width=10,command=clickMe)action.grid(row=12, column=0, sticky=tk.W, padx=10, pady=5)tk.Button(window, text='退出程序',width=10,command=window.quit).grid(row=12, column=1, sticky=tk.E, padx=10, pady=5)tk.mainloop() 基本脚本的注释就已经讲明白了整个脚本执行的过程，简单说来就是界面输入对应的选项，再把这些选项传入到阿里云的api里达到购买负载均衡的目的。这里要注意一下，thinker布局只能从pack,grid,place里选择一种。 脚本就到此结束，后期再给这个脚本添加到对应的端口监听功能就完美了！ 参考资料https://www.mierhuo.com/code/106https://www.jianshu.com/p/5dfeb29aed7bhttps://www.cnblogs.com/ruo-li-suo-yi/p/7425307.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"阿里云","slug":"阿里云","permalink":"http://yoursite.com/tags/阿里云/"},{"name":"python3","slug":"python3","permalink":"http://yoursite.com/tags/python3/"},{"name":"tkinter","slug":"tkinter","permalink":"http://yoursite.com/tags/tkinter/"}]},{"title":"解决微信不支持阿里云OSS域名的问题","slug":"解决微信不支持阿里云OSS域名的问题","date":"2019-04-29T07:52:44.000Z","updated":"2019-04-29T11:08:04.000Z","comments":true,"path":"2019/04/29/解决微信不支持阿里云OSS域名的问题/","link":"","permalink":"http://yoursite.com/2019/04/29/解决微信不支持阿里云OSS域名的问题/","excerpt":"","text":"阿里云OSS的元素（除了图片）是无法通过微信小程序/微信聊天直接打开的，会爆“已停止访问该网页”的错误，如图： 但是复制url地址到手机浏览器是可以正常访问的，无疑这样对于用户来说是一个很不好的体验，因为腾讯屏蔽了阿里云的相关元素地址。所以为了解决这个问题，需要登录OSS后台，在对应的bucket里，点击“域名管理”，然后“绑定用户域名”，在里面输入一个域名即可。如果是HTTPS访问，还需要点击“证书托管”，把域名证书上传到阿里云OSS里，如图： 这样就可以用自定义的域名去替代阿里云OSS的基础域名（http://XXXX.oss-cn-hangzhou.aliyuncs.com/），这样微信就可以正常打开了：","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"微信","slug":"微信","permalink":"http://yoursite.com/tags/微信/"},{"name":"阿里云oss","slug":"阿里云oss","permalink":"http://yoursite.com/tags/阿里云oss/"}]},{"title":"获取阿里云RDS磁盘容量的脚本","slug":"获取阿里云RDS磁盘容量的脚本","date":"2019-04-28T08:16:48.000Z","updated":"2019-04-29T09:30:00.000Z","comments":true,"path":"2019/04/28/获取阿里云RDS磁盘容量的脚本/","link":"","permalink":"http://yoursite.com/2019/04/28/获取阿里云RDS磁盘容量的脚本/","excerpt":"","text":"需求以及脚本正文开发人员提出一个需求，想要每天从企业微信号里获取一下阿里云几个RDS的今天和昨天的磁盘容量，对比一下结果来判断删除模块是否正常运行，由于阿里云的相关API不支持查询历史数据，所以我们要建立一个数据表，把磁盘容量按照日期保存在数据表里，这个table的结构如下： 123456789#以下是创建databases的语句CREATE TABLE IF NOT EXISTS `onlinerds`(`id` INT UNSIGNED AUTO_INCREMENT,`rds_id` VARCHAR(100) NOT NULL, #记录数据库ID号`rds_name` VARCHAR(100) NOT NULL, #记录数据库名称`rds_diskused` VARCHAR(40) NOT NULL, #记录使用磁盘容量`date` VARCHAR(40) NOT NULL, #记录日期PRIMARY KEY ( `id` ))ENGINE=InnoDB DEFAULT CHARSET=utf8; 有了这个table，于是就写了一个py3的脚本，内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154#!/usr/bin/env python#coding=utf-8#这个py3脚本是用来获取阿里云线上数据库的磁盘容量#pip install pymysql &amp; pip install aliyun-python-sdk-rds &amp; pip install aliyun-python-sdk-corefrom aliyunsdkcore.client import AcsClientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionfrom aliyunsdkrds.request.v20140815.DescribeDBInstanceAttributeRequest import DescribeDBInstanceAttributeRequestimport math,pymysql,urllib.request,json,datetime#字典确定kv对应关系，这样可以取到服务器姓名dict = &#123;'第一台RDSid': \"对应数据库名称\",'第2台RDSid': \"对应数据库名称\"，'第3台RDSid': \"对应数据库名称\"，'4台RDSid': \"对应数据库名称\"，'第5台RDSid': \"对应数据库名称\"&#125;usedcap=[] #今天磁盘量usedcap_yes=[] #昨天磁盘量pro = [] #比例#创建获取磁盘容量的类class getRDS(object): def __init__(self,ak,sk,domain): self.ak = ak self.sk = sk self.domain = domain client = AcsClient(ak,sk,domain) #自动换算单位 def convertBytes(self,bytes,lst=None): if lst is None: lst = ['Bytes', 'KB', 'MB', 'GB'] # 这里是单位，如果需要TB，PB，在后面添加进去即可 i = int(math.floor( # 舍弃小数点，取小 math.log(bytes, 1024) # 求对数(对数：若 a**b = N 则 b 叫做以 a 为底 N 的对数) )) if i &gt;= len(lst): i = len(lst) - 1 return ('%.2f' + \" \" + lst[i]) % (bytes / math.pow(1024, i)) def DiskUsed(self,rdsid): lst = ['Bytes', 'KB', 'MB', 'GB'] client = AcsClient(self.ak,self.sk,self.domain) request = DescribeDBInstanceAttributeRequest() request.set_accept_format('json') request.set_DBInstanceId(rdsid) response = client.do_action_with_exception(request) result = str(response, encoding='utf-8') data = json.loads(result) DiskUsed = ((data)['Items']['DBInstanceAttribute'][0]['DBInstanceDiskUsed']) #获取当前使用磁盘 DiskTotal = ((data)['Items']['DBInstanceAttribute'][0]['DBInstanceStorage']) #获取总磁盘 DiskUsed_GB = getRDS.convertBytes(self,DiskUsed,lst=lst) #使用“自动换算单位”的函数 DiskUsed_num = float(getRDS.convertBytes(self,DiskUsed,lst=lst).split(' ', 1)[0]) #提取纯数字 Proportion = \"%.2f%%\" % ((DiskUsed_num / DiskTotal) * 100) #转化成百分比 return DiskUsed_GB,Proportion #返回两个值#获取昨天的日期def getYesterday(): today = datetime.date.today() oneday = datetime.timedelta(days=1) yesterday = today-oneday return yesterday#MYSQL录入def mysql(i,usedcapacity): db = pymysql.connect(\"数据库地址\", \"数据库用户\", \"密码\", \"databases\",charset='utf8') cursor = db.cursor() sql = \"INSERT INTO onlinerds (rds_id,rds_name,rds_diskused,date) VALUES ('%s','%s','%s',now())\" % (i,dict[i],usedcapacity) try: cursor.execute(sql) # 执行sql语句 db.commit() # 执行sql语句 except: db.rollback() # 发生错误时回滚 db.close() #关闭数据库连接#获取昨天的数据def yes_mysql(): db = pymysql.connect(\"数据库地址\", \"数据库用户\", \"密码\", \"databases\",charset='utf8') cursor = db.cursor() yes_sql = \"select rds_diskused from onlinerds where date like '%s\" % (getYesterday()) + \" 20:%';\" try: cursor.execute(yes_sql) results = cursor.fetchall() for GB in results: aaa = GB[0] #增加一个aaa变量来调整格式 usedcap_yes.append(aaa) #获取的数据添加到列表里 except: print(\"Error: unable to fecth data\") db.close() #关闭数据库连接#将类实例化gethzRDS = getRDS(\"杭州区ak\",\"杭州区sk\",\"cn-hangzhou\")getszRDS = getRDS(\"深圳区ak\",\"深圳区sk\",\"cn-shenzhen\")# 获取企业微信token，用来发送微信企业号def get_token(url, corpid, corpsecret): token_url = '%s/cgi-bin/gettoken?corpid=%s&amp;corpsecret=%s' % (url, corpid, corpsecret) token = json.loads(urllib.request.urlopen(token_url).read().decode())['access_token'] return token# 构建告警信息json，用来发送微信企业号def messages(msg): values = &#123; \"touser\": '@all', \"msgtype\": 'text', \"agentid\": 微信企业号应用号码, \"text\": &#123;'content': msg&#125;, \"safe\": 0 &#125; msges=(bytes(json.dumps(values), 'utf-8')) return msges# 发送告警信息，用来发送微信企业号def send_message(url, token, data): send_url = '%s/cgi-bin/message/send?access_token=%s' % (url, token) respone = urllib.request.urlopen(urllib.request.Request(url=send_url, data=data)).read() x = json.loads(respone.decode())['errcode'] # print(x) if x == 0: print('Success!') else: print('Failed')if __name__ == '__main__': list = ['第一台RDSid','第2台RDSid','第3台RDSid','第4台RDSid','第5台RDSid'] for i in list: mysql(i,gethzRDS.DiskUsed(i)) x,y = gethzRDS.DiskUsed(i) #函数return多个值，就这样拆开，一一添加到list里 usedcap.append(x) #添加到列表 pro.append(y) #添加到列表 print (i+\" OKok!\") #证明已经录入到数据库里了 list = ['第一台RDSid','第2台RDSid','第3台RDSid','第4台RDSid','第5台RDSid'] for i in list: mysql(i,getszRDS.DiskUsed(i)) x, y = getszRDS.DiskUsed(i) usedcap.append(x) pro.append(y) print (i+\" OKok!\") yes_mysql() print(usedcap) print(usedcap_yes) corpid = '微信企业号corpid' corpsecret = '微信企业号应用的秘钥' url = 'https://qyapi.weixin.qq.com' msg = '''【第一台数据库】此时的容量是%s，昨天的容量是%s，当前的比例是：%s； 【第2台数据库】此时的容量是%s，昨天的容量是%s，当前的比例是：%s； 【第3台数据库】此时的容量是%s，昨天的容量是%s，当前的比例是：%s； 【第4台数据库】此时此时的容量是%s，昨天的容量是%s，当前的比例是：%s； 【第5台数据库】此时的容量是%s，昨天的容量是%s，当前的比例是：%s； ''' % (usedcap[0],usedcap_yes[0],pro[0],usedcap[1],usedcap_yes[1],pro[1],usedcap[2],usedcap_yes[2],pro[2],usedcap[3],usedcap_yes[3],pro[3],usedcap[4],usedcap_yes[4],pro[4],usedcap[5],usedcap_yes[5],pro[5]) #发送微信告警 test_token = get_token(url, corpid, corpsecret) msg_data = messages(msg) send_message(url, test_token, msg_data) 执行之后，效果如下： 小数和百分数的相互转换百分比转换为小数的代码如下： 1234s = '20%' # 默认要转换的百分比是字符串aa = float(s.strip('%')) # 去掉s 字符串中的 %bb = aa/100.0 #运行环境是Python2.7 其中Python2.X 与 python 3X中的除法是有区别print bb # 输出结果是 0.2 小数转换为百分比的代码如下： 123a = 0.3214323bb = \"%.2f%%\" % (a * 100)print bb # 输出结果是32.14% 如果函数返回了多个值如果函数一次性return了多个值，如何单独获取到这些值？其实这个函数返回的是一个元组。把元组解包，返回结果也可以赋值给单个变量，这时候这个变量值就是函数返回的那个元组本身了。如下： 12345678&gt;&gt;&gt; def myfun():... return 1, 2, 3...&gt;&gt;&gt; a, c = myfun()&gt;&gt;&gt; a1&gt;&gt;&gt; c3 智能转换存储单位智能转换bytes为kb/mb/gb/tb/pb的代码如下： 1234567891011121314151617181920import mathdef convertBytes(bytes, lst=None): if lst is None: lst=['Bytes', 'KB', 'MB', 'GB', 'TB', 'PB'] i = int(math.floor( # 舍弃小数点，取小 math.log(bytes, 1024) # 求对数(对数：若 a**b = N 则 b 叫做以 a 为底 N 的对数) )) if i &gt;= len(lst): i = len(lst) - 1 return ('%.2f' + \" \" + lst[i]) % (bytes/math.pow(1024, i))def main(): lst = ['Bytes', 'KB', 'MB', 'GB', 'TB', 'PB'] bytes = input('Bytes: ') print convertBytes(bytes, lst=lst)if __name__ == '__main__': main() 但是要注意！bytes作为传入值不能为负数，所以如果是负数想要转换单位，先要用abs取绝对值再计算。 参考资料https://www.cnblogs.com/xuchunlin/p/6305720.htmlhttps://python3-cookbook.readthedocs.io/zh_CN/latest/c07/p04_return_multiple_values_from_function.htmlhttps://my.oschina.net/guoenzhou/blog/2989650","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python3","slug":"python3","permalink":"http://yoursite.com/tags/python3/"}]},{"title":"Awk获取最大值、最小值、平均值和求和","slug":"Awk获取最大值、最小值、平均值和求和","date":"2019-04-22T02:33:40.000Z","updated":"2019-04-22T07:37:24.000Z","comments":true,"path":"2019/04/22/Awk获取最大值、最小值、平均值和求和/","link":"","permalink":"http://yoursite.com/2019/04/22/Awk获取最大值、最小值、平均值和求和/","excerpt":"","text":"背景交代在zabbix的监控中，很多场合需要监控到日志里的一些数字，比如下面这个日志： 12342019-04-22 10:43:53.231 [pool-12-thread-2] INFO com.hswx.css.ads.pojo.M3uFile [221] cloud upload index success, CloudfileName=/4J0463CPAG1FEDD_record/cloud_1/20190422104242898_0_c3237911422543f8a66816d043eabb50.m3udeviceId4J0463CPAG1FEDD cost:72019-04-22 10:43:52.795 [pool-9-thread-13] INFO com.hswx.css.ads.pojo.M3uFile [333] cloud upload record success, CloudFileName=/4G00B65PAG1C125_record/cloud_1/20190422103141454_0_9d3ccc60d3f6429c8b5d79aa3222991f_365b2bc872ed42d59de82f0af9b1016d-68237400_1047356.dav deviceId=4G00B65PAG1C125 cost:122019-04-22 10:43:52.888 [pool-9-thread-19] INFO com.hswx.css.ads.pojo.M3uFile [333] cloud upload record success, CloudFileName=/4G00B65PAG7A8B1_record/cloud_1/20190422104014516_0_76184831e6e0400994cf6baf45952368_fdbe495eee81458a8e55ec0bfdebecd5-8385407_1045239.dav deviceId=4G00B65PAG7A8B1 cost:162019-04-22 10:43:52.939 [pool-9-thread-7] INFO com.hswx.css.ads.pojo.M3uFile [333] cloud upload record success, CloudFileName=/5A00D4EPBZE212D_record/cloud_1/20190422104228493_0_2165fd85c6064b43abf0398bdf9c0916_fd279fa8809f45279ae76577629d27f5-43910516_1058372.dav deviceId=5A00D4EPBZE212D cost:12 这段日志主要记录m3u录像文件上传到云存储的情况，后面”cost:”那部分就是记录本次上传操作耗时的时间，我们现在要监控这个时间，如果这个时间大于100，我们就认为线路出了问题。 但是这里有一个问题，因为日志量比较大，一秒钟会刷出来很多的值，比如使用tail 日志文件路径|grep &quot;cost:&quot; | cut -d &quot;:&quot; -f 4： 那么我们就要从这里面取出最大值，这样的场景用awk是最方便的。 具体语句求最大值：awk &#39;BEGIN {max = 0} {if ($1+0 &gt; max+0) max=$1} END {print &quot;&quot;, max}&#39;求最小值：awk &#39;BEGIN {min = 65536} {if ($1+0 &lt; min+0) min=$1} END {print &quot;Min=&quot;, min}&#39;求和：awk &#39;{sum+=$1} END {print &quot;Sum= &quot;, sum}&#39;求平均值：awk &#39;{sum+=$1} END {print &quot;Avg= &quot;, sum/NR}&#39; 把上面的语句用于本次案例中，效果如下： 然后就是配置到zabbix-agent.conf里即可。如果要用zabbix用户登录bash，使用命令：su -s /bin/bash zabbix。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"Awk","slug":"Awk","permalink":"http://yoursite.com/tags/Awk/"}]},{"title":"在Django里插入paramiko实现批量操作","slug":"在Django里插入paramiko，实现批量操作","date":"2019-04-15T05:52:29.000Z","updated":"2019-06-25T14:43:56.000Z","comments":true,"path":"2019/04/15/在Django里插入paramiko，实现批量操作/","link":"","permalink":"http://yoursite.com/2019/04/15/在Django里插入paramiko，实现批量操作/","excerpt":"","text":"背景交代Django:2.1.1paramiko:2.4.1Python:3.6.5 paramiko在“python批量操作”范围内占据着龙头老大的的地位，它主要就是通过IP、端口和密码登录到对应的服务器执行具体的命令。在Django页面里，我们有时候需要批量操作资产去执行同一个命令，这个时候就可以把paramiko接入到django里。 首先先pip install paramiko，然后在app所在的文件夹里的models.py里添加新的数据库： 12345678910111213141516from django.db import models # Create your models here.#这里是服务器数据class server(models.Model): name = models.CharField(verbose_name='服务器名称',max_length=50) inIP = models.GenericIPAddressField(verbose_name='服务器内网IP地址') outIP = models.GenericIPAddressField(verbose_name='服务器外网IP地址',default='0.0.0.0') port = models.IntegerField(verbose_name='登录端口',default='这里是SSH端口') username = models.CharField(verbose_name='登录用户名',max_length=50,default='这里是登录用户名') password = models.CharField(verbose_name='登录密码',max_length=100,default='这里是服务器密码') signtime = models.DateField(auto_now_add=True) remark = models.CharField(verbose_name='甲方环境',max_length=255) def __unicode__(self): return self.name 返回到manage.py这一层的目录，执行python manage.py makemigrations和python manage.py migrate，这个server表就是用来存储资产资料的。 整个paramiko执行的逻辑是这样的：首先在paramiko.html里展示所有的资产信息，同时页面有一个button按钮，点击这个button，后台开始对页面里所有的服务器执行同样的命令（这里举例执行date命令），将执行的结果生成一个新的页面叫result.html，页面跳转到result.html给用户展示。 具体配置有了上面的铺垫，现在说一下paramiko在django里的具体配置。首先先在app所在的文件夹下新建一个paramiko_client.py的文件，内容如下： 12345678910111213141516171819202122232425import time,paramikofrom .models import server #注意这里的.class ParamikoClient: def __init__(self): self.client = paramiko.SSHClient() #创建sshclient对象 self.client.set_missing_host_key_policy(paramiko.AutoAddPolicy()) #允许将信任的主机自动加入到host_allow 列表，此方法必须放在connect方法的前面 self.sftp_client = None self.client_state = 0 def connect(self,sshinfo): try: self.client.connect(hostname=sshinfo.outIP,port=sshinfo.port,username=sshinfo.username,password=sshinfo.password,timeout=1.0) #调用connect方法连接服务器 self.client_state = 1 return True except Exception as e: print (e) try: self.client.close() except: pass def run_cmd(self,cmd_str): stdin,stdout,stderr = self.client.exec_command(cmd_str) return stdout.read() 然后在views.py里增加如下内容： 1234567891011121314151617181920import paramikofrom .paramiko_client import ParamikoClient #引用上面那个文件里的ParamikoClient函数#批量操作@login_requireddef paramiko(request): servers = server.objects.all() #获取server这个表里所有的资产信息 return render(request, 'agparamiko.html',&#123;'servers':servers&#125;) #反馈页面#批量操作结果def run_ssh_cmd(request): sshs = server.objects.all().filter(inIP='192.168.1.1') #这里我就拿出来内网IP是192.168.1.1这个机器的例子 cmd_res = &#123;&#125; #设定一个空的列表 for ssh in sshs: client = ParamikoClient() client.connect(ssh) res = client.run_cmd('date') #执行的命令是date cmd_res[ssh.name] = res #给列表的元素一一对应赋值 return render(request, 'result.html',&#123;'cmd_res':cmd_res&#125;) #反馈界面 urls.py的对应内容如下： 1234567from django.urls import pathfrom . import viewsurlpatterns = [ path(r'paramiko.html',views.paramiko,name=\"paramiko\"), #批量操作界面 path(r'result.html',views.run_ssh_cmd,name=\"run_ssh_cmd\"), #批量操作界面] 至于result.html就很简单了，主体部分代码是： 123456789101112131415161718&lt;div class=\"table-responsive\"&gt; &lt;!-- 响应式表格 --&gt; &lt;table id=\"server_table\" class=\"table table-striped table-bordered table-hove\"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;服务器名称&lt;/th&gt; &lt;th&gt;执行结果&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &#123;% for key,value in cmd_res.items %&#125; &lt;tr&gt; &lt;td&gt;&#123;&#123; key &#125;&#125;&lt;/td&gt; &lt;td&gt;&#123;&#123; value &#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;% endfor %&#125; &lt;/tbody&gt; &lt;/table&gt;&lt;/div&gt; 保存之后，系统重新启动django，在页面执行的效果如下： Django的model加密上面已经实现了通过paramiko批量操作，但是在这个过程中，我们把密码明文的保存在mysql里，这样无疑是有安全隐患的。于是乎就有一个新的需求：当我们输入到mysql的时候是加密的，从mysql取值的时候是解密的，那么这样的需求可以实现么？当然可以，使用django-fernet-fields。 首先要pip install django-fernet-fields安装这个插件，然后在对应的models.py里添加如下语句即可： 1234567from fernet_fields import EncryptedTextField,EncryptedIntegerFieldclass MyModel(models.Model): name = models.CharField(verbose_name='姓名',max_length=1000) cardid = EncryptedTextField() #加密字段 phone = EncryptedIntegerField() #加密字段 address = models.CharField(verbose_name='住址',max_length=1000) 然后在manage.py同级文件夹里执行python manage.py makemigrations和python manage.py makemigrations，发现新的表已经生成，然后在admin.py里添加后台展示代码： 12345from .models import MyModelclass MyModelAdmin(admin.ModelAdmin): list_display = ('name','cardid','phone','address')admin.site.register(MyModel,MyModelAdmin) 然后登陆到django后台，发现一个叫My models的表已经生成了，那么我们添加一条记录如下： 跑到mysql命令行一看： 可见cardid和phone这两个字段已经被加密了，但是在views.py里使用.objects.values()方法获取是直接得到明文的，这样就达到了预期的效果。 补充一下，EncryptedIntegerField这个其实不太实用，它不能保存超过2147483647的数字，也就是说电话号码（11位）是无法用这个方法保存的… 参考资料http://www.maiziedu.com/wiki/frame/embed/https://django-fernet-fields.readthedocs.io/en/latest/https://pypi.org/project/django-encrypted-model-fields/ 据说这个方法也能实现加密效果，我没有尝试https://www.59izt.com/zhoubin/2019/04/10/7025.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"paramiko","slug":"paramiko","permalink":"http://yoursite.com/tags/paramiko/"}]},{"title":"一个批量部署脚本（未完成）","slug":"一个批量部署脚本","date":"2019-04-12T08:40:16.000Z","updated":"2019-04-29T12:04:38.000Z","comments":true,"path":"2019/04/12/一个批量部署脚本/","link":"","permalink":"http://yoursite.com/2019/04/12/一个批量部署脚本/","excerpt":"","text":"脚本设计首先安装ansible，并且用group1,group2…对相同模块的服务器进行分组，注意！group1只能是一台服务器，剩下的服务器均摊。 按模块依赖顺序输入，模块名称用逗号分隔。进行for循环，先使用ansible对group1进行部署工作，部署模块并且启动之后，暂停600秒，让开发利用这10分钟检查日志和配置项是否有问题，如果有问题就ctrl+c，在暂停600秒的同时，脚本新开一个进程A，paramiko到第一台服务器里，检查日志是否出现ERROR等关键字样，如果有就输出，600秒结束之后，关闭线程A，继续部署group2，直至名单里所有的模块都部署完毕。 作画的意思如下： 用python去实现tailf功能在shell下执行tail -f就是一句话的事，但是用python实现则需要一个脚本了，内容如下： 1234567891011121314151617181920#!/usr/bin/env python#coding=utf-8import timedef watch(fn, words): fp = open(fn, 'r') while True: new = fp.readline() if new: for word in words: if word in new: yield (word, new) else: time.sleep(1)fn = '文件路径'words = ['关键词']for hit_word, hit_sentence in watch(fn, words): print \"发现关键词 %r 在日志里: %r\" % (hit_word, hit_sentence) python实现线程通信假设我们有一个函数叫AAA，希望脚本能开两个线程，线程A是等待5秒，线程B是不断的执行AAA（），直到5秒结束，线程B也停止线程AAA（）。那么脚本如下： 按行读取文件取各种集合python对于两个字典求交集（&amp;），差集（-），全集（|）比较简单，而对于两个文件按行取集合的方法如下： 12345678# -*- coding: utf-8 -*-s1 = set(open(r'C:\\Users\\33664\\Desktop\\aaa.txt','r').readlines())s2 = set(open(r'C:\\Users\\33664\\Desktop\\bbb.txt','r').readlines())print ('交集是: %s' % (s1.intersection(s2)))print ('并集是: %s' % (s1.union(s2)))print ('差集是: %s'%(s1.difference(s2)))print ('dif: %s'%(s1.difference(s2).union(s2.difference(s1)))) _的问题有些python脚本在for循环里会有这样的代码： 12for _ in range(5) print (\"我想放假，我想放假\") 这里面的独立_其实没有特殊的意义，仅仅是是用作一个名字，来表示某个变量是临时的或无关紧要的。 不过_还有其他的用途，它可以展示最近的一次表达式的结果，比如： 123456&gt;&gt;&gt; 20 + 323&gt;&gt;&gt; _23&gt;&gt;&gt; print(_)23 额外补充1.tailf命令主动停止命令：tail -f 目标日志|sed &#39;/启动成功/Q&#39;，此语句会在”启动成功”打印时退出，但log只能打印到”启动成功”的上一行；2.subprocess.call(&quot;命令1&quot;)，命令1是按顺序执行的，效果等同于subprocess.Popen(&quot;命令1&quot;).wait()；subprocess.Popen(&quot;命令2&quot;)，命令2是与前一个命令并发进行的； 参考资料https://stackoverflow.com/questions/1703640/how-to-implement-a-pythonic-equivalent-of-tail-fhttps://python3-cookbook.readthedocs.io/zh_CN/latest/c12/p03_communicating_between_threads.htmlhttps://stackoverflow.com/questions/22698754/subprocess-calls-are-they-done-in-parallel/22698825#22698825","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"多线程","slug":"多线程","permalink":"http://yoursite.com/tags/多线程/"}]},{"title":"将Redis监控细节添加到Django页面里","slug":"将redis监控细节添加到Django页面里","date":"2019-04-09T12:50:31.000Z","updated":"2019-05-06T04:09:14.000Z","comments":true,"path":"2019/04/09/将redis监控细节添加到Django页面里/","link":"","permalink":"http://yoursite.com/2019/04/09/将redis监控细节添加到Django页面里/","excerpt":"","text":"Redis的监控一直是重点中的重点，市面上开源的Redis界面监控也不在少数了，但是自己做一个监控页面更加有针对性，而且更加有逼格。我们主要监控redis除了常规的cpu、内存、Key数之外，还有如下几个方面：阻塞客户端数量、使用内存峰值、内存碎片率、缓存命中率、失效KEY、慢日志和连接数。这里挑几个简单的说。 获取连接细节情况首先先来搞定“获取redis的连接细节”。在django里先做一个model,如下： 123456789class redisconnection(models.Model): rank = models.CharField(verbose_name='排名',max_length=10) num = models.CharField(verbose_name='服务器连接数',max_length=50) ip = models.GenericIPAddressField(verbose_name='服务器内网IP地址') date = models.DateField(auto_now_add=True) time = models.TimeField(auto_now_add=False, auto_now=True) def __unicode__(self): return self.host 可见我们只是需要排名、具体的IP、当时有多少连接以及当时时间这4个指标而已。 我承认我道行不够，捅咕两个小时也没有研究出来怎么用python2.7去获取redis的连接数细节，于是乎就用shell写了一个简单的脚本。如下： 1234567891011#!/bin/bash#获取当前连接最多的前五个IP地址和数量到Mysqlredis-cli -h redis地址 -p 6379 -a redis密码 client list | awk &apos;&#123;print $2&#125;&apos;| cut -d = -f 2| cut -d : -f 1 | sort | uniq -c | sort -rn |head -5 &gt; clientip.txtMYSQL=&quot;mysql -h数据库地址 -u数据库账号 -p数据库密码 --default-character-set=utf8 -A -N&quot;cat -n clientip.txt | while read rank num IPdo echo $&#123;num&#125; echo $&#123;IP&#125; sql=&quot;insert into databases.table(num,ip,date,time,rank) values(&apos;$&#123;num&#125;&apos;,&apos;$&#123;IP&#125;&apos;,curdate(),now(),&apos;$&#123;rank&#125;&apos;);&quot; $MYSQL -e &quot;$sql&quot;done 这里先简单解释一下：1.client list是查看redis连接细节的命令，然后通过awk获取第二列，再分别通过“=”和“，”来分割两次，排序去重统计个数最后取出前五名输入到clientip.txt这个文件里；2.连接mysql，-A的含义是不去预读全部数据表信息；-N的含义是获取数据信息省去列名称;3.使用cat -n自动获取到行号当做排名，循环赋值；4.curdate(),now()这俩是sql，但是需要shell里正确使用sql就要-e; 执行效果如下： 剩下的内容就是在views.py里拿值然后通过render反馈到前端页面，这里不说了。 如果使用了Redis中间件，那么就不能统计redis的client list了，而是到中间件服务器里，使用ss -art | awk &#39;{print $5}&#39; | grep &#39;^[1-9]&#39; | cut -d : -f 1 | sort | uniq -dc | sort -nr获取详细连接情况。 获取缓存命中率缓存命中率是info Stats命令里keyspace_hits/(keyspace_hits+keyspace_misses)的值，比如我这个redis： 这个值正常来说应该是90%以上，如果缓存命中率过低，那么要排查对缓存的用法是否有问题，我这个就很不合格… 获取缓存命中率的shell脚本如下： 1234567891011#!/bin/bash#获取当前缓存命中率到Mysqlhit=$(redis-cli -h redis地址 -p 6379 -a redis密码 info Stats | grep \"keyspace_hits\" | cut -d : -f 2) miss=$(redis-cli -h redis地址 -p 6379 -a redis密码 info Stats | grep \"keyspace_misses\" | cut -d : -f 2)HIT=$(echo $hit | tr -d '\\r')MISS=$(echo $miss | tr -d '\\r')total=$(expr $HIT + $MISS)percent=$(awk 'BEGIN&#123;printf \"%.2f\\n\",'$HIT'/'$total'&#125;')MYSQL=\"mysql -h数据库地址 -u数据库账号 -p数据库密码 --default-character-set=utf8 -A -N\"sql=\"insert into databases.table(num,date,time) values('$&#123;percent&#125;',curdate(),now());\"$MYSQL -e \"$sql\" 这里要注意！hit和miss结果是自带”\\r”的，所以要去掉。不然的话就会有expr: non-numeric argument。而且如果用bc命令获取除法结果的话，低于1的值是不会出现整数0，即如果得到的结果是0.97，那么只会显示.97，至于如何出现这个0，可以去看 http://www.361way.com/linux-bc-point-zero/4960.html 。 现在已经通过脚本取到了值，那么剩下的内容就是django去弄一个model，之后在views.py里拿值然后通过render反馈到前端页面，这里不说了。执行效果如下： 其他补充redis的慢日志操作也是我们比较关注的一点。一般来说我们使用slowlog len来获取当前慢日志的总条数，而是用slowlog reset对其进行清理工作。获取它的shell脚本跟上面两个大同小异，这里也略过不表了。 如果要是想获取redis的cpu和内存，最好的方法通过zabbix拿值，CPU使用率的item是：system.cpu.util[]，内存使用率的item是：vm.memory.size[pavailable]。 整个页面做完的效果如下： 参考资料https://segmentfault.com/a/1190000009915519https://blog.csdn.net/secretx/article/details/73498148http://www.cnblogs.com/iforever/p/4459857.htmlhttps://morrisjs.github.io/morris.js/lines.html","categories":[{"name":"监控与技术","slug":"监控与技术","permalink":"http://yoursite.com/categories/监控与技术/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"},{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}]},{"title":"Apache配置Https","slug":"Gitlab配置Https","date":"2019-04-04T05:24:41.000Z","updated":"2019-04-04T08:47:48.000Z","comments":true,"path":"2019/04/04/Gitlab配置Https/","link":"","permalink":"http://yoursite.com/2019/04/04/Gitlab配置Https/","excerpt":"","text":"Httpd配置https事前说明，我的Httpd版本是：Server version: Apache/2.4.6 (CentOS) 首先先准备https证书文件，把他们传递到apache服务器的/etc/httpd/ssl文件夹里，然后安装yum install -y mod_ssl openssl，安装完毕之后，发现/etc/httpd/conf.d文件夹下多了一个ssl.conf，出于安全先备份一份，然后修改ssl.conf的如下几个地方： 12345未涉及的字段保留原样DocumentRoot \"/var/www/html\" #网站的目录ServerName 自己的域名SSLCertificateFile /etc/httpd/ssl/imoulife.crt #秘钥crt文件及路径SSLCertificateKeyFile /etc/httpd/ssl/imoulife.key #秘钥key文件及路径 保存退出，重启httpd即可生效。注意！因为一个ip只能绑一个SSL，因此这里就算在写了两份&lt;VirtualHost *:443&gt;...&lt;/VirtualHost&gt;，也还是会读取第一个SSL。 Httpd配置http跳转https如果想要达到http跳转https的话，还是在ssl文件里的最下面追加这段内容： 12345&lt;VirtualHost *:80&gt; RewriteEngine on RewriteCond %&#123;SERVER_PORT&#125; !^443$ RewriteRule ^/?(.*)$ https://%&#123;SERVER_NAME&#125;%&#123;REQUEST_URI&#125; [L,R]&lt;/VirtualHost&gt; 如果只是单url跳转，比如http://test.imoulife.com/login跳转到https://test.imoulife.com/login，其他的域名依旧是http。那么就把最后一句改成:RewriteRule ^/logon.do$ https://%{SERVER_NAME}%{REQUEST_URI} [L,R]，重启httpd就生效。 httpd配置ip白名单设置了https不能说很安全，我们还需要设置IP白名单才能让WEB界面更加放心。由于我这个httpd主要是给zabbix使用的，所以就拿访问zabbix的IP白名单为例。 首先打开/etc/httpd/conf.d/zabbix.conf，修改如下地方： 1234567891011Alias /zabbix /usr/share/zabbix&lt;Directory \"/usr/share/zabbix\"&gt; Options FollowSymLinks AllowOverride None #Require all granted #这句话是任何人都可以访问的意思&lt;RequireAll&gt; Require ip 192.168.1 #准许192.168.1开头的IP地址的访问 Require ip 192.168.1.104 192.168.1.205 #准许固定IP地址访问 Require ip 10.1.0.0/16 #网络/子网掩码的访问 &lt;/RequireAll&gt; 保存退出，重启httpd即可。 Gitlab配置Https我的gitlab是容器做的，其实无论容器还是非容器其实配置都是一样的。 首先先开放443端口给相应的IP，然后进入容器，在/etc/gitlab/下先创建一个ssl文件夹，里面放入https证书，如图： 放好证书文件之后，返回上一级目录，修改一下gitlab.rb文件： 12345external_url 'https的域名'nginx['redirect_http_to_https'] = truenginx['redirect_http_to_https_port'] = 80nginx['ssl_certificate'] = \"上面https证书的路径/crt文件名称\"nginx['ssl_certificate_key'] = \"上面https证书的路径/key文件名称\" 然后执行gitlab-ctl reconfigure更新配置，完事之后找到nginx的gitlab配置文件gitlab-http.conf，发现由于更新了配置，所以里面已经生成好了一份新的配置文件，如下： 12345678910111213141516server &#123; listen *:443 ssl http2; server_name https的域名; server_tokens off; client_max_body_size 0; ssl on; ssl_certificate 上面https证书的路径/crt文件名称; ssl_certificate_key 上面https证书的路径/key文件名称; ............................. #剩余的信息省略了 &#125; server&#123;listen*:80;server_name https的域名;rewrite^(.*)$https://$host$1permanent;&#125; 确认各个信息无误之后，退出执行gitlab-ctl restart即可。 参考资料http://tonylit.me/2016/02/29/apache_http%E8%B7%B3%E8%BD%AC/http://zhizhi.tangliangdong.me/2017/10/12/2017-10-12-http-to-https/https://blog.mallux.me/2017/02/27/gitlab/https://blog.csdn.net/leshami/article/details/78521031","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Gitlab","slug":"Gitlab","permalink":"http://yoursite.com/tags/Gitlab/"},{"name":"httpd","slug":"httpd","permalink":"http://yoursite.com/tags/httpd/"},{"name":"白名单","slug":"白名单","permalink":"http://yoursite.com/tags/白名单/"}]},{"title":"Zabbix-api获取值在Django页面展示","slug":"Zabbix-api获取值在Django页面展示","date":"2019-04-02T08:38:51.000Z","updated":"2019-04-03T11:20:42.000Z","comments":true,"path":"2019/04/02/Zabbix-api获取值在Django页面展示/","link":"","permalink":"http://yoursite.com/2019/04/02/Zabbix-api获取值在Django页面展示/","excerpt":"","text":"背景交代私有云的同学要求把几个涉及录像的模块带宽每小时从zabbix获取一次，然后在django页面展示出来。由于django跟zabbix并不在一个服务器，那么就采取“zabbix上跑脚本，脚本将实时的带宽值存储到某个数据库里，然后django去数据库取值并且展示”这样的思路来解决问题。 python3 + Django 2.1.1APP：accessgateway 建立数据库首先需要先建立数据模型，在app下的models.py里添加如下： 12345678910#这里是数据模型class lbmrs(models.Model): host = models.CharField(verbose_name='MRS服务器名称',max_length=50) inbandwidth = models.FloatField(verbose_name='入网带宽') outbandwidth = models.FloatField(verbose_name='出网带宽') date = models.DateField(auto_now_add=True) time = models.TimeField(auto_now_add=False, auto_now=True) #获取录入时间，而且有新录入就会覆盖 def __unicode__(self): return self.host admin.py里添加对应的值： 12345from .models import lbmrsclass lbmrsAdmin(admin.ModelAdmin): list_display = ('host','inbandwidth','outbandwidth','date','time')admin.site.register(lbmrs,lbmrsAdmin) 注意!由于我们使用了TimeField，所以要修改一下setting.py: 12TIME_ZONE = 'Asia/Shanghai'USE_TZ = False 这样就能输入准确的时间，不然就是UTC时间。然后就是python manage.py makemigrations和python manage.py migrate，如果在python manage.py migrate的时候出现如下MySQL Strict Mode is not set for database connection &#39;default&#39;的提示，如图： 这提示其实不重要，主要是说当前连接mysql的方式不严谨，如果要避免还是修改一下setting.py，新加一个OPTIONS: 1234567891011121314DATABASES = &#123; 'default': &#123;# 'ENGINE': 'django.db.backends.sqlite3',# 'NAME': os.path.join(BASE_DIR, 'db.sqlite3'), 'ENGINE': 'django.db.backends.mysql', 'NAME': '这里是database名', 'USER': '这里是用户名', 'PASSWORD': '这里是密码', 'HOST': '这里是数据库地址', 'OPTIONS': &#123; \"init_command\": \"SET sql_mode='STRICT_TRANS_TABLES'\", &#125; &#125;&#125; 数据库方面完成，在后台界面里随便添加一个值，如下： 然后在mysql命令行看一下效果： 将值录入数据库由于我使用的是阿里云数据库，所以要现在阿里云数据库里对django服务器和zabbix服务器同时开放白名单。 使用zabbix-api获取zabbix数值的脚本以前在 https://rorschachchan.github.io/2019/01/09/%E4%BD%BF%E7%94%A8Zabbix%E7%9A%84python-api%E5%8E%BB%E8%8E%B7%E5%8F%96%E5%BD%93%E5%89%8D%E7%9B%91%E6%8E%A7%E5%80%BC/ 里面说过了，要把获取的值保存到mysql里，只需要添加下面的代码： 12345678#将值保存到mysqlconnection = pymysql.connect(host='Mysql地址', port=3306, user='账号', passwd='密码', db='databases名称')cursor = connection.cursor() # 创建游标# 执行SQL,插入多行数据并返回受影响行数sql = cursor.executemany(\"insert into accessgateway_ldmrs (host,inbandwidth,outbandwidth,time,date) values (%s,%s,%s,now(),curdate()))\",[(\"第一台机器\",firstin,firstout),(\"第二台机器\",secondin,secondout),(\"第三台机器\",thirdin,thirdout), (\"第四台机器\",fourthin,fourthout),(\"第五台机器\",fivethin,fivethout)])connection.commit() # 提交,不然无法保存修改cursor.close() # 关闭游标connection.close() # 关闭连接 依旧是每小时执行一次，看见mysql能成功存储到值，如图： 将数据库的值反馈到页面上数据库现在已经取到了值，那么思路就很简单了：在views.py里设定变量，让变量可以去数据库里通过objects.values取到相应的值，然后再把这个变量通过render反应到前端页面。url.py很简单： 12#前略path(r'lb_mrs_flow.html',views.lb_mrs_flow,name=\"lb_mrs_flow\"), 这次需求要取到以下几个值，分别是“此时的带宽”，“前一小时的带宽”，“昨天此时的带宽”。在数据库里我们也设定了date和time这两个列，所以通过限制条件就能获取到对应的值了！views.py如下： 123456789101112131415import datetime#展示服务器1.1.1.1当前流量@login_required #需要登陆才能访问def lb_mrs_flow(request): today = str(datetime.date.today()) #获取当前日期 yesterday = str(datetime.date.today() - datetime.timedelta(days=1)) #获取昨天日期 hour = str(datetime.datetime.now().hour) #获取现在小时 lasthour = str((datetime.datetime.now() - datetime.timedelta(hours=1)).hour) #获取前一小时 print (today,yesterday,hour) firstin = lbmrs.objects.values(\"inbandwidth\").filter(host='1.1.1.1',date=today,time__istartswith=hour)) #当前值 firstin_last = lbmrs.objects.values(\"inbandwidth\").filter(host='1.1.1.1',date=today,time__istartswith=lasthour) #前一个小时值 firstin_yes = lbmrs.objects.values(\"inbandwidth\").filter(host='1.1.1.1',date=yesterday,time__istartswith=hour) #昨天的值 print (firstin，firstin_last，firstin_yes) return render(request, 'lb_mrs_flow.html',&#123;'firstin':firstin,'firstin_last':firstin_last,'firstin_yes':firstin_yes,&#125;) #传递到前端 数据库里我们只需要inbandwidth这一列的值，所以这里就不用get()方法了，改用vales()方法，同时搭配filter()添加条件筛选。但是这样获取到的结果是一个QuerySet（查询集），元素为字典，如果要获得里面具体的值，那么就是QuerySet[0][&#39;inbandwidth&#39;],用上面的firstin为例子，如果想要得到具体的值就要改成下面： 1firstin = lbmrs.objects.values(\"inbandwidth\").filter(host='172.1.1.19',date=today,time__istartswith=hour)[0]['inbandwidth'] value和value_list都可以获取指定的字段，但是value_list获得是元素是元组。value_list和value返回的并不是真正的列表或字典，通俗地说，就是用的时候才真正的去数据库查，如果查询后没有使用，在数据库更新后再使用，得到的是新内容。 然后就是前端html文件lb_mrs_flow.html里写一个简单的表格，前端内容就略过不表了，直接来看结果： 可以看到如果value()方法得不到值的话，返回一个&lt;QuerySet []&gt;，如果是get()的话，返回就是一个错误，所以从友好度来说，还是value()更佳。 参考资料https://blog.csdn.net/geerniya/article/details/78549182http://yshblog.com/blog/157https://www.kancloud.cn/hiyang/py/348229 （跨表取字段的方法）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"MySQL","slug":"MySQL","permalink":"http://yoursite.com/tags/MySQL/"}]},{"title":"将Gateone添加到django，实现WEB的ssh链接","slug":"将Gateone添加到django，实现WEB的ssh链接","date":"2019-04-01T04:40:07.000Z","updated":"2019-04-08T09:04:56.000Z","comments":true,"path":"2019/04/01/将Gateone添加到django，实现WEB的ssh链接/","link":"","permalink":"http://yoursite.com/2019/04/01/将Gateone添加到django，实现WEB的ssh链接/","excerpt":"","text":"背景交代python3 + django2.1Django project:accessgateway gateone的安装Gateone是一个web界面的交互工具，很多堡垒机都会使用到它，它的生命力很长久也很经得住考验（不过最近github上已经不再对它有更新了）。安装方法如下： 12345pip install --upgrade setuptoolspip install tornado==4.3pip install Pillowdocker pull liftoff/gateone #拉取镜像，个人推荐把原有的镜像修改一下，添加vim等工具docker run -t -p 8008:8000 -h GATEONE --name gateone liftoff/gateone gateone #创建容器 这样我们就创建了一个叫gateone的容器，宿主机端口是8008，此时通过浏览器访问https://IP：8008，就会看到效果： 默认的gateone是https访问，如果要改成http访问。那么就要修改容器里的/etc/gateone/conf.d文件夹下的10server.conf，修改如下两处： 12\"disable_ssl\": true, #改成http方式\"origins\": [\"localhost:8000\", \"127.0.0.1:8000\", \"594f279c70b0:8000\", \"django的外网IP:django端口\"], #添加django的地址和端口 然后重启容器，改用http://IP：8008方式去访问，发现已经改成HTTP协议了。 gateone的配置现在这个gateone容器需要已经指定准许django来访问，但是还要生成一个api，让django通过api来访问。在容器里执行gateone --new_api_key，发现在/etc/gateone/conf.d文件夹下多了一个30api_keys.conf： 然后修改60docker.conf，把&quot;auth&quot;: &quot;none&quot;,改成&quot;auth&quot;: &quot;api&quot;,保存之后，此时如果重启容器，发现web界面已经不能访问了，会出现unauthenticated的提示，如图： gateone集成到djangogateone部分暂时告于段落，现在配置Django，首先是views.py，注意！python2与python3有些地方不同，我这里是python3版本： 12345678910111213141516171819202122232425262728293031323334import time,hmac,hashlib,json#web交互界面gateonedef gateone(request): id = 1 #这里暂时写死只要id为1的服务器 svr = server.objects.get(id = id) ip = svr.outIP port = svr.port username = svr.username #写死端口和用户名 return render(request,'aggateone.html',locals()) #返回aggateone.html页面#gateone认证def create_signature(secret,*parts): hash = hmac.new(secret, digestmod=hashlib.sha1) for part in parts: hash.update(str(part).encode(\"utf-8\")) return hash.hexdigest()def get_auth_obj(request): # 安装gateone的服务器以及端口. gateone_server = 'http://121.41.37.251:8008' #本地gateone的访问地址，注意http格式 # 生成的api_key 和secret api_key = 'OGQxZGM5OGM1MGNlNDZkNmEwMTNmM2IyY2NlMGZlNjA3Z' #这里是30api_keys.conf文件里的key secret = b'MDIzOWQyN2Y2MmU0NDdhMWIwN2Q3MjIzODU1MGFjYWVkY' #这里是30api_keys.conf文件里的secret authobj = &#123; 'api_key':api_key, 'upn':'gateone', 'timestamp':str(int(time.time() * 1000)), 'signature_method':'HMAC-SHA1', 'api_version':'1.2' &#125; authobj['signature'] = create_signature(secret,authobj['api_key'],authobj['upn'],authobj['timestamp']) auth_info_and_server = &#123;'url':gateone_server,'auth':authobj&#125; return JsonResponse(auth_info_and_server) 然后新增两条路由到urls.py： 12path(r'gateone.html', views.gateone),path(r'get_auth_obj.html',views.get_auth_obj,name=\"get_auth_obj\"), 最后就是编写前端页面aggateone.html： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&#123;% extends 'agbase.html' %&#125;&#123;% load staticfiles %&#125;&#123;% block title %&#125;Gateone远程连接&#123;% endblock %&#125;&#123;% block css %&#125;&lt;script src = \"/static/jquery-3.3.1.min.js\"&gt;&lt;/script&gt;&lt;script src = \"/static/gateone/gateone.js\"&gt;&lt;/script&gt; &lt;!-- 这里需要手动复制一下gateone.js文件到django的静态文件夹里 --&gt;&#123;% endblock %&#125;&#123;% block content %&#125;&lt;script&gt;$(function () &#123; &lt;!--添加参数--&gt; var ip = '&#123;&#123; ip &#125;&#125;'; var user = '&#123;&#123; username &#125;&#125;'; var port = '&#123;&#123; port &#125;&#125;'; var ssh_url = 'ssh://'+user+'@'+ip+':'+port; //请求认证信息 &lt;!--发起认证请求--&gt; $.ajax(&#123; url:'&#123;% url 'get_auth_obj' %&#125;', type:'GET', dataType:'json', success:function (data) &#123; var auth_message = data.auth; var auth_url = data.url; GateOne.init(&#123; auth:auth_message, url:auth_url, theme:'solarized', goDiv:'#gateone', disableTermTransitions:'true', autoConnectURL:ssh_url &#125;); &#125; &#125;); &lt;!--状态记录--&gt; GateOne.Base.superSandbox(\"GateOne.SomePlugin\", [\"GateOne\", \"GateOne.Net\", \"GateOne.Terminal.Input\", \"GateOne.Terminal\"], function(window, undefined) &#123; var location = ip; GateOne.prefs.autoConnectURL=ssh_url; GateOne.prefs.fontSize=\"100%\"; GateOne.prefs.scrollback = 10000; // scrollback buffer up to 10,000 lines GateOne.Terminal.loadFont(\"Source Code Pro\", \"150%\"); GateOne.Net.setLocation(location); &lt;!--记录登录状态--&gt; &#125;);&#125;)&lt;/script&gt;&lt;div id = \"gateone_container\" style = \"position:relative; width: 110em; height: 55em;\"&gt; &lt;div id = \"gateone\"&gt; &lt;/div&gt;&lt;/div&gt;&#123;% endblock %&#125; 重启django进程，浏览器打开gateone.html页面看一下效果： 可见我们已经成功的把gateone嵌入到django里了，而且自动就链接”id=1”这台服务器。大功告成，剩下的就是修改一下细节，给所有服务器一个按钮，只要点击这个按钮就会打开对应的远程链接界面。 事后补充刚才那个views.py里“gateone认证”那两个def函数上面不要加上@login_required，会出现AttributeError: &#39;bytes&#39; object has no attribute &#39;user&#39;错误： 这是因为@login_required这个装饰器首先回去判断user是否是登录状态，会从request里获取User，但是在下面的函数里并没有传递这个User，所以就会报错。如果说非要加上@login_required这个装饰器，那么就要把User传入当做第一个函数。 详情可见：https://stackoverflow.com/questions/13423022/django-str-object-has-no-attribute-user 参考资料http://blog.codecp.org/2018/03/23/Django%E5%9F%BA%E7%A1%80Gateone%E5%AE%9E%E7%8E%B0Web%E7%BB%88%E7%AB%AFSSH%E5%8A%9F%E8%83%BD/https://github.com/liftoff/GateOne/issues/257https://www.jianshu.com/p/b8123a8178de","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"gateone","slug":"gateone","permalink":"http://yoursite.com/tags/gateone/"}]},{"title":"Atlas出了一个很诡异的bug","slug":"Atlas出了一个很诡异的bug","date":"2019-03-26T08:39:18.000Z","updated":"2019-05-06T09:05:14.000Z","comments":true,"path":"2019/03/26/Atlas出了一个很诡异的bug/","link":"","permalink":"http://yoursite.com/2019/03/26/Atlas出了一个很诡异的bug/","excerpt":"","text":"这几天数据库更换密码，就在原有的atlas文件基础上拷贝出来一个新文件，修改了密码，然后启动进程。但是启动之后，发现虽然端口起来了，但是atlas没有连接数据库成功，如图: 登录到atlas后台一看，竟然是双down: 可是在atlas服务器上单独直连阿里云数据库是没任何问题的，而且数据库的监控也没有任何异常。我怀疑是密码含有了atlas不识别的特殊符号，改成了纯数字和字母的组合，重新启动还是不行，这就很尴尬了，明明原来的配置文件可以启动，我就更改了密码和端口，怎么新的进程就不好使？ 于是我尝试抓包，使用tcpdump -s 0 -i any -v port 3318 and src host mysql的ip -w test.pcap，结果发现3318的包少的可怜，于是我就改用tcpdump -s 0 -i any -v host mysql的ip -w test2.pcap扩大了范围，然后发现包有这样的字样： 可见atlas一直以root去请求数据库，但是我这个是阿里云的RDS服务（Mysql 5.6.7)，本身是没有root的，所以就爆“User not exist”。 这就很尴尬了，为什么会突然以root身份请求数据库？莫非这是atlas的BUG？先把问题记录下来，然后慢慢解决… PS.这个BUG后来修复了，需要重新编译安装，新的安装包地址见：https://github.com/RorschachChan/noroot-atlas","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"atlas","slug":"atlas","permalink":"http://yoursite.com/tags/atlas/"},{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"读写分离","slug":"读写分离","permalink":"http://yoursite.com/tags/读写分离/"}]},{"title":"Django搭配anymail去发送邮件","slug":"Django搭配anymail去发送邮件","date":"2019-03-22T11:42:36.000Z","updated":"2019-03-22T12:18:50.000Z","comments":true,"path":"2019/03/22/Django搭配anymail去发送邮件/","link":"","permalink":"http://yoursite.com/2019/03/22/Django搭配anymail去发送邮件/","excerpt":"","text":"注册mailgun账号首先登陆https://app.mailgun.com/sessions/new 里注册一个账号，填写邮件和密码点击注册，会出现这样的页面： 然后在注册的邮件会接到两个邮件，一个是API的邮件，另一个是激活账号邮件，如下： 点击激活之后，就要添加可信任邮箱，mailgun只能对这些可信任邮箱发送邮件，其他邮件就会失败，在Account里选择Authorized Recipients，然后Invite new Recipients创建新的守信邮箱，创建完毕之后，邮箱应该是Unverified的状态，如下： 点击那个Unverified的状态的邮箱，如果你的机器有装foxmail或者outlook的话，就会自动弹出来，你就可以发送一个邮件到指定的邮箱里，不久邮箱就会收到一个确认信，如下： 点击I agree即完成授信，邮箱状态也变成了绿色的Verified。 点击Domains就可以看到账号的api和domain了，如图： 至此，邮箱账号申请部分完成。 开始配置首先安装pip install django-anymail组件，并且在setting.py里添加如下内容： 12345678910111213INSTALLED_APPS = [ ... \"anymail\", ...]ANYMAIL = &#123; \"MAILGUN_API_KEY\": \"这里填写API\", \"MAILGUN_SENDER_DOMAIN\": '这里填写domain',&#125;EMAIL_BACKEND = \"anymail.backends.mailgun.EmailBackend\"# DEFAULT_FROM_EMAIL = \"you@example.com\" # if you don't already have this in settings# SERVER_EMAIL = \"your-server@example.com\" # ditto (default from-email for Django errors) 保存退出之后，在views.py里添加如下信息： 1234from django.core.mail import send_mail#只需一个send_mail 函数，便能发送邮件send_mail(\"It works!这里是标题\", \"This will get sent through Mailgun，这里是内容\",\"domian的内容，即上面图片里那个mailgun.org结尾的东西\", [\"授信的邮箱地址\"]) 保存之后，django会自动重启，就会看到邮件顺利发出去了！ 可以看出只需要一个send_mail就能发送邮件，的确比SMTP方便多了。在实际运用中，就把send_mail放到对应的函数里，然后灵活搭配标题和内容就能使用了！ 故障排错 如果出现Please activate your Mailgun account. Check your inbox or log in to your control panel to resend the activation email.，即账号没激活； 如果出现Sandbox subdomains are for test purposes only. Please add your own domain or add the address to authorized recipients in Account Settings.，即目标邮箱不是授信邮箱，需要添加到授信名单里。 参考资料https://github.com/anymail/django-anymail","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"anymail","slug":"anymail","permalink":"http://yoursite.com/tags/anymail/"}]},{"title":"给Django添加登录拦截器和登录验证码","slug":"给Django添加登录拦截器和登录验证码","date":"2019-03-22T03:39:14.000Z","updated":"2019-03-25T07:45:44.000Z","comments":true,"path":"2019/03/22/给Django添加登录拦截器和登录验证码/","link":"","permalink":"http://yoursite.com/2019/03/22/给Django添加登录拦截器和登录验证码/","excerpt":"","text":"前一篇文章里写了如何做登录、登出界面，看上去效果好像很不错，但是却有一个致命的漏洞：如果有人直接在地址栏里输入对应的url，那么就可以跳过登录验证直接访问！ 这种情况我们需要做一个登录拦截器，这个拦截器的作用就是通过session来判断，如果在没有session的前提下登录网站内部url就会强制跳转到首页，让访问的人登录。 自建的登陆拦截器首先是在APP的目录里（我的project叫Kubernetes）新建一个叫middleware.py的文件，代码如下： 1234567891011121314151617from django.shortcuts import HttpResponseRedirectfrom django.utils.deprecation import MiddlewareMixin#强制登录class SimpleMiddleware(MiddlewareMixin): def process_request(self, request): if request.path != '' and request.path != '/login/': #判断请求的地址不是首页和/login/ if request.session.get('user',None): #如果session里不存在 pass else: return HttpResponseRedirect('/login/') #自动跳回到登录页面#多次访问IP拉黑class BlockedIpMiddleware(object): def process_request(self, request): if request.META['REMOTE_ADDR'] in getattr(settings, \"BLOCKED_IPS\", []): #如果有IP短时间内多次访问 return http.HttpResponseForbidden('&lt;h1&gt;Forbidden&lt;/h1&gt;') #针对此IP给予403 然后在APP的目录里（我的project叫Kubernetes）的setting.py里把这两个中间件加进去。如下： 12345678910MIDDLEWARE = [ 'django.middleware.security.SecurityMiddleware', 'django.contrib.sessions.middleware.SessionMiddleware', 'django.middleware.common.CommonMiddleware', 'django.middleware.csrf.CsrfViewMiddleware', 'django.contrib.auth.middleware.AuthenticationMiddleware', 'django.contrib.messages.middleware.MessageMiddleware', 'django.middleware.clickjacking.XFrameOptionsMiddleware', 'Kubernetes.middleware.SimpleMiddleware', #这个就是新加的] 系统自动重启之后，来验证一下效果，是否在不登录的前提下成功拦截直接访问的url。 Django自带的登陆拦截器上面那个方法逻辑上来说比较简单，能实现功能但是并不是很强力，Django也自带一个“强制登录”的功能，效果比那个强一丢丢。 首先我们先把APP目录里setting.py刚刚新加的&#39;Kubernetes.middleware.SimpleMiddleware&#39;注释掉。在文件末尾添加一句： 12#登录路径LOGIN_URL = '/login/' 然后返回到views.py，给需要登陆才能访问的页面添加一个装饰器： 1234567891011from django.contrib.auth.decorators import login_required@login_required #这个页面需要登陆def tt(request): name = ['james','wade','bosh','yaoming'] return render_to_response('test111.html',&#123;'names':name&#125;)def ttt(request): #这个页面就不需要了，公共读 cpu = 9.66 mem = 66.6 disk = 16.88 return render_to_response('test222.html',&#123;'CPU':cpu,'MEMORY':mem,'DISKUSED':disk&#125;) 我在views.py里设定，访问tt这个函数（urls.py里配置的域名是/k8s/test111)的时候需要强制登陆,访问ttt这个函数（urls.py里配置的域名是/k8s/test222）就可以直接打开。系统重启django之后，我们试一下效果： 可见当访问到/k8s/test111的时候，浏览器会自动跳转到/login/?next=/k8s/test111/ 让你登录，登陆完毕之后才能顺利访问。而/k8s/test222就可以直接访问了。这个方法就是可以更加对受保护的网页有针对性配置，而不是上一个方法统一都跳转到登录面去。 测试的时候出现TypeError: object() takes no parameters报错，看一下是否是post方法请求的，因为get方法是产生一个tcp包，而post是两个。 登录验证码为了防止机器人暴力破解密码，我们往往增加验证码来阻挡一下。市面上开源的比较高级的验证码是google recaptcha2，但是由于国内政策，大陆内的网站往往打不开这个界面。所以用Django Simple Captcha这个比较大众的验证码方式。 首先pip install django-simple-captha，然后在setting.py里把captha加入到INSTALL_APPS里。 然后是执行python manage.py makemigrations和python manage.pymigrate，再打开url.py，添加一句 123456789101112from django.contrib import adminfrom django.urls import path,includefrom . import viewsurlpatterns = [ path('',views.login,name='login'), #登录页 path('homepage.html',views.home,name='home'), #首页 path('admin/',admin.site.urls), path('captcha/',include('captcha.urls')), #这句是新加的，验证码专用 path('k8s/',include('createyaml.urls')), #工具平台分支 path('ag/',include('accessgateway.urls')), #堡垒机分支] 修改一下views.py，如下： 12345678910111213141516171819202122232425262728293031from django.contrib import authfrom django import formsfrom captcha.fields import CaptchaFieldclass CaptchaForm(forms.Form): #引入一个类 captcha = CaptchaField()#登陆def login(request): if request.POST: form = CaptchaForm(request.POST) #将类实例化 username = request.POST.get('username', '') password = request.POST.get('password', '') user = auth.authenticate(username=username, password=password) if form.is_valid(): #如果form合法 human = True #判断是人操作，而不是机器人 if user is not None: auth.login(request, user) # 登录 #request.session['user'] = username # 记录session信息 response = HttpResponseRedirect('homepage.html') response.set_cookie('username',username,3600) #将username写入cookie,超时时间是10分钟 return response else: return render(request,'index.html', &#123;'error': '账号密码有误，请联系管理员!','login_form':form&#125;) else: return render(request,'index.html', &#123;'error': '验证码有误，请重新输入!','login_form':form&#125;) else: form = CaptchaTestForm() # 否者要求重新输入 return render_to_response('index.html',&#123;'login_form':form&#125;)#其他部分略 最后修改对应的html页面，在对应的地方加入即可： 1234&lt;div&gt; &lt;font color='yellow'&gt;验证码(看不清请刷新页面):&lt;/font&gt; &#123;&#123; login_form.captcha &#125;&#125;&lt;/div&gt; 保存之后，系统重新启动django，在浏览器输入网址，就能看到效果了： 这个页面还没有完美，应该再加入一个ajax，实现“点击验证码，刷新页面”的功能就更完美了。 登录验证码的方式还有很多，除了这个django-simple-captha，还有像https://pypi.org/project/django_click_captcha/ 点击倒字的登录方法，甚至还有手机短信的登陆方法，这些高级的方法以后再研究吧。 参考资料https://code.ziqiangxuetang.com/django/django-middleware.htmlhttps://www.jianshu.com/p/1a95808faed9https://blog.csdn.net/xxm524/article/details/48370337http://www.calmkart.com/?p=332https://fanquqi.github.io/2018/03/30/Django%E7%99%BB%E5%BD%95%E9%AA%8C%E8%AF%81/https://blog.csdn.net/teavamc/article/details/77566781https://blog.51cto.com/syklinux/2052484","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://yoursite.com/tags/Django/"},{"name":"url拦截","slug":"url拦截","permalink":"http://yoursite.com/tags/url拦截/"}]},{"title":"给Django添加用户登录登出界面","slug":"给Django添加用户登录页面、验证码和拦截器","date":"2019-03-21T11:50:48.000Z","updated":"2019-03-22T06:40:14.000Z","comments":true,"path":"2019/03/21/给Django添加用户登录页面、验证码和拦截器/","link":"","permalink":"http://yoursite.com/2019/03/21/给Django添加用户登录页面、验证码和拦截器/","excerpt":"","text":"我的Django运维平台很不幸的被公司安全系统扫描出来了，给了我一个超级大警告。主要也怪我当时偷懒，只是在SLB层面做了IP访问限制但是没有给服务器nginx里做白名单，所以网站是可以通过“IP地址加端口”访问的。恰巧ping里面用了一个AES加解密的脚本，那个算法有问题，可以获取当前用户的权限，我特么的还是直接用root启动的nginx，而且这个机器里面还有ansible，当然后果很严重。 出了问题，不能消极对待而要积极解决，于是要先给网站做一个完善的用户登录鉴权系统。再一次背景介绍： python：3.6.5 Django：2.1.1 Project：Kubernetes，文件夹路径就是/django/Kubernetes/ App：createyaml，文件夹路径就是/django/Kubernetes/createyaml 实现用户登录鉴权首先，先编写一个index.html的页面做登录界面，如下： 12345678910111213141516171819202122232425262728293031&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;请先登录&lt;/title&gt; &lt;link rel=\"stylesheet\" href=\"/static/bootstrap-3.3.7/css/bootstrap.min.css\"&gt; #引入css样式 &lt;link rel=\"icon\" href=\"/static/pic/batman.ico\" type=\"image/x-icon\"&gt; #引入一个标签图 &lt;/head&gt; &lt;body background=\"/static/pic/easyplane.jpg\"&gt; #背景图片设置 &lt;div style=\"margin-top: 200px\"&gt; &lt;div style=\"text-align:center;\"&gt; &lt;font color='brown'&gt;&lt;h1&gt;请输入您的账号密码&lt;/h1&gt;&lt;/font&gt; &lt;div&gt; &lt;div&gt; &lt;form class=\"ui form\" method=\"post\" action=\"\"&gt; &lt;div class=\"field\"&gt; &lt;input type=\"text\" name=\"username\" placeholder=\"username\"&gt;&lt;br&gt; &lt;/div&gt; &lt;div class=\"field\"&gt; &lt;input type=\"password\" name=\"password\" placeholder=\"password\"&gt;&lt;br&gt; &lt;/div&gt; &lt;font color=red&gt;&#123;&#123; error &#125;&#125;&lt;/font&gt;&lt;br&gt; #登录错误红色表示 &lt;button class=\"btn btn-default\" type=\"submit\"&gt;登陆&lt;/button&gt; &#123;% csrf_token %&#125; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 效果如下： 在Kubernetes这个app文件夹里的urls.py里给这个鉴权网站添加一个路由： 12345678910from django.contrib import adminfrom django.urls import path,includefrom . import viewsurlpatterns = [ path('',views.login_action,name='login'), #首页就是login_action的函数 path('homepage.html',views.home,name='home'), #将原来的首页改成叫homepage.html path('admin/', admin.site.urls), ...其余省略 ] 在同级的views.py里编写login_action函数，如下： 123456789101112131415161718192021222324from django.shortcuts import render,render_to_responsefrom django.http import HttpResponse,HttpResponseRedirectfrom django.contrib import auth#登陆def login_action(request): if request.method == 'POST': #通过post形式获取，get的话会在地址栏里看到账号密码 username = request.POST.get('username', '') password = request.POST.get('password', '') user = auth.authenticate(username=username, password=password) #使用django自带方式鉴权 if user is not None: auth.login(request, user) # 登录 request.session['user'] = username # 将session信息记录到浏览器 response = HttpResponseRedirect('homepage.html') #鉴权OK就跳转到homepage.html return response else: return render(request,'index.html', &#123;'error': '账号密码有误，请联系管理员!'&#125;) else: return render(request,'index.html')#首页def home(request): context = &#123;&#125; return render_to_response('homepage.html',context) 登陆的用户/密码就是django后台的账号/密码，可以用superuser来登陆。保存文件之后，系统会重启django，查看效果如图： render和render_to_response的区别上面的login_action函数里，用了render和render_to_response，如果只用render_to_response，同时把所有的render改成render_to_response，那么在访问首页的时候就会出现TemplateDoesNotExist at /这样的错误： 明明他俩都是用来展示模板页面的。为什么会有模板不存在这样？原因是render_to_response()的第一个参数必须是要使用的模板名称。如果要给定第二个参数，那么该参数必须是为该模板创建Context时所使用的字典。如果不提供第二个参数，render_to_response()使用一个空字典。而render第一个参数可以是request。 所以如果都要用render_to_response，那么就要改成如下： 1234else: return render_to_response('index.html', &#123;'error': '账号密码有误，请联系管理员!'&#125;，context_instance=RequestContext(request)) else: return render_to_response('index.html') 但是这样的话，可能在登录的时候就会有csrf的错误，需要把csrf去掉。 实现登出功能有了登录还得有登出，还是老套路，先编写路由如下： 1path(r'logout/', views.logout,name=\"logout\"), 然后对应去views.py里写logout这个函数： 123456from django.http import HttpResponseRedirectfrom django.contrib import auth #引入django默认的auth功能#注销def logout(request): auth.logout(request) return HttpResponseRedirect('/login') #跳转到登录页/login 然后就是在首页里添加一个登出的链接，链接指向就是/logout/。测试一下效果： 参考资料http://www.nowamagic.net/academy/detail/1318431","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://yoursite.com/tags/Django/"},{"name":"认证鉴权","slug":"认证鉴权","permalink":"http://yoursite.com/tags/认证鉴权/"}]},{"title":"较深入的理解Pod下的\"多个容器\"定义","slug":"较深入的理解Pod下的多个容器","date":"2019-03-19T07:40:52.000Z","updated":"2019-03-20T03:38:00.000Z","comments":true,"path":"2019/03/19/较深入的理解Pod下的多个容器/","link":"","permalink":"http://yoursite.com/2019/03/19/较深入的理解Pod下的多个容器/","excerpt":"","text":"众所周知，k8s能调度的最小单元就是pod，但是pod里面是可以有多个docker容器的。但是pod和docker之间到底一种什么关系？还是需要实际的操作来更加直白的理解。 首先，先写了一个test.yaml用来启动Pod： 1234567891011121314151617181920212223242526272829303132333435363738394041apiVersion: v1 #这里注意版本号kind: Pod #注意这里的大小写metadata: name: nginx-greenbook labels: app: testspec: volumes: - name: test emptyDir: &#123;&#125; containers: - name: nginx image: nginx ports: - containerPort: 80 volumeMounts: - name: test #这里必须要跟Volumes的名称一致，都是test mountPath: /usr/share/nginx/html - name: debian1 image: debian volumeMounts: - name: test mountPath: /html command: [\"/bin/sh\",\"-c\"] args: - while true; do date &gt;&gt; /html/index.html; sleep 1; done - name: debian2 #每一个容器的名称不能一样 image: debian volumeMounts: - name: test mountPath: /html command: [\"/bin/sh\",\"-c\"] args: - while true; do echo \"woxcwy\" &gt;&gt; /html/index.html; sleep 2; done restartPolicy: Never #死了就死了 这个yaml主要是建立了一个存储卷叫html，它默认类型是emptyDir。这意味着当一个POD被分配到一个节点时，卷先被创建，并只要Pod在节点上运行时，这个卷仍存在（node重启的话，卷内容丢失，所以它只能做一个临时行的存储，如果想要持久化存储请使用hostPath）。第一容器运行nginx的服务器并将共享卷挂载到目录/usr/share/Nginx/html。第二容器使用Debian的镜像，并将共享卷挂载到目录/html，每一秒输入当前时间。第三个容器同理，每两秒输入一些字符串。 然后kubectl create -f test.yaml --record创建这个pod，然后使用docker ps -a就能看到生成了四个docker—分别是pod的三个容器和一个pause容器。使用kubectl exec -it pod名 -c 容器名 /bin/bash进入nginx的容器，会发现里面的/usr/share/nginx/html/index.html果然按照我们的要求在不断的输出日期和字符串。可见这三个容器已经挂载了同一个卷，如图： 可见挂载volume到Pod，本质上是将volume挂载到Pod中的每一个容器。如果在这三个容器ps -ef一下，会发现他们的pid=1的进程是各自的进程而不是pause容器的/pause进程，如图： 所以很多人说pod里每个容器的init进程其实是/pause，而pause容器的作用，可以担任init的角色（默认都docker run -ipc:container:pause），及时的清理僵尸进程。但是在我这里的实验结果看来并不是真的。不知道是不是我某个姿势不对… 话说回来，这个例子很明显的体现了“一个pod里可以有多个容器”这句话，每个pod是一个namespace，即这些容器都可以通过localhost来彼此访问，但是不能重复使用同一个端口而且所有的pod都是同时启动的。 k8s的容器编排这里有一个比较不错的例子：https://cloud.tencent.com/developer/ask/180938 ，个人觉得说的很形象。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"容器","slug":"容器","permalink":"http://yoursite.com/tags/容器/"},{"name":"k8s","slug":"k8s","permalink":"http://yoursite.com/tags/k8s/"},{"name":"云原生","slug":"云原生","permalink":"http://yoursite.com/tags/云原生/"}]},{"title":"从Nginx配置缓存到HTTP缓存","slug":"从Nginx配置缓存到HTTP缓存","date":"2019-03-18T11:52:43.000Z","updated":"2019-03-19T06:15:30.000Z","comments":true,"path":"2019/03/18/从Nginx配置缓存到HTTP缓存/","link":"","permalink":"http://yoursite.com/2019/03/18/从Nginx配置缓存到HTTP缓存/","excerpt":"","text":"使用nginx配置缓存proxy_cache_path是nginx配置缓存的关键词，它是1.7.9之后的版本推出的功能。配置它很简单，只需要在nginx.conf里的http段里添加一句话： 1proxy_cache_path /data/httpd/nginx_cache/ecstore levels=1:2 keys_zone=ecstore:100m max_size=2g inactive=168h; 上面的命令先说明/data/httpd/nginx_cache/ecstore就是nginx配置缓存的文件夹，keys_zone指的是缓存空间名称，100m意思是可以存储8000*100个key；max_size指的是缓存文件可以占用的最大空间；nactive指的是如果一个缓存文件多长时间不被访问，就会被删除； 然后手动建立/data/httpd/nginx_cache/ecstore这个文件夹，给予它nginx可访问的权限，然后在具体的配置文件里加上： 1234567891011121314 location = /wap/ &#123; if ($query_string) &#123; proxy_pass http://172.16.0.199:3000/wap/?$query_string; &#125; proxy_pass http://172.16.0.199:3000/wap/; include headerproxy.conf; proxy_cache ecstore; #这里的ecstore就是上面keys_zone的名称 proxy_cache_key \"$host$request_uri$cookie_user\"; #这里就是缓存的keyproxy_cache_min_uses 5; #至少访问5次就开始缓存，默认情况是访问一次就缓存proxy_cache_methods GET HEAD POST； #对GET、HEAD、POST方法都可以缓存 add_header X-Cache web1$upstream_cache_status; proxy_cache_valid 200 206 302 301 304 2h; #对200、206、302、301、304状态码缓存2小时proxy_no_cache $http_pragma $http_authorization; &#125; 上面这个例子就是“如果访问/wap，会跳转到http://172.16.0.199:3000/，同时记录下缓存” 的配置。重启nginx就会生效。 验证和排错验证nginx是否缓存成功很简单，因为我们在配置文件夹加上了add_header X-Cache web1$upstream_cache_status;这样的配置，那么我们打开目标的网页： 发现看到了add_header的内容，可见缓存是成功的。 如果此刻给这个nginx外面套上一个CDN，那么curl -I在访问页面里具体元素的结果就会是： 我这里用的是阿里云的CDN，可见他们使用Server: Tengine做的CDN，而且这个js元素被CDN成功缓存。如果是TCP_MEM_HIT的字样，那么就说明是是从内存命中的。不同厂家的CDN展示结果不一样的。 如果nginx缓存没有生效，很大可能是Cache-Control和Set-Cookie的问题，那么就要在上面的配置文件里添加： 1proxy_ignore_headers Set-Cookie Cache-Control; 重启nginx看看效果。 Vary跟Etag的差别在上面的截图里看到了Etag和Vary这两个字段，先说Etag。 Etag是一个比较常见的字段，HTTP利用它来判断所访问的元素是否发生了变化—如果浏览器发送请求的请求头If-None-Match里的Etag没有变化（为False）那么服务器就直接304，把缓存内容返给浏览器；如果Etag发生变化了，那么服务器就拿出新的内容给它同时反馈200。它比Last-Modified强的最重要的地方就是Last-Modified只能精确到秒，遇到1s内修改了N次的情况就只能干瞪眼了，而Etag不会。 而说Vary之前要先说一下Cache-Control，Cache-Control有四个比较出名的缓存策略，分别是：1.no-cache：可以在本地缓存，可以在代理服务器缓存，但是这个缓存要服务器验证才可以使用；2.no-store：彻底得禁用缓存，本地和代理服务器都不缓存，每次都从服务器获取；3.private：为仅浏览器客户端可缓存；4.public：为多个用户都可以缓存，比如可以缓存到CDN上。 而图片里的Vary: Accept-Encoding是什么意思呢？它是告诉缓存服务器根据Accept-Encoding头值的不同去缓存不同的版本，比如同一个文件可能有gzip方式压缩的，有compress方式压缩的，甚至还有没压缩的。因为在实际的场景中，我们需要一些特殊的缓存：它会忽略响应头中的Content-Encoding，从而可能给不支持压缩的客户端返回缓存的压缩版本。有两个方案可以避免这种情况发生：1.将响应头中的Cache-Control字段设为private，告诉中继缓存（比如CDN）不要缓存它；2.增加Vary: Accept-Encoding响应头，明确告知缓存服务器按照Accept-Encoding字段的内容，分别缓存不同的版本； 通常为了更好的利用中间实体的缓存功能，我们都用第二种方案。对于css、js这样的静态资源，只要客户端支持gzip，服务端应该总是启用它；同时为了避免有BUG的缓存服务器给用户返回错误的版本，还应该输出Vary: Accept-Encoding。 nginx配置Vary：Accept-Encoding也很简单，在nginx.conf的http段里加上gzip_vary on;即可。 当然Vary还要很多种，比如Vary: User-Agent, Cookie，这表示“服务端同时使用请求头中User-Agent和Cookie这两个字段来生成内容”。注意！客户端如果直接访问源服务器的话，Vary就没意义了。 参考资料https://blog.csdn.net/dengjiexian123/article/details/53386586https://blog.csdn.net/t12x3456/article/details/17301897https://www.jianshu.com/p/625c2b15dad5https://imququ.com/post/vary-header-in-http.htmlhttps://developer.mozilla.org/zh-CN/docs/Web/HTTP/Caching_FAQhttps://segmentfault.com/a/1190000016648967","categories":[{"name":"工作与原理","slug":"工作与原理","permalink":"http://yoursite.com/categories/工作与原理/"}],"tags":[{"name":"CDN","slug":"CDN","permalink":"http://yoursite.com/tags/CDN/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"HTTP","slug":"HTTP","permalink":"http://yoursite.com/tags/HTTP/"}]},{"title":"从limit和request来理解k8s的资源调配","slug":"从limit和request来理解k8s的资源调配","date":"2019-03-13T12:34:00.000Z","updated":"2019-09-23T03:58:42.000Z","comments":true,"path":"2019/03/13/从limit和request来理解k8s的资源调配/","link":"","permalink":"http://yoursite.com/2019/03/13/从limit和request来理解k8s的资源调配/","excerpt":"","text":"背景交代今天用阿里云的k8s做实验，在worker(2核4G)上执行这么一句话： 1kubectl run chengx --image=registry.cn-hangzhou.aliyuncs.com/lechangetest/chentest:chengx --port=80 --replicas=5 --limits=\"cpu=200m,memory=512Mi\" 发现命令执行之后，只剩成了4个pod，一个卡在Pending的状态，如图： 使用kubectl describe pod/chengx-5bb8bcb9c9-tlgz4查看为什么会失败，看到理由是0/4 nodes are available: 1 Insufficient memory, 3 node(s) had taints that the pod didn&#39;t tolerate.，如图： 错误直译过来就是“4个node里已经没有可用的，现在内存爆缸了，其中三个node都因为有污点同时这个pid无法容忍这个污点”。 limit和request的不同我上面的命令里面用到了limit，所以先研究一下limit和request这俩参数，先说request: 123容器使用的最小资源需求, 作为容器调度时资源分配的判断依赖。只有当前节点上可分配的资源量 &gt;= request 时才允许将容器调度到该节点。request参数不限制容器的最大可使用资源 再说limit: 12容器能使用资源的最大值设置为0表示对使用的资源不做限制, 可无限的使用 request和limit的关系: 1234request能保证pod有足够的资源来运行, 而limit则是防止某个pod无限制的使用资源, 导致其他pod崩溃. 两者的关系必须满足:0 &lt;= request &lt;= limit &lt;= Infinity 复制代码如果limit=0表示不对资源进行限制, 这时可以小于request。目前CPU支持设置request和limit，memory只支持设置request， limit必须强制等于request， 这样确保容器不会因为内存的使用量超过request但是没有超过limit的情况下被意外kill掉。 举个例子，在一个2核4G的node里，运行一个(CPU Requst,CPU Limit,Memory Requst, Memory Limit)= (1U, 1U, 2G,2G)的POD是完全OK的，这个POD不一定一定要用满2G，它可以用到0.1G或者1.99G,只要是内存在2G以内，这个POD都是不受影响的。 如果这个时候，又来了一个POD，他的资源参数为(CPU Requst,CPU Limit,Memory Requst, Memory Limit)= (1U, 1U, 1G,2G)，那么这个POD2的内存在2G以内的情况下，POD1和POD2都是OK的。如果POD2的超过了2G，那么POD2会挂掉，而POD1安全无事。 若namespace里事前设定了CPU和内存的request和limit，那么在生成pod的时候，若无特殊说明，pod的request和limit值与所处的namespace相同。如果pod说明了request没说明limit，那么pod的limit等于声明的request。如果pod说明了request没有说明limit，那么limit值等于namespace默认的limit。 注意！namespace的limit值是可以比实际pod的limit值小的，如图： 可见这个叫default-mem-example的namespace默认的request是256Mi，limit是512Mi，而我是可以在这个namespace里创建一个request是1G的pod，如图： 额外补充一下，k8s里的计量单位：1Mi=1024x1024，1M=1000x1000，其它单位类推，如Ki/K、Gi/G。 重新说回来再次说回0/4 nodes are available: 1 Insufficient memory, 3 node(s) had taints that the pod didn&#39;t tolerate.，从这句话里我们看到虽然这个k8s集群有4个node（3个master+1worker)，使用kubectl describe node master节点名称来查看master上是否存在默认的taint: 再看一下worker节点的taint: 在master上默认是不会将Pod调度到具有该污点的Node上，也就是说所有pod都是在worker这个节点上的。worker上只有4G，而我生成了5个limit=512Mi的pod，需要2.5G的内存空间。然而worker这个pod现在有多少可用的内存呢？kubectl describe node worker名称可见剩余的memory已经不足，如图: 1234567Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 200m (10%) 0 (0%) memory 1736Mi (62%) 2248Mi (80%)Events: &lt;none&gt; 现在剩余的内存值仅有20%，所以由于内存不够而生成失败，需要在kubectl run里适当调小内存的limit值，或者干脆扩容一个worker，让它在另一个worker里出现。 如果想要查看某个pod是具体落在哪个node里，使用命令：kubectl get pods -o wide即可。 关于Docker的资源调配docker默认情况对cpu和内存都是无限制的，如果cpu跑爆了，那么容器也不会死掉，而是慢慢的跑。但是如果内存跑爆了，容器会被oom，不过可以通过设置oom的值让容器被干掉的几率低一点。 如果在一个四核的服务器里通过docker run -it --rm --cpus=2 镜像:latest /bin/bash启动了一个容器，那么这个进程跑到200%就到顶了，而且这200%是平均分配到4个核上，每个核50%，而不是把1和2核跑100%，剩下3和4是空着的。 如果想要把某一个CPU跑满，命令是docker run -it --rm --cpuset-cpus=&quot;1，3&quot; 镜像名:latest /bin/bash，这样的话就会只在第一个和第三个CPU上跑，而不会动用其他的CPU。 前面说的是CPU，现在说内存。如果是想要限制某个docker的内存最大是300M:docker run -it -m 300M --memory-swap -1 --name con1 镜像名 /bin/bash，设置 memory-swap 值为 -1，它表示容器程序使用内存的受限，而可以使用的 swap 空间使用不受限制(宿主机有多少 swap 容器就可以使用多少)。 如果这个容器大于300M了，那它就直接被OOM kill了。如果有足够的 swap，程序至少还可以正常的运行。当然，我们也可以通过--oom-kill-disable选项强行阻止OOM kill的发生。限制内存上限虽然能保护主机，但是也可能会伤害到容器里的服务：如果为服务设置的内存上限太小，会导致服务还在正常工作的时候就被 OOM 杀死；如果设置的过大，会因为调度器算法浪费内存。所以内存压力测试是不可避免的，而且也尽量不要使用swap，因为swap的使用会导致内存计算复杂，对调度器非常不友好。 参考资料https://www.qikqiak.com/post/understand-kubernetes-affinity/https://blog.frognew.com/2018/05/taint-and-toleration.htmlhttps://jimmysong.io/kubernetes-handbook/concepts/taint-and-toleration.htmlhttps://stackoverflow.com/questions/53192999/pod-dont-run-insufficient-resourceshttp://dockone.io/article/2509https://www.yangcs.net/posts/understanding-resource-limits-in-kubernetes-cpu-time/http://blog.whysdomain.com/blog/171/https://www.cnblogs.com/sparkdev/p/8052522.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"k8s","slug":"k8s","permalink":"http://yoursite.com/tags/k8s/"},{"name":"云原生","slug":"云原生","permalink":"http://yoursite.com/tags/云原生/"}]},{"title":"使用gdb去进入Too many connections的Mysql","slug":"使用gdb去进入Too-many-connections的Mysql","date":"2019-03-11T06:17:36.000Z","updated":"2019-06-06T06:02:08.000Z","comments":true,"path":"2019/03/11/使用gdb去进入Too-many-connections的Mysql/","link":"","permalink":"http://yoursite.com/2019/03/11/使用gdb去进入Too-many-connections的Mysql/","excerpt":"","text":"今天在登录mysql的时候，发现Too many connections的错误，如图： 很明显，连接数不够用了，在my.cnf里看到当前的最大链接是500。一般来说很多人就会修改my.cnf将max_connections改大然后重启mysql生效。但是我这个mysql是生产环境的，如果重启势必产生不小的影响，于是就需要不重启mysql还要能达到修改max_connections的目的。 那就用gdb，语句如下： 1[root@db-02 data]# gdb -p $(cat /opt/mysql/data/Storage.pid) -ex \"set max_connections=1024\" -batch 执行完毕之后，就可以正常登录到mysql的交互页面了： 此时查询一下最大连接数： 可见已经生效了，但是如果这个时候mysql有重启的话，还是会读取my.cnf里的max_connections配置，所以再手动改下max_connections即可。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"Centos7安装部署Hadoop集群","slug":"Centos6安装部署Hadoop集群","date":"2019-03-07T06:17:06.000Z","updated":"2019-03-08T02:52:40.000Z","comments":true,"path":"2019/03/07/Centos6安装部署Hadoop集群/","link":"","permalink":"http://yoursite.com/2019/03/07/Centos6安装部署Hadoop集群/","excerpt":"","text":"目前大环境感觉不好，哪哪都是裁人的消息，所以这个时候更是要摆正心态、沉淀自己。 今年我个人的小目标是：Hadoop+k8s+python开发，这次就先写Hadoop的部署过程，可能会有一些名词看不懂，等下一篇再说名词解释。 先说环境： 12192.168.1.86 Master 华为云Centos7.5192.168.1.165 Salve 华为云Centos7.5 为了高可用，还要部署zookeeper来监视节点心跳情况，我这个例子里没有，如果有需要可以单独部署。 所有机器都要操作本段过程是所有的服务器都要一起操作的！ 先yum update -y，在等待的时候，我们就新开一个窗口，wget http://apache.01link.hk/hadoop/common/hadoop-3.1.2/hadoop-3.1.2.tar.gz 下载3.1.2版本的hadoop，下载完毕后，解压缩hadoop-3.1.2.tar.gz到/opt下，然后把hadoop-3.1.2改名叫hadoop。 在yum update -y完成之后，我们还要yum install java-1.8.0-openjdk* -y，安装完毕之后，执行java -version确认已经安装java 1.8成功。 在/etc/hosts文件里添加： 12192.168.1.86 master192.168.1.165 slave 修改配置文件，hadoop所有的配置文件都在/opt/hadoop/etc/hadoop路径下。先修改hadoop-env.sh，添加一句export JAVA_HOME=/usr，因为我们直接用yum安装的，java默认就会安装到/usr/bin/java。所以这里写/usr即可，如果是另外方法安装需要写具体的路径而且要修改/etc/profile和source /etc/profile。 在core-site.xml里的configuration里添加如下内容： 12345678910&lt;!-- 指定hadoop运行时产生文件的存储目录,可以指定自己熟悉的目录，默认/tmp/hadoop-$&#123;user.name&#125; --&gt;&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/tmp&lt;/value&gt;&lt;/property&gt;&lt;!-- 指定hadoop使用的文件系统，HDFS的老大NameNode的地址 --&gt;&lt;property&gt; &lt;name&gt;fs.default.name&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt;&lt;/property&gt; 在hdfs-site.xml里的configuration里添加如下内容： 12345678910111213141516171819202122 &lt;!-- 指定HDFS副本数量，默认3 --&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.name.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/dfs/name&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.data.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/dfs/data&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.permissions&lt;/name&gt; &lt;value&gt;true&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;dfs.http.address&lt;/name&gt; &lt;value&gt;0.0.0.0:50070&lt;/value&gt;&lt;!-- 如果不加这句话，50070端口打不开 --&gt; &lt;/property&gt; 在mapred-site.xml里的configuration里添加如下内容： 12345678910111213&lt;!-- 指定mapred运行时的框架：yarn，默认local --&gt;&lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapred.job.tracker&lt;/name&gt; &lt;value&gt;master:49001&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;mapred.local.dir&lt;/name&gt; &lt;value&gt;/opt/hadoop/var&lt;/value&gt;&lt;/property&gt; 在yarn-site.xml里的configuration里添加如下内容： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950 &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;description&gt;The address of the applications manager interface in the RM.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8032&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;description&gt;The address of the scheduler interface.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.scheduler.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8030&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;description&gt;The http address of the RM web application.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.webapp.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8088&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;description&gt;The https adddress of the RM web application.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.webapp.https.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8090&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.resourcemanager.resource-tracker.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8031&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;description&gt;The address of the RM admin interface.&lt;/description&gt; &lt;name&gt;yarn.resourcemanager.admin.address&lt;/name&gt; &lt;value&gt;$&#123;yarn.resourcemanager.hostname&#125;:8033&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.scheduler.maximum-allocation-mb&lt;/name&gt; &lt;value&gt;1024&lt;/value&gt; &lt;discription&gt;每个节点可用内存,单位MB,默认8182MB&lt;/discription&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.vmem-pmem-ratio&lt;/name&gt; &lt;value&gt;2.1&lt;/value&gt;&lt;/property&gt;&lt;property&gt; &lt;name&gt;yarn.nodemanager.resource.memory-mb&lt;/name&gt; &lt;value&gt;1024&lt;/value&gt;&lt;/property&gt; 把workers这个文件里的localhost替换成slave，2.X版本hadoop里的workers文件叫slaves。 至此，所有机器操作的部分完毕，要确认两边的内容必须保持一致，不然启动的时候就会出现优先级出错的故障。 只有Master操作以下操作只有master操作！ 由于Master是namenode，slave是datanode，现在就需要对namenode进行一个初始化的操作，即是hdfs的一个初始化。 进入/opt/hadoop/bin里，执行./hadoop namenode -format ，格式化一个新的分布式文件系统，如果不报错那就说明成功。完毕之后，可以去/opt/hadoop/dfs/name这个目录下发现多了一个current文件夹。 配置普通用户免密码登录至此整个部署过程就完毕了，如果是root用户就可以直接去/opt/hadoop/hadoop-2.8.0/sbin下执行./start-all.sh了，但是为了安全，我们不要用root用户去启动hadoop，而是用普通用户去启动它。 于是我们先在两台机器上adduser hadoop，这里不设置密码。然后chown -R /opt/hadoop，把整个hadoop文件夹的权限都给hadoop用户。 然后执行ssh-keygen -t rsa，一顿回车之后发现在/home/hadoop/.ssh下有了id_rsa和id_rsa.pub这俩文件。这俩就是root用户的ssh公钥和私钥文件，su hadoop切换到hadoop用户上，同样的操作一遍，获取到hadoop用户的ssh公钥和私钥文件。 master和slave都在/home/hadoop/.ssh下新建一个文件叫authorized_keys，并且互相复制对方的hadoop的id_rsa.pub到自己的authorized_keys里，然后再复制自己的root的id_rsa.pub到自己的authorized_keys里。 修改authorized_keys的权限是600，此时无论是master还是salve的hadoop用户都应该可以无密码登录自己和对方，如图： 启动Hadoop当前用户是hadoop，在master机器上执行/opt/hadoop/sbin/start-all.sh即启动hadoop，如图： 此时在slave机器上会看到有两个进程启动： 12hadoop 13552 1 2 10:35 ? 00:00:03 /usr//bin/java -Dproc_datanode -Djava.net.preferIPv4Stack=true -Dhadoop.security.logger=ERROR,RFAS -Dyarn.log.dir=/opt/hadoop/logs -Dyarn.log.file=hadoop-hadoop-datanode-slave.log -Dyarn.home.dir=/opt/hadoop -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/hadoop/lib/native -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=hadoop-hadoop-datanode-slave.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml org.apache.hadoop.hdfs.server.datanode.DataNodehadoop 13670 1 3 10:35 ? 00:00:04 /usr//bin/java -Dproc_nodemanager -Djava.net.preferIPv4Stack=true -Dyarn.log.dir=/opt/hadoop/logs -Dyarn.log.file=hadoop-hadoop-nodemanager-slave.log -Dyarn.home.dir=/opt/hadoop -Dyarn.root.logger=INFO,console -Djava.library.path=/opt/hadoop/lib/native -Dhadoop.log.dir=/opt/hadoop/logs -Dhadoop.log.file=hadoop-hadoop-nodemanager-slave.log -Dhadoop.home.dir=/opt/hadoop -Dhadoop.id.str=hadoop -Dhadoop.root.logger=INFO,RFA -Dhadoop.policy.file=hadoop-policy.xml -Dhadoop.security.logger=INFO,NullAppender org.apache.hadoop.yarn.server.nodemanager.NodeManager 或者使用jps命令在双方机器上查看启动的进程名： 12345[root@slave hadoop]# jps13552 DataNode13670 NodeManager1543 WrapperSimpleApp13790 Jps 在华为云的安全组里对这俩服务器打开50070端口和8088的公网访问端口，然后在浏览器里输入http://master公网IP:50070即可查看效果： 而输入http://master公网IP:8088就会看到cluster页面： 如果要关闭，就在master执行/opt/hadoop/sbin/stop-all.sh，至此一个简单的hadoop集群搭建和启动完毕。 参考资料https://www.cnblogs.com/charlesblc/p/6030008.htmlhttps://blog.wuwii.com/linux-hadoop.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://yoursite.com/tags/大数据/"},{"name":"Hadoop","slug":"Hadoop","permalink":"http://yoursite.com/tags/Hadoop/"}]},{"title":"Zabbix出现数据库IIllegal mix of collations的报错","slug":"Zabbix出现数据库IIllegal-mix-of-collations的报错","date":"2019-03-05T02:07:04.000Z","updated":"2019-03-05T02:22:12.000Z","comments":true,"path":"2019/03/05/Zabbix出现数据库IIllegal-mix-of-collations的报错/","link":"","permalink":"http://yoursite.com/2019/03/05/Zabbix出现数据库IIllegal-mix-of-collations的报错/","excerpt":"","text":"接到新的私有云工作，登录到甲方爸爸的服务器一看是centos6.1，上面安装了zabbix-server但是仅仅做了auto-discovery，于是我就做templates，可见名称是中文的。但是发现在保存的时候，出现了这样的错误： 定眼一看，这是数据库的编码问题，整个database都是拉丁编码而不是utf8编码，所以无法输入中文。 要解决这个问题比较简单，毕竟zabbix刚启动而已，数据库里还没有数据。于是我就干脆把整个zabbix的database干掉，重建一个新的： 12mysql -hlocalhost -uzabbix -p #登录数据库drop databases zabbix; #暴力全部删光 此时的zabbix-server的web界面是如下的： 然后返回到mysql里： 123create database zabbix character set utf8; # ctrl+c 退出数据库zcat /usr/share/doc/zabbix-server-mysql-3.4.15/create.sql.gz |mysql -uzabbix -p26e9p69r zabbix #重新导入初始化表 然后在web界面点击retry，然后重新登陆一下zabbix-server。再次尝试编辑带有中文的监控项，就能顺利保存了！","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"}]},{"title":"不要轻易去打开tcp_tw_recycle！","slug":"不要轻易去打开tcp-tw-recycle！","date":"2019-03-04T07:23:09.000Z","updated":"2019-03-04T09:06:58.000Z","comments":true,"path":"2019/03/04/不要轻易去打开tcp-tw-recycle！/","link":"","permalink":"http://yoursite.com/2019/03/04/不要轻易去打开tcp-tw-recycle！/","excerpt":"","text":"挖坑过程有时候，我们可能发现服务器里存在大量的TIME_WAIT，如图： 其实这2000+的TIME_WAIT真的不算多，至少低于10000条都不算多。但是TIME_WAIT本身是一个占用内存和CPU的东西，所以很多人就想把它干掉。往往这个时候，就会看到这样的答案： 1234打开 sysctl.conf 文件，修改以下几个参数：net.ipv4.tcp_tw_recycle = 1net.ipv4.tcp_tw_reuse = 1net.ipv4.tcp_timestamps = 1 #只有打开这个，前俩才能生效 修改完毕之后，再/sbin/sysctl -p一下，就会看到TIME_WAIT果然大量减少，效果立竿见影！但是不要高兴太早，其实你给自己埋下了一个大坑… TIME_WAIT是干啥的只有主动关闭连接的一方，才会转移到TIME_WAIT。只有被动断开连接的一方会出现CLOSE_WAIT，等待close()执行完毕之后，状态变成LAST_ACK。 TIME_WAIT的主要目的有2个： 避免误收延迟到达的报文：因为报文又快又慢，而若TIME_WAIT太短就会放弃原来的链接，生成新的链接，而新的链接此时接到迟到了报文，这就出现了数据错误的现象； 保证对端已经关闭了连接：由于TIME_WAIT的时间被缩短了，对端还处于LAST_ACK状态，本段发送的syn报文被直接RST掉了。 再说结论当配置了net.ipv4.tcp_tw_recycle = 1之后，TIME_WAIT这个阶段就几乎是不存在了，因为原本它的存活时间是2MSL时间，现在改成了一个RTO，这个RTO可以远远小于2MSL的。当一个socket连接进入TIME_WAIT状态后，内核里会记录包括该socket连接对应的五元组中的对方IP等在内的一些统计数据，当然也包括从该对方IP所接收到的最近的一次数据包时间。当有新的数据包到达，只要时间晚于内核记录的这个时间，数据包都会被统统的丢掉。 那怎么会影响具体业务呢？如果你所在的网络是NAT网络，即“多个客户端，但是同一个IP出口”这样的网络环境，这样很多人其实使用的是同一个IP。但是在服务器端它是始终在跟同一个host打交道，那么在一个RTO的时间内，只能有一个客户端和自己连接成功，而其他人要连接就会出现超时的现象。 抓包体现是客户端发送了syn给服务端，但是服务端不会回复ack，然后客户端就一直处于等待，通畅以为服务器端此时卡死了，可是此时服务器的负载并不高。 为什么TCP4次挥手时等待为2MSL？MSL是Maximum Segment Lifetime,译为“报文最大生存时间”，他是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。等待2MSL时间主要目的是怕最后一个ACK包对方没收到，那么对方在超时后将重发第三次握手的FIN包，主动关闭端接到重发的FIN包后可以再发一个ACK应答包。TCP只有断开了才会释放占用端口等资源，新来的链接才能复用这个端口。若被动断开的一方一直收不到最后一个ACK,那就会等待retry times到了上限，会reset连接。 如果不等，释放的端口可能会重连刚断开的服务器端口，这样依然存活在网络里的老的TCP报文可能与新TCP连接报文冲突，造成数据冲突，为避免此种情况，需要耐心等待网络老的TCP连接的活跃报文全部死翘翘，2MSL时间可以满足这个需求。 正确做法解决办法就是不建议同时开启tcp_timestamp和tcp_tw_recycle。 正确的解决这个总是办法应该是： 1234net.ipv4.ip_local_port_range = 9000 6553 #默认值范围较小net.ipv4.tcp_max_tw_buckets = 10000 #默认值较小，还可适当调小net.ipv4.tcp_tw_reuse = 1 #net.ipv4.tcp_fin_timeout = 10 # 插播一句，tcp_tw_recycle这个参数已经在新的内核kernel 4.12里已经去掉了。 参考资料https://www.cnxct.com/coping-with-the-tcp-TIME_WAIT-state-on-busy-linux-servers-in-chinese-and-dont-enable-tcp_tw_recycle/https://ieevee.com/tech/2017/07/19/tcp-tw-recycle.html#TIME_WAIT%E6%98%AF%E5%B9%B2%E5%95%A5%E7%9A%84https://www.jianshu.com/p/893b5d7e9f30https://www.zhihu.com/question/67013338https://mp.weixin.qq.com/s?__biz=MzI4MjA4ODU0Ng==&amp;mid=2650910938&amp;idx=2&amp;sn=8b0aa87b0f45b8465e3fe9a70f51c895&amp;chksm=f06a55d7c71ddcc120d49d4808ac471d6ae37c105cf37cbfdf142384a3bb2fb5b94ff76b904a&amp;mpshare=1&amp;scene=1&amp;srcid=0226ijYLsAmX7LdKO206NINd&amp;key=d98c1a7a91040c8d88006a294b27c49cb4fc4e200242db9cfabf2f4d98e420954e2210ce8d72d0ea778a548e2596bef617479a59cc23a4164f93cfd0cfa85a8d460c21de5501f934e13fd0fc2e50cbce&amp;ascene=1&amp;uin=MTE4NTkxNTEwMA%3D%3D&amp;devicetype=Windows+7&amp;version=62060720&amp;lang=zh_CN&amp;pass_ticket=RxcXlxUz8iYDMMdnmhYX6NfQJkTaZzim2gD9j8q74LaeYI8X1cSH0njnQZXJfH8g","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"tcp链接","slug":"tcp链接","permalink":"http://yoursite.com/tags/tcp链接/"},{"name":"内核优化","slug":"内核优化","permalink":"http://yoursite.com/tags/内核优化/"}]},{"title":"Linux运维工程师笔试题第十八套","slug":"Linux运维工程师笔试题第十八套","date":"2019-03-04T03:52:02.000Z","updated":"2019-06-10T07:02:02.000Z","comments":true,"path":"2019/03/04/Linux运维工程师笔试题第十八套/","link":"","permalink":"http://yoursite.com/2019/03/04/Linux运维工程师笔试题第十八套/","excerpt":"","text":"试题内容1.docker的exec与attach命令有啥区别？attach开启一个和正在运行的进程交互的终端，如果该进程结束，原docker container的进程也会结束。exec可以开启多个终端实例，exec -i /bin/bash，由此可见exec其实是在运行中的容器中执行一个命令。 2.docker的CMD与ENTRYPOINT命令有啥区别？CMD的命令会被docker run里的命令覆盖，而ENTRYPOINT命令不会。如果要覆盖ENTRYPOINT，则在docker run里添加--entrypoint标签来覆盖即可。如果dockerfile里指定了WORKDIR，那么无论是CMD还是ENTRYPOINT命令都是在这个WORKDIR目录里执行。 3.docker的kill和stop命令有啥区别？stop是“优雅退出”，先发送SIGTERM信号，在一段时间之后（10s）再发送SIGKILL信号。Docker内部的应用程序可以接收SIGTERM信号，然后做一些“退出前工作”，比如保存状态、处理当前请求等。kill是“暴力退出”，即发送SIGKILL信号，应用程序直接退出。 4.假设有一个AAA的容器，现在需要备份它的挂载卷/DATA里的数据，请问如何操作？ 1docker run --volumes-form A -v /tmp:/backup --name BACKUP ubuntu tar cvf /backup/A.tar /DATA 上面这个语句新建立一个叫BACKUP的容器，它与A容器挂载情况相同（即都是挂载/DATA），同时将本地的/tmp挂载到容器的/backup，在容器生成的时候，执行了tar cvf /backup/A.tar /DATA将DATA文件夹的内容进行了打包，又由于/tmp已经与/backup挂载，所以就可以直接从宿主机上的/tmp里得到A.tar了。 4.linux里删除某个用户的所有进程的语句？ps -u username | grep -v PID | awk ‘{print$1}’| xargs kill -9或者killall -u username 5.linux如何彻底删除一个用户？userdel -r zhidao（前提是这个用户下已经没有程序运行了） 6.杀死某进程的命令？ps -ef |grep 进程名 |grep -v grep|awk ‘{print $2}’|xargs kill -9注意！这里awk后面是单引号不是双引号 7.普通用户如何访问docker?使用gpasswd -a lcshop docker把该用户添加到docker组即可。 8.输入ping IP后敲回车，发包前会发生什么？首先要知道，ICMP协议是三层（网络层协议），因为不带端口所以肯定不是四层，又因为依赖IP地址所以肯定比2层高。 其次ping可以帮我们了解到是否能够与对方连通，但是ping如果能不开就不开，因为网络上会有无聊的人给你发大量的ping包把你的带宽占满。 回到题目中，假设是下图中的A在ping B: 回车之后，主机A就要封装二层报文，它会先查自己的MAC地址表，如果没有B的MAC地址，就会向外发送一个ARP广播包。交换机会收到这个报文后，由于交换机有学习MAC地址的功能，所以他会检索自己有没有保存主机B的MAC，如果有，就直接返回给主机A；如果没有，就会向所有端口发送ARP广播，其它主机收到后，发现不是在找自己，就纷纷丢弃了该报文，不去理会。直到主机B收到了报文后，就立即响应，我的MAC地址是多少，同时它也学到主机A的MAC地址，并按同样的ARP报文格式返回给主机A，这时候主机A学到了主机B的MAC，就把B的MAC地址封装到ICMP包中，向主机B发送一个回显请求，主机B收到该报文后，知道是主机A的一个回显请求，就会返回一个相同格式的报文。这样就完成了同一个网段的Ping的过程。 如果主机A要ping主机C，那么主机A发现主机C的IP和自己不是同一网段，它就去找网关转发，但是它也不知道网关的MAC情况下呢?就会像之前那个步骤一样：先发送一个ARP广播，学到网关的MAC，再发封装ICMP报文给网关路由器。当路由器收到主机A发过来的ICMP报文，发现自己的目的地址是其本身MAC地址，根据目的的IP2.1.1.1查路由表，发现2.1.1.1/24的路由表项，得到一个出口指针，去掉原来的MAC头部加上自己的MAC地址向主机C转发。如果网关也没有主机C的MAC地址,还是要向前面一个步骤一样,ARP广播一下即可相互学到。路由器2端口能学到主机D的MAC,主机D也能学到路由器2端口的MAC。最后，在主机C已学到路由器2端口MAC，路由器2端口转发给路由器1端口，路由1端口学到主机A的MAC的情况下，他们就不需要再做ARP解析，就将ICMP的回显请求回复过来。 9.MySQL的数据如何恢复到任意时间点？ 10.假设有一个dockerfile内容如下： 123FROM ubuntuENTRYPOINT [&quot;top&quot;, &quot;-b&quot;]CMD [&quot;-c&quot;] 然后凭借此dockerfile创建一个镜像，然后docker run -it --rm --name test 镜像名称 -H的实际结果是什么？ 实际执行结果是相当于执行top -b -H，没有-c。因为使用exec格式（只能加双引号），在docker run &lt;image&gt;的所有参数，都会追加到ENTRYPOINT之后，并且会覆盖CMD所指定的参数。CMD与ENTRYPOINT一样，如果dockerfile有多个的话，只有最后一个生效。 11.假设有一个dockerfile A内容如下： 12ENV name Cloud ManENTRYPOINT [&quot;/bin/echo&quot;, &quot;Hello, $name&quot;] 还有一个B dockerfile内容如下： 12ENV name Cloud Man ENTRYPOINT echo &quot;Hello, $name&quot; 请问两者分别运行容器结果是啥？A是Hello, $name，B是Hello, Cloud Man。A的环境变量并没有达到效果，如果想要达到效果，应该改成如下： 12ENV name Cloud Man ENTRYPOINT [&quot;/bin/sh&quot;, &quot;-c&quot;, &quot;echo Hello, $name&quot;] 参考资料https://stackoverflow.com/questions/30960686/difference-between-docker-attach-and-docker-exechttp://dockone.io/question/469https://www.ibm.com/developerworks/community/blogs/132cfa78-44b0-4376-85d0-d3096cd30d3f/entry/RUN_vs_CMD_vs_ENTRYPOINT_%E6%AF%8F%E5%A4%A95%E5%88%86%E9%92%9F%E7%8E%A9%E8%BD%AC_Docker_%E5%AE%B9%E5%99%A8%E6%8A%80%E6%9C%AF_17?lang=enhttps://c.isme.pub/2018/07/11/python-interview/","categories":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/categories/大牛之路/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"面试","slug":"面试","permalink":"http://yoursite.com/tags/面试/"}]},{"title":"H5界面实现桌面推送通知","slug":"h5界面实现桌面推送通知","date":"2019-03-01T06:42:20.000Z","updated":"2019-03-01T10:16:06.000Z","comments":true,"path":"2019/03/01/h5界面实现桌面推送通知/","link":"","permalink":"http://yoursite.com/2019/03/01/h5界面实现桌面推送通知/","excerpt":"","text":"我们产品线的服务器告警模式是：“每十分钟执行一次脚本，脚本会使用zkclient获取当前服务器的CPU、内存、带宽、服务负载，然后以邮件的形式发送到运维人员的邮箱里”，每十分钟一次的频率可想而知，一天下来邮箱要有几百几千封邮件，看着就心烦。于是我就冒出了一个大胆的想法，重构这套土了吧唧的告警模式。 思路是这样的：“依旧是通过后台脚本结合crontab定时获取服务器的相关采集值，然后将值传入到Django的views.py里，呈现到某个页面上，这个页面也会定时自动刷新，每次刷新的时候也就顺便取到了新的采集值，如果有告警，那么页面对应的告警值红色标注，同时弹出通知。” 这么一看感觉高大上了很多，至少不用天天去outlook里清理垃圾邮件。 实现自动刷新页面自动刷新的方法很简单，有如下2种：1.页面自动刷新：把如下代码加入&lt;head&gt;区域中 1&lt;meta http-equiv=\"refresh\" content=\"20\"&gt; //其中20指每隔20秒刷新一次页面. 这个功能也能结合页面自动跳转：把如下代码加入&lt;head&gt;区域中 1&lt;meta http-equiv=\"refresh\" content=\"20;url=http://www.webjx.com\"&gt; //其中20指隔20秒后跳转到http://www.webjx.com页面 我想，QQ好友生日祝福功能里10秒钟自动关闭就应该是这么做出来的。 2.页面自动刷新之js版 123456&lt;script language=\"JavaScript\"&gt;function myrefresh()&#123; window.location.reload();&#125;setTimeout('myrefresh()',1000); //指定1秒刷新一次&lt;/script&gt; 这里多说一下http-equiv，http-equiv是响应头报文。它只能出现在meta标签里，用来代替name，它的值使用content属性描述，HTTP服务器通过此属性收集HTTP协议的响应头报文。 比如： 1&lt;meta http-equiv=\"Content-Type\" Content=\"text/html; Charset=gb2312″ /&gt; 上面代码告诉浏览器等设备，文件为html文件，且使用了utf8编码; 1&lt;meta http-equiv=\"Content-Language\" Content=\"zh-CN\" /&gt; 上面代码告诉浏览器等设备，语言使用了中文; 1&lt;meta http-equiv=\"Expires\" Content=\"Wed, 26 Feb 1997 08:21:57 GMT\" /&gt; 上面代码指定网页在缓存中的过期时间，一旦网页过期，必须到服务器上重新调阅。注意：必须使用GMT的时间格式，或直接设为0(数字表示多少时间后过期)。 实现桌面通知桌面通知是一个比较优雅的功能，只要你后台打开网页，那么一旦网页里触发了通知，就会在windows桌面上弹出一个小窗口告诉我们页面发生了，如图： 它的实现关键词就是Notification API，这个动作的js代码如下： 123456789101112131415161718192021222324&lt;script type=\"text/javascript\"&gt; //判断浏览器是否支持Notificationif (window.Notification) &#123; var title; var options; title = '服务器告警提醒'; //通知的标题 options = &#123; //通知的所有内容 body: \"机器千万台，稳定第一条，服务一瘫痪，运维泪两行。\", //通知主体内容 tag: \"custom\", //代表通知的一个识别标签，相同tag时只会打开同一个通知窗口 icon: \"http://img.mp.itc.cn/upload/20160723/a5953dc52c484834ab1ce924bb344da8_th.jpg\", //要在通知中显示的图标的URL // images: \"https://xxx.jpg\" //要在通知中显示的图像的URL requireInteraction: false //通知保持自动关闭 &#125;; Notification.requestPermission(function() &#123; var notification = new Notification(title, options); notificationEvents.forEach(function(eventName) &#123; notification[eventName] = function(event) &#123; &#125;; &#125;); &#125;); &#125; else &#123; alert(\"你使用的浏览器不支持弹出提示，请更换Chrome内核浏览器！\"); &#125;&lt;/script&gt; 再结合上面的自动刷新语句，在浏览器打开的时候，首先会询问是够接受“通知”，如图： 同意了之后，浏览器每10秒钟自动刷新，同时弹出上面那个加菲猫弹窗。 而且Notification API只能对https的网站可用，详情可见： https://stackoverflow.com/questions/30542287/are-push-notifications-possible-in-html5-without-fully-https-site 。 全部整合现在就需要把上面两个功能全部整合到一起，实现每10分钟自动刷新，同时判断传入数值，如果数值超标就发送桌面通知。 首先，先在django的url.py里设定访问的路径和对应的函数: 1234567from django.urls import pathfrom . import views urlpatterns = [ # 前面略 path(r'test222/',views.ttt),] 然后在views.py里简单设置一下这个ttt函数： 12345def ttt(request): cpu = 6.66 mem = 66.6 disk = 26 return render_to_response('test222.html',&#123;'CPU':cpu,'MEMORY':mem,'DISKUSED':disk&#125;) 现在已经传入了三个数值，然后我们加工一下test222.html页面，如下： 1234567891011121314151617181920212223242526272829303132333435363738&lt;html&gt; &lt;head&gt; &lt;meta http-equiv=\"refresh\" content=\"60\"&gt; &lt;title&gt;服务器监控页面&lt;/title&gt; &lt;script type=\"text/javascript\"&gt; var cpu=\"&#123;&#123;CPU&#125;&#125;\",mem=\"&#123;&#123;MEMORY&#125;&#125;\",disk=\"&#123;&#123;DISKUSED&#125;&#125;\" // alert(cpu+' '+mem+' '+disk) if ( cpu &gt; 80 || mem &gt; 80 || disk &gt; 80) &#123; if (window.Notification) &#123; var title; var options; title = '服务器告警提醒'; //通知的标题 options = &#123; //通知的所有内容 body: \"机器千万台，稳定第一条，服务一瘫痪，运维泪两行。\", //通知主体内容 tag: \"custom\", //代表通知的一个识别标签，相同tag时只会打开同一个通知窗口 icon: \"http://img.mp.itc.cn/upload/20160723/a5953dc52c484834ab1ce924bb344da8_th.jpg\" //要在通知中显示的图标的URL &#125;; Notification.requestPermission(function() &#123; var notification = new Notification(title, options); notificationEvents.forEach(function(eventName) &#123; notification[eventName] = function(event) &#123; &#125;; &#125;); &#125;); &#125; else &#123; alert(\"你使用的浏览器不支持弹出提示，请更换Chrome内核浏览器！\"); &#125; &#125; &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;h3&gt;服务器名称是test-ooxx-001&lt;/h3&gt; &lt;hr&gt; &lt;h4&gt;CPU情况是：&#123;&#123; CPU &#125;&#125;&lt;/h4&gt; &lt;h4&gt;内存情况是：&#123;&#123; MEMORY &#125;&#125;&lt;/h4&gt; &lt;h4&gt;磁盘容量情况是：&#123;&#123; DISKUSED &#125;&#125;&lt;/h4&gt; &lt;/body&gt;&lt;/html&gt; 界面如下： 现在修改一下views.py里的三个值，只要有一个大于设定的标准值，就会触发桌面推送。 js里“a=空就判断b，b如果也是空再判断C，然后执行func()”的语句是： 123if ( a != null || b != null || c != null ) &#123; fun();&#125; 参考资料https://developer.mozilla.org/zh-CN/docs/Web/API/notificationhttp://www.ptbird.cn/html5-notification-browser.htmlhttps://segmentfault.com/a/1190000011670082","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"html5","slug":"html5","permalink":"http://yoursite.com/tags/html5/"}]},{"title":"让Nginx鉴权功能保护Kibana网页","slug":"让Nginx鉴权功能保护Kibana网页","date":"2019-02-28T07:55:27.000Z","updated":"2019-02-28T08:52:46.000Z","comments":true,"path":"2019/02/28/让Nginx鉴权功能保护Kibana网页/","link":"","permalink":"http://yoursite.com/2019/02/28/让Nginx鉴权功能保护Kibana网页/","excerpt":"","text":"Kibana本身是一个Web界面，但是出于安全和机密的考虑，我们肯定不会让互联网上所有的人都能随便看到Kibana里的内容，但是X-pack目前又不支持6.2以上的版本，于是我们可以使用Nginx的密码功能来保护Kibana的网页：要访问Kibana时需要先输入密码，正确就登陆到Kibana，如果错误就是403。 Kibana是容器安装的，安装过程可以去查看：https://rorschachchan.github.io/2019/01/21/%E5%B0%86kafka%E5%8A%A0%E5%85%A5%E5%88%B0Elk%E9%9B%86%E7%BE%A4/ 事前准备Nginx也是容器安装，docker pull nginx拉取最新的nginx镜像，在下载的时候呢我们也别对着屏幕干巴巴的等。由于在nginx配置转发的时候，需要知道Kibana的容器IP，这是因为Kibana和正在下载的Nginx是两个不同的容器，Nginx是需要跨容器访问的。 默认的官方Kibana镜像登录是非root的，这种虽然安全，但是不能config也不能yum，于是我们首先要使用root账号登录进去，语句是： 123docker exec -it --user root kibana容器ID /bin/bashyum update -yyum install -y net-tools #下载ifconfig 使用ifconfig和netstat查看容器的IP和工作端口： 可以确认Kibana的IP是172.17.0.4，端口是5601。这时候我们就可以写一个kibana.conf，让nginx容器用这个配置文件达到跳转的目的！ kibana.conf全文如下： 12345678910111213141516171819upstream kibana_server &#123; server 172.17.0.3:5601 weight=1 max_fails=3 fail_timeout=60; #这里写的就是kibana的容器IP和端口，如果是多台kibana想要按权重访问，就写weight&#125;server &#123; listen *:33664; #nginx容器自己的端口 server_name _; auth_basic \"Restricted Access\"; # 验证 auth_basic_user_file /etc/nginx/conf.d/htpasswd.users; # 验证文件 location / &#123; proxy_pass http://kibana_server; #这个地方就是upstream proxy_http_version 1.1; proxy_set_header Upgrade $http_upgrade; proxy_set_header Connection 'upgrade'; proxy_set_header Host $host; proxy_cache_bypass $http_upgrade; &#125;&#125; 把这个文件保存在/mnt/nginx目录里。 配置nginx密码nginx要创建验证文件授权,需要先安装httpd-tools工具： 123yum install -y httpd-tools htpasswd -bc /mnt/nginx/htpasswd.users kibana password123 # 创建验证文件Adding password for user admin 这时我们就创建了一个/mnt/nginx/htpasswd.users，里面的用户是kibana，密码是password123。这个密码在文件里是加密的，用cat命令无法正常查看到的。 启动nginx容器此时nginx镜像应该下载完毕了，那么就直接启动镜像，启动语句是： 1docker run --hostname Kngx -p 80:33664 --name Knginx -v /mnt/nginx/:/etc/nginx/conf.d/ -d nginx 简单说一下这个命令：这个容器名叫Knginx，hostname是Kngx，做了宿主机80端口到此容器33664端口的转发，将宿主机的/mnt/nginx/挂载到容器里的/etc/nginx/conf.d/，同时直接启动nginx。 启动成功之后，我们看到刚刚建立的htpasswd.users和kibana.conf都已经成功被Knginx容器配置上，然后打开浏览器，看看效果： 这样就达到了密码访问页面的效果，如果想加IP白名单呢，也可以直接在kibana.conf里补充相关配置，修改完毕之后，重启Knginx容器即可。 参考资料https://www.hugeserver.com/kb/how-secure-kibana-nginx-centos/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"kibana","slug":"kibana","permalink":"http://yoursite.com/tags/kibana/"}]},{"title":"Linux运维工程师笔试题第十七套","slug":"Linux运维工程师笔试题第十七套","date":"2019-02-19T03:22:07.000Z","updated":"2019-07-08T06:53:56.000Z","comments":true,"path":"2019/02/19/Linux运维工程师笔试题第十七套/","link":"","permalink":"http://yoursite.com/2019/02/19/Linux运维工程师笔试题第十七套/","excerpt":"","text":"试题内容如果网站配置了多域名，要根据不同的域名分别https访问，应该怎么配置？在rewrite的时候使用$host，如下： 1234567891011server&#123; listen 80; server_name www.test.com www.test.com.cn; index index.html index.htm index.php; root /home/wwwroot; location / &#123; rewrite ^/(.*)$ https://$host/$1 permanent; &#125;&#125; 如果是要笨一点的方法就是： 12345678910111213server &#123; listen 80; server_name www.test.com www.test.com.cn; index index.html index.htm index.php; root /home/wwwroot; if ($host = 'www.test.com.cn' ) &#123; rewrite ^/(.*)$ https://www.test.com.cn/$1 permanent; &#125; if ($host = 'www.test.com' ) &#123; rewrite ^/(.*)$ https://www.test.com/$1 permanent; &#125; ps.阿里云的SLB绑定多个HTTPS证书的文档：https://help.aliyun.com/document_detail/87023.html?spm=a2c4g.11186623.6.741.7e11301bVLBAJz 2.在Nginx中，如何使用未定义的服务器名称来阻止处理请求?只需将请求删除的服务器就可以定义为： 12345Server &#123; listen 80; server_name \" \"; return 444;&#125; 这里，服务器名被保留为一个空字符串，它将在没有“主机”头字段的情况下匹配请求，而一个特殊的Nginx的非标准代码444被返回，从而终止连接。 3.ajax是同步还是异步，怎么样实现同步?ajax里async属性默认的设置值为true，这种情况为异步方式。即网页里有两个函数func(x)和func(y)，在打开网页的时候，后台会先去执行func(x)，然后等待server返回结果，同时还有一个线程会去执行func(y)。 当把async设为false时，这时ajax的请求是同步的，也就是说，这个时候ajax块发出请求后，他会等待在func(x)这个地方，不会去执行func(y)，直到func(x)部分执行完毕。 4.nginx如何实现http跳转https?需要用到地址重写代码，用以下代码能让http强制跳转到https: 123456server &#123; listen 80; listen [::]:80; #支持ipv6 server_name www.test.com; return 301 https://$server_name$request_uri;&#125; 6.如果某个网站做了两个域名，分别是https://www.aaa.com和https://www.bbb.com，如果做了www.aaa.com cname到www.bbb.com，那么浏览器打开www.aaa.com会是什么界面？打开页面会出现“https证书不正确”的风险提示。 7.接着上面问题，在nginx里做了rewrite或者配置了显性URL，此时取消掉www.aaa.com本身的ip（即www.aaa.com没有ip,但是www.bbb.com有ip），浏览器里打开www.aaa.com会是什么界面？会显示“无法找到www.aaa.com的IP地址”（第一步就失败了…）。 8.要求a.com和www.a.com都跳到www.b.com，而www.a.com/123不跳，如何配置？配置如下： 1234567891011121314server &#123; listen 80; server_name www.a.com a.com; #根目录跳转 location / &#123; rewrite .+ http://www.b.com/ permanent; &#125; #非根目录本地执行 location ~* /.+ &#123; #已省略余下通用配置内容 &#125;&#125; 9.为了安全，Web服务器不要求启用所有可用的方法，只允许GET，HEAD和POST方法，其他的全部过滤掉。实现其功能的代码如下： 123if ($request_method !~ ^(GET|HEAD|POST)$ ) &#123; return 444;&#125; 10.对/download/目录做“最大下载速度20K，同时最多2个并发链接的限制” 123456789http &#123; limit_zone my_zone $binary_remote_addr 10m; #在 http 段配置定义一个limit_zone server &#123; location /download/ &#123; limit_conn my_zone 2; #limit_conn和 limit_rate参数进行限速设置 limit_rate 20k; &#125; &#125; &#125; limit_zone:针对每个 IP 定义一个存储 session 状态的容器。本例中定义了一个my_zone的10m大小的容器。 limit_conn my_zone 2：限制在my_zone中记录状态的每个IP只能发起2个并发连接。本例中，客户端访问/download目录时，会限制2个并发连接。 limit_rate 20k：对每个连接限速20k。注意，这里是对连接限速，而不是对IP限速。如果一个IP允许2个并发连接，那么这个IP就是限速为limit_rate*2，在设置的时候要根据自己的需要做设置调整。 11.简单说明nginx配置文件里面alias和root的区别Nginx配置文件server中指定两个location执行，分别为root和alias指令： 123location /test/ &#123; alias /www/test/;&#125; 按照上述配置，则访问/test/目录里面的文件时，nginx会去/www/test/目录找文件： 123location /test/ &#123; root /www/test;&#125; 按照这种配置，则访问/test/目录下的文件时，nginx会去/www/test/test/目录下找文件。 另一个区别是alias后面必须要用/结束，否则会找不到文件，而root则对/可有可无。 注意！location后面的/test/如果是/test的话（没有用/收尾），而同时alias的文件夹是有/收尾的话，就会出现“目录穿越”漏洞，即外来人可以访问你/www/test../即www文件夹的内容。详情可见 https://www.leavesongs.com/PENETRATION/nginx-insecure-configuration.html 。 12.CDN缓存命中率下降的因素有哪些？ 客户是否刷新过缓存？答：如果刷新缓存，有可能会短时间表现命中率下降。特别说明下：CDN的url或者目录刷新是清除CDN缓存的动作（这个比较容易理解偏差） 带宽是否突增？并且访问的都是新的URL？答：带宽突增或者访问的新URL较多，会导致CDN节点回源较多，命中率会表现有下降趋势。 源站是否有新内容发布？答：CDN节点访问新内容，导致CDN节点回源较多，命中率会表现有下降趋势。 源站是否出现过异常导致5XX和4XX增加，由于5XX和4XX不缓存，会表现命中率下降。 源站的访问url的header参数，或者在CDN控制管理后台的缓存配置规则是否改变过？答：缓存时长的调整，有可能会带来命中率的变化。 13.如果判断url是否命中CDN缓存？查看响应头信息中的X-Cache字段。 显示MISS，说明没有命中CDN缓存，是回源的。 显示HIT，是命中了CDN缓存。 除了X-Cache还有如下几个参数与CDN有关：X-Swift-SaveTime：内容开始在CDN上缓存的时间。由于系统时间是GMT时间，所以需要折算成北京时间。X-Swift-CacheTime：CDN的默认缓存时间，以秒为单位。Age：该内容在CDN上已经缓存了的时间。 14.AJAX从b.com请求另一个域a.com的地址会有跨域的问题，如何配置？ 123456789server &#123; listen 80; server_name b.com; location /&#123; add_header 'Access-Control-Allow-Origin' 'http://a.com'; add_header 'Access-Control-Allow-Credentials' 'true'; add_header 'Access-Control-Allow-Methods' 'GET'; &#125;&#125; 第一条add_header：授权从a.com的请求第二条add_header：当该标志为真时，响应于该请求是否可以被暴露第三条add_header：指定请求的方法，可以是GET，POST，PUT，DELETE，HEAD如果想允许来自任何域的请求，可以这样： 1234567server &#123; listen 80; server_name b.com; location /&#123; Access-Control-Allow-Origin: * &#125; &#125; 15.如果想配置2-3个域设置为信任，其他的域名被排除，应该如何配置？ 123456789server &#123; listen 80; server_name b.com; location /&#123; if ( $http_referer ~* (a.com|b.com|c.com) ) &#123; Access-Control-Allow-Origin: * &#125; &#125; &#125; 16.将不带www的访问强制加上www怎么做？ 1234 # 下面这句就是当识别到 HOST 不是带 www 的全部都 302 带上 wwwif ( $host != 'www.your-domain.com' ) &#123; rewrite ^(.*)$ https://www.your-domain.com$1 permanent;&#125; 参考资料https://my.oschina.net/mrpei123/blog/1794001http://note.qidong.name/2017/09/nginx-https-hsts/https://www.ssllabs.com/ssltest/index.html（测试ssl安全的网站）","categories":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/categories/大牛之路/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"面试笔试","slug":"面试笔试","permalink":"http://yoursite.com/tags/面试笔试/"}]},{"title":"使用Logstash的正则匹配日志格式","slug":"使用Logstash的正则匹配日志格式","date":"2019-02-15T09:00:13.000Z","updated":"2019-02-21T09:02:32.000Z","comments":true,"path":"2019/02/15/使用Logstash的正则匹配日志格式/","link":"","permalink":"http://yoursite.com/2019/02/15/使用Logstash的正则匹配日志格式/","excerpt":"","text":"牛刀小试在ELK里经常需要写正则来匹配日志里的的具体信息，这样可以在kibana上更加直观的观看，grok就是Logstash最重要的插件。你可以在grok里预定义好命名正则表达式，在稍后(grok参数或者其他正则表达式里)引用它。 grok的格式是：%{SYNTAX:SEMANTIC}，如果需要转义就要加上\\。具体的grok匹配规则可以在logstash查看grok-patterns这个文件，如图： SYNTAX代表匹配值的类型，例如，0.11可以NUMBER类型所匹配，10.222.22.25可以使用IP匹配。 SEMANTIC表示存储该值的一个变量声明，它会存储在elasticsearch当中方便kibana做字段搜索和统计，你可以将一个IP定义为客户端IP地址client_ip_address，eg:%{IP:client_ip_address}，所匹配到的值就会存储到client_ip_address这个字段里边，类似数据库的列名。 而检测grok正则的网站：http://grokdebug.herokuapp.com/ 。 举个例子，如果日志里是： 1100.97.73.142 - - [15/Feb/2019:16:54:24 +0800] 可以看到里面有IP、日期、时间、时区，那么对比刚才的grok-patterns文件，就知道要匹配IP这个字段，就是用IP (?:%{IPV6}|%{IPV4})，IP即包含了IPV6也有IPV4，那么具体的匹配就是%{IP:client}，client是自己定义名称。同理，[15/Feb/2019这部分是日期，可以使用如下的配置规则： 如法炮制，匹配结果就是\\[%{MONTHDAY:day}/%{MONTH:month}/%{YEAR:year}。 拿到检测网站试一下结果： 上面那个例子比较简单，比如匹配下面这样的一个日志： 1[2019-02-01T08:59:59.124] [INFO] default - [115.63.121.10 GET /wap/_nuxt/vendor.61a8f274bce0acb0de6d.js 200 97s][https://www.lechange.com/wap/node/goodDetail/264 HTTP/1.1 Mozilla/5.0 (Linux; Android 8.1; V1818A Build/OPM1.171019.026; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/57.0.2987.132 MQQBrowser/6.2 TBS/044409 Mobile Safari/537.36] 那么写法就是： 120%&#123;YEAR:year&#125;-%&#123;MONTHNUM:month&#125;-%&#123;MONTHDAY:day&#125;T%&#123;HOUR:hour&#125;:?%&#123;MINUTE:minutes&#125;(?::?%&#123;SECOND:second&#125;)] \\[%&#123;LOGLEVEL:level&#125;\\] default - \\[%&#123;IP:client&#125; %&#123;WORD:method&#125; %&#123;URIPATHPARAM:request&#125; %&#123;NUMBER:status&#125; %&#123;NUMBER:duration&#125;s\\]\\[%&#123;DATA:data&#125;\\] 效果如图: 但是要注意!在网站上的匹配可能是OK的，但是在logstash的grok里是不可以有-、&#39;、&quot;等这样的字符出现，比如下面这个日志： 1100.97.73.232 - - [15/Feb/2019:16:54:24 +0800] \"GET /public/app/site/statics/favicon.ico HTTP/1.1\" 200 4286 \"https://www.lechange.com/wap/\" \"Mozilla/5.0 (Linux; Android 7.1.1; OPPO R11 Build/NMF26X; wv) AppleWebKit/537.36 (KHTML, like Gecko) Version/4.0 Chrome/57.0.2987.132 MQQBrowser/6.2 TBS/044409 Mobile Safari/537.36 Imou\" 虽然下面的规则是可以正确匹配的： 1%&#123;IP:client&#125; - - \\[%&#123;MONTHDAY:day&#125;/%&#123;MONTH:month&#125;/%&#123;YEAR:year&#125;:%&#123;HOUR:hour&#125;:%&#123;MINUTE:minutes&#125;:%&#123;SECOND:second&#125; \\+0800] \\\"%&#123;WORD:method&#125; %&#123;URIPATH:request&#125; HTTP/%&#123;NUMBER:httpversion&#125;\" %&#123;NUMBER:status&#125; %&#123;NUMBER:bytes&#125; \"%&#123;DATA:website&#125;\" \"%&#123;DATA:data&#125;\" 但是当你把这个配置复制到logstash.conf里的时候，启动logstash就会有参数不合法的报错： 1[2019-02-18T17:33:52,060][FATAL][logstash.runner ] The given configuration is invalid. Reason: Expected one of #, &#123;, -, \", ', &#125; at line 32, column 218 (byte 1226) 。 应该改成这样： 1%&#123;IPORHOST:client_ip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \\[%&#123;HTTPDATE:timestamp&#125;\\] \"(?:%&#123;WORD:verb&#125; %&#123;NOTSPACE:request&#125;(?: HTTP/%&#123;NUMBER:http_version&#125;)?|-)\" %&#123;NUMBER:response&#125; (?:%&#123;NUMBER:bytes&#125;|-) %&#123;QUOTEDSTRING:domain&#125; %&#123;QUOTEDSTRING:data&#125; 一般来说对于字符串，有双引号包含的用QS，没有的用DATA类型，如%{DATA:request_body}。 grok配置到logstash假设这个服务的日志输入到kafka里的topic叫lcshop-log，那么对应的logstash如下： 1234567891011121314151617181920212223242526272829303132333435input &#123; kafka&#123; bootstrap_servers=&gt;\"172.31.0.84:9092\" #这里写的是kafka的ip和端口 topics=&gt;[\"lcshop-log\",\"lcshop-errorlog\"] #这里是对应的topic decorate_events=&gt;\"true\" codec=&gt;plain &#125; &#125; filter &#123; if [@metadata][kafka][topic] == \"lcshop-log\" &#123; mutate &#123; add_field =&gt; &#123;\"[@metadata][index]\" =&gt; \"lcshop-log-%&#123;+YYYY-MM&#125;\"&#125; &#125; grok &#123; match =&gt; &#123; \"message\" =&gt; \"%&#123;IPORHOST:client_ip&#125; %&#123;USER:ident&#125; %&#123;USER:auth&#125; \\[%&#123;HTTPDATE:timestamp&#125;\\] \\\"(?:%&#123;WORD:verb&#125; %&#123;NOTSPACE:request&#125;(?: HTTP/%&#123;NUMBER:http_version&#125;)?|-)\\\" %&#123;NUMBER:response&#125; (?:%&#123;NUMBER:bytes&#125;|-) %&#123;QUOTEDSTRING:domain&#125; %&#123;QUOTEDSTRING:data&#125;\"&#125; remove_field =&gt; [\"message\"] #这里对双引号增加了转义符 &#125; &#125; else if [@metadata][kafka][topic] == \"lcshop-errorlog\" &#123; mutate &#123; add_field =&gt; &#123;\"[@metadata][index]\" =&gt; \"lcshop-errorlog-%&#123;+YYYY-MM&#125;\"&#125; &#125; &#125;&#125;output &#123; stdout &#123; codec =&gt; rubydebug #日志输出，这个看情况开启，生成日志量非常可观！ &#125; elasticsearch &#123; hosts=&gt;[\"172.31.0.76:9200\"] #这里是es的ip和端口 index=&gt;\"%&#123;[@metadata][index]&#125;\" #这里对不同的topic分配不同的index &#125;&#125; 然后去kibana里查看结果,然而会发现这是失败的。 为什么明明在grok的测试网站里通过了，但是在实际的kibana里却失败？这是因为在kibana里会自动给双引号添加一个转义符！正式因为多了这个转义符，所以整段正则都不匹配了，自然grok无法生效了。 这个时候需要改成这样： 1%&#123;IPORHOST:clientip&#125; - %&#123;NOTSPACE:remote_user&#125; \\[%&#123;HTTPDATE:timestamp&#125;\\] \\\\\"%&#123;DATA:request&#125;\\\\\" %&#123;NUMBER:response&#125; %&#123;NUMBER:bytes&#125; %&#123;DATA:data&#125; \\\\\"%&#123;DATA:detail&#125;\\\\\" 重启logstash之后，再去kibana里看结果： 参考资料https://doc.yonyoucloud.com/doc/logstash-best-practice-cn/filter/date.htmlhttps://segmentfault.com/q/1010000003801260https://www.cnblogs.com/Orgliny/p/5592186.htmlhttp://kuring.me/post/elk_nginx/http://blog.51cto.com/seekerwolf/2106509http://blog.51cto.com/liqingbiao/1928653https://www.jianshu.com/p/d46b911fb83e","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"elk","slug":"elk","permalink":"http://yoursite.com/tags/elk/"},{"name":"logstash","slug":"logstash","permalink":"http://yoursite.com/tags/logstash/"},{"name":"正则表达式","slug":"正则表达式","permalink":"http://yoursite.com/tags/正则表达式/"}]},{"title":"Linux运维工程师笔试题第十六套","slug":"Linux运维工程师笔试题第十六套","date":"2019-02-13T04:13:20.000Z","updated":"2019-06-10T06:52:28.000Z","comments":true,"path":"2019/02/13/Linux运维工程师笔试题第十六套/","link":"","permalink":"http://yoursite.com/2019/02/13/Linux运维工程师笔试题第十六套/","excerpt":"","text":"试题内容1.Mysql的bin-log有几种形式？分析其特点Statement Level模式: 123简介：每一条会修改数据的sql都会记录到master的bin-log中。Slave在复制的时候sql线程会解析成和原来master端执行过的相同语句来执行。优点：不需要记录每一行数据的变化，减少bin-log的日志量，节约IO，提高性能。因为他只记录在master上所执行语句的细节，以及执行语句时候的上下文的信息。缺点：很多新功能的加入在复制的时候容易导致出现问题。 Row Level模式: 123简介:日志中会记录成每一行数据被修改的模式，然后再slave 端在对相同的数据进行修改。优点：在row level模式下，bin-log中可以不记录执行的sql语句的上下文相关的信息。仅仅只需要记录那一条记录被修改了。所以row level的日志内容会非常清楚记录下每一行数据修改的细节，非常容易理解。而且不会出现某些特点情况下的存储过程，或function 以及triggeer的调用和触发无法被正确复制的问题。缺点：所有执行的语句当记录到日志中的时候，都将以每行记录的修改来记录，可能会产生大量的日志。 Mixed(前两种的混合模式): 1根据执行的每一条具体的sql语句来区分对待记录日志的形式，即Mysql决定什么时候写statement格式的，什么时候写row格式的binlog。； 2.如何在线正确清理MySQL的binlog？手动删除方法如下： 123456#首先查看主从库正在使用的binlog文件名称 show master(slave) status\\G#删除之前一定要备份purge master logs before'2017-09-01 00:00:00'; #删除指定时间前的日志purge master logs to'mysql-bin.000001'; 自动删除的方法如下： 1234#通过设置binlog的过期时间让系统自动删除日志#查看过期时间与设置过期时间show variables like 'expire_logs_days'; set global expire_logs_days = 30; binlog记录了数据中的数据变动，便于对数据的基于时间点和基于位置的恢复。但是也要定时清理，不然越来越大。 3.简述MySQL主从复制原理及配置主从的完整步骤。MySQL主从是一个异步过程（网络条件上佳的话，同步效果几乎是实时），原理就是从库得到主库的binlog，然后执行这个binlog的内容，达到两边数据库数据一致的目的。具体工作步骤如下： 主mysql服务器将数据库更新记录到binlog中，使用自己的log dump线程将binlog先读取然后加锁，再发送到从库，在从库当读取完成，甚至在发动给从节点之前，锁会被释放； 当从库上执行start slave命令之后，从节点会创建一个I/O线程用来连接主节点，请求主库中更新的binlog。I/O线程接收到主节点binlog dump进程发来的更新之后，保存在本地relay log中。 从库此时还有一个SQL线程，它负责读取relay log中的内容，解析成具体的操作并执行，最终保证主从数据的一致性。 切记！在从库上使用show slave status\\G；看到结果里的Slave_IO_Running:Yes和Slave_SQL_Running:Yes，才算是同步成功，两个YES缺一不可。注意！MySQL只读实例的Binlog日志是没有记录更新信息的，所以它的Binlog无法使用。4.如何理解MySQL里最大连接数和请求数之间的关系假设某个数据库的最大连接数是1000，并不是指最多只能支持1000个访问，因为数据库与应用之间肯定会隔着中间件，这个中间件的连接池会管理链接，一般如果代码写的好、事物控制得当，一个事物完成连接会被连接池收回重复利用，所以不是说一个用户登录你的系统或网站就一直占用着，一个连接也可以包含多次请求。5.MySQL出现IOPS过高，应该如何处理？IOPS (Input/Output Operations Per Second)，即每秒进行读写（I/O）操作的次数。IOPS是指存储每秒可接受多少次主机发出的访问，主机的一次IO需要多次访问存储才可以完成。IOPS过高比较普遍的原因是实例内存满足不了缓存数据或排序等需要，导致产生大量的物理IO或者是查询执行效率低，扫描过多数据行。6.Sort_Buffer_Size是什么参数？设置它对服务器性能有何影响？Sort_Buffer_Size是一个connection级参数，在每个connection第一次需要使用这个buffer的时候，一次性分配设置的内存。Sort_Buffer_Size并不是越大越好，由于是connection级的参数，过大的设置+高并发可能会耗尽系统内存资源。Sort_Buffer_Size超过256KB的时候，MySQL就会使用mmap()而不是malloc()来进行内存分配，导致性能损耗、效率降低。如果列长度大于max_length_for_sort_data的参数值的话，iowait会增加, 响应时间明显变长。此时通过show processlist查看,发现有很多session在处理sort操作,此时需要适当调大max_length_for_sort_data的参数值。7.如何从MySQL全库备份中恢复某个库和某张表主要用到的参数是–one-database简写-o的参数，举个例子： 1234全库备份[root@HE1 ~]# mysqldump -uroot -p --single-transaction -A --master-data=2 &gt;dump.sql只还原erp库的内容[root@HE1 ~]# mysql -uroot -pMANAGER erp --one-database &lt;dump.sql从全库备份中抽取出t表的表结构: 1sed -e'/./&#123;H;$!d;&#125;' -e 'x;/CREATE TABLE `t`/!d;q' dump.sql从全库备份中抽取出t表的内容: 1grep'INSERT INTO `t`' dump.sql8.随意举出一次解决Mysql故障的事例Mysql反应很慢，发现服务器CPU飙升，出现僵尸进程但是连接数并不高，show processlist发现有大量的unauthenticated user。通过更改配置文件/etc/my.cnf里的在[mysqld]那一栏中添加skip-name-resolve，然后重启mysql即可解决。注意！ skip-name-resolve可以禁用dns解析，但是，这样不能在mysql的授权表中使用主机名了，只能使用IP。以前创建mysql用户是若用的是localhost现在则需要用127.0.0.1来代替在grant语句中执行一下添加该用户。当然CPU飙升还有其他情况：查询以及大批量的插入或者是网络状态突然断了,导致一个请求服务器只接受到一半…9.你们数据库是否支持emoji表情，如果不支持，如何操作？如果是utf8字符集的话，需要升级至utf8_mb4方可支持。10.mysqldump备份时，–master-data选项的作用是什么？还用过其他的参数么？--master-data选项的作用就是将二进制的信息写入到输出文件中，即写入备份的sql文件中。1. --master-data=2表示在dump过程中记录主库的binlog和pos点，并在dump文件中注释掉这一行；2. --master-data=1表示在dump过程中记录主库的binlog和pos点，并在dump文件中不注释掉这一行，即恢复时会执行；3. --dump-slave=2表示在dump过程中，在从库dump，mysqldump进程也要在从库执行，记录当时主库的binlog和pos点，并在dump文件中注释掉这一行；4. --dump-slave=1表示在dump过程中，在从库dump，mysqldump进程也要在从库执行，记录当时主库的binlog和pos点，并在dump文件中不注释掉这一行；注意!在从库上执行备份时，即–dump-slave=2，这时整个dump过程都是stop io_thread的状态加了--single-transaction就能保证innodb的数据是完全一致的，而myisam引擎无法保证（因为myisam压根就不支持事务），要保证myisam引擎数据一致必须加--lock-all-tables。11.什么是数据库事务，事务有哪些特性？一个数据库事务通常包含对数据库进行读或写的一个操作序列。它的存在包含有以下两个目的： 12为数据库操作提供了一个从失败中恢复到正常状态的方法，同时提供了数据库即使在异常状态下仍能保持一致性的方法。当多个应用程序在并发访问数据库时，可以在这些应用程序之间提供一个隔离方法，以防止彼此的操作互相干扰。它的特性如下： 1234原子性（Atomicity）：事务作为一个整体被执行，包含在其中的对数据库的操作要么全部被执行，要么都不执行。一致性（Consistency）：事务应确保数据库的状态从一个一致状态转变为另一个一致状态。一致状态的含义是数据库中的数据应满足完整性约束。隔离性（Isolation）：多个事务并发执行时，一个事务的执行不应影响其他事务的执行。持久性（Durability）：一个事务一旦提交，他对数据库的修改应该永久保存在数据库中。事务的原子性与一致性缺一不可。 12.数据表student有id,name,score,city字段，其中name中的名字可有重复，需要消除重复行,请写sql语句语句如下： 1select distinct name from student 注意！单独的distinct只能放在开头，否则就报语法错误。 select * from table limit 2,1;、select * from table limit 2 offset 1;和select * from employee limit 3;这三个sql有什么区别？第一个sql含义是跳过2条取出1条数据，limit后面是从第2条开始读，读取1条信息，即读取第3条数据；第二个sql含义是从第1条（不包括）数据开始取出2条数据，limit后面跟的是2条数据，offset后面是从第1条开始读取，即读取第2,3条；第三个sql含义是返回前三行； 参考资料https://www.cnblogs.com/wajika/p/6718552.htmlhttps://www.hollischuang.com/archives/898https://zhuanlan.zhihu.com/p/50597960https://segmentfault.com/a/1190000008663001https://segmentfault.com/a/1190000000616820http://seanlook.com/2014/12/05/mysql_mysqldump_options_examples/","categories":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/categories/大牛之路/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"}]},{"title":"ES对应Kafka的topic生成不同的Index","slug":"ES对应kafka的topic生成index","date":"2019-01-30T08:57:45.000Z","updated":"2019-02-15T08:29:48.000Z","comments":true,"path":"2019/01/30/ES对应kafka的topic生成index/","link":"","permalink":"http://yoursite.com/2019/01/30/ES对应kafka的topic生成index/","excerpt":"","text":"假设有两个模块分别叫shopauth和shoporder，日志文件也对应分别是shopauth.log和shoporder.log，现在需要把日志对应放到同个kafka里不同的topic里。 shopauth的filebeat.yml内容如下： 12345678910111213141516171819filebeat.prospectors:- type: log enabled: true paths: - /mnt/shopauth/logs/shopauth.log #日志路径 tags: [\"logmessages\"] encoding: utf-8 scan_frequency: 10s harvester_buffer_size: 15000 tail_files: true fields: alilogtype: app_log serverip: 172.16.0.201 #本地IP地址 log_topics: ecnode-logoutput.kafka: enabled: true hosts: [\"172.31.0.84:9092\"] #指定kafka的地址信息 topic: '%&#123;[fields][log_topics]&#125;' #自动识别topic 如果只有一个log源输入日志（不是指paths只有一个路径，paths可以同时指定多个路径），那么output.kafka的topic当然可以写死。如果是多个log源写入日志，而且又要对应输入到kafka的topic里，可以使用&#39;%{[fields][log_topics]}&#39;，达到自动识别的目的。 但是要注意！如果加上了fields_under_root: true，那么&#39;%{[fields][log_topics]}&#39;是错误的，要改成topic: &quot;%{[log_topic]}&quot;才可以。 shoporder的filebeat.yml内容如下： 123456789101112131415161718filebeat.prospectors:- type: log enabled: true paths: - /mnt/shoporder/logs/shoporder.log #指定路径 tags: [\"logmessages\"] encoding: utf-8 scan_frequency: 10s harvester_buffer_size: 15000 tail_files: true fields: alilogtype: app_log serverip: 172.16.0.207 #本地IP地址output.kafka: enabled: true hosts: [\"172.31.0.84:9092\"] #指定kafka的地址信息 topic: 'shoporder-log' #指定topic 启动filebeat和kafka，kafka的配置这里略过不表。在kafka里查看，发现已经生成对应的topic： 而logstash.yml内容如下： 123456789101112131415161718192021222324252627input &#123; kafka&#123; bootstrap_servers=&gt;\"172.31.0.84:9092\" #指定kafka的IP和端口 topics=&gt;[\"shoporder-log\",\"shopauth-log\"] #说明从这两个topic里消费 decorate_events=&gt;\"true\" #这个很重要，等会细说 codec=&gt;plain &#125;&#125;filter &#123; #利用kafka域的内容构建自定义的域 if [@metadata][kafka][topic] == \"shopauth-log\" &#123; mutate &#123; add_field =&gt; &#123;\"[@metadata][index]\" =&gt; \"shopauth-log-%&#123;+YYYY-MM&#125;\"&#125; &#125; &#125; else if [@metadata][kafka][topic] == \"shoporder-log\" &#123; mutate &#123; add_field =&gt; &#123;\"[@metadata][index]\" =&gt; \"shoporder-log-%&#123;+YYYY-MM&#125;\"&#125; &#125; &#125;&#125;output &#123; elasticsearch &#123; hosts=&gt;[\"172.31.0.76:9200\"] #指定es的IP和端口 index=&gt;\"%&#123;[@metadata][index]&#125;\" #对应生成各自的index &#125;&#125; 说一下decorate_events，如果只用了单个logstash，订阅了多个主题，你肯定希望在es中为不同主题创建不同的索引，那么decorate_events就是你想要的配置项。这个值默认是false，当指定这个选项为true时，会附加kafka的一些信息到logstash event的一个名为kafka的域（Metadata fields）中，然后再通过filter进行判断，如果是从shopauth-log这个topic得到信息，就把index设定成shopauth-log-%{+YYYY-MM}&quot;。 启动logstash，待其正常之后，在es的控制台查看日志，发现index索引已经成功生成： 现在在kibana里就可以创建索引然后查找了！","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"elk","slug":"elk","permalink":"http://yoursite.com/tags/elk/"},{"name":"logstash","slug":"logstash","permalink":"http://yoursite.com/tags/logstash/"}]},{"title":"解决html里单引号转义的问题","slug":"解决html里单引号转义的问题","date":"2019-01-23T08:45:08.000Z","updated":"2019-01-25T08:35:38.000Z","comments":true,"path":"2019/01/23/解决html里单引号转义的问题/","link":"","permalink":"http://yoursite.com/2019/01/23/解决html里单引号转义的问题/","excerpt":"","text":"正文在使用Django展现页面的时候，会出现这样的一个需求： 我们在views.py里获取到的一个数组，比如叫name，内容是：[&#39;james&#39;,&#39;wade&#39;,&#39;bosh&#39;,&#39;yaoming&#39;]，然后return render_to_response(&#39;a.html&#39;,{&#39;names&#39;:name,})，让a.html可以使用到这个name数组。若在a.html里需要对这个name数组进行for循环展示，正常思路的话，js如下： 123456function test() &#123; var name=\"&#123;&#123;names&#125;&#125;\".split(\",\") alert(name) 进行for循环，略过不表 &#125; 那么得到的会是如下效果： 可见虽然name在views.py里是list，但是传入到html是一个字符串，对于字符串使用split按照逗号分隔。而html里会把单引号转义成了&amp;#39;，而&amp;#39;这个玩意儿比较恶心，它不能被JSON.parse加工成一个数组，进而不能被for循环。 那么遇到这种问题怎么办?改成这样： 1234567function test() &#123; var str=\"&#123;&#123;names&#125;&#125;\".replace(/&amp;#39;/g,'\"') var name=JSON.parse(str) alert(name) 进行for循环，略过不表 &#125; 执行效果如下：上面代码首先先把所有的单引号replace成双引号，Html是不会转义双引号的，所以就可以正常使用了。 当然如果views.py里提供的name直接是双引号的话，就不用这么折腾了。 数组如何使用双引号而不是单引号python默认生成数组是单引号的，也就是说是[&#39;apple&#39;,&#39;banana&#39;,&#39;candy&#39;]的样子，而不会自动生成[&quot;apple&quot;,&quot;banana&quot;,&quot;candy&quot;]，这一点是不能改变的。那么要获得到双引号的数组，比较好的办法是json： 12345&gt;&gt;&gt; names = ['james','wade','bosh','yaoming']&gt;&gt;&gt; import json&gt;&gt;&gt; print(json.dumps(names))[\"james\", \"wade\", \"bosh\",\"yaoming\"] 如果元素是中文的话，那么就要用(json.dumps(names,ensure_ascii=False))。 与正文内容无关的补充Centos 7修改中文字符集的方法： 123localedef -c -f UTF-8 -i zh_CN zh_CN.UTF-8export LC_ALL=zh_CN.UTF-8echo 'LANG=\"zh_CN.UTF-8\"' &gt; /etc/locale.conf","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"html","slug":"html","permalink":"http://yoursite.com/tags/html/"},{"name":"js","slug":"js","permalink":"http://yoursite.com/tags/js/"}]},{"title":"将本地时间转化成UTC时间","slug":"将本地时间转化成UTC时间","date":"2019-01-22T05:56:46.000Z","updated":"2019-01-22T08:06:40.000Z","comments":true,"path":"2019/01/22/将本地时间转化成UTC时间/","link":"","permalink":"http://yoursite.com/2019/01/22/将本地时间转化成UTC时间/","excerpt":"","text":"实际代码在日常工作中，有些时候需要把本地时间转换成UTC时间，通常来说，最直接的方法就是把北京时间（CST时间）减去8小时，但是如果考虑到夏令时，那么这样简单的数学计算就会得到错误的结果。要解决这种涉及时区的问题，就要使用特殊的模块pytz。 1234567891011121314151617181920212223Python 3.6.4 (default, Sep 3 2018, 10:11:51) [GCC 4.8.5 20150623 (Red Hat 4.8.5-28)] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; import datetime,time,pytz #引入模块&gt;&gt;&gt; now = time.strftime(\"%Y-%m-%d %H:%M:%S\") #得到当前时间&gt;&gt;&gt; now'2019-01-22 14:03:03'&gt;&gt;&gt; type(now)&lt;class 'str'&gt; #此时类型是字符串&gt;&gt;&gt; now = datetime.datetime.now()&gt;&gt;&gt; nowdatetime.datetime(2019, 1, 22, 14, 4, 49, 707859) #转换成datetime模式&gt;&gt;&gt; type(now)&lt;class 'datetime.datetime'&gt;&gt;&gt;&gt; utc_time = now.astimezone(pytz.utc) #转换成了UTC时间就不要用担心夏令时等等麻烦事了&gt;&gt;&gt; print(utc_time)2019-01-22 06:04:49.707859+00:00&gt;&gt;&gt; type(utc_time)&lt;class 'datetime.datetime'&gt; #还需要将datetime格式转换成str&gt;&gt;&gt; utc_now = utc_time.strftime('%Y-%m-%d %H:%M:00')'2019-01-22 13:57:00'&gt;&gt;&gt; type(utc_now)&lt;class 'str'&gt; #此时返回了字符串 上面的代码说明了过程，以及得到的东西的类型，其实精简下来只有三行： 123456&gt;&gt;&gt; import datetime,time,pytz&gt;&gt;&gt; now = datetime.datetime.now()&gt;&gt;&gt; utc_time = now.astimezone(pytz.utc)&gt;&gt;&gt; utc_now = utc_time.strftime('%Y-%m-%dT%H:%M:00Z')&gt;&gt;&gt; print (utc_now)2019-01-22T06:46:00Z 如果要查时区名称，可以使用pytz.country_timezones，如下： 12345&gt;&gt;&gt; from pytz import timezone &gt;&gt;&gt; pytz.country_timezones['CN']['Asia/Shanghai', 'Asia/Urumqi']&gt;&gt;&gt; pytz.country_timezones['US']['America/New_York', 'America/Detroit', 'America/Kentucky/Louisville', 'America/Kentucky/Monticello', 'America/Indiana/Indianapolis', 'America/Indiana/Vincennes', 'America/Indiana/Winamac', 'America/Indiana/Marengo', 'America/Indiana/Petersburg', 'America/Indiana/Vevay', 'America/Chicago', 'America/Indiana/Tell_City', 'America/Indiana/Knox', 'America/Menominee', 'America/North_Dakota/Center', 'America/North_Dakota/New_Salem', 'America/North_Dakota/Beulah', 'America/Denver', 'America/Boise', 'America/Phoenix', 'America/Los_Angeles', 'America/Anchorage', 'America/Juneau', 'America/Sitka', 'America/Metlakatla', 'America/Yakutat', 'America/Nome', 'America/Adak', 'Pacific/Honolulu'] 参考资料https://www.cnblogs.com/cathouse/archive/2012/11/19/2777678.htmlhttps://blog.csdn.net/junli_chen/article/details/52999448《Python cookbook》字符串如何转化成日期《Python cookbook》处理设计到市区的日期问题","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python3","slug":"python3","permalink":"http://yoursite.com/tags/python3/"},{"name":"UTC时间","slug":"UTC时间","permalink":"http://yoursite.com/tags/UTC时间/"},{"name":"时区转换","slug":"时区转换","permalink":"http://yoursite.com/tags/时区转换/"}]},{"title":"较深入解析filebeat.yml各字段功能","slug":"较深入解析filebeat-yml各字段功能","date":"2019-01-21T12:31:46.000Z","updated":"2019-06-05T06:48:18.000Z","comments":true,"path":"2019/01/21/较深入解析filebeat-yml各字段功能/","link":"","permalink":"http://yoursite.com/2019/01/21/较深入解析filebeat-yml各字段功能/","excerpt":"","text":"首先，6.0之后的版本的filebeat，已经不再支持document_type这个选项了。因为ES6不再支持自己在同一个index下定义多个type。 常见的几个参数以下面这个filebeat.yml为例： 1234567891011121314151617181920212223242526filebeat.prospectors:- type: log #这个值可以是stdin(读入标准)、udp（通过udp读取事件） enabled: true paths: - /var/log/messages #指定文件，可以使用通配符 tags: [\"logmessages\"] #lostash能区分不同目录发过来的日志，用tag区分 encoding: utf-8 #设置字符编码 scan_frequency: 10s #每 10 秒钟扫描一次 harvester_buffer_size: 15000 #实际读取文件时，每次读取15000字节 tail_files: true #是否从文件末尾开始读取 fields: alilogtype: usercenter_serverlog serverip: 172.16.0.207 fields_under_root: true #field 字段会放在根索引下，否则会放在 fields 字段下#这里添加第二个日志路径 - type: log enabled: true paths: - /tmp/test.log tags: [\"test\"]output.kafka: enabled: true hosts: [\"172.31.0.84:9092\"] topic: 'system-secure' #支持 topic: '%&#123;[fields][alilogtype]&#125;' 这种写法 在kibana上看到的效果如图： exclude和include而如果是这样： 123456789101112- type: log enabled: true paths: - /tmp/test.log exclude_lines: ['^JAMES'] #排除掉JAMES开头的行 include_lines: ['^HARDEN', '^CURRY'] #保留HARDEN或者CURRY开头的行 tags: [\"test\"]output.kafka: enabled: true hosts: [\"172.31.0.84:9092\"] topic: 'system-secure' 效果如图： 注意！如果同时定义了include_lines和exclude_lines，则Filebeat首先执行include_lines，然后执行exclude_lines。 这两个选项的定义顺序无关紧要。 即使exclude_lines出现在配置文件中的include_lines之前，include_lines选项也会始终在exclude_lines选项之前执行。 参考资料http://www.xiaot123.com/post/elk_filebeat1https://blog.csdn.net/u013613428/article/details/78665081http://www.51niux.com/?id=204https://github.com/wangriyu/docker-elk/wiki/Filebeat-Kafka-ELK","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"elk","slug":"elk","permalink":"http://yoursite.com/tags/elk/"},{"name":"filebeat","slug":"filebeat","permalink":"http://yoursite.com/tags/filebeat/"}]},{"title":"将kafka加入到Elk集群","slug":"将kafka加入到Elk集群","date":"2019-01-21T07:08:31.000Z","updated":"2019-06-10T02:58:46.000Z","comments":true,"path":"2019/01/21/将kafka加入到Elk集群/","link":"","permalink":"http://yoursite.com/2019/01/21/将kafka加入到Elk集群/","excerpt":"","text":"环境交代架构如图： 1（目标模块 ---&gt;filebeat） ---&gt;（kafka ---&gt;logstash） ---&gt;（es ---&gt;kibana） 具体服务器信息如下： 1234172.16.0.207 工作模块+filebeat CentOS 7.4 64位 阿里云1核2G172.31.0.84 kafka+logstash CentOS 7.4 64位 阿里云2核4G172.31.0.76 es+es-head+kibana CentOS 7.4 64位 阿里云2核16G安全组已经开放了elk相应的端口 首先先执行yum update -y &amp;&amp; yum install java-1.8.0-openjdk* -y，在更新的时候不要闲着，在https://www.elastic.co/downloads网站下载所有的elk模块，然后上传到对应的服务器里。 filebeat的部署、配置和启动filebeat与目标机器安装在一起，它是用6.5.4版本，先从官网上下载rpm包，然后上传到服务器里。 1234#假设已经下载好了filebeat-6.5.4-x86_64.rpmrpm -ivh filebeat-6.5.4-x86_64.rpmcd /etc/filebeatcp filebeat.yml filebeat.yml-default #备份模板配置文件 修改filebeat.yml如下： 12345678910filebeat.prospectors:- type: log enabled: true paths: - /var/log/messages #设定日志输入源output.kafka: enabled: true hosts: [\"172.31.0.84:9092\"] #这里填入kafka的地址和端口 topic: 'system-secure' #指定一个topic 配置文件说明了数据的来源和目的地，使用/etc/init.d/filebeat start -e -c /etc/filebeat/filebeat.yml启动filebeat，然后ps -aux|grep filebeat查看一下进程。而filebeat的日志地址是在/var/log/filebeat目录下。 logstash的部署、配置和启动logstash是跟kafka在一台服务器里，首先是下载包并且解压缩： 123wget https://artifacts.elastic.co/downloads/logstash/logstash-6.5.4.tar.gztar -zxvf logstash-6.5.4.tar.gz -C /opt/cd /opt/logstash-6.5.4/config 新建一个配置文件，叫logstash_kafka2ES.conf： 12345678910111213input &#123; kafka&#123; bootstrap_servers=&gt;\"172.31.0.84:9092\" #kafka的地址和端口 topics=&gt;\"system-secure\" #topic要一致 codec=&gt;plain &#125;&#125;output &#123; elasticsearch &#123; hosts=&gt;[\"172.31.0.76:9200\"] #es的地址和端口 index=&gt;\"system-secure-%&#123;+YYYY-MM&#125;\" #规定es使用的索引，按月份分类 &#125;&#125; 配置文件里规定数据来源是kafka的system-secure这个topic，再修改同目录下的jvm.options： 12-Xms512m #根据自己实际情况来-Xmx512m #根据自己实际情况来 保存退出，./bin/logstash -f ./config/logstash_kafka2ES.conf &amp;启动之，日志是logstash目录/logs/logstash-plain.log。 kafka的配置和启动已经在https://rorschachchan.github.io/2019/01/16/%E6%90%AD%E5%BB%BAKakfa2-11%E4%B8%BAELK%E6%9C%8D%E5%8A%A1/ 里说过了，这里略过。 elasticsearch-6.5.4的部署、配置和启动登录到es的服务器上，首先先下载安装包并且解压缩： 12345wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-6.5.4.tar.gztar -zxvf elasticsearch-6.5.4.tar.gz -C /opt/cd elasticsearch-6.5.4/useradd elk #es不能用root启动，需要新建一个用户chown -R elk:elk elasticsearch-6.5.4/ #整个文件夹都给elk了 修改一下elasticsearch.yml： 123456789#cluster.name: my-application #由于实验环境是一个es，就没写集群名称node.name: lcshopelkpath.data: /opt/elasticsearch-6.5.4/data/ #存数据的地方path.logs: /data/tmp/elklog #存日志的路径bootstrap.memory_lock: true #为了防止swapping，官方建议设定为true，阿里云的云服务器是没有swap，可以不写network.host: 0.0.0.0http.port: 9200http.cors.enabled: true #准许es-headhttp.cors.allow-origin: \"*\" 保存之后修改同目录的jvm.options： 12-Xms2g #根据自己实际情况来-Xmx2g #根据自己实际情况来 这里的配置，官网标准的建议是把50％的可用内存作为Elasticsearch的堆内存，保留剩下的50％。当然它也不会被浪费，Lucene会很乐意利用起余下的内存。查看node下是否开启了Mem_lock的语句是：curl &#39;localhost:9200/_nodes?filter_path=**.mlockall&#39;。 保存完毕，还没完,vim /etc/security/limits.conf，最后两行改成如下: 12345* soft nofile 65536* hard nofile 65536# allow user 'elk' mlockallelk soft memlock unlimitedelk hard memlock unlimited 然后切换成elk用户，执行./elasticsearch -d就是后台启动了。 简单的几句es命令： 12345curl -XGET http://127.0.0.1:9200/_cat/allocation?v #查看本机node磁盘容量curl -XGET http://127.0.0.1:9200/_cat/nodes?v #能查看node的CPU和负载情况curl -XGET http://127.0.0.1:9200/_aliases #查看所有的索引curl 'http://localhost:9200/_search?pretty' #查看索引一些细节curl -XDELETE 'localhost:9200/shoporder-log-2019-02?pretty&amp;pretty' #删除shoporder-log-2019-02这个索引，同时磁盘释放空间 kibana和es-head的部署、配置和启动es-head是用docker部署的，语句如下： 12#假设docker已经安装好了docker run --name es-head -p 9100:9100 tobias74/elasticsearch-head:6 #这里必须安装6版本，不然的话，数据不会显示 运行完之后，要进入到容器里修改一下对应的配置文件Gruntfile.js，修改一下connect段落： 12345678910connect: &#123; server: &#123; options: &#123; port: 9100, base: '.', keepalive: true, hostname: '*' #新增加这样一句话 &#125; &#125; &#125; 保存文件，docker restart es-head即可。在浏览器里访问外网ip地址:9100，如图： Kibana也是用docker部署的，语句如下： 12#假设docker已经安装好了docker run --name kibana -p 5601:5601 docker.elastic.co/kibana/kibana:6.5.4 运行完之后，要进入到容器里修改一下对应的配置文件kibana.yml： 123456789101112---# Default Kibana configuration from kibana-docker.server.name: kibanaserver.host: \"0.0.0.0\" #准许所有人访问elasticsearch.url: http://es外网IP:9200xpack.monitoring.ui.container.elasticsearch.enabled: false# SSL for outgoing requests from the Kibana Server (PEM formatted)server.ssl.enabled: trueserver.ssl.key: /usr/share/kibana/config/mykey.key #这里是https证书server.ssl.certificate: /usr/share/kibana/config/mycert.crt #这里是https证书 修改完事之后，docker restart kibana，此时进入到kibana容器发现5601的端口并没有与任何的程序相关联，如图： 其实这是没关系的，可以无视掉。然后在浏览器里访问外网ip地址:5601就可以查看kibana了，先去menagement —&gt;index pattern填入刚刚生成的index，然后在discover页面里选择刚刚生成的index就能看到日志内容了： 如果kibana在某一天突然出现了”重定向过多”,重启kibana进程可破，但是index都会消失…但愿你永远不会遇到这样的bug情况… X-pack目前还不支持6.2以上的版本，故此先略。因为没有X-pack，所以再kibana.yml里的elasticsearch.url我们还是写http，有了X-pack就要改成elasticsearch.url: &quot;https://&lt;your_elasticsearch_host&gt;.com:9200&quot;的样子，让es与kibana之间的传输是加密的。 参考资料https://dzone.com/articles/just-say-no-swappinghttps://www.elastic.co/guide/cn/elasticsearch/guide/cn/heap-sizing.htmlhttps://www.elastic.co/guide/cn/kibana/current/settings.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"elk","slug":"elk","permalink":"http://yoursite.com/tags/elk/"},{"name":"kafka","slug":"kafka","permalink":"http://yoursite.com/tags/kafka/"}]},{"title":"搭建Kakfa2.11为ELK服务","slug":"搭建Kakfa2-11为ELK服务","date":"2019-01-16T13:20:51.000Z","updated":"2019-05-23T09:26:26.000Z","comments":true,"path":"2019/01/16/搭建Kakfa2-11为ELK服务/","link":"","permalink":"http://yoursite.com/2019/01/16/搭建Kakfa2-11为ELK服务/","excerpt":"","text":"准备工作试验机器：阿里云centos 7.5，IP地址是172.31.0.84。 本文是单台kafka+zookeeper架构，如果土豪可以尝试3台zookeeper+3台kafka。 12345yum install java-1.8.0-openjdk* -ywget http://apache.website-solution.net/kafka/2.1.0/kafka_2.11-2.1.0.tgztar -zxvf kafka_2.11-2.1.0.tgz -C /optwget http://apache.website-solution.net/zookeeper/zookeeper-3.4.10/zookeeper-3.4.10.tar.gztar -zxvf zookeeper-3.4.10.tar.gz -C /usr/local 其实最新的kafka里面已经包括zookeeper了，不过我习惯了单独启动zookeeper，还是单独下载单独配置单独启动。 启动zookeeper首先先去zookeeper下的conf文件夹里编写配置文件： 12/usr/local/zookeeper-3.4.10/confcp zoo_sample.cfg zoo.cfg 然后编辑zoo.cfg，把最下面几行改成这样： 12345autopurge.snapRetainCount=3 #保留3个文件# Purge task interval in hours# Set to \"0\" to disable auto purge featureautopurge.purgeInterval=1 #保留一小时以内的日志server.1=172.31.0.84:2888:3888 #本机IP地址 2888端口：表示的是这个服务器与集群中的Leader服务器交换信息的端口；3888端口：表示的是万一集群中的Leader服务器挂了，需要一个端口来重新进行选举，选出一个新的Leader，而这个端口就是用来执行选举时服务器相互通信的端口。 然后回到/usr/local/zookeeper-3.4.10/bin里，执行./zkServer.sh start，执行完毕之后，再用./zkServer.sh status检查一下状态，由于是单台，所以状态应该是standalone。 启动kafka同zookeeper一样，先去kafka的conf文件夹/opt/kafka_2.11-2.1.0/config里，在配置文件zookeeper.properties最下面加上如下几句话: 1234tickTime=2000initLimit=20syncLimit=10server.1=172.31.0.84:2888:3888 #zookeeper的地址，也就是本机地址 tickTime:这个时间是作为Zookeeper服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个tickTime时间就会发送一个心跳。 修改好了zookeeper.properties之后，才是正式的kafka配置文件server.properties： 12345678broker.id=1port=9092 #broker监听的端口host.name=172.31.0.84 #填服务器 IPlog.dir = / data / kafka - logs # 该目录可以不用提前创建，在启动时自己会创建zookeeper.connect = 172.31.0.84:2181 # 这个就是zookeeper的ip及端口num.partitions = 16 # 需要配置较大 分片影响读写速度log.dirs = /data/kafka-logs # 数据目录也要单独配置磁盘较大的地方log.retention.hours = 168 # 时间按需求保留过期时间,避免磁盘满 确认zookeeper状态是启动之后，./bin/kafka-server-start.sh ./config/server.properties &amp;来启动Kafka服务，然后检查一下端口9092是否正常打开(9092端口不会立即启动，需要等待一会时间)。 kafka简单操作语句一些常用的操作语句（前提是你在kafka的bin文件夹内）如下： 123456789101112#创建topic./kafka-topics.sh --create --zookeeper zookeeperIP地址:2181 --replication-factor 1 --partitions 1 --topic chenshuotest #factor大小不能超过broker的个数#查看topic./kafka-topics.sh --list --zookeeper zookeeperIP地址:2181#在topic里增加信息./kafka-console-producer.sh --broker-list kafkaIP地址：9092 --topic chenshuotest#消费掉topic里的信息，需要在另外一个xshell窗口界面操作./kafka-console-consumer.sh --bootstrap-server kafkaIP地址9092 --topic chenshuotest --from-beginning#查看group./kafka-consumer-groups.sh --bootstrap-server kafkaIP地址:9092 --list#查看消费情况./kafka-consumer-groups.sh --bootstrap-server kafkaIP地址:9092 --describe --group logstash kafka与mq类似，都有一个“入队”、“出队”、“堆积值”的展示，如下： 简单说一下上面这个图： PARTITION：分区编号，它与server.properties里的num.partitions是一致的，这个值不是越大越好，会增加不可用的风险，而且过多的分区意味要打开过多的句柄，增加点对点的延迟； CURRENT-OFFSET：表示消费者组最新消费的位移值； LOG-END-OFFSET：表示topic所有分区当前的日志终端位移值，即总生产值； LAG：表示有多少条message没有被消费； 如果想用zabbix监控LAG值，很简单： 1./kafka-consumer-groups.sh --bootstrap-server kafkaIP地址:9092 --describe --group logstash | grep 目标topic |awk '&#123;print $5&#125;' 参考文档http://www.cnblogs.com/JetpropelledSnake/p/10057545.html （zookeeper+kafka集群的配置，请看这里）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"kafka","slug":"kafka","permalink":"http://yoursite.com/tags/kafka/"}]},{"title":"在Django里添加Celery让脚本异步在后台运行","slug":"在Django里添加Celery做异步任务处理","date":"2019-01-16T06:12:00.000Z","updated":"2019-01-16T11:52:16.000Z","comments":true,"path":"2019/01/16/在Django里添加Celery做异步任务处理/","link":"","permalink":"http://yoursite.com/2019/01/16/在Django里添加Celery做异步任务处理/","excerpt":"","text":"前言当使用Django执行脚本的时候，经常遇到一种情况：跳转到某个url，结果是先在后台执行一个时间较长的脚本，然后才能打开这个url页面，这样用户体验就很不好。 比如说像这样的views.py配置： 12345678910111213141516171819202122232425#使用ansible执行远程命令@csrf_exemptdef run_command(request): command = \"ansible all -i /root/.ssh/hosts -m shell -a 'echo 'worinixianren' &gt;&gt; /tmp/xianren.txt'\" #设定ansible远程命令 if request.method == 'POST': id = request.POST.getlist(\"ecs\") #通过html来获取id num = [] num.append(len(id)) #传递参数，给下一个页面用的 name = [] #传递参数，给下一个页面用的 db = pymysql.connect(\"阿里云数据库\",\"数据库账号\",\"数据库密码\",\"databases名\") #根据上面获得的id去数据库里得到对应的内网IP cursor = db.cursor() with open('/root/.ssh/hosts','w') as f: for i in id: sql = 'select * from createyaml_ecs where name = \"'+ i + '\";' cursor.execute(sql) ip = cursor.fetchall()[0][3] cursor.execute(sql) name.append(cursor.fetchall()[0][1]) f.write(ip+\" ansible_ssh_user=root\"+\"\\n\") #将得到的内网IP写入到一个文件里 db.close() #关闭数据库 child = subprocess.Popen(command,stdout=subprocess.PIPE, stderr=subprocess.PIPE,shell=True) #执行ansible命令 stdout, stderr = child.communicate() return render(request,'run_command.html',&#123;'data':num[0],'name':name&#125;) #将内容反馈到html页面里 else: return render(request,'homepage.html') 像上面这段代码，要看到run_command.html页面就要先把整个ansible部署的脚本全跑完，如果是几百台机器批量操作的脚本，那就要等到海枯石烂水倒流。那遇到这样的情况怎么解决呢？根据不同的请求，有不同的对策： 单纯的后台跑一个脚本，那么就可以使用Celery； 在后台跑脚本的同时，还需要不断的向后台发送请求（比如微信上的茶叶妹聊天机器人），那么就要使用Channels； Celery原理部分和配置定时任务就不多说了，文末的参考资料里有网站，这里主要说的是如何配置Celery。 环境交代存储后端:阿里云redis(需要支持evalsha命令，如果不支持，去控制台升级小版本即可)Python:3.6.5Django:2.1.1django-celery:3.2.2，安装方法：pip install django-celerycelery-with-redis：3.0，安装方法pip install celery-with-rediscelery:3.1.26.post2 具体配置首先配置setting.py，全文最后添加这样几句话： 1234567891011121314#celery配置信息#celery中间人 redis://:redis密码@redis服务所在的ip地址:端口/数据库号，我用的是254号#channels配置redis也是这样配置，如果没有密码，就可以把':redis密码@'省略BROKER_URL = 'redis://:redis密码@阿里云redis地址:6379/254'#celery结果返回，可用于跟踪结果CELERY_RESULT_BACKEND = 'redis://:redis密码@阿里云redis地址:6379/254'#celery内容等消息的格式设置CELERY_ACCEPT_CONTENT = ['application/json',]CELERY_TASK_SERIALIZER = 'json'CELERY_RESULT_SERIALIZER = 'json'#celery时区设置，使用settings中TIME_ZONE同样的时区CELERY_TIMEZONE = TIME_ZONE 在setting.py同级的文件夹里创建celery.py，内容如下： 12345678910111213141516171819202122#coding:utf-8from __future__ import absolute_import, unicode_literals from celery import Celeryfrom django.conf import settingsimport os #获取当前文件夹名，即为该Django的项目名project_name = os.path.split(os.path.abspath('.'))[-1]project_settings = '%s.settings' % project_name #设置环境变量os.environ.setdefault('DJANGO_SETTINGS_MODULE', project_settings) #实例化Celeryapp = Celery(project_name) #使用django的settings文件配置celeryapp.config_from_object('django.conf:settings') #Celery加载所有注册的应用app.autodiscover_tasks(lambda: settings.INSTALLED_APPS) 还是在同样的文件夹里，编辑__init__.py： 12345#coding:utf-8from __future__ import absolute_import, unicode_literals #引入celery实例对象from .celery import app as celery_app 然后在app（具体应用的文件夹里），创建一个叫tasks.py，这里面就是需要在后台执行的具体脚本： 1234567891011#coding:utf-8from celery.decorators import taskimport subprocess@task #在原有的方法上加上celery装饰器task#ansible批量部署命令def run_ansible(): command = \"ansible all -i /root/.ssh/hosts -m shell -a 'echo 'worinixianren' &gt;&gt; /tmp/xianren.txt'\" #设定命令 child = subprocess.Popen(command,stdout=subprocess.PIPE, stderr=subprocess.PIPE,shell=True) stdout, stderr = child.communicate() print (\"success!!!\") #执行成功！ 保存退出之后，修改原有的views.py，把原来涉及脚本的字段删除，改成: 12345678910111213141516171819202122@csrf_exemptdef run_command(request): if request.method == 'POST': id = request.POST.getlist(\"ecs\") num = [] num.append(len(id)) #传递参数，给下一个页面用的 name = [] db = pymysql.connect(\"阿里云数据库\",\"数据库账号\",\"数据库密码\",\"databases名\") cursor = db.cursor() with open('/root/.ssh/hosts','w') as f: for i in id: sql = 'select * from createyaml_ecs where name = \"'+ i + '\";' cursor.execute(sql) ip = cursor.fetchall()[0][3] cursor.execute(sql) name.append(cursor.fetchall()[0][1]) f.write(ip+\" ansible_ssh_user=root\"+\"\\n\") db.close() run_ansible.delay() #celery异步执行后台ansible程序，使用delay函数 return render(request,'run_command.html',&#123;'data':num[0],'name':name&#125;) else: return render(request,'homepage.html') 返回到manage.py所在的目录，先正常启动django，然后再/usr/local/python3/bin/celery -A project名称 worker -l info启动celery，如图： 看到tasks.py已经成功被celery使用了，然后在页面上去执行原本的命令，就会看到celery页面有刷新： 此时再去redis里查看一下存储的效果： 可见tasks执行的状态已经被保存到了redis里。但是上面我们是在前台页面启动celery，如果想把celery作为一个后台守护进程，那么命令语句如下： 1/usr/local/python3/bin/celery multi start worker -A project名称 -l info 效果如图： 停止或重启将上面的start换为stop或restart即可。 补充如果tasks.py内容变化了，需要重启celery才能生效。 如果在启动celery的时候，日志有写UserWarning: Using settings.DEBUG leads to a memory leak, never use this setting in production environments! warnings.warn(&#39;Using settings.DEBUG leads to a memory leak, never &#39;，那么就在settings.py里把DEBUG = True改成DEBUG = False即可。 查看redis有几个库的命令：config get databases。 参考资料http://yshblog.com/blog/163 （对照代码做一遍就更有体会了）https://www.cnblogs.com/wdliu/p/9517535.html (原理以及如何配置定时任务)https://www.cnblogs.com/wdliu/p/9530219.htmlhttp://docs.celeryproject.org/en/latest/getting-started/brokers/redis.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://yoursite.com/tags/Django/"},{"name":"celery","slug":"celery","permalink":"http://yoursite.com/tags/celery/"},{"name":"异步任务","slug":"异步任务","permalink":"http://yoursite.com/tags/异步任务/"}]},{"title":"大量任务冲击下的activeMQ报错\"GC overhead limit exceeded\"","slug":"大量任务冲击下的activeMQ报错GC-overhead-limit-exceeded","date":"2019-01-14T11:54:19.000Z","updated":"2019-01-14T13:19:22.000Z","comments":true,"path":"2019/01/14/大量任务冲击下的activeMQ报错GC-overhead-limit-exceeded/","link":"","permalink":"http://yoursite.com/2019/01/14/大量任务冲击下的activeMQ报错GC-overhead-limit-exceeded/","excerpt":"","text":"半夜阿里云的杭州可用B区出现了机房抖动，几乎所有的B区服务全部掉线。阿里云的技术人员捅咕了半个小时左右，在大约11点40左右恢复了正常。此时几百万的设备开始同时恢复上线，然而经过了1个小时左右，依旧有几十万设备无法上线，有的甚至上线后又掉线。 我们的架构是设备要先去“注册中心”注册，注册成功之后才会正常的工作。如果多次注册不成功，就会释放连接，把连接让给其他需要注册的设备。但是发现设备上线的速度很慢，扩容了几台“注册中心”模块，效果依旧不见好转。发现注册模块的CPU全部都达到了100%： 登录到服务器里一看，日志不断的刷新这样的内容： 模块与activemq的延迟特别大，此时activemq又有几百万的消息没有消费堆积在队列里。大约十分钟左右，就开始抛出java.lang.OutOfMemoryError: GC overhead limit exceeded的错误，如图： 但是同一时间段里的activemq并没有出现内存吃紧的情况： 没有办法，就先赌一下的重启了activemq，没想到问题就解决了… 奇怪，明明activemq没有内存的明显消耗，却报内存耗尽。先把结果记录下来，等下一次再有类似的情况，好好观察一下（也但愿不要再在放假的时候出现故障了…）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"activemq","slug":"activemq","permalink":"http://yoursite.com/tags/activemq/"}]},{"title":"使用Zabbix的Python api去获取当前监控值","slug":"使用Zabbix的python-api去获取当前监控值","date":"2019-01-09T07:24:49.000Z","updated":"2019-01-15T06:56:22.000Z","comments":true,"path":"2019/01/09/使用Zabbix的python-api去获取当前监控值/","link":"","permalink":"http://yoursite.com/2019/01/09/使用Zabbix的python-api去获取当前监控值/","excerpt":"","text":"事前准备有些时候我们需要在非zabbix的web界面里得到zabbix-server对某台服务器的实时监控值。但是有些值是zabbix-server加工过的，比如eth0入网流量，zabbix-server加工的方法如下： 可见是每秒的变量并且还乘了8，那么如果要得到这样加工过的值，想通过shell得到linux的指标无疑是十分麻烦的。那么对于这种需求，我们想到的第一个办法就是使用zabbix的api，通过api去获取值比爬网页要方便许多（而且zabbix-server的web页面不是那么好爬的）。 Zabbix 3.0的API官方文档：https://www.zabbix.com/documentation/3.0/manual/apiZabbix 3.0的python版API官方文档：https://github.com/gescheit/scripts/tree/master/zabbix这里我更推荐用python版的api，因为使用zabbix-api这个python第三方库让开发变得更为简洁。 安装zabbix-api安装zabbix-api最方便的方法就是pip安装。本文的python版本2.7.15，使用源码安装的，安装包并不带pip，那么安装pip的方法如下： 123456789101112yum install -y zlib-devel zlib openssl openssl-develmv /usr/bin/pip /usr/bin/pip-bak #备份原有的pipwget --no-check-certificate https://pypi.python.org/packages/source/s/setuptools/setuptools-12.0.3.tar.gz#md5=f07e4b0f4c1c9368fcd980d888b29a65tar -zxvf setuptools-12.0.3.tar.gzcd setuptools-12.0.3python setup.py install #这一步需要上面刚安装的zlibwget https://files.pythonhosted.org/packages/d0/92/1e8406c15d9372084a5bf79d96da3a0acc4e7fcf0b80020a4820897d2a5c/pip-7.1.2.tar.gz#或者去https://pypi.org/project/pip/7.1.2/#files页面下载pip-7.1.2.tar.gz tar -zxcf pip-7.1.2.tar.gzcd pip-7.1.2sudo python setup.py installln -s /usr/local/python27/bin/pip2.7 /usr/bin/pip #做一个新的快捷方式 有了pip之后，就可以安装zabbix-api，命令是：pip install zabbix-api 。在python的命令行里输入from zabbix_api import ZabbixAPI不报错就代表安装成功。 链接zabbix通过zabbix-server鉴权的代码如下： 123456#coding:utf-8#这个脚本是用来获取zabbix 定时流量值from zabbix_api import ZabbixAPIzapi = ZabbixAPI(server=\"http://网页地址/zabbix/api_jsonrpc.php\") zapi.login(\"网页的用户名\", \"网页的密码\") #鉴权 如果没报错，就证明已经成功连接到zabbix-server了。 获取监控项还是以eth0入网流量为例，获取它的代码如下： 123456789101112#coding:utf-8#这个脚本是用来获取zabbix 定时流量值from zabbix_api import ZabbixAPIzapi = ZabbixAPI(server=\"http://网页地址/zabbix/api_jsonrpc.php\") zapi.login(\"网页的用户名\", \"网页的密码\") #鉴权hostname = [\"服务器1名称\",\"服务器2名称\",\"服务器3名称\",\"服务器4名称\"] for name in hostname: list_item = zapi.item.get(&#123;\"output\": \"extend\",\"filter\":&#123;'host':name&#125;,\"search\":&#123;'key_':'net.if.in[eth0]'&#125;&#125;) eth0_value = list_item[0][\"lastvalue\"] print \"Incoming traffic bandwidth is:\"+(eth0_value) 可见多么简单！ 上面代码里的hostname就是zabbix网页里的Host name，如图： 然后使用zapi.item.get方法通过filter来过滤，最后得到对应的key值。zapi下面还有很多方法，比如zapi.hostgroup.get、zapi.host.get、zapi.application.get等等等等，可以对于自己的需要，灵活运用。 参考文档https://blog.csdn.net/LYJ_viviani/article/details/70568434https://segmentfault.com/a/1190000014241994http://blog.51cto.com/xiaofengfeng/1907573","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"api","slug":"api","permalink":"http://yoursite.com/tags/api/"}]},{"title":"Html制作progress进度条","slug":"Html制作progress进度条","date":"2019-01-07T07:07:15.000Z","updated":"2019-01-24T11:32:16.000Z","comments":true,"path":"2019/01/07/Html制作progress进度条/","link":"","permalink":"http://yoursite.com/2019/01/07/Html制作progress进度条/","excerpt":"","text":"简单介绍无论是下载还是上传，亦或者是执行脚本。进度条都是必不可少的环节，它能让人清晰直观的看到事情发展的进度。现在生成进度条有很多种方法，我选择的是progress，它的用法很简单： 1&lt;progress value='70' max='100'&gt;&lt;/progress&gt; value属性表示进度条已经完成的进度值，范围为0~max之间。如果没有设置max属性，那么value属性值的范围要在0~1之间。如果没有value值，那么完成进度是不确定的。那么整个进度条就是一个动态效果，就像一个加载中loading，中间的进度块来回游荡。如下图： 动态进度条有些时候，我们无法正常获取到后台脚本运行的进度，因为某些脚本无法反馈给前端一个值来衡量目前运行到什么阶段，于是这种情况我们只能预估一下这个脚本大约用多少时间，做一个假的进度条来展示进度。如果想做一个逐渐进行的进度条，比如2秒钟跑满的进度条，那么代码如下： 12345678910111213141516171819&lt;body&gt;&lt;p&gt;进度条：&lt;progress value=\"0\" max=\"100\"&gt;&lt;/progress&gt;&lt;/p&gt;&lt;input type=\"button\" value=\"开始\" onclick=\"goprogress()\"/&gt;&lt;/body&gt;&lt;script&gt; function goprogress()&#123; var pro=document.getElementsByTagName(\"progress\")[0]; //获取progress的第一行 gotoend(pro,0); &#125; function gotoend(pro,value)&#123; var value=value+1; pro.value=value; if(value&lt;100) &#123; setTimeout(function()&#123;gotoend(pro, value);&#125;,20) //这里是时间，20的意思是2秒完成 &#125;else&#123; setTimeout(function()&#123;alert(\"任务完成\")&#125;,20); &#125; &#125;&lt;/script&gt; 整个动态效果如下： 如何页面自动执行函数上面的例子，需要手动点击button，如果不想把函数绑定点击按钮事件上，而是要页面加载出来后自动执行函数就出现此效果，那么有两种办法： 直接把函数写到html的body标签里面 123&lt;body onload=\"myfunction()\"&gt; //具体函数&lt;/body&gt; 在JS语句里调用 12345678&lt;script type=\"text/javascript\"&gt; function myfun() &#123; alert(\"this window.onload\"); &#125; /*用window.onload调用myfun()*/ window.onload = myfun; //不要括号&lt;/script&gt; 或者在JS语句里按以下方法调用： 1234567&lt;script type=\"text/javascript\"&gt; window.onload=function()&#123; func1(); func2(); func3(); &#125;&lt;/script&gt; a href页面不刷新方法使用&lt;a href=&quot;#&quot;&gt;页面是会原地刷新的，那么如何不让页面刷新呢？使用&lt;a href=&#39;javascript:&#39;&gt; 。 参考资料https://blog.csdn.net/qq965194745/article/details/80034993https://frontenddev.org/article/how-to-use-javascript-to-do-a-high-force-the-progress-bar.htmlhttp://www.voidcn.com/article/p-crqmibur-a.htmlhttps://blog.csdn.net/Zhaky/article/details/50922613http://www.webfront-js.com/articaldetail/47.htmlhttps://www.cnblogs.com/witchgogogo/p/5547258.html （这个用bootstrap做的进度条更牛逼）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"html","slug":"html","permalink":"http://yoursite.com/tags/html/"},{"name":"前端","slug":"前端","permalink":"http://yoursite.com/tags/前端/"},{"name":"进度条","slug":"进度条","permalink":"http://yoursite.com/tags/进度条/"}]},{"title":"使用Nginx+Uwsgi将Django部署上线","slug":"使用Nginx-Uwsgi将Django部署上线","date":"2019-01-05T09:58:17.000Z","updated":"2019-01-07T02:17:08.000Z","comments":true,"path":"2019/01/05/使用Nginx-Uwsgi将Django部署上线/","link":"","permalink":"http://yoursite.com/2019/01/05/使用Nginx-Uwsgi将Django部署上线/","excerpt":"","text":"Uwsgi与Nginx搭配Django的原理请移步去看https://rorschachchan.github.io/2018/02/02/Uwsgi%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E7%AE%80%E5%8D%95%E4%BD%BF%E7%94%A8/ 。 配置uwsgi安装Uwsgi的方法很简单，pip install uwsgi即可，一般来说会直接下载到python路径下的bin目录夹里。 首先，如果启动了django的进程，请先关闭。 然后我们要在django根目录同级里，新增一个文件夹，比如叫chensite_uwsgi，里面手动编写一个配置文件chensite.ini，内容如下： 1234567891011121314[uwsgi]chdir = /chendjango/Kubernetes #这里指定django根目录地址module = Kubernetes.wsgi:application #这里指定django默认自带的wsgi文件路径，前面是文件夹名，后面带上:applicationmaster = True #指定启动主进程processes = 4 #指定进程数harakiri = 60 #当客户端请求uWSGI接口超过60s时，uWSGI会强制关闭客户端连接，然后重启响应客户端的workermax-requests = 5000 #最多5000请求socket = 127.0.0.1:8000 #使用本地的8000端口启动Django，效果等于python manage.py runserver 0.0.0.0:8000uid = www #使用www的用户去启动uwsgi，这里注意，如果非root用户可能会出现权限不足的情况，但是使用root用户会危险gid = wwwpidfile = /chendjango/chensite_uwsgi/chendjango.pid #指定pid文件daemonize = /chendjango/chensite_uwsgi/chendjango.log #指定log文件，同时要求进程在后台运行vacuum = True #当服务器退出时自动删除socket文件和pid文件logfile-chmod=644 #指定日志文件的权限 配置文件搞定之后，就可以使用/usr/local/python3/bin/uwsgi --ini chensite.ini来启动uwsgi了，启动完毕之后，ps -aux|grep uwsgi看一下进程是否正常，正常的话Django的进程就应该被uwsgi拉起来了，如果不正常可以通过我们刚刚指定的log文件来调试问题。 配置nginxNginx在这里的用途就是监听uwsgi，由于uwsgi已经把django进程开启，所以也达到了nginx“控制”django的效果。Nginx的安装方法就不多说了，这里主要说具体配置。 在nginx的conf/vhosts文件夹里，新建一个叫django.conf的文件来搭配uwsgi。文件内容如下： 123456789101112131415161718192021server &#123; listen 80; #指定外人对应访问端口 server_name django.lechange.com; #指定域名 charset utf-8; client_max_body_size 75M; location /static &#123; #这里如实填写静态资源路径 alias /chendjango/Kubernetes/static; &#125; location /media &#123; #同上 alias /chendjango/Kubernetes/media; &#125; location / &#123; #如果非静态资源，那么就跳转访问去8000端口 uwsgi_pass 127.0.0.1:8000; include /usr/local/nginx/conf/uwsgi_params; #这里填写uwsgi_params文件的地址 &#125;&#125; 保存退出之后，直接启动nginx，确认进程和端口号都正常的话，在浏览器里上登录对应的django页面就OK了！ 给网页title添加ico图标首先先找到一个喜欢的图片，然后去google一下“ico图标转换”，这种转换网站一搜一大把。登录到网站将这个喜欢的图片制作成16X16的ico图标文件，然后上传到服务器，放到django的静态文件目录里的任何地方。比如我只做好了一个batman.ico文件，然后把它放到static/pic文件夹下： 然后就是在html文件的title字段里添加如下两句话： 1234&lt;!--网页标题左侧显示--&gt;&lt;link rel=\"icon\" href=\"/static/pic/batman.ico\" type=\"image/x-icon\"&gt;&lt;!--收藏夹显示图标--&gt;&lt;link rel=\"shortcut icon\" href=\"/static/pic/batman.ico\" type=\"image/x-icon\"&gt; 保存之后，刷新一下页面，就看到效果了： 参考资料https://uwsgi-docs-zh.readthedocs.io/zh_CN/latest/tutorials/Django_and_nginx.htmlhttps://segmentfault.com/a/1190000014361352http://www.runoob.com/django/django-nginx-uwsgi.htmlhttps://segmentfault.com/a/1190000007952589","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"},{"name":"Django","slug":"Django","permalink":"http://yoursite.com/tags/Django/"},{"name":"Uwsgi","slug":"Uwsgi","permalink":"http://yoursite.com/tags/Uwsgi/"}]},{"title":"Mysql语句导出成excel时解决科学计数法的情况","slug":"Mysql语句导出成excel时解决科学计数法的情况","date":"2019-01-04T08:02:25.000Z","updated":"2019-01-07T07:47:04.000Z","comments":true,"path":"2019/01/04/Mysql语句导出成excel时解决科学计数法的情况/","link":"","permalink":"http://yoursite.com/2019/01/04/Mysql语句导出成excel时解决科学计数法的情况/","excerpt":"","text":"普通情况导出excel将结果直接导出到/tmp/result.xls： 1mysql -h127.0.0.1 -u用户名 -p密码 -e \"具体SQL命令\" database名 &gt; /tmp/result.xls #请注意单引号双引号 解决科学计数法有时候数据库里会有比较长的数字，比如订单号或者身份证号，但是由于excel的操蛋设定，长数字在导出后在Excel中打开后却是用科学计数法显示的，过长的话，后面几位数字全都转换为0了，解决这样问题的方法就是引入CONCAT： 比如我要从sdb_b2c_delivery这个tables里查询两个时间戳之间的情况，将结果导出到/tmp/result.xls： 1mysql -h127.0.0.1 -u用户名 -p密码 -e 'SELECT CONCAT(\"\",对应的列名1),CONCAT(\"\",对应的列名2) FROM sdb_b2c_delivery WHERE t_begin &gt;= 1543593600 AND t_begin &lt;= 1546271999;' database名 &gt; /tmp/result.xls #请注意单引号双引号 但是这样导出来的结果还是科学计数法，不过可以修改单元格格式，改成“数值”，然后把小数位数改成0即可。 解决中文乱码的问题有时候数据库里会有中文，但是导出的时候发现excel看到的中文全是乱码，解决这样问题的方法需要加上--default-character-set=utf8，比如： 1mysql -h127.0.0.1 -u用户名 -p密码 --default-character-set=utf8 -e 'SELECT CONCAT(\"\",对应的列名1),CONCAT(\"\",对应的列名2) FROM sdb_b2c_delivery WHERE t_begin &gt;= 1543593600 AND t_begin &lt;= 1546271999;' database名 &gt; /tmp/result.xls #请注意单引号双引号 将result.xls直接使用notepad++打开，然后将excel列的格式设置为文本，再粘贴就能得到正确的表格了。 参考资料https://www.jianshu.com/p/2c8bfbfcd288https://qianrong.me/sql/2.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"excel","slug":"excel","permalink":"http://yoursite.com/tags/excel/"}]},{"title":"Python3写文件的几个例子","slug":"Python3写文件的几个例子","date":"2019-01-04T03:22:55.000Z","updated":"2019-01-04T06:31:44.000Z","comments":true,"path":"2019/01/04/Python3写文件的几个例子/","link":"","permalink":"http://yoursite.com/2019/01/04/Python3写文件的几个例子/","excerpt":"","text":"拷贝一个文件的全部内容到另一个文件复制aaa.txt内容到另一个bbb.txt 12345fp = open('aaa.txt','r') for line in fp: fq = open('bbb.txt','a') #这里用追加模式，这里不能用w fq.write(line) fp.close() 在文件头部插入数据读出原有文件内容aaa.txt，移动索引到开始，写入新的数据data，然后再写入旧的数据。 12345with open('aaa.txt', \"r+\") as f: old = f.read() #将原来的内容取出 f.seek(0) #索引移动到头 f.write(data) f.write(old) 清空文件的内容当已存在一个文件对象，且这个文件对象可以对文件进行写write操作(注意不是追加append操作),则可以通过如下语句来清空一个文件的内容: 12&gt;&gt;&gt; f = open('file.txt','r+')&gt;&gt;&gt; f.truncate() #使用文件对象的成员函数truncate()来清空一个文件 如何让html文件识别换行符？如果使用替换方法把\\r\\n替换成&lt;br&gt;的话太蠢了，其实这种需求可以一句话解决：头尾加&lt;pre&gt;&lt;/pre&gt;。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"文件读写","slug":"文件读写","permalink":"http://yoursite.com/tags/文件读写/"}]},{"title":"伦敦八日游记","slug":"英伦10日游","date":"2019-01-02T02:42:22.000Z","updated":"2019-01-09T12:37:32.000Z","comments":true,"path":"2019/01/02/英伦10日游/","link":"","permalink":"http://yoursite.com/2019/01/02/英伦10日游/","excerpt":"","text":"这次的伦敦八日行其实是我的蜜月假期，原本打算跟媳妇去一趟巴塞罗那，但是网上攻略查了查发现巴塞罗那的小偷太多，甚至还有拦路抢包的事情发生。毕竟出门旅游，不想遇到什么添堵的事情，于是想来想去就选择了治安情况更好的伦敦作为本次的落脚点。 前期工作办理英国签证还是比较麻烦的，虽然在杭州可以直接办理，但是需要提交很多的证件—收入证明、公司营业执照复印件等等，然后要等待一个月左右再去照相按手印。若心急的话，可以走付费的加速通道。机票我媳妇选择了国航，路线是“杭州–&gt;北京–&gt;伦敦”，选择国航的主要原因是“行李在转机的时候可以直挂”。至于住宿，伦敦毕竟也是寸土寸金的地方，住宿还是蛮贵的，100磅一晚是正常价格，我媳妇选择了Airbnb，地址很不错，是靠近牧羊丛地铁站的Richman街道，交通很便利，周围也很安静。 出门游玩得需要现金吧，于是乎去中国银行兑换英镑，兑换汇率是8.9，我媳妇兑换了1000磅，兑换完了才知道原来市场上流通的英镑最大面值才50…最后就是在淘宝上购买英国电话卡，我俩八天里使劲用才用了6G左右，所以其实10G完全够用了，20G流量纯粹浪费。 具体行程这10天的具体行程如下：22日 从杭州出发，中午北京转机，晚上抵达伦敦希斯罗机场，办理oyster card，入住Airbnb23日 大英博物馆 + 考文特花园 + 海德公园嘉年华24日 杜莎夫人蜡像馆 + 贝克街散步 + 伦敦眼 + 去媳妇的朋友家圣诞聚餐25日 圣诞节全城休息，步行去摄政街看灯，在唐人街吃饭26日 WestField购物 + 温布利看球 + 哈罗德百货购物27日 西敏寺 + 伦敦塔桥 + 大本钟 + 泰晤士河游船28日 温莎城堡 + 碎片大厦观景29日 由于前几天太累了，原定的去剑桥大学参观取消，改成了牛津街购物30日 WestField购物 + 返程到北京31日 抵达杭州 伦敦的人伦敦是一个特别国际化的都市，出飞机场坐上地铁的那一刻，我发现车厢里有好多的印度人，让我一度怀疑飞机是不是飞到了新德里。伦敦大街上也是各种肤色，既有黑人白人也有头戴面纱的穆斯林，各路人马聚齐于此。伦敦人给人感觉是很友好的—只要人看到你拿着手机在路上一副不知所措的神情，就会上前主动问你“Are you lost?”记得我跟我媳妇第一天晚上9点多拖着行李找Airbnb的时候，就是一个黑人胖大姐帮我们联系了房东，而且还与我们一起找房东留下的钥匙。 我所住的Airbnb是提供有线电视的，总共有700个频道（另外还有100个电台），其中收费频道大约是400个，剩下300个频道里只有一个中文频道—凤凰卫视。但是我个人更感兴趣的是那些印度频道、巴基斯坦频道和穆斯林频道，因为第一次能接触到他们的电视节目觉得很新奇好玩。为什么能收到这些频道？我猜可能是英国政府为了照顾当地的印度人和中东人，让他们可以在千里之外看到自己家乡的节目。每天早上，穆斯林频道每天早上都有念经（古兰经？）的环节，屏幕上一盏烛火，背景是巨大的清真寺，然后飘过一行又一行的阿拉伯字，一个浑厚的男声在咿咿呀呀的念经…这个节目基本陪我度过了两个早上煮方便面的时间。 伦敦街头的卖艺人随处可见，多数是自弹自唱的音乐艺人，也有杂技艺人和幽默剧艺人。英国人很喜欢唱歌，尤其是喝酒的时候大家一起大合唱更是壮观。而每到周五周六的晚上，酒吧一条街人满为患，甚至有人在店外喝酒，同时马路上也会有临时的简易厕所供男士们方便。 英国不愧是腐国，本身洋人就比较高大，所以“彩虹小哥”在马路上就更有视觉冲击力，部分街道甚至会出售男同用品，而他们对这种现象也是司空见惯、习以为常。 英国男人最有名的，除了腐之外，那就是秃了。上到威廉、哈里两个王子下到地铁里的普通上班族，秃头的概率的确很高，我经常感叹那些白人们有着帅气的面庞和隐隐看到头皮的后脑勺。为什么英国是秃头的重灾区？有人说是因为英国的水质硬，所以毛孔不通畅，也有人说英国雨水多，而且当地人还不喜撑伞，频繁的冷水对头发也有伤害。但是我看到的几个印度和中东的店员却都不秃，那么英国白人秃头的真实原因不得而知，不过秃头的杀伤力的确对他们造成了很大的伤害，所以他们戴帽子的人不在少数。 说完了男人说女人，英国的女人不秃，头发茂密的很，而且他们还特别抗冷！零度左右的天气，我看到很多穿着破洞牛仔裤的女性，甚至还有穿短袖的，在大街上走来走去。至于什么“发热御寒丝袜”在英国都没得卖。这种抗冷属性应该算是他们的种族天赋。 顺便插一句题外话，伦敦街头的抗议行动我们看到了三处，第一处是大英博物馆门口有法轮功的静坐和散发传单；第二处是在摄政街的动物保护组织抗议“加拿大鹅”店残杀郊狼扒毛；第三处也是摄政街，有5个左右的伊斯兰人手持经书控诉美国政府。这里面让我印象比较深的是动物保护组织，他们堵着加拿大鹅的门店喊口号，但是抗议归抗议，并没有进去打砸，而且店里依旧有客人在购买，可以说除了闹一点之外都比较和谐。 伦敦的吃有人说伦敦的美食很少，因为英国人本身对于吃的想象力特别匮乏；也有人说伦敦的美食很多，因为它是地球上米其林餐厅最多的城市。其实这两个对立的说法都对，英国人自身对吃仅仅定义为“填饱肚子的行为”而已，所以纵然电视里的美食节目不少，但是英国本土并没有什么饮食文化而言。如果肯舍得钱下馆子的话，那么伦敦还是有很多上佳口味的饭店供人选择。 我在这几天在伦敦吃到了如下几种菜：牛排（网红店Flat Iron Steak和Bill’s）、龙虾（网红店Burger &amp; Lobster）、披萨（网红店Pane Cunzato）、中国菜（唐人街的金龙轩）、麦当劳、烤鸡（网红店Nando’s）、日料（超赞而且实惠的Eat Tokyo），反倒是鼎鼎大名的“炸鱼薯条”却只是看而没有吃。总体上来说，原味的欧洲菜跟亚洲口味的确有很大的不同，首先是每餐必有薯条（我个人喜欢薯条搭配蛋黄酱吃），其次各种酱汁种类很多，味道七七八八，再其次就是肉蛮好吃的，但是水果基本没有。当然我去的店相对平民，如果去米其林餐厅肯定会吃到高档的菜肴。 上面说了那么多饭里，我个人最喜欢的还是中国菜—-金龙轩的福建炒饭，蟹肉芡勾的很棒，而且分量十足！ 伦敦的买从行程规划里可以看到，我跟我媳妇准备了大量买买买的时间，因为圣诞节之后，就是会持续十天左右的Boxing Day。在此期间，几乎所有的商品都会让利，新品可能折扣少一点，部分老款甚至会打五折乃至更低！ 作为二次元的拥趸，Forbidden Planet是绝对不能错过的书店！它在大英博物馆附近，一楼是各种周边，地下室是书籍出售。在里面我买了两个蝙蝠侠周边。那里的日漫也很多，《暗杀教室》两本只需要三磅，划算的很！ 若要正经购物的话，伦敦也有很多去处。我跟媳妇先去了考文特花园，那里能买到很多好玩又精美的小玩意，比如银制的勺子和挂链，甚至还有潘海立根。摄政街跟哈罗德百货更是购物的火拼集中地，附近的商铺应该有100家，消费群体主要是中东人和亚洲人。白人和黑人更多的是聚集在像JD那种体育用品专卖店买鞋。至于为什么高端店被外国人包围，我想因为英国本身福利比较给力，所以土著平民都没有攒钱的意识，过着“今朝有酒今朝醉”的月光生活，自然也不会拿出那么多钱来买奢侈品。 大名鼎鼎比斯特小镇我俩没有去，因为那个地方在这种打折季肯定人满为患，事实也印证了我俩的预测。 不过英国的退税跟日本的不同，日本是在商家处直接退税，而英国是要在指定地点退税或者机场退税。机场退税有两条路，一条是去直接退英镑，但是排队非常夸张，大约要排4小时左右；还有一条就是直接退本国的货币，需要收取不俗的手续费而且兑换的汇率也很低，所以英国的退税政策其实并不友好。 伦敦文化几天接触下来，只管感觉到伦敦是一个“传统与现代”并存的城市。说它现代，就是各种高大上的各路品牌、宝马奔驰在马路上驰骋、超市基本都实现了无人结账而且几乎各处都配有免费wifi（最良心的是注册wifi只填写电子邮件，而根本不需要填写手机号，这一点跟国内众多注册很不一样！）；说它传统呢，就是普通居民建筑还保留传统英式风格，大大小小的教堂无论年代目前都在服务，特殊地方还有骑马巡警。景点里那些百年以上的软文化都妥善保存，景点外伦敦人喜欢看戏剧的习惯流传至今。这种“新与旧”和谐共存最明显的体现就是在温莎城堡，女王家虽然面积远不如故宫那么大，但是论奢华一点不虚我们。 不过，伦敦公共设施维护的普遍都不咋地，最让人吐槽的就是以下几点：垃圾箱很少导致街边烟头满地，非居民区垃圾袋随处可见，喝剩的纸杯也随意放在路边橱窗上，地铁没信号不说而且椅套看上去都旧旧的。据我媳妇在伦敦的朋友说，伦敦居民区的环卫工人每周三才会出来清理一次街道的垃圾袋，所以平时都是把垃圾袋放在家里，到了周三才一并拿出去扔掉，如果平时乱扔会被罚很重的款。 伦敦看球到了伦敦怎能不现场观看英超比赛？伦敦是著名的“足球之城”，当地就有6支英超联赛球队（切尔西、热刺、阿森纳、西汉姆、富勒姆、水晶宫），但是圣诞节期间主场作战的只有热刺一家，于是我在StubHub上买了两张热刺VS伯恩茅斯的门票。不过我真的不推荐各位去StubHub上买票，手续费高不说，而且出票速度奇慢，我是11月30日下单，12月21号才通知可以下载球票电子档，中途还不能退票。主要是StubHub毕竟是卖2手票的，只有有人卖才会出单通知你，所以还是在官网买票是最省心最效率的，但是要提前注册会员。 到了温布利下车一出门就能看到温布利球场，路上都是卖热刺队围巾的小贩，5磅一条。到了球场，首先对背包大小有要求，包不能大于4A纸的面积，否则就是要花10磅寄存。进场的时候要求安检并且把饮料瓶盖扔掉，在机器上扫描电子票的二维码入场，不检查实名制。 进了球场就是要狂躁起来，那场比赛热刺队也很给力，5：0痛击伯恩茅斯，孙球王梅开二度，我身后手持太极旗的韩国妹子们兴奋不已。热刺的球迷很热情，每个球员有了上佳表现，球迷都会唱歌，从穆萨登贝莱唱到哈里凯恩。出场之后，意犹未尽的我还跟温布利球场的雕像们一一合影。如果将来有一次能去巴塞罗那，肯定也会去诺坎普朝圣一下。 其他轶事倒时差的小秘诀：静下心来或者把自己弄疲惫，该睡觉的时候一定要正常睡觉，哪怕只有几个小时。 都说英国不准许肉类入境，但是我媳妇带的鸭脖子、鸡爪子在行李箱里就大摇大摆的登陆了。 伦敦地铁没有安检，Paddington火车车厢里也压根没有检票。 伦敦的热水非常方便，而且他们的自来水是可以直接饮用的，如果不能饮用的话会有提示。 伦敦普通居民区的门锁完全不是国内常见的“防盗门+防盗锁”，而是很老式的“木门+插钥匙锁”，所以那些特工电影里一脚破门的镜头果然不是在骗人… 伦敦市区电子屏幕上铺天盖地的是“抖音”海外版app的广告，而华为的广告只有商场里才有，但是我并没有发现卖华为手机的地方… 这八天里唯一看到的中国公众人物是杨幂，在杜莎夫人蜡像馆里(其实还有达赖喇嘛的蜡像，但是他毕竟自建流亡政府，就不能算中国人了)。她周围很冷清，跟布拉德皮特、约翰尼德普、乔治克鲁尼等人气大户完全没法比。 伦敦黑人很多，我看见不少的黑人喜欢把裤裆穿的很低，然后漏出来半截内裤甚至是屁股（囧），不知道这是不是他们的什么衣着文化… 其他小tips 大英博物馆的语音向导是有数的，请提早去拿； 杜莎夫人蜡像馆和伦敦眼可以买连票，价钱优惠而且都有快速通行权限； 圣诞期间碎片大厦晚上10点才关门，所以如果看不到日落那就干脆不用急了； London Pass卡的游船晚上5点05就停业了； London Pass卡支持两种大巴车，我个人推荐Golden Tours，虽然它的APP可能做得不太好，但是营业时间长，至少晚上9点我还看到车在马路上跑，而BIG BUS六点多就休息了； 准备的APP：航旅纵横+CityMapper+TripAdvisor； 一定要带伞！虽然伦敦各个小店都有卖伞，但是基本10磅一把，价格还是蛮贵的； 自带拖鞋、牙刷、毛巾等用品，还有插销转换头； 伦敦行李寄存地点不多，而且价格不菲，8磅一个箱子，当然啦，土豪可以无视此条；","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"旅游","slug":"旅游","permalink":"http://yoursite.com/tags/旅游/"},{"name":"伦敦","slug":"伦敦","permalink":"http://yoursite.com/tags/伦敦/"}]},{"title":"Django实现文件上传功能","slug":"Django实现图片上传","date":"2018-12-19T06:42:26.000Z","updated":"2018-12-20T05:47:50.000Z","comments":true,"path":"2018/12/19/Django实现图片上传/","link":"","permalink":"http://yoursite.com/2018/12/19/Django实现图片上传/","excerpt":"","text":"准备工作python：3.6.5Django：2.1.1执行pip install pillow，安装python图片处理库pillow 图片单张上传首先先修改一下setting.py，添加如下两行代码： 12MEDIA_URL = '/media/'MEDIA_ROOT = os.path.join(BASE_DIR, 'media').replace('\\\\', '/') #media即为图片上传的根路径 保存之后，在项目根目录即manage.py同级目录里创建media这个文件夹。然后编辑models.py，内容如下： 1234from django.db import modelsclass Img(models.Model): img_url = models.ImageField(upload_to='photos/',blank=True,null=True) #指定图片上传路径，即media/photos/ 保存之后执行一下python manage.py makemigrations和python manage.py migrate，建立项目与数据库之间的关系。 增加urls.py的内容如下： 123456from django.urls import pathfrom . import viewsurlpatterns = [ path(r'uploadImg/',views.uploadImg,name='uploadImg'),] 增加views.py的内容如下： 123456789其他内容略from .models import Img#图片上传def uploadImg(request): if request.method == 'POST': img = Img(img_url=request.FILES.get('img')) img.save() return render(request, 'imgUpload.html') 最后就是写一个前端页面imgUpload.html: 1234567891011121314 &lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;图片上传&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action=&quot;&quot; method=&quot;post&quot; enctype=&quot;multipart/form-data&quot;&gt; &#123;% csrf_token %&#125; &lt;input type=&quot;file&quot; name=&quot;img&quot;&gt; &lt;input type=&quot;submit&quot; value=&quot;上传&quot;&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 启动django，打开imgUpload.html就可以看到界面，并且上传图片了，效果如图（我这个前端是加工过的，不是上面的代码）： 然后在django项目目录里的media/photos路径里找到我们刚刚上传的test333.png，而且在数据库里也能看到这条记录，如下： 图片批量上传不过在现实工作中，图片批量上传的应用场景更为普遍，如果是批量上传的话，我们尝试一个全新而且更简单粗暴的方法。 首先先修改前端页面imgUpload.html，把&lt;input type=&quot;file&quot; name=&quot;img&quot;&gt;改成&lt;input type=&quot;file&quot; name=&quot;img&quot; multiple=&quot;&quot;&gt;，就这一处而已，其他都不动。 然后就是修改views.py，如下： 123456789 #图片上传def uploadImg(request): files = request.FILES.getlist('img') for f in files: destination = open('/tmp/' + f.name,'wb+') #上传的文件都放到/tmp文件夹里 for chunk in f.chunks(): destination.write(chunk) destination.close() return render(request, 'imgUpload.html') 可以看出，这次views.py在执行uploadImg已经完全脱离img数据库和media路径了，就是一个非常单纯的图片上传功能。效果如图： 此时去/tmp里检查文件是否成功传上来： 可见已经成功的一次性传上来三个文件到目标文件夹了。 使用阿里云云存储的API上传文件阿里云云存储上传文件的脚本如下： 1234567891011121314# -*- coding: utf-8 -*-#需要先执行pip install oss2import oss2,ospath = \"图片所在文件夹的绝对路径\"files = os.listdir(path) #得到文件夹下的所有文件名称#鉴权auth = oss2.Auth('这里是AK', '这里是SK')bucket = oss2.Bucket(auth, 'http://oss-cn-hangzhou.aliyuncs.com', '目标BUCKET名称')for i in files: bucket.put_object_from_file('路径/'+i, path+i) print (\"上传成功！\"+i+\"的url地址是：https://lechangebbs.oss-cn-hangzhou.aliyuncs.com/jjfjj/\"+i) print (\"\\n\" * 2) #空两行 执行效果如下： 通过搭配这个脚本写到views.py里就可以把上传上来的图片转到阿里云云存储里去了！ PS，阿里云OSS有官方支持django的模块：django-aliyun-oss2-storage（果然够牛逼！），直接pip安装即可，如何使用待我研究一番先。 参考资料https://jinfagang.gitlab.io/2017/11/27/Django%E5%90%8C%E6%97%B6%E4%B8%8A%E4%BC%A0%E5%A4%9A%E5%BC%A0%E5%9B%BE%E7%89%87%E6%88%96%E6%96%87%E4%BB%B6/https://blog.csdn.net/c_beautiful/article/details/79755368https://www.jianshu.com/p/3c79b19849f5https://blog.csdn.net/u014633966/article/details/78727034https://abersheeran.com/articles/Django-MutliImageFormSet/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"使用ZABBIX自带模板去监控Mysql","slug":"使用ZABBIX自带模板去监控Mysql","date":"2018-12-18T06:17:45.000Z","updated":"2018-12-18T12:09:30.000Z","comments":true,"path":"2018/12/18/使用ZABBIX自带模板去监控Mysql/","link":"","permalink":"http://yoursite.com/2018/12/18/使用ZABBIX自带模板去监控Mysql/","excerpt":"","text":"事前准备Zabbix-agent:3.0.8，安装路径是/etc/zabbix/Mysql:5.7.10，安装路径是/opt/mysql/配置/etc/sudoers让zabbix用户可以使用sudo，如下： 1234## Allow root to run any commands anywhereroot ALL=(ALL) ALLzabbix ALL=(ALL) NOPASSWD:ALLDefaults:zabbix !requiretty 配置.my.cnf众所周知，Zabbix官方提供了自带监控Mysql的模板，但是这个模板并不能直接使用。所以我们需要有如下的改动： 首先，先在mysql目录下的etc文件夹里先创建一个.my.cnf文件，全路径是/opt/mysql/etc/.my.cnf，这个文件是zabbix要求的用于存放连接mysql数据库的账户信息的隐藏文件，这样可以避免在命令行里输入密码。整个.my.cnf文件内容如下： 1234567891011[mysql] #mysql程序要使用的账户信息host=localhostuser=用户名password=&quot;密码&quot; #此处的密码强烈建议加上引号socket=/tmp/mysql.sock #确认mysql的sock文件路径[mysqladmin] #mysqladmin程序要使用的账户信息host=localhostuser=用户名password=&quot;密码&quot;socket=/tmp/mysql.sock 这里建议在mysql里插入一个叫zabbix的用户，密码自己设定，然后在.my.cnf里就是用这个用户即可。此时，在命令行直接输入HOME=/opt/mysql/etc/ mysql和HOME=/opt/mysql/etc/ mysqladmin ping都应该是直接出结果，而不是用输入账号和密码，如图： 注意!这个.my.cnf的权限是644，用户和用户组是root，如果权限过大，那么启动mysql时就会报错：Warning: World-writable config file &#39;/opt/mysql/etc/.my.cnf&#39; is ignored。 修改userparameter_mysql.conf然后在zabbix-agent配置文件的文件夹/etc/zabbix/zabbix_agentd.d/里，会发现一个叫userparameter_mysql.conf的文件，把里面的内容改成如下样子: 1234567# For all the following commands HOME should be set to the directory that has .my.cnf file with password information.# Flexible parameter to grab global variables. On the frontend side, use keys like mysql.status[Com_insert].# Key syntax is mysql.status[variable].UserParameter=mysql.status[*],echo \"show global status where Variable_name='$1';\" | sudo HOME=/opt/mysql/etc /opt/mysql/bin/mysql -N | awk '&#123;print $$2&#125;'UserParameter=mysql.ping,sudo HOME=/opt/mysql/etc/ /opt/mysql/bin/mysqladmin ping | grep -c aliveUserParameter=mysql.version,/opt/mysql/bin/mysql -V 这个文件第一行注释的内容就是说明HOME路径就是.my.cnf文件所在的路径，后面的mysql和mysqladmin都要用绝对路径，同时加上sudo，这样zabbix才能正确的调用它。 来到zabbix-server端使用zabbix-get去试试结果： 然后就是在zabbix网页端将目标机器添加Template DB MySQL，至此，使用zabbix自带的mysql监控模板监控mysql数据库就结束了，效果如下： 监控连接数上面那个模板是不带有监控连接数的，要是单纯的去使用netstat获取当前链接值可能会反应较慢，那么就是用mysql自带的查连接数的命令：show status like &#39;%connect%&#39;;，执行效果如下： 简单说下这几个值的含义： Connections：试图连接到（不管是否成功）MYSQL服务器的连接总数 Locked_connects：锁住的链接数 Max_used_connections：服务器启动后已经同时使用过的连接最大数量（并发） Max_used_connections_time：出现Max_used_connections时的时间 Aborted_connects：尝试连接到MySQL服务器失败的次数 Threads_connected：当前的连接数 那么知道了含义，我们就可以对症下药了，这里我们监控两个数值Locked_connects和Threads_connected，那么就把下面的语句添加到userparameter_mysql.conf里： 123UserParameter=mysql.connections,echo \"show status like '%Threads_connected%';\" | sudo HOME=/opt/mysql/etc /opt/mysql/bin/mysql -N | awk '&#123;print $2&#125;'UserParameter=mysql.lockconnections,echo \"show status like '%Locked_connects%';\" | sudo HOME=/opt/mysql/etc /opt/mysql/bin/mysql -N | awk '&#123;print $2&#125;'UserParameter=mysql.rowofalarm,echo \"select count(*) from alarm.adm_log_alarm;\" | sudo HOME=/opt/mysql/etc /opt/mysql/bin/mysql -N | awk '&#123;print $1&#125;' #这个是检测alarm.adm_log_alarm的数据行数 重启zabbix-agent，配置对应的items和trigger即可。 额外补充一下，查看mysql数据库对应每个IP的详细链接情况的语句是： 1select substring_index(host,':',1) as ip , count(*) from information_schema.processlist group by ip; 效果如下： 参考资料https://github.com/erasin/notes/blob/master/linux/mysql/monitor.md （其他mysql状态监控语句）http://www.cnblogs.com/kerrycode/p/9206787.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Zabbix","slug":"Zabbix","permalink":"http://yoursite.com/tags/Zabbix/"}]},{"title":"将list重新排列后获取原来的索引","slug":"将list重新排列后获取原来的索引","date":"2018-12-14T06:02:42.000Z","updated":"2018-12-14T07:22:32.000Z","comments":true,"path":"2018/12/14/将list重新排列后获取原来的索引/","link":"","permalink":"http://yoursite.com/2018/12/14/将list重新排列后获取原来的索引/","excerpt":"","text":"具体需求与解决方案假设我们有一个列表，现在要对列表里进行从大到小排序，然后再获取列表里原来各位元素的索引，怎么办？ 12#Python2.7new_list = sorted(enumerate(old_list),key=lambda x: x[1],reverse=True) #old_list就是原列表 举一个详细一点的例子： 可见原来aaa这个列表的元素虽然经过了大小排序，但是各元素的索引下标没有丢，而且通过zip（）方法能拆出来供我们继续使用。 enumerate() 函数这个enumerate()函数可以将一个可遍历的数据对象组合一个索引序列，同时列出数据和数据下标，默认情况下标是从0开始的，也可以手动更改，比如： 12345&gt;&gt;&gt;seasons = ['Spring', 'Summer', 'Fall', 'Winter']&gt;&gt;&gt; list(enumerate(seasons))[(0, 'Spring'), (1, 'Summer'), (2, 'Fall'), (3, 'Winter')]&gt;&gt;&gt; list(enumerate(seasons, start=1)) # 下标从 1 开始[(1, 'Spring'), (2, 'Summer'), (3, 'Fall'), (4, 'Winter')] 有了它，我们就可以轻松获取索引下标值了。 sorted(key=lambda)sorted（）是用来排列列表的函数，默认情况下是从小到大排列。如果列表里是每一个元素并不是单纯的一个数字，而是多字段，那么就要规定以哪一个字段作为标准来排列，这个这顶标准就是key。 举个例子： 123456&gt;&gt;&gt; listA = [3, 6, 1, 0, 10, 8, 9] #这个列表就是单字段，排序就是单纯按照数字大小排序&gt;&gt;&gt; print(sorted(listA))[0, 1, 3, 6, 8, 9, 10]&gt;&gt;&gt; listC=[('e', 4), ('o', 2), ('!', 5), ('v', 3), ('l', 1)] #这个列表是多字段&gt;&gt;&gt; print(sorted(listC, key=lambda x: x[1])) #指定按照多字段里第二个元素，即数字的大小进行排序[('l', 1), ('o', 2), ('v', 3), ('e', 4), ('!', 5)] x:x[]字母可以随意修改，排序方式按照中括号[]里面的维度进行排序，[0]按照第一维排序，[2]按照第三维排序 参考资料https://stackoverflow.com/questions/7851077/how-to-return-index-of-a-sorted-listhttps://stackoverflow.com/questions/16310015/what-does-this-mean-key-lambda-x-x1https://blog.csdn.net/u010758410/article/details/79737498","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"enumerate","slug":"enumerate","permalink":"http://yoursite.com/tags/enumerate/"},{"name":"列表加工","slug":"列表加工","permalink":"http://yoursite.com/tags/列表加工/"}]},{"title":"Django前端输入变量通过内部脚本加工返回前端展示之八","slug":"从checkbox里得到传入值","date":"2018-12-10T12:25:59.000Z","updated":"2018-12-13T01:48:16.000Z","comments":true,"path":"2018/12/10/从checkbox里得到传入值/","link":"","permalink":"http://yoursite.com/2018/12/10/从checkbox里得到传入值/","excerpt":"","text":"背景说明python：3.6.5Django：2.1.1Project：Kubernetes，文件夹路径就是/django/Kubernetes/App：createyaml，文件夹路径就是/django/Kubernetes/createyaml前文地址：https://rorschachchan.github.io/2018/12/04/Django%E5%88%B6%E4%BD%9C%E4%B8%80%E4%B8%AA%E5%AF%86%E7%A0%81%E7%94%9F%E6%88%90%E5%99%A8/ 需求说明以及实现思路之前在Django实现了输入文本然后通过ajax传递参数到后端执行脚本并且返回结果的效果。这一次要实现的是“多选框选中对应的选项然后提示确认，最后给后台执行命令”。 多选框在实际的页面里很常见，这一次要实现的效果如图： 要想在django的views.py里获取到checkbox的选择项，如果用表单方法很简单，只要request.POST.getlist就好，我尝试去用ajax去获取，但是得到的data是空值。可能是我道行不够，不过从代码简洁的角度来说还是更推荐用django的方法。 为了用户体验友好，我们一般都会在页面提交的时候加上提示的对话框，让用户再三确认。这样就要把form表单和confirm()对话框一起用，但是有一个现象要注意：如果把&lt;form&gt;标签写到&lt;button type=&quot;submit&quot;&gt;下面的话，comfirm()时点击了“取消”，return false是会生效的，即停留在本页，但是form表单是无法正常传递到目的地；如果把&lt;form&gt;标签写到&lt;button type=&quot;submit&quot;&gt;上面，现在表单可以正常传递了，但是“取消”功能又不生效了—即使点击取消依旧会跳转到表单的目标地。 这种现象产生的原因是：如果函数是包含在form的submit中的话，当点击按钮的时候，在弹出confirm()对话框之前，有很多的js需要执行的，而大家都知道在点击按钮的时候，表单会自动提交的；所以就没有等到用户点击“取消”按钮，form表单已经提交了，自然就不会管你有没有点击”取消”了。 解决方法：只要在按钮的onclick()事件的方法前面加一个return就ok了，这样肯定会先等返回结果在提交表单了，例如： 1&lt;input type=\"button\" value=\"请点击我！\" onclick=\"return method()\"&gt; 具体代码ecs_list.html的body部分: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;h1 style=\"text-align:center;\"&gt;数据库里的ECS数据展示&lt;/h1&gt; &lt;script&gt; function ecs_deploy() &#123; var name=prompt(\"请输入要执行的命令：1&gt;测试连通；2&gt;部署模块并启动；\",\"1\"); //添加一个输入框 var userids = []; //配置一个空集 $(\"input:checkbox[name = ecs]:checked\").each(function(i)&#123; //使用循环遍历迭代的方式得到所有被选中的checkbox复选框 console.log($(this).val()); userids.push( $(this).val() ); //当前被选中checkbox背后对应的值 &#125;) if(confirm(\"你确定要对\"+userids+\"进行\"+name+\"操作？\")) //让用户再次确认 &#123; location.href=\"&#123;% url \"run_command\" %&#125;\"; &#125; else &#123; return false; //停留在本页，没有操作 &#125; &#125; &lt;/script&gt; &lt;div align=\"left\" style=\"float:left\"&gt; &lt;a href=\"&#123;% url \"create_ecs\" %&#125;\"&gt;&lt;button type=\"button\" class=\"btn btn-default\"&gt;返回录入界面&lt;/button&gt;&lt;/a&gt; &lt;/div&gt; &lt;form action=\"/k8s/run_command/\" method=\"POST\"&gt; &lt;div align=\"right\" style=\"float:left\"&gt; &lt;button type=\"submit\" class=\"btn btn-default\" onclick=\"return ecs_deploy()\" /&gt;选择服务器&lt;/button&gt; //这里添加了return &lt;/div&gt; &lt;table width=\"100%\" border=\"1\"&gt; &lt;thead&gt; &lt;br&gt; &lt;form&gt; &lt;tr&gt; &lt;td align=\"center\"&gt;序号&lt;/td&gt; &lt;td align=\"center\"&gt;云服务器名称&lt;/td&gt; &lt;td align=\"center\"&gt;云服务器ID&lt;/td&gt; &lt;td align=\"center\"&gt;内网地址&lt;/td&gt; &lt;td align=\"center\"&gt;外网地址&lt;/td&gt; &lt;td align=\"center\"&gt;操作系统&lt;/td&gt; &lt;td align=\"center\"&gt;网络类型&lt;/td&gt; &lt;td align=\"center\"&gt;CPU&lt;/td&gt; &lt;td align=\"center\"&gt;内存&lt;/td&gt; &lt;td align=\"center\"&gt;外网带宽&lt;/td&gt; &lt;td align=\"center\"&gt;备注&lt;/td&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &#123;% for ecs in ecss %&#125; &lt;tr&gt; &lt;td&gt;&lt;input type=\"checkbox\" value=&#123;&#123;ecs.name&#125;&#125; name=\"ecs\"/&gt;&#123;&#123; ecs.id &#125;&#125; &lt;/td&gt; &lt;td align=\"center\"&gt;&#123;&#123; ecs.name &#125;&#125; &lt;/td&gt; &lt;td align=\"center\"&gt;&#123;&#123; ecs.ecsid &#125;&#125;&lt;/td&gt; &lt;td align=\"center\"&gt;&#123;&#123; ecs.inIP &#125;&#125;&lt;/td&gt; &lt;td align=\"center\"&gt;&#123;&#123; ecs.outIP &#125;&#125;&lt;/td&gt; &lt;td align=\"center\"&gt;&#123;&#123; ecs.osname &#125;&#125;&lt;/td&gt; &lt;td align=\"center\"&gt;&#123;&#123; ecs.networktype &#125;&#125;&lt;/td&gt; &lt;td align=\"center\"&gt;&#123;&#123; ecs.CPU &#125;&#125;&lt;/td&gt; &lt;td align=\"center\"&gt;&#123;&#123; ecs.memory &#125;&#125;&lt;/td&gt; &lt;td align=\"center\"&gt;&#123;&#123; ecs.netwidth &#125;&#125;&lt;/td&gt; &lt;td align=\"center\"&gt;&#123;&#123; ecs.remark &#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;% endfor %&#125; &lt;/tbody&gt; &lt;/table&gt; &lt;/form&gt; views.py相关部分如下: 1234567@csrf_exemptdef run_command(request): if request.method == 'POST': id = request.POST.getlist(\"ecs\") return HttpResponse(id) else: pass urls.py相关部分如下： 1path(r'run_command/',views.run_command), 启动django后，在ecs_list.html页面如动图点击要操作的选项提交即可看到效果，再配上后台数据库查询+ansible的辅助，我们就可以完成一个运维平台的部署功能啦！ 点击页面直接选取上面说的是复选框选取，如果需要直接点击就能得到值的话，那么就要用click函数搭配this来实现该效果，举个例子： 1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;body&gt; &lt;script src=\"https://ajax.googleapis.com/ajax/libs/jquery/1.8.3/jquery.min.js\"&gt;&lt;/script&gt; &lt;script type=\"text/javascript\"&gt; $(document).ready(function()&#123; $(\"p\").click(function()&#123; //触发一个点击的函数，点击标签范围是p alert($(this).html()); //this的用途就是获取当前的元素 &#125;); &#125;); &lt;/script&gt; &lt;body&gt; &lt;p&gt;这是第一个段落。&lt;/p&gt; &lt;p&gt;这是第二个段落。&lt;/p&gt; &lt;p&gt;这是第三个段落。&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; 页面效果如图： 参考资料https://stackoverflow.com/questions/4359238/how-do-i-get-multiple-values-from-checkboxes-in-djangohttps://stackoverflow.com/questions/14460421/get-the-contents-of-a-table-row-with-a-button-clickhttps://blog.csdn.net/stpeace/article/details/50816128http://www.runoob.com/js/js-popup.htmlhttps://blog.csdn.net/qq_36769100/article/details/79173476https://blog.csdn.net/qq_24018243/article/details/52316949https://bbs.csdn.net/topics/320062312","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Django","slug":"Django","permalink":"http://yoursite.com/tags/Django/"},{"name":"checkbox","slug":"checkbox","permalink":"http://yoursite.com/tags/checkbox/"}]},{"title":"Github如何删除掉一个commit","slug":"Github如何删除掉一个commit","date":"2018-12-06T06:58:33.000Z","updated":"2018-12-06T14:34:28.000Z","comments":true,"path":"2018/12/06/Github如何删除掉一个commit/","link":"","permalink":"http://yoursite.com/2018/12/06/Github如何删除掉一个commit/","excerpt":"","text":"写完了一个脚本，里面使用了阿里云的api，那自然也有公司的阿里云ak\\sk，在调试的时候发现没问题，于是就上传到github上。传完之后一看，发现脚本里忘了删除敏感字段，连通公司的ak\\sk一起被提交上去了… 卧槽，这还得了？要是这个commit被人发现并且拷贝走了，岂不是得到了公司的ak\\sk，后果不堪设想啊。但是如何在github远端删除掉一个commit呢？ 先记录下这次commit之前一次正常的版本号，查询版本号也可以通过命令git log -5（查询最近5次提交历史）： 得到上一次的版本号是051ebceaedd6b64801aada354f921d6ea7ef0622，然后git reset --hard 051ebceaedd6b64801aada354f921d6ea7ef0622。 然后再git push origin HEAD --force即可。整个过程如下： 此时再去github上刷新commit的历史页面，发现记录已经回滚到051ebce（版本号前面7位）了，如图： 但是要注意！如果你的代码是两个地方在上传github，比如含敏感词汇的文件是通过windows客户端上传的，但是你在某个linux服务器上进行了删除commit的操作，那么如果windows继续commit的话，是会再次提交所有的commit的(含带有机密字段的commit)，所以要把源头也就是windows里的commit也要用这个方法干掉，这样才算彻底删除。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Github","slug":"Github","permalink":"http://yoursite.com/tags/Github/"}]},{"title":"Django前端输入变量通过内部脚本加工返回前端展示之七","slug":"Django制作一个密码生成器","date":"2018-12-04T06:23:03.000Z","updated":"2018-12-05T02:53:52.000Z","comments":true,"path":"2018/12/04/Django制作一个密码生成器/","link":"","permalink":"http://yoursite.com/2018/12/04/Django制作一个密码生成器/","excerpt":"","text":"背景说明python：3.6.5Django：2.1.1Project：Kubernetes，文件夹路径就是/django/Kubernetes/App：createyaml，文件夹路径就是/django/Kubernetes/createyaml前文地址：https://rorschachchan.github.io/2018/12/03/%E9%A1%B5%E9%9D%A2%E5%B1%80%E9%83%A8%E5%88%B7%E6%96%B0%E5%BE%97%E5%88%B0AES%E5%8A%A0%E5%AF%86%E5%80%BC/ secrets模块这个secrets模块是Python 3.6才有的模块，在说它之前，先看一下string.ascii_letters和string.digits，其中ascii_letters是生成所有字母，即a-z和A-Z,而digits是生成所有数字，即0-9,如下： 那么他俩搭配secrets模块就可以生成密码，代码如下： 12345678&gt;&gt;&gt; import secrets,string&gt;&gt;&gt; characters = string.ascii_letters + string.digits + \"!@#$%^&amp;*()&#123;&#125;[]~\" #加入特殊符号&gt;&gt;&gt; password = ''.join(secrets.choice(characters) for i in range(20)) #生成一个20位的随机字符串&gt;&gt;&gt; password'a%45BW5bxFlN3ylr!!IE'&gt;&gt;&gt; password = ''.join(secrets.choice(characters) for i in range(10)) #生成一个10位的随机字符串&gt;&gt;&gt; password')vqRWYxgxs' 看上去secrets.choice和random.choice的效果差不多，但是还是有差别的。因为random模块的官方文档清楚的写着该模块完全不适合用作数据加密，而secrets模块不但可以生成安全随机数还可以生成一个笃定长度的随机字符串—-可用作令牌和安全URL。 所以与random模块中的默认伪随机数生成器相比，我们应该优先使用secrets模块！ 后台检验输入值合法之前的文章，曾经写过在django的views.py里判断输入值是否为空的方法，地址是https://rorschachchan.github.io/2018/09/26/Django%E4%BD%BF%E7%94%A8form%E8%A1%A8%E5%8D%95%E5%88%A4%E6%96%AD%E8%BE%93%E5%85%A5%E5%80%BC%E6%98%AF%E5%90%A6%E5%90%88%E6%B3%95/ ，但是那套方法毕竟还太粗糙。这一次我们可以通过jQuery+Ajax获取到值，然后进行一个具体的判断，看一下这个值是否是数字，如果不是数字就直接在页面提示“输入非法”，如果是数字，就不会提示。 思路就是先获取到前端传来的值，然后在views.py里增加一个定义，如果值满足定义，就不会有动静，如果值不满足，那么就局部刷新一个页面。 具体代码路由文件urls.py部分如下： 123开头略 path(r'mkpasswd/',views.make_passwd,name='mkpasswd'), path(r'get_mkpasswd/',views.get_passwd,name='get_passwd'), 配置文件views.py相关部分如下： 12345678910111213141516171819开头略from django.views.decorators.csrf import csrf_exemptimport secrets,stringdef make_passwd(request): return render(request,'mkpasswd.html')@csrf_exemptdef get_passwd(request): characters = string.ascii_letters + string.digits + \"!@#$%^&amp;*()~[]&#123;&#125;=+\" if request.method == 'POST': num = request.POST.get('number',20) #这里得到的是str格式 if str.isdigit(num) is False: #判断是否是数字 return HttpResponse(\"输入值不合法！必须是数字！\") else: result = ''.join(secrets.choice(characters) for i in range(int(num))) return HttpResponse(result) else: pass 前端页面mkpasswd.html如下： 1234567891011121314151617181920212223242526&#123;% extends 'base.html' %&#125;&#123;% block title %&#125; 创建密码&#123;% endblock %&#125;&#123;% block content %&#125; &#123;% csrf_token %&#125; &lt;h2&gt;创建密码&lt;/h2&gt; &lt;h3&gt;默认密码是20位，并且带有特殊符号&lt;/h3&gt; 密码长度：&lt;input type=\"text\" id=\"number\" /&gt;&lt;br /&gt; &lt;button&gt;生成密码&lt;/button&gt; &lt;div id=\"ask\"&gt;&lt;h2&gt;&lt;/h2&gt;&lt;/div&gt; &lt;script&gt; $(document).ready(function()&#123; $(\"button\").click(function()&#123; var word=document.getElementById('number').value //获取输入框的值 $.ajax(&#123; type:\"POST\", url:\"&#123;% url \"get_passwd\" %&#125;\", data:&#123;number:word&#125;, //传递参数 success:function(result)&#123;$(\"#ask\").html(result);&#125; &#125;); &#125;); &#125;); &lt;/script&gt;&#123;% endblock %&#125; 最后整个的过程执行效果如下： 前端检验输入值合法俗话说得好，人生不折腾不舒服斯基。为了更好的体验，现在改一下方略：在用户输入的时候，页面要随时的判断输入值，有错误就直接提醒，这样就不用在提交的时候才告诉用户“输入值非法”了，但是这样的需求就需要更改判断逻辑—-把判断的任务交给jQuery而不是后台，jQuery判断成功了，再把值提交到后台。 要在输入的时候随时判断，那么就要使用jQuery的keydown功能，然后再配上each功能进行遍历。each的用法是$(selector).each(function(index,element))，这里index是选择器的index位置,而element是当前的元素，这两个元素都是必须的！ 那么只需要更改的是mkpasswd.html，内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041&#123;% block content %&#125; &#123;% csrf_token %&#125; &lt;h2 style=\"text-align:center;\"&gt;创建密码&lt;/h2&gt;&#123;% endblock %&#125;&#123;% block content %&#125; &#123;% csrf_token %&#125; &lt;div style=\"text-align:center;\"&gt; &lt;h2&gt;创建密码&lt;/h2&gt; //增加了居中效果 &lt;h3&gt;默认密码是20位，并且带有特殊符号&lt;/h3&gt; &lt;div&gt;密码长度：&lt;input style=\"margin: 5px; padding: 10px;\" type=\"text\" id=\"number\" /&gt;&lt;br /&gt; //调整输入框的长宽 &lt;p style=\"color: red\" id=\"error\"&gt;&lt;/p&gt; //这里是警告出现的位置 &lt;button &gt;生成密码&lt;/button&gt; &lt;div id=\"ask\"&gt;&lt;h2&gt;&lt;/h2&gt;&lt;/div&gt; //这里是结果出现的位置 &lt;/div&gt; &lt;script&gt; $(document).ready(function()&#123; $(\"#number\").bind('keydown',function()&#123; //输入就开始检查 $('input').each(function(i,n)&#123; //进行遍历 var isnum = n.value.match(/^\\d+$/g); //匹配正则表达式，是否是数字 if(null != isnum)&#123; $(n).css('border','2px solid green'); //是数字，边框变为绿色 document.getElementById(\"error\").innerText=\"\"; &#125;else&#123; $(n).css('border','2px solid red'); //不是数字，边框变为红色作为警告 document.getElementById(\"error\").innerText=\"输入值必须是数字！\"; &#125; &#125;); &#125;); $(\"button\").click(function()&#123; //配置点击动作 var word=document.getElementById('number').value //获取输入框的值 $.ajax(&#123; type:\"POST\", url:\"&#123;% url \"get_passwd\" %&#125;\", data:&#123;number:word&#125;, //传递参数！！！！ success:function(result)&#123;$(\"#ask\").html(result);&#125; &#125;); &#125;); &#125;); &lt;/script&gt;&#123;% endblock %&#125; 整改之后的效果如下： 参考资料http://www.blog.pythonlibrary.org/2017/02/16/pythons-new-secrets-module/https://www.cnblogs.com/yyds/p/7072492.htmlhttp://qindongliang.iteye.com/blog/2147336https://segmentfault.com/q/1010000002760528","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"Jquery","slug":"Jquery","permalink":"http://yoursite.com/tags/Jquery/"},{"name":"Ajax","slug":"Ajax","permalink":"http://yoursite.com/tags/Ajax/"}]},{"title":"Django前端输入变量通过内部脚本加工返回前端展示之六","slug":"页面局部刷新得到AES加密值","date":"2018-12-03T02:08:14.000Z","updated":"2018-12-04T06:21:18.000Z","comments":true,"path":"2018/12/03/页面局部刷新得到AES加密值/","link":"","permalink":"http://yoursite.com/2018/12/03/页面局部刷新得到AES加密值/","excerpt":"","text":"背景说明python：3.6.5Django：2.1.1Project：Kubernetes，文件夹路径就是/django/Kubernetes/App：createyaml，文件夹路径就是/django/Kubernetes/createyaml前文地址：https://rorschachchan.github.io/2018/11/29/Django%E4%B8%8EJquery%E3%80%81Ajax%E7%9A%84%E8%81%94%E5%90%88%E8%BF%90%E7%94%A8/ 需求说明以及实现思路原来通过前端输入值到后台脚本执行结果再反回页面是这样的： 现在接触了jQuery+ajax，那么就可以使用局部刷新来让界面变的更加友好。 我们在页面里配置了ajax，也要在views.py里配置request.POST.get，但是要注意，执行顺序是先执行ajax后执行request.POST.get，也就是说request.POST.get得到的是ajax加工过的值。如果是json字符串，就加一个dataType:&#39;json&#39;说明一下。 如果是一般的form表单形式，那么ajax的data部分可以这么写： 12345678$.ajax(&#123; url: url, data: &#123; limit: 10 &#125;, type: 'post', dataType: 'json'&#125;), 如果是直接发送一个json字符串到服务器，那么就要这么写： 123456789$.ajax(&#123; url: url, data: JSON.stringify(&#123; limit: 10 &#125;), type: 'post', dataType: 'json', contentType: 'text/plain'&#125;), 更多的使用方法可以去https://www.haorooms.com/post/jquery_ajax_wg 观摩一番。 具体代码前端文件encrypt.html内容如下： 12345678910111213141516171819202122232425&#123;% extends 'base.html' %&#125; &#123;% block title %&#125; AES加密&#123;% endblock %&#125;&#123;% block content %&#125; &#123;% csrf_token %&#125; &lt;h2&gt;AES加密&lt;/h2&gt; //将原来的form都取消了 要加密的字段：&lt;input type=\"text\" id='word'&gt;&lt;br /&gt; &lt;button&gt;查询加密结果&lt;/button&gt; &lt;div id=\"ask\"&gt;&lt;h2&gt;这里是结果&lt;/h2&gt;&lt;/div&gt; //设定id=ask，那么下面也要说明ask的div是要被局部刷新的 &lt;script&gt; $(document).ready(function()&#123; $(\"button\").click(function()&#123; var keyword=document.getElementById('word').value //获取输入框的值，即name $.ajax(&#123; type:\"POST\", //指定方法是POST，如果不说明就是GET url:\"&#123;% url \"get_encrypt\" %&#125;\", //目标url就是get_encrypt函数结果 data:&#123;word:keyword&#125;, //规定name等于上面那个id，然后传递参数给django的views.py success:function(result)&#123;$(\"#ask\").html(result);&#125; //返回get_encrypt函数结果 &#125;); &#125;); &#125;); &lt;/script&gt;&#123;% endblock %&#125; urls.py对应的部分如下： 12path(r'encrypt/',views.encrypt,name='encrypt'),path(r'get_encrypt/',views.get_encrypt,name='get_encrypt'), #这个是展示结果对应的函数 views.py对应的部分如下： 123456789101112131415默认部分略from django.views.decorators.csrf import csrf_exemptimport subprocessdef encrypt(request): return render(request,'encrypt.html') #请求encrypt就是展示encrypt.html页面@csrf_exempt #POST不检查csrf，正式环境不要这么用def get_encrypt(request): if request.method == 'POST': word = request.POST.get('word') #获取到name值，这个name是ajax加工过的 result = (\"加密的结果是：\"+list(subprocess.getstatusoutput(\"java -jar /yunwei/AES/aesEncrpt.jar \"+ word))[1].split(\"=\")[1]) #这里执行java的命令得到结果 return HttpResponse(result) else: pass 启动django之后，打开对应的页面，效果如下： 而Request Headers部分如下： input标签id与name的区别最简单的说明：id就像是一个人的身份证号码，而name就像是他的名字，id显然是唯一的，而name是可以重复的，checkbox和radio都可以用name。id要符合标识的要求，比如大小写敏感，最好不要包含下划线（因为不兼容CSS）。而name基本上没有什么要求，甚至可以用数字。 如果在reset便签里这么写的话，重置功能将不会生效，因为id=&quot;reset&quot; name=&quot;reset&quot;，所以请极力避免用reset作为关键词。 1&lt;input type=\"reset\" id=\"reset\" name=\"reset\" value=\"Reset\" /&gt; 更多的区别可以看https://stackoverflow.com/questions/7470268/html-input-name-vs-id 。 参考资料https://blog.csdn.net/mingliangniwo/article/details/45533201https://thief.one/2017/09/14/3/https://www.haorooms.com/post/jquery_ajax_wghttp://www.cnblogs.com/birdshome/archive/2005/01/31/99562.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"Jquery","slug":"Jquery","permalink":"http://yoursite.com/tags/Jquery/"},{"name":"Ajax","slug":"Ajax","permalink":"http://yoursite.com/tags/Ajax/"}]},{"title":"Django前端输入变量通过内部脚本加工返回前端展示之五","slug":"Django与Jquery、Ajax的联合运用","date":"2018-11-29T10:50:39.000Z","updated":"2018-12-04T06:22:14.000Z","comments":true,"path":"2018/11/29/Django与Jquery、Ajax的联合运用/","link":"","permalink":"http://yoursite.com/2018/11/29/Django与Jquery、Ajax的联合运用/","excerpt":"","text":"背景说明python：3.6.5Django：2.1.1Project：Kubernetes，文件夹路径就是/django/Kubernetes/App：createyaml，文件夹路径就是/django/Kubernetes/createyaml前文地址：https://rorschachchan.github.io/2018/11/24/Django%E5%90%8E%E5%8F%B0%E6%89%A7%E8%A1%8C%E8%84%9A%E6%9C%AC%E5%8F%8D%E9%A6%88%E5%88%B0%E5%89%8D%E7%AB%AF%E8%BE%93%E5%87%BA/ 需求说明以及实现思路之前Django已经实现了点击按钮把值传入到后台脚本，同时把结果反馈到页面的效果了。但是那个逻辑太挫了:得把前端的变量存到本地去，然后后台的python脚本要去读取本地文件取的变量值执行任务。如果想用更加优雅的方法实现我们的目的那就要用jQuery+Ajax技术—-把目标反馈值包装成function调用，修改内置参数的方法，更容易上手，适合新手入门。 jQuery和Ajax的定义这里就不多说了，说直白点它们的作用就是不用离开当前的页面，而是在当前的页面加载出我们想要的结果，这就叫做异步刷新，这种刷新方法比较友好，而且可以少写一些html。 本次试验的目的就是在test111.html里随机输入内容，然后把数字“666”在当前页展示。效果如图： 这里我先使用POST方法，因为它无论是安全还是输入字符长度都要比GET方法优秀。但是要注意！如果代码中没有指明方法，那么默认就是GET方法。 具体代码前端页面test111.html的内容如下： 12345678910111213141516171819202122232425262728293031323334353637&lt;!DOCTYPE html&gt;&lt;html&gt; &lt;head&gt; &lt;meta charset=\"utf-8\"&gt; &lt;title&gt;TEST PAGE&lt;/title&gt; &lt;script src=\"https://cdn.staticfile.org/jquery/1.10.2/jquery.min.js\"&gt;&lt;/script&gt; // 这里引用jquery.min.js &lt;script&gt; $(document).ready(function()&#123; //元素加载完成之后，绑定事件 $(\"#AJAX_post\").click(function()&#123; //这里的AJAX_post与按钮的id一致，并且配置了点击click动作 var someth = $(\"#someth\").val(); // 获取输入框的值 var data = &#123;\"someth\": someth&#125;; // 打包成get请求发送的数据 alert_text = '666即将出现！'; alert(alert_text); $.post( // post 方法请求服务器 '&#123;% url 'test111' %&#125;', // 请求的url data, // 这个data就是上面打包的数据 function(ret)&#123; // 回调函数，其中ret是返回的JSON var someth = ret['someth']; var num = ret['num']; // 这里把得到的两个值ret成查询结果 $(\"#result\").text(num); // result就是输出到网页上的值，格式是text，如果是text(someth)，那么就会出现的是你随机输入的那段字符 &#125;) &#125;) &#125;); &lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;请随便输入：&lt;input type=\"text\" id=\"someth\" value=\"\"&gt;&lt;/p&gt; &lt;p&gt;这里出现666：&lt;span id=\"result\"&gt;&lt;/span&gt;&lt;/p&gt;&lt;/p&gt; &lt;button id=\"AJAX_post\" type=\"button\"&gt;ajax post&lt;/button&gt; &lt;/body&gt;&lt;/html&gt; ajax那部分虽然有注释，但是还是要多说一点： $(document).ready(function(){}:等待{}中涉及到的元素全部加载完，就按照function具体内容给它们绑定特殊事件; $(&quot;button&quot;).click(function(){}:$(&quot;AJAX_post&quot;)是Jquery的选择器，表示页面的“按钮”，.click(function(){}为前面选中的元素，绑定一个鼠标点击的事件，具体事件是function()里面； $.post：表示调用了post方法，里面有三个元素，用逗号隔开，分别是URL,data（可省略）和callback（可省略，其中URL可以就是要局部刷新后展示的那个页面； 如果想把变量以字符串的形式输入，那么就是var id=document.getElementById(&#39;name&#39;).value，如果单独使用request.GET.get，得到的数据类型是&#39;NoneType&#39;; 而对应的views.py那部分函数的内容如下： 1234567891011121314from django.views.decorators.csrf import csrf_exempt@csrf_exempt #取消CSRF保护，线上环境请不要这样def test(request): if request.method == 'POST': someth = request.POST.get('someth') #从前端获取name值 num = \"666\" #已经定义好了666，然后会被ret得到 data = &#123;&#125; data['someth'] = someth data['num'] = num print (data) return JsonResponse(data) else: return render(request,'test111.html') 对应的urls.py内容如下： 1path(r'test111',views.test,name='test111'), 保存之后，启动django，在test111.html页面即可达到效果。 参考资料http://www.runoob.com/jquery/jquery-ajax-get-post.htmlhttps://zhuanlan.zhihu.com/p/27665172https://my.oschina.net/esdn/blog/814094https://www.jianshu.com/p/26cd9f442a13https://segmentfault.com/a/1190000009938183 （rel=noopener的问题）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"Jquery","slug":"Jquery","permalink":"http://yoursite.com/tags/Jquery/"},{"name":"Ajax","slug":"Ajax","permalink":"http://yoursite.com/tags/Ajax/"}]},{"title":"服务器被入侵了","slug":"服务器被入侵了","date":"2018-11-27T03:20:04.000Z","updated":"2018-12-12T12:13:16.000Z","comments":true,"path":"2018/11/27/服务器被入侵了/","link":"","permalink":"http://yoursite.com/2018/11/27/服务器被入侵了/","excerpt":"","text":"情况描述今天上班，甲方爸爸在微信里叫“设备直播无法播放”，登录到zabbix发现，播放模块的服务器的zabbix-agent已经脱落，而且这个服务器可以ping通但是不能ssh通。 让机房的人去重启了一下服务器，登录之后发现里面有一个很奇怪的进程watchbog： 这个进程不应该出现的，同时查看crontab -l的内容也已经变了： 我登录了一下https://pastebin.com，发现这个是一个提供类似便签记事的网站，黑客应该就是现在这个网站里输入了远程的脚本，然后让这台肉鸡去curl这个网站的网页达到下载脚本然后启动了watchbog进程的目的。 于是我就find / -name \\* -type f -print | xargs grep &quot;pastebin&quot;，看一下系统里都有哪些文件里含有pastebin这个关键词。于是乎先发现/usr/bin里有几个不应该存在的命令： 然后顺藤的发现几乎所有的crontab文件都已经被污染了： 把以上所有被污染的文件全部删光内容，将watchbog进程彻底杀死。观察了一会，貌似没有复现问题。 后续解决方案 在zabbix监控上添加对watchbog进程的监控，如果出现直接通知负责人； 将ssh的22端口更改成33664端口，规定只有堡垒机可以登录； 与开发商议，确认此服务器的外网权限可以撤掉，于是撤掉外网IP； PS. http://www.4usky.com/ https://www.shutterstock.com/zh/ 这俩是很不错的壁纸网站~","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"centos 6.5","slug":"centos-6-5","permalink":"http://yoursite.com/tags/centos-6-5/"},{"name":"后门软件","slug":"后门软件","permalink":"http://yoursite.com/tags/后门软件/"}]},{"title":"Django前端输入变量通过内部脚本加工返回前端展示之四","slug":"Django后台执行脚本反馈到前端输出","date":"2018-11-24T02:16:58.000Z","updated":"2018-11-29T13:41:54.000Z","comments":true,"path":"2018/11/24/Django后台执行脚本反馈到前端输出/","link":"","permalink":"http://yoursite.com/2018/11/24/Django后台执行脚本反馈到前端输出/","excerpt":"","text":"背景说明python：3.6.5Django：2.1.1Project：Kubernetes，文件夹路径就是/django/Kubernetes/App：createyaml，文件夹路径就是/django/Kubernetes/createyaml前文地址：https://rorschachchan.github.io/2018/09/26/Django%E4%BD%BF%E7%94%A8form%E8%A1%A8%E5%8D%95%E5%88%A4%E6%96%AD%E8%BE%93%E5%85%A5%E5%80%BC%E6%98%AF%E5%90%A6%E5%90%88%E6%B3%95/ 需求说明之前我们已经达到了“页面判断输入值是否合法”，“页面输入值录入数据库”这两个目的，现在就到了重头戏–网页上点击按钮，然后调用后台python脚本，并且把脚本的结果反馈到网页端。 我们本次使用一个加密的python脚本encrypt.py，它主要得作用是输入某个字段，然后进行AES256加密，然后把加密结果返回给界面，整个脚本内容如下： 1234567#!/usr/bin/env python#coding=utf-8import subprocessAESWord = input(\"输入字段：\")result = list(subprocess.getstatusoutput(\"java -jar /yunwei/AES/aesEncrpt.jar \"+AESWord))[1].split(\"=\")[1]print (AESWord+ \"的加密结果是：\"+(result)) 脚本执行效果如下： 笨方法解决前端的页面内容如下： 12345678910111213&#123;% extends &apos;base.html&apos; %&#125; #这部分是引入base.html这个模板&#123;% block title %&#125; AES加密&#123;% endblock %&#125;&#123;% block content %&#125; &lt;form action=&quot;/k8s/encrypt/&quot; method=&quot;post&quot; name=&apos;encrypt&apos;&gt; &#123;% csrf_token %&#125; 要加密的字段：&lt;input type=&quot;text&quot; name=&quot;AESWord&quot; /&gt;&lt;br /&gt; &lt;input type=&quot;reset&quot; value=&quot;清除所有&quot; /&gt; &lt;input type=&quot;submit&quot; value=&quot;查询解析&quot; /&gt; &lt;/form&gt;&#123;% endblock %&#125; 目前已知views.py里使用request.POST.get()方法是可以捕获到前端输入值，但是这个输入值怎么传递给encrypt.py呢？这一点非常的复杂。 可能这个时候很多人会想使用“外部脚本引入django系统”的方法，但是那个方法可以引用到数据库，但是无法引用views.py里的函数的变量。于是只能用一个笨招：先把前端输入值记录到本地某个文件里，然后encrypt.py去读取这个文件，这样达到获取变量的方法。 于是views.py里的相关部分就是这样： 123456789101112前面略def encrypt(request): if request.method == 'POST': AESWord = request.POST.get('AESWord') with open('/yunwei/AES/AESWord.txt','w') as f: #把前端获取到的值记录到本地的AESWord.txt文件里 f.write(AESWord+\"\\n\") child = subprocess.Popen('python /yunwei/AES/Encrypt.py',stdout=subprocess.PIPE, stderr=subprocess.PIPE,shell=True) stdout, stderr = child.communicate() result = str(stdout,encoding='utf-8') #将脚本反馈的结果输入result return HttpResponse(result) #页面展示result else: return render(request,'encrypt.html') 而encrypt.py内容改成如下： 1234567#!/usr/bin/env python#coding=utf-8import linecache,subprocessAESWord = linecache.getline(&apos;/yunwei/AES/AESWord.txt&apos;,1).strip(&apos;\\n&apos;) #在这里读取前端的变量result = list(subprocess.getstatusoutput(&quot;java -jar /yunwei/AES/aesEncrpt.jar &quot;+AESWord))[1].split(&quot;=&quot;)[1]print (AESWord+ &quot;的加密结果是：&quot;+(result)) 执行效果如下： 这样的操作达到了目的！后期就是把result使用render加工映射到某个网页，页面就好看很多了。 js+ajax方法解决上面的方法虽然可以达到我们想要的目的，但是其实是十分不推荐的：一是因为网页调用本地程序的权限正在被取消，二是因为真不如JS写直接，三是只能在自己本地调用。 所以还是用前端来解决更专业更优雅，那么就要使用js+ajax。 具体内容下次补充… 补充在外部脚本引入django系统的方法就是在外部脚本的开头加上下面的内容： 12345678#!/usr/bin/env python#coding=utf-8import os,sys,djangosys.path.append('/django/Kubernetes/') # 将项目路径添加到系统搜寻路径当中os.environ['DJANGO_SETTINGS_MODULE'] = 'Kubernetes.settings' # 设置项目的配置文件django.setup()from createyaml.models import parameter #这样就可以引入models.py文件里的parameter这个类 但是上面说过，这个方法可以引入数据库models.py文件，并不能引入views.py文件。 参考资料https://stackoverflow.com/questions/15151133/execute-a-python-script-on-button-clickhttps://blog.csdn.net/yzy_1996/article/details/80223053https://simpleisbetterthancomplex.com/tutorial/2016/08/29/how-to-work-with-ajax-request-with-django.htmlhttps://www.candypapi.com/2017/11/02/Python-external-script-calls-the-Django-project-model-table/https://segmentfault.com/q/1010000005096919","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Git clone的几个错误","slug":"Git-clone的几个小故障","date":"2018-11-12T04:12:20.000Z","updated":"2018-11-12T08:27:06.000Z","comments":true,"path":"2018/11/12/Git-clone的几个小故障/","link":"","permalink":"http://yoursite.com/2018/11/12/Git-clone的几个小故障/","excerpt":"","text":"Git clone的时候可能会出现fatal: HTTP request failed的错误，如图： 一般来说这样的情况多半就是git版本太低，&lt;=1.7的版本经常出现这样的错误，解决问题的办法就是使用最新的git，安装git 1.9的方法在这里：https://rorschachchan.github.io/2018/06/13/Centos6%E5%AE%89%E8%A3%85git1-9%E5%AE%89%E8%A3%85%E8%BF%87%E7%A8%8B/ 。 更新到1.9之后重新去git clone，这一次换成了SSL connect error错误： 此时就需要执行一下yum update -y nss curl libcurl，这样才能顺利的git clone。 如果出现了easy_install command not found，可以使用wget https://bootstrap.pypa.io/ez_setup.py -O - | python 解决，有了easy_install就可以安装pip了。 以上的操作是在python2.7下进行的。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"},{"name":"Python 2.7","slug":"Python-2-7","permalink":"http://yoursite.com/tags/Python-2-7/"}]},{"title":"通过调整Css让界面美观一点","slug":"通过调整Css让界面美观一点","date":"2018-11-05T06:07:43.000Z","updated":"2018-11-05T08:23:46.000Z","comments":true,"path":"2018/11/05/通过调整Css让界面美观一点/","link":"","permalink":"http://yoursite.com/2018/11/05/通过调整Css让界面美观一点/","excerpt":"","text":"数据可视化肯定需要前端知识，同时也要美化前端，让用户的体验更好，这时候就需要接触到css技术。 css简单来说就是先给你需要修饰的部分设定变量，然后针对不同的变量做不同的声明，达到修改界面的目的。css规则由两个主要的部分构成：选择器，以及一条或多条声明，格式是：selector {declaration1; declaration2; ... declarationN }。 在html文本里添加一个style标签，比如：&lt;style type=&quot;test/css&quot;&gt; &lt;/style&gt;。这个标签可以放到&lt;body&gt;最尾处也可以放到&lt;head&gt;最尾处。不过一般来说都是放到&lt;body&gt;里。 在调整css的时候，可以搭配chrome的F12键直接修改，然后将修改的内容拷贝粘贴到html文件里。 比如我现在的页面是如下这个样子的： 这个结构可以看出使用最直白的html语言编写，为了美观大方，我们需要把它改成如下的样子： 原来的代码如下： 12345678910111213&lt;body&gt; &lt;div&gt; &lt;a href=\"&#123;% url 'home' %&#125;\"&gt; &lt;h2&gt;Homepage&lt;/h2&gt; &lt;/a&gt; &lt;a href=\"&#123;% url 'blog_list' %&#125;\"&gt;List&lt;/a&gt; &lt;a href=\"http://www.baidu.com\"&gt;跳往百度&lt;/a&gt; &lt;a href=\"http://www.lechange.com\"&gt;跳往乐橙&lt;/a&gt; &lt;/div&gt; &lt;hr&gt; &#123;% block content %&#125; &#123;% endblock %&#125;&lt;/body&gt;&lt;/html&gt; 更改后的代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;body&gt; &lt;div class=\"nav\"&gt; &lt;!-- 给这个div标签添加一个class叫nav --&gt; &lt;a class=\"logo\" href=\"&#123;% url 'home' %&#125;\"&gt; &lt;!-- 给这个div下的这个a标签添加一个class叫logo --&gt; &lt;h2&gt;Homepage&lt;/h2&gt; &lt;/a&gt; &lt;a href=\"&#123;% url 'blog_list' %&#125;\"&gt;List&lt;/a&gt; &lt;a href=\"http://www.baidu.com\"&gt;跳往百度&lt;/a&gt; &lt;a href=\"http://www.lechange.com\"&gt;跳往乐橙&lt;/a&gt; &lt;/div&gt; &lt;hr&gt; &#123;% block content %&#125; &#123;% endblock %&#125; &lt;style type='text/css'&gt; body&#123; margin: 0; padding: 0; &lt;!-- 这是对整个body标签进行声明，外边距和内边距都是0 --&gt; &#125; div.nav&#123; background-color: #eee; border-bottom: 2px solid blue; padding: 5px 10px; &lt;!-- 这是对整个nav的div标签进行声明：颜色灰色 --&gt; &lt;!-- 增加一条底线取代&lt;hr&gt;，设定宽是2px，实线，颜色是蓝色 --&gt; &lt;!-- 设定上下边距5px,左右边距10px --&gt; &#125; div.nav a&#123; text-decoration: none; color: #000; &lt;!-- 这是对整个nav的div标签里的所有a标签说明：取消下划线，并且规定为黑色 --&gt; &#125; div.nav a.logo &#123; display: inline-block; color: green; font-size:120%; &lt;!-- 在这里对nav的div标签里那个叫logo的a标签进行单独的说明：缩进，并且规定为绿色 --&gt; &lt;!-- 字体大小是原来的120% --&gt; &#125; &lt;/style&gt;&lt;/body&gt;&lt;/html&gt; 调整css是一个很繁琐很麻烦的事情，需要耐心。至于如何整合css样式到一个文件然后统一配置的内容，请去看：https://rorschachchan.github.io/2018/05/12/%E5%8A%A0%E8%BD%BDcss%E6%A0%B7%E5%BC%8F%E7%9A%84%E4%B8%A4%E4%B8%AA%E6%96%B9%E6%B3%95/ 。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"html","slug":"html","permalink":"http://yoursite.com/tags/html/"},{"name":"css","slug":"css","permalink":"http://yoursite.com/tags/css/"}]},{"title":"使用模板嵌套来精简html代码","slug":"使用模板标签来精简html代码","date":"2018-11-02T02:41:19.000Z","updated":"2018-11-02T08:10:38.000Z","comments":true,"path":"2018/11/02/使用模板标签来精简html代码/","link":"","permalink":"http://yoursite.com/2018/11/02/使用模板标签来精简html代码/","excerpt":"","text":"在编写django的时候，前端html文件里经常会遇到很多有大量重复代码的情况出现，为了代码精简好看以及后期维护的方便，就需要把那些重复的代码统一放到一个文件里去，不重复的部分自然保留，文件到时直接调用重复模板就好，不同的部分对应填充。 举个例子，有一个代码是templates/aaa.html： 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&apos;UTF-8&apos;&gt; &lt;title&gt;&#123;&#123; blog.title &#125;&#125;&lt;/title&gt; &lt;!-- blog.title就是文章标题，从数据库中提取，使用vender映射出来 --&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; &lt;a href=&quot;&#123;% url &apos;home&apos; %&#125;&quot;&gt; &lt;h2&gt;BACK TO HOMEPAGE&lt;/h2&gt; &lt;!-- 这部分是重复的 --&gt; &lt;/a&gt; &lt;/div&gt; &lt;h3&gt;&#123;&#123; blog.title &#125;&#125;&lt;/h3&gt; &lt;!-- 这一部分也是同样用vender映射，展现每一篇文章对应的作者和内容 --&gt; &lt;p&gt;作者：&#123;&#123; blog.author &#125;&#125;&lt;/p&gt; &lt;p&gt;分类： &lt;a href=&quot;&#123;% url &apos;blogs_with_type&apos; blog.blog_type.pk %&#125;&quot;&gt; &#123;&#123; blog.blog_type &#125;&#125; &lt;/a&gt; &lt;/p&gt; &lt;p&gt; &#123;&#123; blog.blog_type.pk &#125;&#125;&lt;/p&gt; &lt;p&gt;发表时间：&#123;&#123; blog.created_time|date:&quot;Y-m-d H:i:s&quot;&#125;&#125;&lt;/p&gt; &lt;!-- 这里规定了时间格式 --&gt; &lt;hr&gt; &lt;p&gt;&#123;&#123; blog.content &#125;&#125;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 假设aaa.html里”BACK TO HOMEPAGE”这个部分是重复的，即每一个页面都有返回主页的点击。既然都有这个功能，那么就单独做一个base.html文件当框架，把重复的部分写进去： 12345678910111213141516&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset=&apos;UTF-8&apos;&gt; &lt;title&gt;&#123;% block title %&#125;&#123;% endblock %&#125;&lt;/title&gt; &lt;!--这里加入了一个block(块），块的名字叫title--&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; &lt;a href=&quot;&#123;% url &apos;home&apos; %&#125;&quot;&gt; &lt;h2&gt;BACK TO HOMEPAGE&lt;/h2&gt; &lt;/a&gt; &lt;/div&gt; &lt;hr&gt; &#123;% block content%&#125; &#123;% endblock %&#125; &lt;!--这里又加入了一个block，块的名字叫content--&gt;&lt;/body&gt;&lt;/html&gt; 现在的base.html就是一个框架，里面有了两个block，这两个块有各自的名称，因为这两个块的内容是变化的。再把aaa.html里需要对应配置的部分定义成对应的变量，并且引入这个base.html即可。重新修理后的aaa.html就长这个样子了： 12345678910111213141516171819&#123;% extends &apos;base.html&apos; %&#125; &lt;!--首先引入同目录下的base.html--&gt;&#123;% block title%&#125; &#123;&#123; blog.title &#125;&#125; &lt;!--这部分就是title块的内容--&gt;&#123;% endblock%&#125;&#123;% block content %&#125; &lt;!--这一段就是content块的内容--&gt; &lt;h3&gt;&#123;&#123; blog.title &#125;&#125;&lt;/h3&gt; &lt;p&gt;作者：&#123;&#123; blog.author &#125;&#125;&lt;/p&gt; &lt;p&gt;分类： &lt;a href=&quot;&#123;% url &apos;blogs_with_type&apos; blog.blog_type.pk %&#125;&quot;&gt; &#123;&#123; blog.blog_type &#125;&#125; &lt;/a&gt; &lt;/p&gt; &lt;p&gt; &#123;&#123; blog.blog_type.pk &#125;&#125;&lt;/p&gt; &lt;p&gt;发表时间：&#123;&#123; blog.created_time|date:&quot;Y-m-d H:i:s&quot;&#125;&#125;&lt;/p&gt; &lt;hr&gt; &lt;p&gt;&#123;&#123; blog.content &#125;&#125;&lt;/p&gt;&#123;% endblock %&#125; 将aaa.html保存之后，刷新对应的页面，会发现依旧可以成功读取而且界面没有任何的变化。 可是在实际操作中也会出现这样的需求：多个不同的django APP可能会要访问同一个模板文件（即base.html），那么就要每一个app都复制一遍base.html吗？其实大可不必。这里可以修改一下setting.py，在里面设置一下公共的模板文件路径。 首先我们现在project根目录下建立一个base文件夹，把base.html复制进去，然后修改一下setting.py如下的字段： 1234567891011121314151617TEMPLATES = [ &#123; &apos;BACKEND&apos;: &apos;django.template.backends.django.DjangoTemplates&apos;, &apos;DIRS&apos;: [ os.path.join(BASE_DIR，&apos;base&apos;), #BASE_DIR是在文件最开始定义的，即project的根目录 ], &apos;APP_DIRS&apos;: True, #这句话的意思是templates文件夹里所有的文件都可以访问 &apos;OPTIONS&apos;: &#123; &apos;context_processors&apos;: [ &apos;django.template.context_processors.debug&apos;, &apos;django.template.context_processors.request&apos;, &apos;django.contrib.auth.context_processors.auth&apos;, &apos;django.contrib.messages.context_processors.messages&apos;, ], &#125;, &#125;,] 保存之后，再次刷新界面，发现界面没变化。这里django在寻找页面的时候，就会去project的路径/base下先找对应的文件，如果没有，会再去自己应用下的templates文件夹里找。如果两个都没有，那就会报错base.html is not exist。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"前端","slug":"前端","permalink":"http://yoursite.com/tags/前端/"}]},{"title":"Nginx配置IP白名单","slug":"Nginx配置IP白名单","date":"2018-10-31T08:47:57.000Z","updated":"2018-11-01T12:02:22.000Z","comments":true,"path":"2018/10/31/Nginx配置IP白名单/","link":"","permalink":"http://yoursite.com/2018/10/31/Nginx配置IP白名单/","excerpt":"","text":"环境交代Nginx配置IP白名单是非常基础的工作，这次试验就是配置某网页可以正常被部分IP访问，而其他网页访问将是403。目标网页地址是http://xxdtq.lechange.com/test/test.html，内容如下： 本机的外网IP地址是115.205.2.28，如图： 首先先nginx.conf里的日志配置格式如下： 123log_format access &apos;$http_x_forwarded_for - $remote_user [$time_local] &quot;$request&quot; &apos; &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; &apos;&quot;$http_user_agent&quot; $remote_addr $request_time $upstream_response_time $http_host&apos;; Nginx的转发文件default.conf如下： 123456789101112131415server &#123; listen 80; server_name xxdtq.lechange.com; #如果浏览器输入的是xxdtq.lechange.com，那么就跳转到82端口 location / &#123; proxy_pass http://localhost:82; &#125;&#125;server &#123; listen 80; server_name xhssf.lechange.com; #如果浏览器输入的是xhssf.lechange.com，那么就跳转到82端口 location / &#123; proxy_pass http://localhost:83; &#125;&#125; 配置步骤现在配置xxdtq.conf文件内容如下： 123456789101112131415161718192021 server&#123; listen 82 default; #82端口 server_name xxdtq.lechange.com; root /mnt/xiuxiudetiequan/; #根目录是/mnet/xiuxiudetiequan/ index index.html index.htm index.php; add_header Set-Cookie &quot;HttpOnly&quot;; add_header Set-Cookie &quot;Secure&quot;; add_header X-Frame-Options &quot;SAMEORIGIN&quot;; add_header Strict-Transport-Security &quot;max-age=31536000; includeSubDomains&quot; always; location = /test/test.html &#123; #如果remote_addr是125.205.2.28来访问/test/test.html，那么就返回403 if ($remote_addr = 115.205.2.28) &#123; return 403; &#125; &#125; access_log /var/log/nginx/xxdtq/access.log access; error_log /var/log/nginx/xxdtq/error.log error;&#125; 执行了nginx -s reload后，刷新一下界面，却发现页面没变，并不是预期中的403，打开nginx的日志一看，发现获取到的$remote_addr是127.0.0.1！如下： 为什么是127.0.0.1？因为我们这个nginx做了一个80到82端口的转发呀，所以到80的地址是真实的外界IP，而80转发到82就是本机IP了。那这样的情况怎么办？就需要在default.conf里添加一句proxy_set_header x-forwarded-for $remote_addr;，如下： 12345678server &#123; listen 80; server_name xxdtq.lechange.com; location / &#123; proxy_pass http://localhost:82; proxy_set_header x-forwarded-for $remote_addr; &#125;&#125; 重启一波nginx，发现http_x_forwarded_for正是远程访问的IP地址115.205.2.28，于是将xxdtq.conf判断IP改成如下内容： 12345location = /test/test.html &#123; if ($http_x_forwarded_for = 115.205.2.28) &#123; #改用http_x_forwarded_for return 403; &#125; &#125; 重启nginx之后，果然页面是403，如图： 然后用其他的IP地址，比如用手机连接4G去打开http://xxdtq.lechange.com/test/test.html ，发现是正常读取的，试验成功！ 如果是要整个/test/目录都不让访问的话，就要改成如下内容： 12345location ^~ /test/ &#123; if ($http_x_forwarded_for = 115.205.2.28) &#123; # =是精确匹配 return 403; &#125; &#125; 如果要配置多个IP地址，就要改成如下内容： 12345location ~ ^/shopadmin &#123; if ($remote_addr ~* &quot;第一个IP|第二个IP|第三个IP&quot;) &#123; #这里改成~* return 403; &#125;&#125; elk里提取http_x_forwarded_fornginx日志中的http_x_forwarded_for字段会有多个IP。使用自定义的模板，grok常用表达式的IPORHOST匹配http_x_forwarded_for该字段，获取的IP值是最后一个，如何取第一个IP值？ 答案是： 1234mutate &#123; split =&gt; [&quot;http_x_forwarded_for&quot;,&quot;,&quot;] add_field =&gt; [&quot;real_remote_addr&quot;,&quot;%&#123;http_x_forwarded_for[0]&#125;&quot;] &#125; IPORHOST这些变量匹配不到所有IP，只能通过自定义正则来匹配到所有IP；再通过以上方法截取第一个IP值。正则表达式写法是：[\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\,\\s]* 参考资料http://seanlook.com/2015/05/17/nginx-location-rewrite/https://zhuanlan.zhihu.com/p/21354318http://blog.pengqi.me/2013/04/20/remote-addr-and-x-forwarded-for/http://gong1208.iteye.com/blog/1559835https://my.oschina.net/moooofly/blog/295853","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"两个Zabbix_get问题记录","slug":"Zabbix-get反馈的结果是contacting","date":"2018-10-30T10:56:56.000Z","updated":"2018-11-20T09:11:22.000Z","comments":true,"path":"2018/10/30/Zabbix-get反馈的结果是contacting/","link":"","permalink":"http://yoursite.com/2018/10/30/Zabbix-get反馈的结果是contacting/","excerpt":"","text":"Zabbix_get的结果是contacting在监控zookeeper的时候，我写了一个简单的脚本checkZKrole.sh来获取当前的角色，如下： 1234[root@zookeeper1 ~]# cat checkZKrole.sh #!/bin/bashrole=$(sh /usr/zookeeper/bin/zkServer.sh status| cut -d&quot; &quot; -f2)echo $role 执行效果如下： 本地执行没问题，然后在zabbix-agentd.conf里也把这个脚本添加到自定义监控项里： 重启了zabbix-agent后，发现一个很奇怪的现象，在zabbix-server里使用zabbix-get去拿值的时候拿到的是contacting，如图： 从上图可见，同样在127.1.1.28里取值，proc.num没问题，而且是秒取，但是这个自定义项就取不到。 我怀疑是脚本的问题，于是我改成一个单纯的echo，如下: 12345[root@zookeeper1 ~]# cat checkZKrole.sh #!/bin/bashrole=$(sh /usr/zookeeper/bin/zkServer.sh status| cut -d&quot; &quot; -f2)#echo $roleecho woshinibaba 这一次的返回值是正常的，可见不是脚本的问题： 那是他妈的什么问题，真是见了鬼了…后来想干脆写一个crontab，让crontab把角色写到本地，然后再用cut命令切开把结果当做zabbix_get的目标。但是在这里发现了问题所在，当我的crontab是* * * * * cd /usr/zookeeper/bin/; ./zkServer.sh status &gt; /tmp/role.txt &gt; /dev/null 2&gt;&amp;1，发现/tmp/role.txt里根本没有值，应该是crontab在执行有参数的命令的时候出现了问题。 后来发现了，原来是sudo搞得鬼，如果是由于zookeeper是root用户启动的，所以只有root用户能成功访问，如果是sudo的话，那么就会返回“Error contacting service. It is probably not running.”，所以截取出来的部分就是contacting，如图： zabbix_get执行脚本超时在监控mq队列时候，同样也需要到了自定义监控项，我写了几个简单的脚本如下： 1234567891011121314151617[root@dahuatech zabbix]# cat monitor_mq.sh #!/bin/ship=$1queuename=$2type=$3case $&#123;type&#125; in Pending) curl -s -u &apos;admin:admin&apos; &quot;http://$&#123;ip&#125;:8161/admin/queues.jsp&quot;|grep &quot;$&#123;queuename&#125;&lt;/a&gt;&lt;/td&gt;&quot; -A 5|sed -n &apos;2p&apos;|egrep -o &apos;[0-9]+&apos; ;; Enqueued) curl -s -u &apos;admin:admin&apos; &quot;http://$&#123;ip&#125;:8161/admin/queues.jsp&quot;|grep &quot;$&#123;queuename&#125;&lt;/a&gt;&lt;/td&gt;&quot; -A 5|sed -n &apos;4p&apos;|egrep -o &apos;[0-9]+&apos; ;; Dequeued) curl -s -u &apos;admin:admin&apos; &quot;http://$&#123;ip&#125;:8161/admin/queues.jsp&quot;|grep &quot;$&#123;queuename&#125;&lt;/a&gt;&lt;/td&gt;&quot; -A 5|sed -n &apos;5p&apos;|egrep -o &apos;[0-9]+&apos; ;;esac 配置了UserParameter=activemq.check[*],sh /etc/zabbix/monitor_mq.sh $1 $2 $3放到zabbix-agentd.conf里，重启了zabbix-agent。在zabbix-server配置了对应的item，如图： 然后在本地执行这个脚本，发现回值秒取，但是同样在zabbix-get里使用，就是timeout： 后来发现原来自己摆了一个乌龙，在zabbix-get的时候不能使用{HOST.IP}，因为zabbix-get不识别他，但是zabbix-server是识别的，所以在脚本里把ip=$1改成ip=真实的IP地址即可。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"zookeeper","slug":"zookeeper","permalink":"http://yoursite.com/tags/zookeeper/"}]},{"title":"Mysql主从同步的几个要点总结","slug":"Mysql主从同步的几个要点总结","date":"2018-10-23T07:42:04.000Z","updated":"2018-10-24T01:31:28.000Z","comments":true,"path":"2018/10/23/Mysql主从同步的几个要点总结/","link":"","permalink":"http://yoursite.com/2018/10/23/Mysql主从同步的几个要点总结/","excerpt":"","text":"同步原理主从同步是Mysql非常常见的一个应用，也是非常重要的监控之处，这里简单总结在配置Mysql时候的几个要点，防止以后自己踩坑。 先说一下主从同步的原理，就是主数据库在数据库更新的时候会更新自己的binlog，同时也会向读数据库（一个或多个）传递这个binlog，此时从库开始一个io_thread这个线程用来接收这个binlog，然后把binlog写入到自己的relaylog，当relaylog发现有数据更新了，就开始一个sql_thread来按照主库更新自己的库，这样达到了“主库读库一致”的效果。图示如下： 上述过程：主从延迟：「步骤2」开始，到「步骤7」执行结束。步骤 2：存储引擎处理，时间极短步骤 3：文件更新通知，磁盘读取延迟步骤 4：Bin Log 文件更新的传输延迟，单线程步骤 5：磁盘写入延迟步骤 6：文件更新通知，磁盘读取延迟步骤 7：SQL 执行时长 要监控主从同步是否出现异常，可以通过show slave status\\G里的Seconds_Behind_Master字段来查看，如图： 但是要注意！Seconds_Behind_Master是有前提的，那就是主库跟读库之间的网络情况要良好，因为这个字段是从属服务器SQL线程和从属服务器I/O线程之间的时间差距，（即比较binlog和relaylog执行sql的timestamp时间差），单位是秒。如果主服务器和从属服务器之间的网络连接较快，则从属服务器I/O线程会非常接近主服务器，所以本字段能够十分近似地指示，从属服务器SQL线程比主服务器落后多少。如果网络较慢，则这种指示不准确；从属SQL线程经常会赶上读取速度较慢地从属服务器I/O线程，因此，Seconds_Behind_Master经常显示值为0。即使I/O线程落后于主服务器时，也是如此。换句话说，本列只对速度快的网络有用。 要点总结 主库和读库的mysql版本保持一致，硬件情况也保持一致； binlog文件在生产系统中不易过大，建议小于500m，不然容易拖慢数据库性能； 设置slave前先检查一下设置的账号能不能远程登陆； 在设置多个库同步时，一个binlog-do-db参数对应一个库，不能一行写多个库； 如果出现了Slave_IO_Running: No这个状态，去主库上show master status\\G，查看一下是否file跟从库的file是不是对不上； 代码里避免出现“查询读库后马上到主库操作”的字段，由于主从同步有延迟，这样很有可能会出现前端多次请求，而从库一致无法从主库得到最新的数据消息，所以sql被执行了好几次的错误，这样的情况可以考虑加入“可以用唯一索引限制”或者用insert … select … where not exist这种方式； 主库的慢sql太多的话，也会影响主从同步； 参考资料https://dba.stackexchange.com/questions/24793/mysql-replication-slave-is-continuously-lagging-behind-masterhttp://ningg.top/inside-mysql-master-slave-delay/http://database.51cto.com/art/201108/287653.htmhttps://zhuanlan.zhihu.com/p/28554242","categories":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/categories/大牛之路/"}],"tags":[{"name":"Mysql","slug":"Mysql","permalink":"http://yoursite.com/tags/Mysql/"}]},{"title":"使用Dockbix监控进程","slug":"使用dockbix监控进程","date":"2018-10-15T12:07:11.000Z","updated":"2018-10-15T16:23:44.000Z","comments":true,"path":"2018/10/15/使用dockbix监控进程/","link":"","permalink":"http://yoursite.com/2018/10/15/使用dockbix监控进程/","excerpt":"","text":"之前在https://rorschachchan.github.io/2018/05/17/%E4%BD%BF%E7%94%A8zabbix%E5%8E%BB%E7%9B%91%E6%8E%A7docker%E5%AE%B9%E5%99%A8/ 介绍了如何使用dockbix去自动监控容器的cpu、mem和端口等值。而本文的内容就是讲述如何使用dockbix监控进程。 服务器情况如下：172.31.0.77，普通模式安装zabbix-server；172.16.0.194，服务器里有两个容器，一个是dockbix，另一个是具体的服务，里面是一个centos 7跑着nginx和php两个进程，如图： 如果你启动dockbix的语句是这样的话: 12345678910docker run \\ --name=dockbix-agent-xxl \\ --net=host \\ --privileged \\ -v /:/rootfs \\ -v /var/run:/var/run \\ --restart unless-stopped \\ -e \"ZA_Server=zabbix-server的IP地址\" \\ -e \"ZA_ServerActive=zabbix-server的IP地址\" \\ -d monitoringartist/dockbix-agent-xxl-limited:latest 那么发现监控进程是失败的，如图： 原因就是dockbix和具体服务之间是两个独立的进程，所以dockbix无法访问到另一个容器的进程情况，这样就要干掉原有的dockbix，并且更改一下dockbix的启动语句： 1234567891011docker run \\ --name=dockbix-agent-xxl \\ --net=host \\ --pid=host \\ #增加这句话 --privileged \\ -v /:/rootfs \\ -v /var/run:/var/run \\ --restart unless-stopped \\ -e \"ZA_Server=172.31.0.77\" \\ -e \"ZA_ServerActive=172.31.0.77\" \\ -d monitoringartist/dockbix-agent-xxl-limited:latest 然后再去重新使用zabbix-get命令，就可以获取到进程了！ 默认下，所有的容器都启用了PID命名空间。PID命名空间提供了进程的分离。PID命名空间删除系统进程视图，允许进程ID可重用，包括pid 1。docker run的时候添加了--pid=host就是允许容器内的进程可以查看主机的所有进程。 如果是不要看所有主机的进程，而只是看某一个容器的进程，其他进程pid不看怎么设置呢？ 12docker run --name my-redis -d redis #假设你启动了一个名叫my-redis的容器docker run -it --pid=container:my-redis my_strace_docker_image bash #在建立一个my_strace_docker_imag容器，只与my-redis共享pid 如果zabbix-server发现容器内的某个服务死了，要进入容器里重启服务怎么办？答曰：docker exec 容器ID /bin/bash -c &quot;启动服务命令&quot; 参考资料https://github.com/monitoringartist/dockbix-agent-xxl/issues/42https://www.zabbix.com/documentation/3.4/zh/manual/appendix/items/proc_mem_num_noteshttps://docs.docker.com/engine/reference/run/#imagetag","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"Mysql.sock没了怎么办？","slug":"Mysql-sock没了怎么办？","date":"2018-10-15T03:33:55.000Z","updated":"2018-10-15T09:52:38.000Z","comments":true,"path":"2018/10/15/Mysql-sock没了怎么办？/","link":"","permalink":"http://yoursite.com/2018/10/15/Mysql-sock没了怎么办？/","excerpt":"","text":"今天在调整jumpserver堡垒机资产用户的时候，在点击“更新”的时候，爆出127.0.0.1:3306无法被访问，于是登录到服务器里一看，发现mysql进程挂了。先检查服务器存储空间，发现还很富裕，于是就启动mysql，爆出来如下错误： 12[root@lcshop-jumpserver ~]# mysqlERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (111) 然后来到/var/lib/mysql/里，瞅着这个紫了吧唧的mysql.sock，脑子一抽，把它删了… 删了… 这尼玛，再次启动mysql，错误码从111变成2： 12[root@lcshop-jumpserver mysql]# mysqlERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/lib/mysql/mysql.sock' (2) 这一下就尴尬了，mysql.sock没了怎么生成？有人说“重启服务器可以生成”，事实证明这就是纯粹的扯淡。真实的方法是：mysqld_safe &amp;。 如果mysqld_safe &amp;命令失败了，就要去查看一下mysql的日志，多半是某个文件权限不对，要改成mysql用户。 补充一句其他的问题：ImportError: libxslt.so.0: cannot open shared object file: No such file or directory，遇到这个问题怎么办？ yum install libxslt-devel -y","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"jumpserver堡垒机","slug":"jumpserver堡垒机","permalink":"http://yoursite.com/tags/jumpserver堡垒机/"}]},{"title":"Docker部署的几个tips","slug":"Docker部署的几个tips","date":"2018-10-10T06:17:58.000Z","updated":"2019-05-29T09:22:24.000Z","comments":true,"path":"2018/10/10/Docker部署的几个tips/","link":"","permalink":"http://yoursite.com/2018/10/10/Docker部署的几个tips/","excerpt":"","text":"公司的电商平台使用的是阿里云VPC网络，整个交换机和云服务器都是部署在D区。今天在部署测试环境的时候，发现无法购买服务器，在钉钉上与阿里云售后交涉后，接到噩耗—D区已经不再出售服务器了，如图： 没办法，只能把现有的服务器调高配置，在里面安装docker，尽可能的让各进程的环境彼此之间不受干扰。由于事发仓促，整个架构都要重新调整，镜像就先选用centos：latest，生成容器后在里面装环境以及git pull代码，把容器当做虚拟机来用了。 几个小提示 如果要pecl install swoole的话，要先yum install -y glibc-headers gcc-c++ kernel-headers gcc openssl pcre-devel和yum install -y openssl-devel； centos:latest镜像目前是7.5版本，如果要查看的话需要先安装lsb命令：yum install redhat-lsb -y； 如果容器里使用yum下载爆’Operation too slow. Less than 1000 bytes/sec transferred the last 30 seconds’，用yum -y install wget解决； 容器需要php7.2的环境的话，就要用最新的源： 12yum install epel-release -yrpm -Uvh https://mirror.webtatic.com/yum/el7/webtatic-release.rpm 别忘了开机自启动docker进程：systemctl enable docker； yum install node npm之前要 123yum install -y epel-releasecurl --silent --location https://rpm.nodesource.com/setup_8.x | bash -yum install -y nodejs #这样版本是8.12,npm的版本是6.4.1 在容器里查看端口情况就要安装netstat命令：yum install -y net-tools； 将一个运行中的容器做成镜像的命令：docker commit 容器ID号 镜像名称； 进入容器最好不要用docker attach 容器ID的方式，而是用docker exec -it 容器ID /bin/bash，离开容器的时候也不要用exit或者ctrl + D，这样会将容器停止，而是用ctrl + P、ctrl + Q 或者ctrl + Q + P组合键退出，这样就不会终止容器运行； 容器默认的时间与宿主机的时间相差8个小时，可以在docker run的时候使用-v挂载的方法挂载宿主机的时间文件，比如：docker run --name 容器名 -v /etc/localtime:/etc/localtime:ro ...，或者在dockerfile里添加“设定时区”的语句： 123#设置时区RUN /bin/cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime \\ &amp;&amp; echo 'Asia/Shanghai' &gt;/etc/timezone \\ 容器映射默认情况下是tcp6的，这是正常的现象，如果telnet不通，请先去检查容器内的服务是否正常，比如在容器里curl 127.0.0.1 端口号； 使用docker top 容器id命令能获取的PID是容器内进程在宿主机上的pid，ppid是容器内进程在宿主机上的父进程pid； 如果多个容器要挂载一样的数据就是用-volumes-from，比如docker run --volume-from 容器ID号； 在容器外启动容器内部进程的方法是：docker exec 容器ID /bin/bash -c &quot;对应的命令&quot;，在zabbix监控docker发现进程死了后，就可以用这个方法拉起来； 接上一条的说，docker跟虚拟机不同，它启动的时候是不会运行/etc/rc.d/rc.local的，如果想要Docker在启动后就自动运行/etc/rc.d/rc.local，请看https://github.com/johnnian/Blog/issues/13 里面说的方法； 容器内的进程是会映射到宿主机上的，举个例子，比如容器里运行了swoole，如图： 在宿主机上看也是能看到这个进程的： 有时候是需要用一个脚本来启动镜像进程的，但是要知道容器只能管理一个主进程，当脚本执行完毕了，容器也会EXIT，所以我们需要在启动脚本后面添加tail -f /dev/null让这个启动脚本永远执行不结束。举个例子：1docker run --name XXX -dit -v /data/httpd/yii_ecadmin/:/var/www -w /var/www --restart=always registry.cn-hangzhou.aliyuncs.com/lechangeshop/ecadmin:20190520 ./start.sh 参考资料http://blog.sina.com.cn/s/blog_5ff8e0a00102wmti.htmlhttps://outmanzzq.github.io/2018/01/11/docker-exit-without-stop/http://dockone.io/article/128https://blog.csdn.net/halcyonbaby/article/details/46884605https://stackoverflow.com/questions/30960686/difference-between-docker-attach-and-docker-exechttps://www.binss.me/blog/learn-docker-with-me-about-volume/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"容器","slug":"容器","permalink":"http://yoursite.com/tags/容器/"}]},{"title":"容器报错：rpc error: code = 14 desc = grpc: the connection is unavailable","slug":"容器报错：rpc-error-code-14-desc-grpc-the-connection-is-unavailable","date":"2018-09-29T06:14:52.000Z","updated":"2018-10-11T09:06:44.000Z","comments":true,"path":"2018/09/29/容器报错：rpc-error-code-14-desc-grpc-the-connection-is-unavailable/","link":"","permalink":"http://yoursite.com/2018/09/29/容器报错：rpc-error-code-14-desc-grpc-the-connection-is-unavailable/","excerpt":"","text":"开发同学反馈某一个开发环境的机器卡的要命，我登录一看，内存已经被耗的差不多，但是一看top又看不出来哪个进程占用了很多的内存，如图： 换ps -e -o &#39;pid,comm,args,pcpu,rsz,vsz,stime,user,uid&#39; | sort -nrk5看也没看出来个之乎者也。 发现这个服务器里有两个容器，但是很奇怪，用docker stats却无法获得他们的基础值： 明明容器都是up状态啊，于是我就尝试链接到其中一台，发现报错：rpc error: code = 14 desc = grpc: the connection is unavailable，而且不能restart和kill,如图： 使用docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --shim docker-containerd-shim --runtime docker-runc --debug，发现里面是这样： 后来在https://github.com/moby/moby/issues/30984 这个文章下面找到了一个跟我情况差不多的哥们，也是docker stats命令失效。解决方法是重启docker进程：systemctl restart docker.service，果然，重启之后在手动启动上面两个容器，容器就可以正常访问了： 服务器的内存情况也得到了一定的缓解： 后来跟开发复盘，原来是这个机器上一次死机了，没法关闭容器，只能直接在阿里云控制台重启，而正常的流程应该是先关闭容器再重启的。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"容器","slug":"容器","permalink":"http://yoursite.com/tags/容器/"}]},{"title":"Django前端输入变量通过内部脚本加工返回前端展示之三","slug":"Django使用form表单判断输入值是否合法","date":"2018-09-26T07:08:24.000Z","updated":"2018-11-29T13:42:16.000Z","comments":true,"path":"2018/09/26/Django使用form表单判断输入值是否合法/","link":"","permalink":"http://yoursite.com/2018/09/26/Django使用form表单判断输入值是否合法/","excerpt":"","text":"背景说明python：3.6.5Django：2.1.1Project：Kubernetes，文件夹路径就是/django/Kubernetes/App：createyaml，文件夹路径就是/django/Kubernetes/createyaml前文地址：https://rorschachchan.github.io/2018/09/18/Django%E9%80%9A%E8%BF%87%E5%94%AF%E4%B8%80%E6%A0%87%E8%AF%86%E7%AC%A6%E5%B0%86%E5%90%8E%E5%8F%B0%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%B9%E5%BA%94%E8%BE%93%E5%87%BA/ 需求与解决思路对于表单而言，检查用户输入的信息是否合法是必然项。检查合法一般来说都是用JavaScript或JQuery。不过我是一个前端白痴，JavaScript对我来说就是天书。但是Django非常的贴心，在form表单里就准备了“验证输入内容”这个功能。 如果使用这个功能，首先先在app的views.py里导入form模块：from django import forms。 导入模块之后，设定一个类，这个类就是要在前端html页面中生成form表单中的input标签的，比如： 123456class YamlInfo(forms.Form): #定义的django表单 name = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;,) #自定义错误信息 replicas = forms.DecimalField(max_digits=2,error_messages=&#123;&apos;required&apos;: u&apos;副本个数不能大于100&apos;&#125;) #最大只有2位数 labels_app = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;) containers_name = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;) containers_image = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;) 表单上输入的东西可能会有很多，根据实际情况哪些字段不能为空就把那些字段写到这个class里，在上面那个YamlInfo里把这五项配置对应的Django表单字段，比如replicas，这个字节代表的是容器副本个数，所以它只能是数字，而且我们不要求它大于100，就设定max为2。 创建完类之后，需要在html页面里根据类的对象创建html标签，然后再提交的时候，需要后台views.py把前端页面提交的数据封装到一个对象里：obj = YamlInfo(request.POST)。由于每个Django表单的实例都有一个内置的is_valid()方法，用来验证接收的数据是否合法。如果所有数据都合法，那么该方法将返回True，并将所有的表单数据转存到它的一个叫做cleaned_data的属性中，该属性是以个字典类型数据，然后对这组数据进行展示或者保存到数据库就随你便了；如果有一个数据是非法的，就可以return一个别的结果。 实际代码理论到此结束，先看views.py: 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667from django.shortcuts import render,render_to_responsefrom django.http import HttpResponsefrom .models import parameter #引入数据库里的类from django import forms #引入模块class YamlInfo(forms.Form): #定义的django表单 name = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;,) replicas = forms.DecimalField(max_digits=2,error_messages=&#123;&apos;required&apos;: u&apos;副本个数不能大于100&apos;&#125;) #最大只有2位数 labels_app = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;) containers_name = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;) containers_image = forms.CharField(error_messages=&#123;&apos;required&apos;: u&apos;此节点不能为空&apos;&#125;)#create_yaml就是用来展示输入的页面而已def create_yaml(request): obj = YamlInfo() #创建form的对象 return render(request,&apos;create_yaml.html&apos;,&#123;&apos;obj&apos;:obj&#125;) #返回create_yaml这个模板，模板里的内容其实都是空的#yaml_list就是展示所有的输入情况def yaml_list(request): obj = YamlInfo() #创建form的对象 if request.method == &apos;POST&apos;: input_obj = YamlInfo(request.POST) #request.POST为提交过来的所有数据 if input_obj.is_valid(): data = input_obj.clean() #用clean()函数获取提交的数据 apiVersion = request.POST.get(&apos;apiVersion&apos;,&apos;v1&apos;) #POST.get方法获取到非form的对象 kind = request.POST.get(&apos;kind&apos;,&apos;RC&apos;) name = data[&apos;name&apos;] #用data字典来获取form的对象 replicas = data[&apos;replicas&apos;] labels_app = data[&apos;labels_app&apos;] containers_name = data[&apos;containers_name&apos;] containers_image = data[&apos;containers_image&apos;] containerPort1 = request.POST.get(&apos;containerPort1&apos;,None) containerPort2 = request.POST.get(&apos;containerPort2&apos;,None) containers_name2 = request.POST.get(&apos;containers_name2&apos;,None) containers_image2 = request.POST.get(&apos;containers_image2&apos;,None) containerPort2_1 = request.POST.get(&apos;containerPort2_1&apos;,None) containerPort2_2 = request.POST.get(&apos;containerPort2_2&apos;,None) print (data) #可以在后台看到整个data的内容 else: #如果输入不合法，返回错误信息 error_msg = input_obj.errors #errors为错误信息 return render(request,&apos;create_yaml.html&apos;,&#123;&apos;obj&apos;:input_obj,&apos;errors&apos;:error_msg&#125;) #将错误信息直接返回到前端页面去展示,刚刚输入的非法字段也保留 else: #如果不是post提交，那么就是展示数据里的情况 yamls = parameter.objects.all().order_by(&apos;-id&apos;) #以倒数展示，即新加的在上面 context = &#123;&#125; context[&apos;yamls&apos;] = yamls return render_to_response(&apos;yaml_list.html&apos;,context) #返回yaml_list.html，里面有数据库的所有数据 Parameter = parameter() #将数据库的类实例化 Parameter.apiVersion = apiVersion Parameter.kind = kind Parameter.name = name Parameter.replicas = replicas Parameter.labels_app = labels_app Parameter.containers_name = containers_name Parameter.containers_image = containers_image Parameter.containerPort1 = containerPort1 Parameter.containerPort2 = containerPort2 Parameter.containers_name2 = containers_name2 Parameter.containers_image2 = containers_image2 Parameter.containerPort2_1 = containerPort2_1 Parameter.containerPort2_2 = containerPort2_2 Parameter.save() #保存这些到数据库里 yamls = parameter.objects.all().order_by(&apos;-id&apos;) context = &#123;&#125; context[&apos;yamls&apos;] = yamls return render_to_response(&apos;yaml_list.html&apos;,context) 配置一下urls.py: 123456789from django.contrib import adminfrom django.urls import pathfrom createyaml import views #将app的views.py文件引入urlpatterns = [ path(&apos;admin/&apos;, admin.site.urls), #每个页面对应各自在views.py里的函数 path(r&apos;create_yaml/&apos;, views.create_yaml), path(r&apos;yaml_list/&apos;, views.yaml_list),] 配置一下用户输入的界面—create_yaml.html： 123456789101112131415161718192021222324252627282930313233343536373839&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;生成K8S所用的YAML文件&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;用户输入&lt;/h1&gt; &lt;h2&gt;请注意！大小写敏感！！！&lt;/h2&gt; &lt;form action=&quot;/yaml_list/&quot; method=&quot;post&quot; name=&apos;yamllist&apos;&gt; &#123;% csrf_token %&#125; API版本： &lt;select name=&apos;apiVersion&apos;&gt; &lt;option value=&quot;v1&quot; selected&gt;v1&lt;/option&gt; &lt;option value=&quot;extensions/v1beta1&quot;&gt;beta1&lt;/option&gt; &lt;/select&gt;&lt;br /&gt; 任务类型： &lt;select name=&apos;kind&apos;&gt; &lt;option value=&quot;Pod&quot; selected&gt;Pod&lt;/option&gt; &lt;option value=&quot;Service&quot;&gt;Service&lt;/option&gt; &lt;option value=&quot;Deployment&quot;&gt;Deployment&lt;/option&gt; &lt;option value=&quot;ReplicationController&quot;&gt;ReplicationController&lt;/option&gt; &lt;/select&gt;&lt;br /&gt; &lt;p&gt;任务名称：&#123;&#123; obj.name &#125;&#125; &lt;span&gt;&#123;&#123; errors.name &#125;&#125;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;任务数量：&#123;&#123; obj.replicas &#125;&#125; &lt;span&gt;&#123;&#123; errors.replicas &#125;&#125;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;APP名称：&#123;&#123; obj.labels_app &#125;&#125; &lt;span&gt;&#123;&#123; errors.labels_app &#125;&#125;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;容器1名称：&#123;&#123; obj.containers_name &#125;&#125; &lt;span&gt;&#123;&#123; errors.containers_name &#125;&#125;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;容器1镜像：&#123;&#123; obj.containers_image &#125;&#125; &lt;span&gt;&#123;&#123; errors.containers_image &#125;&#125;&lt;/span&gt;&lt;/p&gt; 容器1开放端口1：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort1&quot; /&gt;&lt;br /&gt; 容器1开放端口2：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort2&quot; /&gt;&lt;br /&gt; 容器2名称：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containers_name2&quot; /&gt;&lt;br /&gt; 容器2镜像：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containers_image2&quot; /&gt;&lt;br /&gt; 容器2开放端口1：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort2_1&quot; /&gt;&lt;br /&gt; 容器2开放端口2：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort2_2&quot; /&gt;&lt;br /&gt; &lt;input type=&quot;reset&quot; value=&quot;清除所有&quot; /&gt; &lt;input type=&quot;submit&quot; value=&quot;生成yaml文件&quot; /&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 而跳转后的yaml_list.html就是这样： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;yaml文件展示&lt;/title&gt;&lt;/head&gt; &lt;body&gt; &lt;h1&gt;数据库里的yaml数据展示&lt;/h1&gt; &lt;table width=&quot;100%&quot; border=&quot;1&quot;&gt; &lt;thead&gt; &lt;a href=&quot;http://121.41.37.251:33664/create_yaml/&quot;&gt;&lt;button&gt;返回&lt;/button&gt;&lt;/a&gt; &lt;!--插入按钮 开始--&gt; &lt;input type=&quot;button&quot; value=&quot;执行&quot; onclick=&quot;MsgBox()&quot; /&gt; &lt;!--插入按钮 结束--&gt; &lt;!--引用JS代码以达到弹出对话框目的 开始--&gt; &lt;script language=&quot;javascript&quot;&gt; function MsgBox() //声明标识符 &#123; confirm(&quot;确定要执行后台脚本么？&quot;); //弹出对话框 &#125; &lt;/script&gt; &lt;!--引用JS代码以达到弹出对话框目的 结束--&gt; &lt;br&gt; &lt;form&gt; &lt;tr&gt; &lt;td align=&quot;center&quot;&gt;任务序号&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;yaml名称&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;api版本&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;任务类型&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;任务数量&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;对应应用&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;使用的第一个镜像名称&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;镜像1的第一个端口&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;镜像1的第二个端口&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;使用的第二个镜像名称&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;镜像2的第一个端口&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;镜像2的第二个端口&lt;/td&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &#123;% for yaml in yamls %&#125; &lt;tr&gt; &lt;td&gt;&lt;input type=&quot;radio&quot; name=&quot;id&quot; checked=&quot;checked&quot;/&gt;&#123;&#123; yaml.id &#125;&#125; &lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.name &#125;&#125; &lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.apiVersion &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.kind &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.replicas &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.labels_app &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.containers_image &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.containerPort1 &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.containerPort2 &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.containers_image2 &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.containerPort2_1 &#125;&#125;&lt;/td&gt; &lt;td align=&quot;center&quot;&gt;&#123;&#123; yaml.containerPort2_2 &#125;&#125;&lt;/td&gt; &lt;/tr&gt; &#123;% endfor %&#125; &lt;/tbody&gt; &lt;/table&gt; &lt;/body&gt;&lt;/html&gt; 启动django，我们来看一下效果！ 不过说实话，对于用户来说，肯定选择题的感觉要比填空题好。所以到时候我们可以把阿里云容器仓库里的所有的镜像做成一个数据库，到时候映射到这个页面，让用户去在里面做选择而不是填空。而且django的form检查相比较JavaScript而言还是很粗糙的，如果是处女座的话，还是要搞JavaScript，而且两者也并不冲突，一个是对前端用户而言，一个是后台检查录入数据库的。 参考资料https://docs.djangoproject.com/en/2.1/topics/forms/ （官方文档）http://www.liujiangblog.com/course/django/152https://www.cnblogs.com/chenchao1990/p/5284237.htmlhttp://dokelung-blog.logdown.com/posts/221431-django-notes-8-form-validation-and-modelinghttps://www.jb51.net/article/103135.htm","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Django将某个数据库字段给多个app使用","slug":"Django将某个数据库字段给多个app使用","date":"2018-09-25T06:48:20.000Z","updated":"2018-09-25T12:23:48.000Z","comments":true,"path":"2018/09/25/Django将某个数据库字段给多个app使用/","link":"","permalink":"http://yoursite.com/2018/09/25/Django将某个数据库字段给多个app使用/","excerpt":"","text":"前言Django里经常会有这样的一个需求—-同样的一组数据要给很多个app使用。比如一个运维系统，运维人员的名单就既要给“项目部署”这个APP用又要给“责任负责人”这个APP用。如果每次都要去跨应用去from XXX.models import xxx的话，代码感觉很不友好。那么要解决这个问题，就要用到django自带的ContentTypes框架。以下是所用软件版本：Django:2.1.1Python:3.6.4old app:Articlesnew app:read_stats 原始状态与前期配置目前在django的控制台页面的情况是这样的： 可见里面就一个叫Articles的app，点开之后，发现对应的项目也很简单，只有id和title这两个字段而已： 本次试验的目的就是新建立一个文章统计计数的app，在里面配置数据库，然后让原来的blog这个app能够使用得到新app的数据项。 首先先建立一个专门用来计数的app，比如就叫read_stat。那么就在django项目路径下python manage.py startapp read_stats，再把这个新的app名称添加到settings.py里： 12345678910INSTALLED_APPS = [ &apos;django.contrib.admin&apos;, &apos;django.contrib.auth&apos;, &apos;django.contrib.contenttypes&apos;, &apos;django.contrib.sessions&apos;, &apos;django.contrib.messages&apos;, &apos;django.contrib.staticfiles&apos;, &apos;article&apos;, #先加载django自身的app，然后是第三方app，最后是自己开发的app &apos;read_stats&apos;,] 编辑一下read_stats里的models.py，创建模型先： 12345678910from django.db import modelsfrom django.contrib.contenttypes.fields import GenericForeignKey #这句话是固定的，引用类型from django.contrib.contenttypes.models import ContentType #这句话是固定的，引用类型# Create your models here.class ReadNum(models.Model): read_num = models.IntegerField(default=0) #设定read_num就是一个普通的数字 content_type = models.ForeignKey(ContentType,on_delete=models.DO_NOTHING) #说明这是一个外键，即关联的模型，加上后面的话的意思是：即使删除了这个字段也不会影响其他数据 object_id = models.PositiveIntegerField() #这里是一个主键，即pk content_object = GenericForeignKey(&quot;content_type&quot;,&quot;object_id&quot;) #通过上面两个变量，配置成一个通用的外键 通过使用一个content_type属性代替了实际的model（如Post，Picture），而object_id则代表了实际model中的一个实例的主键，其中，content_type和object_id的字段命名都是作为字符串参数传进content_object的。 配置了数据库，肯定需要python manage.py makemigrations和python manage.py migrate： 数据更新完毕之后，修改一下负责后台展示的admin.py： 1234567from django.contrib import adminfrom .models import ReadNum #引用ReadNum这个模型# Register your models here.@admin.register(ReadNum) #装饰器class ReadNumAdmin(admin.ModelAdmin): list_display = (&apos;read_num&apos;,&apos;content_object&apos;) 此时刷新一下django页面就看到read_stats这个app已经注册成功了： 由于是新的，所以里面空空如也，点击一下ADD，就可以输入值了：Read num就是设定的“阅读次数”，Content type这个数据是一个选择项，选择需要对应的数据库模型，即Article这个app里的models.py的类—Article，而Object id就Articles对应的文章编号： 这样达到了后台配置“将Article应用里的第2篇文章的阅读次数上调到了99次”。 数据库的跨app配置刚才手动在后台配置完毕，但是目前这个read_num数据只能是在read_stats这个app里自嗨。要给让Article能够得到这个read_num的话，就需要通过模型获取到具体数值，这里要用到ContentType.objects.get_for_model方法。首先要配置Article下的models.py： 123456789101112131415161718from django.db import modelsfrom django.db.models.fields import exceptions #引入错误给try...except使用from django.contrib.contenttypes.models import ContentType #引入ContentTypefrom read_stats.models import ReadNum #从另一个app里引入类# Create your models here.class Article(models.Model): title = models.CharField(max_length=30) content = models.TextField() #这是它原来的数据库内容 #添加一个方法给admin.py使用，如果有就直接返回值（字符串），如果没有object就返回一个0 def get_read_num(self): try: ct = ContentType.objects.get_for_model(self) #确定ContentType readnum = ReadNum.objects.get(content_type=ct,object_id=self.pk) #每个readnum都是content_type和object_id对应的QuerySet return readnum.read_num #这样返回就是一个具体的值，不然只是一个数据 except exceptions.ObjectDoesNotExist: return 0 再修改Article下的admin.py，让后台可以体现出来read_num： 1234567from django.contrib import adminfrom .models import Article# Register your models here.@admin.register(Article)class Article(admin.ModelAdmin): list_display = (&apos;id&apos;,&apos;title&apos;,&apos;get_read_num&apos;) #这里新加上刚才的那个方法 由于admin.py里返回的必须是字段，所以我们才在models.py里添加了一个方法去生成字段。 刷新一下Django后台页面，就看到效果了： 至此，这个read_num数据就同时被两个APP关联分享了。至于再把read_num通过一定的处理方法之后映射到html前端就很简单了。 参考资料https://docs.djangoproject.com/en/2.1/ref/contrib/contenttypes/ （官方文档）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Django前端输入变量通过内部脚本加工返回前端展示之二","slug":"Django通过唯一标识符将后台数据库对应输出","date":"2018-09-18T11:18:51.000Z","updated":"2018-11-29T13:42:28.000Z","comments":true,"path":"2018/09/18/Django通过唯一标识符将后台数据库对应输出/","link":"","permalink":"http://yoursite.com/2018/09/18/Django通过唯一标识符将后台数据库对应输出/","excerpt":"","text":"背景说明python：3.6.5Django：2.1.1Project：Kubernetes，文件夹路径就是/django/Kubernetes/App：createyaml，文件夹路径就是/django/Kubernetes/createyaml前文地址：https://rorschachchan.github.io/2018/09/13/Django%E5%88%B6%E4%BD%9C%E5%89%8D%E7%AB%AF%E9%A1%B5%E9%9D%A2%E7%94%9F%E6%88%90yaml%E6%96%87%E4%BB%B6%E4%B9%8B%E6%94%B9%E8%BF%9B%E7%89%88/ sqlite3的用法sqlite是django默认的数据库，如果只是存一点简单的数据，那么它是足够胜任的。如果在django的APP文件夹里配置了models.py而且执行了python manage.py makemigrations和python manage.py migrate的话，那么在project的文件夹里是会生成db.sqlite3这个文件的。至于如何命令行操作sqlite和python调用sqlite，请去看：http://blog.51cto.com/zengestudy/1904680 ，里面说的已经很清楚了。 不过要注意的是execute方法得到的是一个对象，是看不到具体的sql结果。还需要fetchall方法进一步的解析，这样得到的是一个列表，然后取其中的具体元素，如图： 使用唯一标识符由于yaml的参数是从前端传入的，如果同时有多个人传入数据，那么后端脚本在取参数就会出现错误：多个人在传入不同的数据之后得到的结果却是一样的，即服务器接收到的最后那个数据返回的结果。为了不出现这样的混乱，所以我们就要引入唯一标识符保证每个人得到都是他们的结果。 在数据库里是有一个主键的也就是id，它是django生成数据库的时候自带的private key，每一个id都是唯一的，既然唯一那肯定就是我们选做唯一标识符的首选。至于怎么用它，其实就是在原有的views.py上做一点小手脚。如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344from django.shortcuts import renderfrom django.http import HttpResponsefrom .models import parameter #引入同级的modes.py里的parameter类def create_yaml(request): return render(request,'create_yaml.html') #这个页面是用来输入各值def get_yaml(request): if request.method == 'POST': #如果是post传参，那么就记录下来 apiVersion = request.POST.get('apiVersion','v1') kind = request.POST.get('kind','RC') name = request.POST.get('name') replicas = request.POST.get('replicas','1') labels_app = request.POST.get('labels_app',None) containers_name = request.POST.get('containers_name',None) containers_image = request.POST.get('containers_image',None) containerPort1 = request.POST.get('containerPort1',None) containerPort2 = request.POST.get('containerPort2',None) containers_name2 = request.POST.get('containers_name2',None) containers_image2 = request.POST.get('containers_image2',None) containerPort2_1 = request.POST.get('containerPort2_1',None) containerPort2_2 = request.POST.get('containerPort2_2',None) signer = request.POST.get('signer', 'Micheal Jackson') else: return HttpResponse('404') Parameter = parameter() #将parameter实例化 Parameter.apiVersion = apiVersion #把刚刚从前端得到的值对应赋值 Parameter.kind = kind Parameter.name = name Parameter.replicas = replicas Parameter.labels_app = labels_app Parameter.containers_name = containers_name Parameter.containers_image = containers_image Parameter.containerPort1 = containerPort1 Parameter.containerPort2 = containerPort2 Parameter.containers_name2 = containers_name2 Parameter.containers_image2 = containers_image2 Parameter.containerPort2_1 = containerPort2_1 Parameter.containerPort2_2 = containerPort2_2 Parameter.save() #保存修改 yaml = parameter.objects.get(id=Parameter.id) #通过object.get方法是得到保存的所有值，但是我们只要本次的值，也就是id与private key一致的 return HttpResponse('api版本:%s yaml类型:%s yaml名称:%s 副本数量:%s yaml所属APP:%s 容器名称:%s 容器镜像名:%s' % (yaml.apiVersion,yaml.kind,yaml.name,yaml.replicas,yaml.labels_app,yaml.containers_name,yaml.containers_image))) #输出部分刚输入的值到页面，检查一下是否正确 urls.py如下： 123456789from django.contrib import adminfrom django.urls import pathfrom createyaml import viewsurlpatterns = [ path('admin/', admin.site.urls), path(r'create_yaml/', views.create_yaml), path(r'get_yaml/', views.get_yaml),] 启动django，在前端页面测试一下看看是否得到的结果就是本次输入的结果，如图： 可以看到，返回的页面正确的输出了本次各个参数！剩下还有三部分： 做一个python脚本，把脚本加工的结果返回到前端； 用css/js把界面加工一下； 加入javascript，在前端输入的时候判断输入值是否合法； 参考资料http://blog.51cto.com/lannyma/1735751http://www.liujiangblog.com/course/django/152https://www.jianshu.com/p/46188b39eae5","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"html","slug":"html","permalink":"http://yoursite.com/tags/html/"}]},{"title":"调用阿里云api去修改域名对应IP","slug":"调用阿里云api去修改域名","date":"2018-09-17T06:13:26.000Z","updated":"2018-10-17T01:36:44.000Z","comments":true,"path":"2018/09/17/调用阿里云api去修改域名/","link":"","permalink":"http://yoursite.com/2018/09/17/调用阿里云api去修改域名/","excerpt":"","text":"问题简述以阿里云厂家为例，假设我们有一个网站，它的服务器、数据库、负载均衡都部署在杭州区可用区B,将IP A绑定到某个域名上，启动了系统之后为客户提供服务。那么如果现在要对这套系统进行灾备，应该怎么做？ 第一个方法：在可用区D复制一模一样的环境，然后以“主备服务器组”的方式配置一下负载均衡：如果端口监听不正常就会切换到备用服务器上，监听正常了再切回来。但是这个方式有一个问题，就是当前模式阿里云的主备切换是不支持HTTPS/HTTP的，如图： 可见，这种方式是有很大的局限性的。 那既然同是花钱，干脆就做一个异地容灾，整套系统在其他的地理区域比如上海区也复制一遍，把上海区的B IP也绑定到这个网站域名上，阿里云的域名解析是支持多IP绑定同一个域名的。平时的时候，上海区的IP被域名解析的权重是0，一旦杭州区出现了某些线路方面的硬件问题，那么就将杭州区的权重降成0，同时提高上海区的权重，这样用户就会直接访问到上海区的系统。 理想是丰满的，但是现实是骨感的，因为阿里云的权重配置区域是1~100，而不是0~100，如下图： 也就是说这个云解析的负载均衡是不能当做主备切换使用的，如果想要通过阿里云解析来达到主备切换的目的，方法只能是升级VIP DNS，配置网站监控，具体操作是https://help.aliyun.com/document_detail/59372.html?spm=5176.215331.1147916.23.65de614dac85Sw 。但是这个VIP升级是需要钱的，如果监控的网站越多，花费越大，如果老板不肯掏这份钱，那就只能换条路走。 脚本内容想来想去，还是老办法—-调用阿里云API修改云解析记录达到切换IP的目的。脚本如下，这里我采取了命令行交互的形式，实际上都是将域名IP写死的： 1234567891011121314151617181920212223242526272829303132333435363738#!/usr/bin/env python#coding=utf-8#此脚本版本是2.7，用来修改阿里云云解析IP地址，使用之前请先安装sdk:pip install aliyun-python-sdk-domainimport jsonfrom aliyunsdkcore.client import AcsClientfrom aliyunsdkcore.request import CommonRequestprint \"请注意！本脚本只会修改lechange.com域名下的A记录！！！\"RRKeyWord = raw_input(\"请输入您要修改的域名：\")Value = raw_input(\"请输入新的IP：\")client = AcsClient('这里是AK', '这里是SK','cn-hangzhou')request = CommonRequest()request.set_accept_format('json')request.set_domain('alidns.aliyuncs.com')request.set_method('POST')request.set_version('2015-01-09')def getRecordId(RRKeyWord): global RecordId request.set_action_name('DescribeDomainRecords') request.add_query_param('DomainName', 'lechange.com') #这里写死了lechange.com域名 request.add_query_param('RRKeyWord', RRKeyWord) request.add_query_param('TypeKeyWord', 'A') response = client.do_action_with_exception(request) encode_json = json.loads(response) RecordId = encode_json['DomainRecords']['Record'][0]['RecordId'] #需要获取这个RecordId def UpdateDomainRecord(RRKeyWord,Value): request.set_action_name('UpdateDomainRecord') request.add_query_param('RecordId', RecordId) request.add_query_param('RR', RRKeyWord) request.add_query_param('Type', 'A') request.add_query_param('Value', Value) response = client.do_action_with_exception(request)if __name__ == \"__main__\": getRecordId(RRKeyWord) UpdateDomainRecord(RRKeyWord,Value) 这个脚本比较粗糙，可以改进的地方如下： 判断输入的域名和IP是否符合格式的规范； 判断输入的域名是否存在； 如果添加错误，对应的报错； 搭配爬虫页面脚本使用，如果爬虫页面脚本出现了异常，那么直接启动这个脚本，并且发送微信/邮件通知！ 效果展示整个脚本启动后效果如下： 参考资料https://help.aliyun.com/document_detail/29776.html?spm=a2c4g.11186623.2.37.d31b31dfNqojPThttps://help.aliyun.com/document_detail/44657.html?spm=a2c4g.11186623.6.579.4d1d7cd208aSgl","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"阿里云","slug":"阿里云","permalink":"http://yoursite.com/tags/阿里云/"}]},{"title":"Django前端输入变量通过内部脚本加工返回前端展示之一","slug":"Django制作前端页面生成yaml文件之改进版","date":"2018-09-13T01:20:16.000Z","updated":"2018-11-29T13:42:36.000Z","comments":true,"path":"2018/09/13/Django制作前端页面生成yaml文件之改进版/","link":"","permalink":"http://yoursite.com/2018/09/13/Django制作前端页面生成yaml文件之改进版/","excerpt":"","text":"前言之前搞了一个简易版的“通过前端页面生成yaml”的方法，地址在此：https://rorschachchan.github.io/2018/09/03/制作前端页面生成yaml文件/ 。但是这个方法实际上有很多的不足，比如说每一次生成记录就消失了，无法追溯，所以要引入数据库，把每一次的数据保存到数据库里。 整体的流程设计还是跟以前的一样： 制作一个create_yaml.html网页让用户输入相关数值，并且有两个按钮，一个是重置，一个是生成yaml供K8s使用； 数值保存到django的数据库里； 做一个脚本，脚本从django数据库里取值然后执行； 脚本的结果返回到get_yaml网页，它也有两个按钮，一个是返回，一个是执行此yaml； 本篇文章的内容是第一步和第二步，Django的project名是Kubernetes，app名是createyaml。 配置数据库由于这个小系统保存的数据量不多，所以我就直接使用django默认的db.sqlite3数据库。跑到Kubernetes/createyaml的models.py里，根据yaml的实际情况编写一下数据库各字段： 123456789101112131415161718192021222324252627282930313233from django.db import models # Create your models here.class parameter(models.Model): type = ( (U'Pod','Pod'), (U'Service','Service'), (U'Deployment','Deployment'), (U'ReplicationController','ReplicationController'), ) api_type = ( (U'v1','v1'), (U'extensions/v1beta1','beta1'), ) apiVersion = models.CharField(verbose_name='API版本',max_length=20,choices=api_type) kind = models.CharField(verbose_name='任务类型',max_length=50,choices=type) name = models.CharField(verbose_name='任务名称',max_length=100) replicas = models.CharField(verbose_name='任务数量',max_length=50,default='1') #默认情况下副本数是1 labels_app = models.CharField(verbose_name='APP名称',max_length=100) containers_name = models.CharField(verbose_name='容器1名称',max_length=100) containers_image = models.CharField(verbose_name='容器1镜像',max_length=100) containerPort1 = models.CharField(verbose_name='容器1开放端口1',max_length=25,blank=True) #可以为空，下同 containerPort2 = models.CharField(verbose_name='容器1开放端口2',max_length=25,blank=True) containers_name2 = models.CharField(verbose_name='容器2名称',max_length=100,blank=True) containers_image2 = models.CharField(verbose_name='容器2镜像',max_length=100,blank=True) containerPort2_1 = models.CharField(verbose_name='容器2开放端口1',max_length=25,blank=True) containerPort2_2 = models.CharField(verbose_name='容器2开放端口2',max_length=25,blank=True) signer = models.CharField(verbose_name='登记人',max_length=50, default='system') signtime = models.DateField(auto_now_add= True) #默认添加当前时间#返回相应的值def __unicode__(self): return self.name 保存之后，python manage.py makemigrations和python manage.py migrate，就会看到db.sqlite3文件在Kubernetes这个project文件夹里诞生了。 配置URL路由根据整体的流程设计所说，url.py就新增了如下几个路由： 12345urlpatterns = [ path(r'create_yaml/', views.create_yaml), #create_yaml网页里的内容就是views.py里的create_yaml函数，下同 path(r'get_yaml/', views.get_yaml), path(r'addok/', views.addok),] 在admin后台界面也要体现出每一次数据输入，于是就配置一下Kubernetes/createyaml/admin.py: 123456789101112from django.contrib import adminfrom .models import parameter #把parameter这个class引入# Register your models here.class parameterAdmin(admin.ModelAdmin): list_display = ('name','apiVersion','kind','replicas','labels_app','containers_name','containers_image','containerPort1','containers_name2','containers_image2','containerPort2_1','signer','signtime') #把models.py里的字段都添加进去 exclude = ['signer'] #signer字段不要添加 def save_model(self, request, obj, form, change): obj.signer = str(request.user) obj.save()admin.site.register(parameter,parameterAdmin) 准备工作完事，开始搞前端页面。 配置前端在createyaml文件夹下建立一个template文件夹，里面先写一个create_yaml.html： 12345678910111213141516171819202122232425262728293031323334353637383940&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt; &lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;生成K8S所用的YAML文件&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;用户输入：&lt;/h1&gt; &lt;h2&gt;请注意！大小写敏感！！！&lt;/h2&gt; &lt;form action=&quot;/get_yaml/&quot; method=&quot;post&quot; name=&apos;addyaml&apos;&gt; &lt;!-- form action的意思就是，submit的指向就是/get_yaml/，以post形式传递 --&gt; &#123;% csrf_token %&#125; API版本： &lt;select name=&apos;apiVersion&apos;&gt; &lt;option value=&quot;v1&quot; selected&gt;v1&lt;/option&gt; &lt;option value=&quot;extensions/v1beta1&quot;&gt;beta1&lt;/option&gt; &lt;/select&gt;&lt;br /&gt; 任务类型： &lt;select name=&apos;kind&apos;&gt; &lt;option value=&quot;Pod&quot; selected&gt;Pod&lt;/option&gt; &lt;option value=&quot;Service&quot;&gt;Service&lt;/option&gt; &lt;option value=&quot;Deployment&quot;&gt;Deployment&lt;/option&gt; &lt;option value=&quot;ReplicationController&quot;&gt;ReplicationController&lt;/option&gt; &lt;/select&gt;&lt;br /&gt; 任务名称：&lt;input type=&quot;text&quot; name=&quot;name&quot; /&gt;&lt;br /&gt; 任务数量：&lt;input type=&quot;text&quot; placeholder=&quot;请输入阿拉伯数字&quot; name=&quot;replicas&quot; /&gt;&lt;br /&gt; APP名称：&lt;input type=&quot;text&quot; placeholder=&quot;对应的APP&quot; name=&quot;labels_app&quot; /&gt;&lt;br /&gt; 容器1名称：&lt;input type=&quot;text&quot; name=&quot;containers_name&quot; /&gt;&lt;br /&gt; 容器1镜像：&lt;input type=&quot;text&quot; name=&quot;containers_image&quot; /&gt;&lt;br /&gt; 容器1开放端口1：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort1&quot; /&gt;&lt;br /&gt; 容器1开放端口2：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort2&quot; /&gt;&lt;br /&gt; 容器2名称：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containers_name2&quot; /&gt;&lt;br /&gt; 容器2镜像：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containers_image2&quot; /&gt;&lt;br /&gt; 容器2开放端口1：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort2_1&quot; /&gt;&lt;br /&gt; 容器2开放端口2：&lt;input type=&quot;text&quot; placeholder=&quot;没有可以不填&quot; name=&quot;containerPort2_2&quot; /&gt;&lt;br /&gt; &lt;input type=&quot;reset&quot; value=&quot;清除所有&quot; /&gt; &lt;input type=&quot;submit&quot; value=&quot;生成yaml文件&quot; /&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 写完了之后，再来一个addok.html： 123456789101112131415161718192021&lt;!DOCTYPE html&gt;&lt;html lang=&quot;en&quot;&gt;&lt;head&gt; &lt;meta charset=&quot;UTF-8&quot;&gt; &lt;title&gt;添加成功&lt;/title&gt; &lt;style&gt; * &#123; margin: 0; padding: 0; &#125; a&#123; text-decoration:none; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; &lt;p&gt;添加成功&lt;/p&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 前端准备完毕。 配置views.pyviews.py里的具体函数是整个django的主心骨，内容如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647from django.shortcuts import renderfrom django.http import HttpResponse,HttpResponseRedirectdef create_yaml(request): return render(request,'create_yaml.html') #只是展现一个页面而已def get_yaml(request): if request.method == 'POST': #如果是POST就获取前端传入的值 apiVersion = request.POST.get('apiVersion','v1') kind = request.POST.get('kind','RC') name = request.POST.get('name') replicas = request.POST.get('replicas','1') labels_app = request.POST.get('labels_app',None) containers_name = request.POST.get('containers_name',None) containers_image = request.POST.get('containers_image',None) containerPort1 = request.POST.get('containerPort1',None) containerPort2 = request.POST.get('containerPort2',None) containers_name2 = request.POST.get('containers_name2',None) containers_image2 = request.POST.get('containers_image2',None) containerPort2_1 = request.POST.get('containerPort2_1',None) containerPort2_2 = request.POST.get('containerPort2_2',None) signer = request.POST.get('signer', 'Micheal Jackson') else: return HttpResponse('404') from createyaml.models import parameter #数据库对应项进行赋值 Parameter = parameter() Parameter.apiVersion = apiVersion Parameter.kind = kind Parameter.name = name Parameter.replicas = replicas Parameter.labels_app = labels_app Parameter.containers_name = containers_name Parameter.containers_image = containers_image Parameter.containerPort1 = containerPort1 Parameter.containerPort2 = containerPort2 Parameter.containers_name2 = containers_name2 Parameter.containers_image2 = containers_image2 Parameter.containerPort2_1 = containerPort2_1 Parameter.containerPort2_2 = containerPort2_2 Parameter.save() #保存到数据库里 # 重定向到添加成功页面 return HttpResponseRedirect('/addok/')def addok(request): return render(request,'addok.html') 效果验证启动django之后，首先先去admin后台看一下当前的情况，如图： 可以看到里面是有几个记录的，那么我们现在登录外网地址:端口/create_yaml，输入一些字段看一下效果： 再返回到admin后台刷新，发现刚才新加的任务已经体现出来了： 至此，就达到了“前端html传入数据，后端数据库记录”的效果。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"一篇旧文----《当今中国会不会发生革命》","slug":"一片旧文-当今中国会不会发生革命","date":"2018-09-05T16:10:22.000Z","updated":"2018-09-07T01:54:20.000Z","comments":true,"path":"2018/09/06/一片旧文-当今中国会不会发生革命/","link":"","permalink":"http://yoursite.com/2018/09/06/一片旧文-当今中国会不会发生革命/","excerpt":"","text":"苏振华对本文的初稿提出了中肯的批评和建议，在此致以感谢。 二十世纪中国是一个革命的世纪。二十世纪上半叶，中国经历的主要革命运动有辛亥革命、二次革命、五四运动、北伐战争和共产主义革命。1949年中国共产党取得政权后，又搞了许多具有社会革命性质的社会运动，其中最为著名的有土地改革、人民公社运动、大跃进和文化大革命。改革开放后，中国共产党逐渐从一个革命党转变为执政党，但是中国的一些知识分子、学生和民众却从共产党手中接过“革命的旗帜”，于是就有了1989年的学生运动以及最近的“零八宪章运动”和所谓“茉莉花运动”等集体行动的事件。当然也有知识分子提出中国应该“告别革命”，应该反对激进主义。这是一种应然性吁求，但问题在于：中国是否会再发生（或者能避免）一场革命性的社会动荡？ 这一问题甚至引发中国政治精英的广泛关注。最近网上有文章说中共高层有不少人在阅读托克维尔（Alexis de Tocqueville）的《旧制度与大革命》（L’Ancien regime et la Revolution），幷说王岐山看完此书后曾担忧地表示：中国的现代化转型不会那么顺利；中国人自己的代价也没有付够。当然，革命一旦发生，人民将付出的代价在一定程度上是由革命性质决定。一般来说，政治革命（一场只改变政权的性质，而不改变社会经济结构的革命）给社会带来的震荡要远远低于社会革命（一场既改变政权的性质，又改变社会经济结构的革命），非暴力革命给社会带来的震荡要远远低于暴力革命。王岐山也许是在担心中国会发生一场暴力革命，甚至是暴力性的社会革命。 不管上述中共高层读书的传说可信度如何，有一点十分明确：虽然近年来中国政府在维护稳定上花了很大的力气，中国的经济在近三十年来取得了举世瞩目的发展，民众的生活水平在近年来也有了很大的提高，但中共高层丝毫没有减轻对在中国再发生一次革命的可能性的焦虑。中共高层为甚么会如此忧虑？当前中国与政权稳定相关的根本问题是甚么？本文试图在理论的指导下对当前中国面临的困境作出分析。 一 革命为甚么会发生：理论简述早期的西方理论都把现代化过程中所发生的巨大社会变迁看作是一个国家发生革命的主要诱导因子。这一理论的逻辑很简单：现代化带来了传统的生活方式和价值观的变化，给身处其中的人们带来很大的不适应和不确定性；同时，现代化过程也削弱了传统社会组织对于人们的控制，给革命造就了机会1。的确，世界上的革命无一不发生在正在发生巨大变化的社会之中，而巨大的社会变迁确实会给身处其境的人们带来多方面的不确定性。从这个意义上说，这种理论自有它的道理。但是，世界上每一个国家在现代化过程中都经历过巨大的社会变迁，却不是每个国家都发生了剧烈的革命。社会变迁充其量只能是引发革命的一个必要条件。 在过去的大多数时间，有些学者也常用阶级或者是利益集团的视角来解释一个国家革命的成功与否2。他们的逻辑也很简单：如果一个国家中的一个主要阶级拥护和加入了革命，那么革命就会成功；反之革命就不会发生，就是发生了也会失败。当今中国的不少学者也仍然会自觉或者不自觉地运用这一视角来分析中国社会的危机所在。依笔者所见，这类分析方法表现出了左派知识分子的天真，而反映出来的则是这些知识分子看待问题时的教条性。 这并不是说人们在现代社会中不会产生阶级认同。问题在于：每一个人在社会上都会同时拥有许多身份（比如一个人同时可具有如下的身份：工人、浙江人、男人、某些圈子中的一员、某个俱乐部的成员等），并且具有某一身份的人们之间又存在着巨大的差别（比如工人之间就有蓝领工和白领工、技术工和非技术工、熟练工和非熟练工、临时工和正式职工之间的差别等）。因此，除非存在巨大无比的外力，比如国家对社会上的一个主要人群的利益完全漠视，幷且对这一人群的抗争进行严厉的和系统性的镇压，否则那些被天真的知识分子所认定的“阶级”就很难形成强烈的认同感，去完成知识分子所赋予他们的“历史使命”。 当今世界只有两类大型群体会有着较为“天然的”强大认同感，那就是族群和宗教群体。他们所发起的抗争和革命也因此往往有较大的威力。在很大的程度上，当今所流行的各种“社会分层研究”都是过去知识分子的研究误区的某种产物。不同的社会分层方法除了对了解社会流动和指导政府的公共政策制订有一定的应用性意义外，从社会行动或革命的角度来看，其价值却十分有限。这当然是题外话。 1970年代后，西方学者开始强调国家的性质和结构性行为对革命产生乃至成功的影响3。这类理论背后的一个核心逻辑是：在当代交通和通讯技术的支持下，现代国家获得了古代国家完全没有的渗透社会的能力。与古代国家相比，现代国家的管治领域不但十分宽泛，而且它的政令更能严重影响到社会上绝大多数成员的利益。现代国家的这一性质导致了如下三个后果：第一，国家的错误政策非常容易触发民众大规模的针对国家的怨恨情绪；第二，国家的强势刺激了人们组织起来进行抗争，要求国家颁布和施行对自己群体有利的法律和社会政策；第三，部分人就会想到通过夺取国家的权力（即革命）来彻底改变国家的性质，通过掌握国家权力来推行他们的理想。在这种所谓“国家中心论”的视角下，西方学者做了大量的研究，幷逐渐产生了以下三点共识（即衡量一个国家发生革命可能性的三个维度）：第一，革命不容易发生在一个有着效率较高的官僚集团的国家（官僚集团内的程序政治会增强国家精英的团结、国家决策的合理性和国家镇压机器的有效性）；第二，革命不容易发生在一个对社会精英有着很强吸纳能力的国家；第三，革命不容易发生在一个对社会有着很强渗透力（不仅仅指由国家所控制的交通和通讯工具，而且指警察机构对社会的监控能力）的国家4。 以上的三个维度有很强的解释力。的确，早期的革命，包括法国革命（1789）、俄国革命（1917）、中国革命（1949）和伊朗革命（1979），都发生在用以上三个维度来衡量处境都不太妙的国家。其实，官僚集团的效率、国家对社会精英的吸纳能力，以及国家对社会的渗透能力，是任何国家进行有效统治的关键要素。一个没有这些能力或者是这三方面能力不足的现代国家，无论是民主国家还是威权国家，都会在其运行过程中遇到大量的困难。但问题是，长期以来在分析革命的可能性时，西方学者过于借重了这三个因素，因此直到1980年代他们还在强调苏联和东欧国家具有很大的政治稳定性（因为这些国家都有着比较有效率的官僚集团、对社会精英的吸纳能力和对社会的渗透力）5，而完全没有料想到革命竟然马上就在这些国家发生了，而且其中不少国家的革命都取得了成功。 笔者认为，在分析苏联和东欧国家爆发革命的可能性时，西方学者都忽略了国家权力的合法性基础和国家政权稳定性之间的关系这一维度的重要性。具体来说，一个国家的权力愈是建立在较为稳定的合法性基础之上，这一国家就愈不可能发生革命。苏联和东欧之所以发生革命，不仅仅是因为它们的经济没搞好、它们的军事落后、它们在民族问题上走入误区、它们的领导人采取了错误的政策等（这些因素都很重要），而且更在于这些国家没有把政权建立在一个比较稳定的合法性基础之上。笔者多年来对中外各国革命作出分析时不断强调国家的合法性基础与政权稳定性之间的紧密关系6。笔者认为，西方学者所着重的三个维度都是国家统治手段中偏“硬件”性质的成份，而国家的合法性基础和政权稳定性则构成了国家统治的关键性“软件”，它们缺一不可。 二 合法性和政权的稳定性国家虽然掌握着强大的官僚组织以及军队与警察等武装力量，但是其统治的有效性仍必须依赖于国家政权在大众（包括国家官员）心目中的合法性。考察古今中外的统治史，我们会发觉国家在寻求统治合法性时只能采取以下三种方式：通过一种价值性的承诺、通过提供公共服务、通过一个普遍被接受的国家领导选拔程序。相应地，我们可以界定三种理想状态的国家合法性基础：意识形态型、绩效型和程序型7。如果一个国家统治的正当性是基于一个被民众广为信仰的价值体系，我们可以说这个国家的统治是基于意识形态合法性；如果一个国家统治的正当性来源于国家向社会提供公共物品的能力时，这个国家的统治则基于绩效合法性；如果一个国家的领导人是通过一个被大多数人所认可的程序而产生，这一国家的统治则基于程序合法性。 需要强调的是，以上定义的是国家合法性来源的三个理想类型（ideal types）。现实中，任何国家都不会把合法性完全建立在某一理想类型之上；或者说，任何国家的合法性来源都是这些理想类型的一个混合体。但是，在某一历史时期内，某一理想类型往往会成为一个国家统治最为重要的基础，幷在很大程度上定义了一个国家的性质。 现在让我们来讨论不同的国家合法性基础和政权稳定性之间的关系。 （一）意识形态合法性意识形态是国家统治的一个最为根本的合法性基础。一个国家如果把执政基础完全建立在某一意识形态之上，那是不行的；但是，一个国家的执政如果没有意识形态作为基础，则是万万不行的。当大多数的民众都认同国家所推崇的某一意识形态时，这种意识形态不仅仅为国家的统治提供了道德性依据，而且为社会提供了一个“核心价值观”。如果一个国家有一个被广为接受的核心价值观，统治成本就会大大降低。 需要强调的是，核心价值观不能是“八荣八耻”，也不能是“雷锋精神”，因为这些都只能是一个国家的从属性价值观，只有核心价值观才有助于建立国家的合法性基础。国家的核心价值观必须是一种宏大的给予历史以某种道德意义的叙事（即西方后现代学者所说的“宏大叙事”[grand narrative]）。美国中学教科书上所描述的美国建国历史以及那些由建国时期政治家所确定的建国原则和理念，就是核心价值观的一个例子；西周初期所形成的“天命论”以及在西周历史中逐渐得以完善的“宗法制度”是有周一代的核心价值观，幷对古代中国的政治哲学和政治文化产生过重大的影响；当代中国学生在学校里学过的围绕着历史唯物主义和“只有共产党才能救中国”而展开的中国近代史叙事，也是核心价值观的一个例子。当然，美国的宏大叙事在其社会中仍然可以获得广泛的认同，而中国教科书中的叙事方式和内容在国内已经没有多少人真正认同了，幷且中国政府至今也没有创造出一套能被广泛认同的宏大叙事。这一意识形态的缺失所导致的后果就是核心价值观的缺乏，幷给当下中国政府的执政带来了很大的困扰。此是后话。 不同的意识形态有着不同的性质，幷对国家政权的稳定性有着不同的影响。意识形态合法性有三个主要类型：领袖魅力型、世俗意识形态型、宗教意识形态型。在这三个类型中，领袖的魅力（近似于韦伯所说的“克里斯玛合法性”）最不能给予政权一个稳定的合法性基础，因为领袖的寿命有限。 一般来说，世俗意识形态对大众所作的承诺比较容易被验证。一旦当国家不能兑现那些承诺，就会产生合法性危机。从这个意义上来说，世俗意识形态也不是一个稳定的合法性基础。但是如果我们把世俗意识形态进一步细分，就会发觉不同的意识形态对人性有不同的要求和对民众有不同的许诺。一般来说，要是一种意识形态对人性的要求愈接近于人的本性幷且其许诺愈不容易被证伪，这一意识形态就愈能为国家的合法性提供一个可靠的基础。比如美国建立在个人主义基础上的“机会之地”（Land of Opportunity）这一意识形态，不但与人的竞争和趋利本性十分接近，而且很难被证伪。这一意识形态有着人们所说的“钱币落在正面我赢，落在反面你输”（heads I win, tails you lose）的性质：你的成功证明了这意识形态的正确性，而你没有成功很容易被解释为是你没有付出足够或恰当的努力。与之相比较，“共产主义”这一意识形态就很难为一个政权提供稳定的合法性基础。共产主义意识形态不但建立在一个过于理想的人性的基础之上，幷且承诺提供一个比其他社会制度更为完美的世俗世界，例如“各尽所能、按需分配”之类。如果一个国家把共产主义意识形态作为合法性基础，一旦国家不能兑现相应的承诺，民众马上就会产生“信仰危机”，从而给国家带来合法性危机。 但是从理论上来说，即使一个国家把合法性建立在像共产主义这样很不牢靠的意识形态之上，这一国家也是有可能取得较为长久的政权稳定的。这里的诀窍是：当大多数民众还相信这一意识形态时，国家就应该采用选举（程序合法性）来补充共产主义意识形态的内禀不稳定性。因为一旦有了选举，幷且在社会上的大多数民众都认可共产主义意识形态的情况下，当政府搞得不好时，候选人就可以攻击政府没有带领人民在共产主义的“康庄大道”上正确地前进，民众就会去怪罪当朝政府的施政，而不是从意识形态本身的误区来检讨国家中所存在的根本问题。读者可以假设，如果中国在毛泽东时代能搞出一个共产党领导下的民主社会的话，今天的中国也许就不会面临如此严重的意识形态合法性危机。 以上的逻辑还支持了以下的推论：宗教意识形态要比任何世俗意识形态更能为一个国家提供稳定的合法性基础。宗教源自于人的可怜的本性──因为害怕失去和死亡而无限放大生命的意义。宗教的承诺也不具有可验证性──“来世”、“净土”或者“天堂”这样的宗教承诺既十分动人又无法验证，而对于宗教来说，最具权威的克里斯玛都是不存在于世俗世界的“神”、“佛”或者是“圣人”。宗教意识形态与人性的贴近和承诺的无法验证性，赋予那些把国家合法性建基于宗教意识形态之上的国家很大的政权稳定性。 不过，在现代社会，宗教意识形态合法性的最大弱点来自宗教力量和国家政权之间的紧张。现代社会极其复杂且变化极快。为了适应新的变化，国家政权就必须以务实的态度来处理日益复杂的世俗性事物，但是国家的务实态度及其所带来的社会后果势必会招来具有强烈保守倾向的宗教力量的反对。由政教斗争所导致的政权不稳定性，对于那些把宗教意识形态作为合法性基础的国家来说，是必定要面临的一个难题。当今伊朗的政治就在较大程度上受到这一因素的困扰。 （二）绩效合法性任何一个政府都需要为治下的民众提供必要的公共服务，例如仲裁、维持公共秩序、保证人身安全、保卫国家等。这个层面上的绩效是绝不可少的。如果一个政府没有能力提供这些最为基本的公共物品，相应的国家就不会存在，即便存在也会很快垮台。这里所说的“绩效合法性”，指的是国家领导集团在一个更为进取的层面上积极创造绩效以获取合法性。 获取这一合法性的手段可分为三种亚类型：领导经济发展、官员作为民众的道德表率和炒作民族主义情绪。但是，这三种手段都不能为国家提供一个稳定的合法性基础。首先，没有一个国家能保证经济的永久高增长。其次，把官员的道德表率作为国家合法性基础就会将贪污这样在法律层面上能解决的问题提升为政治问题，从而从根本上削弱了国家的合法性。最后，如果在和平时期政府经常以炒作国际危机来提高其统治合法性的话，这一国家的国际环境就会日趋险恶，幷且大量的极端民族主义者就会在这一国家中产生。这将推动一个国家朝着战争的方向发展，后果不堪设想。 总之，当一个国家的合法性系于绩效承诺时，这一国家的政府就必须设法来兑现这些承诺。如果这些绩效承诺得到了兑现，民众的欲望就会提高，幷对政府提出更高的要求，而政府则不得不把民众不断提高的要求作为新的、更新的，甚至是即时的工作目标。但是，一旦政府不能够兑现其承诺时，这一国家马上就会出现合法性危机。 （三）程序合法性现代社会到来之前，除了古希腊之外，程序始终不是世界各国权力合法性的一个重要基础。这幷不是说在古代政府首脑产生的背后没有程序可言，而是说这些程序只在一小部分精英之间才有意义，幷且这些程序在国家政治中不占有像今天的选举政治般重要的地位。笔者认为，以下三个原因使得程序合法性在现代政治中的地位不断上升： 第一，现代国家绝大多数都采取了政教分离原则，宗教意识形态不再是国家的主要合法性来源，或者说现代国家失去了古代国家所拥有的一个十分稳定的合法性基础；第二，现代国家的政府管理的事情愈来愈多，这就使得绩效在现代国家合法性中的地位大大增强，幷给现代国家的政治带来很大的不稳定性；第三，在现代技术的支持下，政府的统治能力不断加强，民众生活受到国家政策愈来愈严重的影响。在这一背景下，怎么控制政府的权力，幷使之不滥用权力，对广大民众来说就变得十分迫切。 我们可以从多种视角来解释为甚么民主政治会在现代国家中兴起。就本文的角度而言，民主兴起的一个重要原因就是现代国家意识形态合法性不足幷且严重倚重于绩效合法性，这就使得国家不得不依靠程序合法性来获得政权的稳定性。 由于以下原因，现代意义上的程序合法性（即民主选举）会给国家政权带来很大的稳定性8： 第一，一旦国家首脑是由民选产生，只要选举被认为是公正的，执政者即使在上台后表现很差，也不会影响政府执政的合法性。用通俗的话说，在绩效合法性的统治基础上，当官如果不为民作主，就有被赶回家卖红薯的危险；而在程序合法性的统治基础上，当官即使不为民作主，也至少得当完一届才回家卖红薯。从这个意义上说，程序合法性大大减低了民众对政府执政的压力。 第二，当一个国家有了程序合法性后，即使有执政者被赶下台也不是甚么大事。这是因为程序合法性在很大程度上把政府和政体分开了。政府即使垮台（比如水门事件[Watergate Scandal]后的尼克松[Richard M. Nixon]政府），政体也不会受到根本性的动摇。 第三，当一个国家有了程序合法性后，民众的不满在相当程度上可以通过选举或其他常规程序的政府更迭而得到缓解。一旦民众有了选择，他们就难以联合起来进行革命，这也给国家政权带来了稳定性。 第四，一旦当官的不为民作主也没有马上就被赶回家卖红薯的危险的时候，公开批评国家领导就不是甚么大事了，这就给言论和结社自由提供了基础。但这自由同时也约束了人民的行为，缓解了社会矛盾，从而构成了政权稳定的一个重要机制。这是因为言论和结社自由让社会上各种思想及利益的交流和竞争，使人们对社会其他群体的利益有了更深的理解，对社会现状有了现实感。同样重要的是，一旦有了言论和结社自由，现代社会的多样性势必会导致社会组织在利益和观点上的分化，这些组织互相牵制使得任何全民性的革命运动变得不大可能。 但就稳定国家政权而言，程序合法性也有着很多弱点，其中最为重要的是它背后必须有一个核心价值观支撑，或者说只有在竞选各方都服从同一意识形态（即“忠诚反对”）时，程序合法性才能为国家提供政权稳定性。如第二次世界大战前的德国，共产党、纳粹党和社会民主党各自有着完全不同的意识形态，幷且共产党和纳粹党都想利用选举来夺取政权，把国家彻底引向对自己有利的方面，形成赢者通吃的格局，选举在这种情形下就不可能成为国家政权稳定的基础。从这个意义上说，一个政治上最为稳定的国家（或者说最不可能发生革命的国家）应该是一个同时拥有意识形态合法性和程序合法性的国家：程序合法性需要强有力的意识形态合法性的支持，幷且程序合法性又是维持国家的意识形态合法性的关键。 三 有关中国政府合法性的经验研究在“世界价值观调查”（World Values Survey）和“亚洲民主动态调查”（Asian Barometer Survey）等调查数据基础上，一些学者对中国的国家合法性进行了研究。他们的一个重要发现是：中国民众对政府的认可度要远远高于许多西方民众对他们政府的认可度。他们于是就得出中国政局稳定、国家具有很高的合法性这一结论9。一般来说，我们都会相信这些研究的结论是成立的。这些学者都受过严格的西方学术训练，他们的材料所展示的也是全国民众的普遍看法，而不是少数人的极端观点。同时，中国政府近年来加强了吏治，采取了一系列的“亲民政策”，这些政策应该说是取得一定效果的。笔者近年来在全国范围内与农村和城市的各界民众进行了不少交流，感到中国百姓的生活水平在近年来有了普遍的和显著的提高，或者说大多数百姓确实从国家的政策中获得了实惠。这些学者的研究结果所反映的正是民众对于当今政府的绩效在一定程度上的认可。 但问题是，从“百姓对当下政府的绩效是肯定的”这一现象中，我们是不能推论出“这个国家的政局是稳定的”这样一个结论的。遍览世界各国，民众对政府绩效的评价，可以说是说变就变的。在西方，民众对政府的认可度数月内就可以波动许多个百分点（他们对政府的认可度有时甚至低至百分之十几）。在西方国家，民众对政府绩效的认可度与国家政局的稳定性之间没有很大的关系，因为西方国家合法性的根本基础不是政府的绩效，而是被主流精英和人民所认可的核心价值观和具有程序公正的选举。但是在中国，百姓对政府执政绩效的认可度与政局的稳定却有着密切的关系：如果中国百姓对政府绩效的认可显著下跌的话，的确是有可能引发一场大规模的政治波动甚至革命的。这背后的原因很简单：共产主义意识形态在中国已经式微，但是国家又拿不出其他有效的价值观取而代之；同时，中国领导人也不是通过一种被大多数人所认可的程序而产生的。中国因此非常缺乏意识形态和程序层面上的合法性，于是绩效就成了国家合法性的最为重要、甚至是唯一的基础。 四 当前中国的问题所在──合法性问题中国经济发展举世瞩目，百姓的生活水平近年来有了很大的提高。但是，中国维稳的成本却愈来愈高。2011年，中国一些人受到突尼斯“茉莉花革命”的影响，促动“茉莉花运动”，但国内几乎没有人响应。尽管如此，不少市政府还是如临大敌，弄得马路上的警察人数不知超过了寥寥无几的闹事人群多少倍。显然，繁荣的经济和大多数百姓对当下政府在不少方面的表现还算满意这些事实，完全不能减轻中共高层领导的焦虑。到底甚么是当前中国政局的关键性不稳定因素？或者问：中共高层领导到底在忧虑甚么？说到这一点，国内的绝大多数知识分子和百姓都会把诸如贫富差距过大、官员贪污腐败等放在首列，但这些因素的重要性或许幷不是想象般大。当前中国的贫富差距的确很大，而官员贪污腐败（特别是在那些吏治较差的省份）无疑也十分严重。相比之下，印度的贫富差距和官员腐败也十分厉害，甚至在不少方面明显超过了中国，可是印度却不是人们认为很可能发生革命的国家。显然，仅仅是贫富差距和官员贪污腐败是不足以引发革命的。 中国的知识分子和百姓都对贫富差距和官员腐败深恶痛绝，但是中国却完全不存在这方面的高质量研究。于是，在考虑这些问题时，中国的知识分子和民众就不得不凭借想象：你对政府有多大程度上的不信任，你就会把中国的贫富差距和官员腐败问题想象得有多严重。笔者认为，当前中国的问题归根到底是政治问题，或者说国家的合法性问题，而不是诸如贫富差距和官员腐败这类社会问题。而中共政权合法性问题的关键在于：第一，国家在共产主义意识形态式微后再也拿不出一个能被广泛认可的主流价值体系；第二，国家不敢（或者不愿意）把合法性的重心转移到程序合法性的层面上来；第三，国家对于绩效合法性产生了过度的依赖。 当下中国的领导人似乎仍然不了解绩效合法性的内禀不稳定这一特质，因为在他们的各种发言中不断流露出人民自然会拥护一个绩效优良的政府这样一种天真的论点，幷且他们也正在努力地通过加强政府绩效来获取国家的合法性。他们的做法与百姓情绪的耦合就给中国带来了如下的悖论：中国的经济和民众的生活水平在近年来都取得了举世羡慕的发展，但是社会却有朝着革命方向发展的倾向。 当社会上的大多数精英和百姓都认同于国家建构的意识形态时，这一意识形态就会成为一个社会的核心价值观或者说核心意识形态。在有着主流意识形态的国家中，社会就会显得非常平和甚至是保守。比如媒体：如果一个记者经常在某一媒体上发表与主流意识形态不符的言论，百姓就会不喜欢这个媒体，其订阅量或收视率就会下降，媒体老板也因此会不喜欢这一记者。可以说，当国家建构的主流意识形态被广为接受时，百姓就会更相信那些平和甚至是保守的报导，而发表偏激言论的媒体就会没有出路。个体也一样：如果一个人经常在公开场合（和网络上）发表与主流意识形态不符的言论，他的言论就会被忽视，他的朋友也不会喜欢他，他也不会有任何社会影响。但是，如果社会上的精英和大多数百姓不认同国家建构的主流意识形态时，人们就会不相信主流媒体中的报导，特别是与政治有关的报导，与主流意识形态保持一致的媒体就会在民众的心目中被边缘化，幷且不再能建构民众的舆论，而敢于反对主流意识形态的媒体和个人就会被看作是“社会的良知”。 当国家建构的意识形态不再是社会上的主流价值观时，在面对以上的异议时国家也就失去有效的对策。如果国家对闹事者或者发表对国家不满观点的人士进行镇压的话，那么国家政权在民众心目中就会进一步失去道义，稍有良知的国家干部就会感觉愧疚，而闹事者和发表对国家不满观点的人士就会被大家看作是“英雄”。但是如果国家选择容忍的话，那么这些人的行动和言论就得不到约束。更有之，一旦形成了这样的“机会结构”，人们就会发觉“会闹的孩子多吃奶”这一妙诀，社会民风于是趋于民粹和暴戾。同时，一旦大众有着把闹事者和发表对国家强烈不满观点的人士看作是“英雄”的倾向，随着“英雄”形象而产生的种种利益就会刺激有些人带着寻租的心态去装扮“英雄”。社会道德就在围绕着反体制而产生的种种“高尚”话语下不断下降。 当国家建构的意识形态不再是社会上的主流价值观时，政府就会失去公信力。这时，如果国家对舆论不加控制，反政府的言论就会在社会上产生很大的影响力，从而引发政治危机。但是如果国家控制舆论的话，人们就会去追逐谣言；加上长期控制舆论而导致人们普遍的无知，天方夜谭式的谣言很容易不胫而走，比如“江泽民去世了，但是中共却秘不发葬”、“薄熙来手上有一百多条人命”、“被重庆警察击毙的不是周克华而是一个便衣警察”等，也会被大家（包括不少社会精英）津津乐道。这些传言不但会给中国的政局增加不确定因素，幷且使得中国本来就很糟糕的政治文化进一步走向糜烂。 当国家建构的意识形态不再是社会上的主流意识形态时，国家的当权者甚至不敢运用民主选举来增强其合法性。从当权者的私利角度看，在这样的情况下举行选举不但会使他们马上下台，而且整个共产党的统治也会结束；很少有当权者愿意在这样的条件下推动民主选举。而从国家利益来说，如果政治精英不能服从一个主流价值观，由选举而产生的“非忠诚反对派”就会撕裂社会，这给了当局拒绝搞民主选举以一定的道德依据。但接下来的问题是，不搞以选举为核心的程序政治只会使得社会矛盾不断积累，幷为中国从威权国家到民主国家的平稳过渡增加了难度。 一旦国家的合法性不能依托于意识形态和领导人的产生程序，绩效就成了国家唯一可依托的合法性基础。得益于中国的“强国家”传统，中国政府在加强执政绩效方面应该说还是可圈可点的。但是，即便可圈可点的绩效使得中国政府变得十分富有，其后果却是金钱使国家领导变得短视，以为金钱能解决一切问题，结果在解决一个问题的同时制造了几个问题。更令人担忧的是，围绕着金钱所产生的种种利益，使得大量的利益相关者带着工具理性围聚在政府周围。这些人对体制毫无忠诚可言，他们一方面死死地把住体制的大船，另一方面则随时准备另寻高就甚至搞狡兔三窟。当前中国出现了“裸官”现象，即不少国家干部的妻子和子女都在国外拥有永久居住权甚至是公民资格，大多数年轻人都向往公务员和国企的工作，其原因盖出于此。这带来的后果就是当前中国民众的强烈仇官心理以及由此生发出来的对任何成功者的仇恨心理，整个社会的道德维系（moral fabric）被大面积毁坏。 为了进一步加强绩效合法性，政府就必须加强吏治、采取悦民政策，幷且把社会上可能出现各种不安定因素的事情统统管了起来。但是，恶性循环不可避免地开始了：政府管得愈好，民众对政府的要求就会愈高；政府管得愈多，问题也就愈多，很多社会问题于是成了政治问题。社会问题的重新政治化是近十年来中国出现的一个令人担忧的发展方向。 五 中国的前途在国内，对国家前途不看好的还真是大有人在，其中既有国内语境下的“自由主义者”和比较极端的“左派”，也有难以计数的掌握着一定话语权的网民。最近，甚至连吴敬琏这样比较持重的学者，都在发表文章惊呼当前中国的“经济社会矛盾几乎到了临界点”10。本文认为，中国的确有再爆发一次革命的可能。与以上的观点不同是，笔者认为当这场动荡到来时，其引发的根本原因不应该是当今中国社会上存在着的各种“经济社会矛盾”，而是民众在主观层面上的不满情绪以及由此带来的大量的社会矛盾。而这些不满情绪和社会矛盾的根源，则是当今政府在国家的法律─选举合法性不足的情况下，过多地把绩效当作了国家合法性的根本基础。笔者同时认为，虽然当前的形势很严峻，但是由于以下原因，中国并没有马上就爆发一场革命的危险： 第一，尽管近年来中国经济发展的势头有所减缓，但是中国仍然是世界上经济发展最为迅速、百姓生活水平有着快速提高的国家。只要中国经济继续能保持目前的增长势头，绩效合法性就还能维持一定的效力，一场革命性的动荡在中国就暂时不会发生。 第二，在中国的不少地区（特别是藏区和新疆地区）有着很严重的民族问题，但中国少数民族人口与汉人相比比例实在太小；这就是说，与前苏联不同，少数民族地区的动乱在中国不会是引发革命的一个主要动因。 第三，由于美国经济的衰退和美国对外政策在世界上普遍不得人心，相当部分的中国知识分子不再简单地把美国政治和政治体制作为理想，或者说当前中国的“自由派”知识分子不再享有1980年代的道德高度，因此也失去了1980年代一呼百应的能力。 第四，中国知识分子在近年来生活水平有了很大的提高，幷且他们发表言论的渠道也大大增加。如果说前一个变化给了知识分子耐心，使他们不会急于鼓动革命，后一个变化则促进了知识群体的分化，从而降低了在中国产生一个人们广为接受的反体制意识形态的可能性。第五，国内外大多数的学者往往会把中国每天都在发生的群体性抗争事件（特别是一些重大事件）看作为革命性事件的可能促发因素。这种观点再一次反映了知识分子的天真。笔者认为，大量的群体性事件对中国政治的稳定实际上有着巨大的正面作用。当前不少地方的地方政府软弱，中国大规模爆发群体性抗争事件的阈值因此较低，社会矛盾也不容易有大规模的堆积。此外，当前中央政府对地方发生的群体性抗争事件采取的基本态度就是让地方政府自己去处理。只要地方政府能控制住局面，中央就保持袖手旁观的姿态；但是如果地方政府让事件失控，或者在处理过程中造成了流血事件，在国内外引起广泛关注，中央政府则会对地方政府官员进行处罚。中央政府的这一做法强化了群体性事件参加者“反贪官不反皇帝”的心态，同时也促使地方政府在处理群体性事件时表现出了极大的多样性和灵活性，从而大大缓解了中国群体性事件走向政治化的倾向。 第六，与一些领袖终身制的国家相比，中国已经形成了一套比较成型的国家领导每届五年，每任不超过两届的做法。虽然新的领导人不是由普选产生，幷且换届过程的不透明也给各种政治流言提供了温床，但是换届送走了人们已经厌烦了的领导（不在于干得好不好，而在于一个人在领导位置坐长了人们都会产生厌倦感），给了人们一种新的想象和希望，从而缓解了社会矛盾朝着革命的方向发展。 但是以上这些有利于缓解社会矛盾激化的因素，完全不可能改变以下的事实：在意识形态和程序合法性严重不足的情况下，执政绩效成了当前中国政府最为主要的合法性基础。因此，即便中国没有马上就发生革命性动荡的危险，只要国家的性质得不到根本性的改变，再发生一次革命的危险在中国始终存在。从这个意义上来说，“中国人自己的代价”的确“没有付够”。 注释1 Samuel P. Huntington, Political Order in Changing Societies (New Haven, CT: Yale University Press, 1968); William Kornhauser, The Politics of Mass Society (Glencoe, IL: Free Press, 1959); Eric R. Wolf, “Peasant Rebellion and Revolution”, in National Liberation: Revolution in the Third World, ed. Norman Miller and Roderick Aya (New York: Free Press, 1971), 48-67. 2 Barrington Moore, Social Origins of Dictatorship and Democracy: Lord and Peasant in the Making of the Modern World (Boston: Beacon Press, 1966); Jeffrey M. Paige, Agrarian Revolution: Social Movements and Export Agriculture in the Underdeveloped World (New York: Free Press, 1975). 3 Jeff Goodwin, No Other Way Out: States and Revolutionary Movements, 1945-1991 (New York: Cambridge University Press, 2001); Tim McDaniel, Autocracy, Capitalism, and Revolution in Russia (Berkeley, CA: University of California Press, 1988); Autocracy, Modernization, and Revolution in Russia and Iran (Princeton, NJ: Princeton University Press, 1991); Theda Skocpol, States and Social Revolutions: A Comparative Analysis of France, Russia, and China (New York: Cambridge University Press, 1979); Timothy P. Wickham-Crowley, Guerrillas and Revolution in Latin America: A Comparative Study of Insurgents and Regimes since 1956 (Princeton, NJ: Princeton University Press, 1992). 4、5 Jeff Goodwin and Theda Skocpol, “Explaining Revolutions in the Contemporary Third World”, Politics and Society 17, no. 4 (1989): 489-509. 6 Dingxin Zhao, “State Legitimacy, State Policy, and the Development of the 1989 Beijing Student Movement”, Asian Perspective 23, no. 2 (1999): 245-84; “State-Society Relations and the Discourses and Activities of the 1989 Beijing Student Movement”, American Journal of Sociology 105, no. 6 (2000): 1592-632. 7 Dingxin Zhao, The Power of Tiananmen: State-Society Relations and the 1989 Beijing Student Movement (Chicago: University of Chicago Press, 2001); “The Mandate of Heaven and Performance Legitimation in Historical and Contemporary China”, American Behavioral Scientist 53, no. 3 (2009): 416-33. 8 赵鼎新：〈民主的生命力、局限与中国的出路〉，《领导者》，2007年第18期，页76-86。 9 Jie Chen, Popular Political Support in Urban China (Washington, DC: Woodrow Wilson Center Press; Stanford, CA: Stanford University Press, 2004); Bruce Gilley, “Legitimacy and Institutional Change: The Case of China”, Comparative Political Studies 41, no. 3 (2008): 259-84; Lianjiang Li, “Political Trust in Rural China”, Modern China 30, no. 2 (2004): 228-58; Tianjian Shi, “Cultural Values and Political Trust: A Comparison of the People’s Republic of China and Taiwan”, Comparative Politics 33, no. 4 (2001): 401-19; Wenfang Tang, Public Opinion and Political Change in China (Stanford, CA: Stanford University Press, 2005). 10 参见吴敬琏的博客，http://wujinglianblog.i.sohu.com/blog/view/236115860.htm。","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"政治","slug":"政治","permalink":"http://yoursite.com/tags/政治/"}]},{"title":"Django制作前端页面生成yaml文件","slug":"制作前端页面生成yaml文件","date":"2018-09-03T03:06:42.000Z","updated":"2018-09-05T13:56:38.000Z","comments":true,"path":"2018/09/03/制作前端页面生成yaml文件/","link":"","permalink":"http://yoursite.com/2018/09/03/制作前端页面生成yaml文件/","excerpt":"","text":"整体流程与环境说明整体流程如下图，请感受灵魂画师的功力： Django:2.1.1，阿里云服务器Python:3.6.4，安装方法见：https://rorschachchan.github.io/2018/07/31/获取网站title的脚本/ Django启动由于是python3，所以直接pip install django就安装最新的Django版本。 12345django-admin startproject Kubernetes #如果提示django-admin命令不存在可以做一个软连接到/usr/local/bin/目录下cd Kubernetespython manage.py startapp createyaml #创建APPpython manage.py migratepython manage.py createsuperuser app创建完毕之后，在Kubernetes/settings.py的INSTALLED_APPS字段添加createyaml，此时就创建好了项目和app。python manage.py runserver 0.0.0.0:8000启动django，然后浏览器地址栏输入外网IP：8000，就会看到django正常启动了，如图： Django准备首先我们先准备一个脚本111.sh，这个脚本很简单，就是接收到前端传入的数值然后加工成一个yaml文件，如下： 123456789101112131415161718192021222324#!/bin/bash#用来生成对应的yaml文件cat &lt;&lt; EOF================================ HERE IS YOUR YAML ================================EOFecho apiVersion: v1echo kind: $1echo metadata:echo name: $2echo labels:echo app: webecho spec:echo containers:echo -- name: front-endecho image: $5echo ports:echo -- containerPort: $3echo -- name: rss-readerecho image: nickchase/rss-php-nginx:v1echo ports:echo - containerPort: $4 可以看出上面这个生成yaml脚本太粗糙了，很多地方还有待改进，但是这仅仅是一个小例子而已。再去/django/Kubernetes/createyaml/templates里准备一个比较简单的前端页面脚本，内容如下： 12345678910111213141516171819202122&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt; &lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;创建yaml文件&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;创建YAML文件用于K8s部署&lt;/h1&gt; &lt;h2&gt;请根据实际情况填写以下内容&lt;/h2&gt; &lt;form method=\"post\" action=\"/create_yaml/\"&gt; &lt;input type=\"text\" name=\"kind\" placeholder=\"类型\"&gt;&lt;br&gt; &lt;input type=\"text\" name=\"name\" placeholder=\"名称\"&gt;&lt;br&gt; &lt;input type=\"text\" name=\"containerPort1\" placeholder=\"容器端口1\"&gt;&lt;br&gt; &lt;input type=\"text\" name=\"containerPort2\" placeholder=\"容器端口2\"&gt;&lt;br&gt; &lt;input type=\"text\" name=\"mirror\" placeholder=\"镜像\"&gt;&lt;br&gt; &#123;&#123; error &#125;&#125;&lt;br&gt; &lt;button id=\"btn\" type=\"submit\"&gt;生成yaml&lt;/button&gt; &#123;% csrf_token %&#125; &lt;!-- 标签添加CSRF令牌，这是因为django针对CSRF(跨站请求伪造)有保护措施，没有这句话就是403 --!&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 有了页面，还需要一个域名指向这个页面，修改一下/django/Kubernetes/Kubernetes/urls.py，改成如下： 12345678from django.contrib import adminfrom django.urls import pathfrom createyaml import views #将createyaml这个app的views引进urlpatterns = [ path('admin/', admin.site.urls), path(r'create_yaml/', views.create_yaml), #新版的这里不再是url了，把这个url指向views.py里的create_yaml函数] 再继续，写一下views.py里的create_yaml函数： 1234567891011121314import subprocess #引入这个库#创建yamldef create_yaml(request): if request.method == 'POST': kind = request.POST.get('kind', '') #后面的''是默认值的意思 name = request.POST.get('name', '') containerPort1 = request.POST.get('containerPort1', '') containerPort2 = request.POST.get('containerPort2', '') mirror = request.POST.get('mirror', '') result = subprocess.Popen(args=['bash','/docker/111.sh',name,mirror,containerPort1,containerPort2],stdout = subprocess.PIPE,shell = False).stdout.read() #在这里通过subprocess去启动111.sh这个脚本 return HttpResponse(result,content_type=\"text/plain\") else: return render(request,'createyaml.html') 以上函数多说几句： 首先判断请求的方法是否是POST，不是的话返回该页面; request.POST.get方法获取前端传入的名称或者端口等值，此处的kind、name、mirror和containerPort就是html文件里form表单部分那两个input标签的name属性； 获取到了变量，然后就让subprocess来调用111.sh来用这些变量去运行脚本，执行的结果就是result，然后return这个result结果； 使用subprocess最好不打开shell = True，因为这样的话，要是不小心rm -rf /，你就gg了，但是如果shell = False的话，就会把刚才的命令看成rm和-rf /两部分，也就是不能成功，这样也免去了别人恶意注入的危险； 实际操作效果 参考资料https://blog.csdn.net/xiaoyaozizai017/article/details/72794469http://lipeilipei.top/2018/02/07/python+django%E5%AE%9E%E7%8E%B0%E7%99%BB%E9%99%86%E5%8A%9F%E8%83%BD%EF%BC%88%E4%B8%8B%E7%AF%87%EF%BC%89/https://blog.csdn.net/bjbz_cxy/article/details/79358718 (如果不想用django就可以看看这个cgi方法)http://blog.51cto.com/laomomo/2163399","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Jenkins自动构建镜像并且发送钉钉通知","slug":"Jenkins自动构建镜像并且发送钉钉通知","date":"2018-08-30T03:39:27.000Z","updated":"2018-08-31T08:33:56.000Z","comments":true,"path":"2018/08/30/Jenkins自动构建镜像并且发送钉钉通知/","link":"","permalink":"http://yoursite.com/2018/08/30/Jenkins自动构建镜像并且发送钉钉通知/","excerpt":"","text":"部署流程图把k8s引入到整个部署的自动化流程如下图： 上图已经说的很明白了，但是结合到我公司的内部情况，再加一点文字的解释： 运维做一个前端页面，上面提供一些关键词作为变量传入; 开发将代码上传到svn或者gitlab，进行jira通知，如果是svn的话，jenkins将新代码打包成zip文件，启动jenkins把windows的zip包上传到阿里云云存储上；如果是到gitlab，就不用打包成zip了，直接就把包传到云存储上； Gitlab/Svn通过webhook通知jenkins去挂载云存储bucket的文件夹里，并且根据对应的dockerfile进行build成镜像，然后再把镜像推送到云镜像仓库里，推送成功后，Jenkins发送一个钉钉成功的通知； Jinkens针对本次镜像和实际部署内容再搭配上之前传递进来的变量，构建一个yaml文件； 通过create这个yaml文件，启动对应的services来达到用户访问的目的，此时Jenkins再发一条钉钉通知，整个部署流程结束。 环境说明Jenkins:2.124,jenkins与docker在同一台云服务器上，并且确定这个机器上可以顺利login到阿里云的私有仓库云存储:阿里云OSSGitlab:10.7.3镜像仓库:阿里云容器镜像仓库钉钉:4.5.5 Jinkens安装钉钉插件既然要让jenkins调用钉钉发送成功消息，那么就需要把jenkins跟钉钉结合在一起。至于怎么配自定义钉钉机器人，请看钉钉的官方文档：https://open-doc.dingtalk.com/docs/doc.htm?spm=a219a.7629140.0.0.karFPe&amp;treeId=257&amp;articleId=105735&amp;docType=1 。而jenkins里也是有官方的钉钉插件，界面系统管理–管理插件，然后搜索“dingding”，安装即可，如图： 插件安装完毕之后，重启jenkins即可。 挂载阿里云存储阿里云官方挂载云存储的方法是ossfs，登陆到jenkins所在的服务器(centos 7.4)里，步骤如下： 123456wget https://github.com/aliyun/ossfs/releases/download/v1.80.5/ossfs_1.80.5_centos7.0_x86_64.rpmyum localinstall ossfs_1.80.5_centos7.0_x86_64.rpm #这一步安装可能会比较慢echo 需要挂载的bucket名:云存储对应ak:云存储对应sk &gt; /etc/passwd-ossfs #将云存储的ak,sk写入到文件里chmod 640 /etc/passwd-ossfsmkdir /tmp/ossfs #创建挂载文件ossfs 需要挂载的bucket名 /tmp/ossfs -ourl=http://oss-cn-hangzhou-internal.aliyuncs.com #如果不是阿里云就要用外网的endpoint 操作的效果如下，我挂载的bucket叫ligentest，毕竟代码是高度机密，bucket属性设置是私有，256T的容量爽爽的： 配置任务在jenkins里创建一个新的工程，取名叫“构建镜像并且上传到云仓库”。“gitlab更新就触发jenkins”的配置内容可以参考 https://rorschachchan.github.io/2018/05/25/Gitlab-Jenkins搭建持续集成系统/ 一文进行操作。 配置正确jenkins与gitlab各自的webhook，测试提交能返回200之后。就要配置构建和构建后操作。 构建选择执行shell，里面填写这样一个命令：sudo sh /docker/pushimage.sh，也就是运行一个脚本，脚本内容如下： 12345678#!/bin/bash#这个脚本用来推送最新的镜像去阿里云镜像仓库version=$(date +20%y%m%d) #用当前日期作为versiondocker build -f /docker/chenpyfile -t chentest/python:$version . #先本地构建镜像image_id=$(docker images | awk '&#123;print $3&#125;' | sed -n '2p') #获取image的id号docker tag $image_id registry.cn-hangzhou.aliyuncs.com/lechangetest/chentest:$version #给本地的镜像打一个tagdocker push registry.cn-hangzhou.aliyuncs.com/lechangetest/chentest:$version #推送到阿里云对应的仓库去 构建后操作选择钉钉通知器配置，jenkins URL一栏应该默认填好的，即jenkins的网址；钉钉access token这一栏就是直接填机器人的那个access token，然后选择根据什么情景机器人触发通知，如图： 触发验证首先要确认jenkins用户能否正常使用docker命令，方法就是修改一下/etc/sudoers添加jenkins这个用户即可。 这次测试，我们就不搞nginx那种静态页面了，换一个python在后台运行的例子。首先，准备一个叫time.py的脚本，这个脚本很简单，就是不断的输出当前时间的脚本： 123456789101112#!/usr/bin/env python#coding=utf-8import timedef get_time(): localtime = time.asctime( time.localtime(time.time()) ) print (\"本地时间为 :\", localtime) #python的dockerfile用的是latest，python3是要求有括号的if __name__ == '__main__': while True: get_time() time.sleep(1) 对应的dockerfile叫chenpyfile，如下： 123456789101112############################################################# Dockerfile to build A python container images ## Based on Python #############################################################FROM python:latestMAINTAINER ChrisChan \"Chris@jjfjj.com\"RUN apt-get update &amp;&amp; \\ apt-get install -y vim &amp;&amp; \\ apt-get install -y procpsRUN mkdir -p /root/appCOPY /script/ /root/script #把上面那个脚本拷贝到容器里，当然挂载也可以CMD [\"python\", \"/root/script/time.py\"] #这里不要写“python /root/script/time.py”，注意前后台问题 这个dockerfile在本地测试构建镜像是完全没问题的，然后触发一下git push，就会看到钉钉机器人启动了： 构建完毕之后，机器人也会给一个成功的标志，然后去阿里云的云仓库一看，嗯，果然已经推送过来了！如图： 再docker run -dit --name chen-pytest registry.cn-hangzhou.aliyuncs.com/lechangetest/chentest:20180831，也能看到新创建的镜像是可以启动的： 至此整个“Jenkins自动构建镜像并且发送钉钉通知”部分就结束了。 参考资料https://jimmysong.io/posts/kubernetes-jenkins-ci-cd/https://help.aliyun.com/document_detail/32196.htmlhttp://www.cnblogs.com/jianxuanbing/p/7211006.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://yoursite.com/tags/Jenkins/"},{"name":"钉钉","slug":"钉钉","permalink":"http://yoursite.com/tags/钉钉/"},{"name":"Docker","slug":"Docker","permalink":"http://yoursite.com/tags/Docker/"}]},{"title":"K8s的基础操作","slug":"K8s从部署到扩容","date":"2018-08-27T06:25:03.000Z","updated":"2018-08-29T07:14:24.000Z","comments":true,"path":"2018/08/27/K8s从部署到扩容/","link":"","permalink":"http://yoursite.com/2018/08/27/K8s从部署到扩容/","excerpt":"","text":"环境说明kubenetes:阿里云服务，版本v1.10.4，三个master，一个node，我也不知道为啥阿里云设定master最少是3个，而node最少可以是1个…服务器:阿里云Centos 7.4 部署服务首先，我们先部署一个以dockhub最新nginx镜像为底的nginx。命令如下：kubectl run nginx-test --image=nginx:latest --port=80。同理，再部署一个最新版redis的话，就是找葫芦画瓢：kubectl run redis-test --image=redis:latest --port=6379。 两个命令敲完，这就给k8s下达了一个deployment（部署任务），可用kubectl get deployments和kubectl get pods命令查看： 可以看到现在已经生成了对应的pod，而pod里就是容器了，容器里就是对应的服务。如果想爬进这个容器看一下里面的文件等情况，命令是：kubectl exec -it nginx-test-bb95c4645-7qpbj bash。 这里插播一下kubectl get deployment里各参数的含义： 1234DESIRED：对应.spec.replicas，用户设定的期望副本数CURRENT：对应.status.replicas，目前运行的副本数UP-TO-DATE:对应.status.updatedReplicas，包含最新的pod template的副本数AVAILABLE：对应.status.availableReplicas，进入正常状态的副本数 但是现在这个服务是外网无法访问的，因为宿主机还没有一个端口与这个nginx容器的80端口相对应。所以要暴露一个端口给外部用于访问。命令是：kubectl expose deployment/kubernetes-bootcamp --type=&quot;NodePort&quot; --port 80，然后用kubectl get services查看一下效果： 然后在对应的master和node里就看到宿主机随机分配的那个30497端口已经启动了，如图： 在浏览器上访问一下30497端口，果然可以访问到nginx服务： 扩容服务服务嘛，总有高峰低谷。比如微博，突然爆出来哪个娱乐明星的新闻，肯定就会有大量的流量涌入，此时就需要扩容，那么k8s的扩容很简单，就是pod的复制，如果要把上面那个nginx-test的部署任务进行扩展，命令就是kubectl scale deployments/nginx-test --replicas=4，如图： 可见nginx-test又生成了三个pod，与原来的组成了4个pod，而另一个redis的部署任务是没有变化的。 用kubectl get pods -o wide可见，每一个pod分配到了不同的虚拟IP上，而且node都是阿里云的那台node服务器。 在阿里云控制台也能看到里面的情况： 此时进入到node节点，docker ps -a就会看到新的nginx景象生成，同时也生成了三个/pause的容器： kubernetes中的pause容器主要为每个业务容器提供以下功能： 在pod中担任Linux命名空间共享的基础； 启用pid命名空间，开启init进程。 注意！目前kubernetes似乎仅仅支持共享网络，还不支持进程体系、文件系统之间的共享。如果此时在访问，就会看到访问会相对均匀的落到这四个pod中的每一个，起到一个负载均衡的作用。如果高峰期过了，不需要那么多pod了，就kubectl scale deployments/nginx-test --replicas=1，pod就会恢复成1个，据我几次试验，每次都是保留最老的那一个pod。 yaml文件创建一个podK8s的yaml文件的文法和规矩，官方社区就有教程：https://www.kubernetes.org.cn/1414.html 。但是如果要搭配阿里云的私有镜像，需要先参考一下阿里云文档：https://help.aliyun.com/document_detail/86562.html 。注意，这个方法不能在命令行里使用，只能在yaml或者json里用。这里先写一个简单的nginx配置文件pod-nginx.yaml做例子，全文如下： 1234567891011121314151617181920---apiVersion: v1kind: Podmetadata: name: aliyun-nginx labels: app: webspec: restartPolicy: Always #表明该容器一直运行，默认k8s的策略，在此容器退出后，会立即创建一个相同的容器 nodeSelector: zone: node1 #节点选择 containers: - name: aliyun-test-nginx image: registry-vpc.cn-hangzhou.aliyuncs.com/lechangetest/chentest:1.1 imagePullPolicy: IfNotPresent #可选择Always、Never、IfNotPresent，即每次启动时检查和更新images的策略，IfNotPresent是节点上没有此nginx镜像时才执行pull操作 ports: - containerPort: 80 #容器开发对外的端口 hostPort: 33664 #映射到主机的端口/对外映射的端口（一般可以不写） imagePullSecrets: - name: regsecret #这句话为了通过阿里云似有仓库的鉴权 保存退出，再kubectl create -f pod-redis.yaml把这个文件执行一下。然后kubectl get pod看一下效果： 发现我们创建那个redis-pod状态是Pending（等待中），那就是不成功啊。于是就kubectl describe pod/pod-redis查看一下原因，反馈如下： 这个错误的意思是“如果指定的label在所有node上都无法匹配，则创建Pod失败”。原来是我没有配置kubectl label nodes，那先把pod-redis删除，再把nodeSelector那一段去掉，改成nodeName: cn-hangzhou.i-bp1978gmunq3oalfcqlx，去掉再重新create一下。kubectl get pod检查： 然后就是给这个pod增加一个对外的端口。kubectl expose pod/aliyun-nginx --type=&quot;NodePort&quot; --port 80，效果如下： 再去浏览器里，输入node的外网网址：31829看看效果： 配置成功，当然这整个过程也可以在阿里云的控制台操作，更简单更直观，而且阿里云还会自动把对外端口配置到SLB里，具体步骤可以看阿里云的官方文档。 升级与回滚假设我们把nginx-test这个deployment的镜像升级成阿里云私有仓库的1.1版本，那么命令是： 1kubectl set image deployments/nginx-test nginx-test=registry.cn-hangzhou.aliyuncs.com/lechangetest/chentest:1.1 升级之后，kubectl get pod发现有几个节点不正常，如图： 那么这种情况下需要紧急回滚，回滚命令： 1kubectl rollout undo deployment/nginx-test 一会就看到回滚成功了。如图： 参考资料https://jimmysong.io/posts/what-is-a-pause-container/https://blog.csdn.net/mailjoin/article/details/79686937http://pipul.org/2016/05/why-we-need-the-pod-and-service-of-kubernetes/https://www.imooc.com/article/30473","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"容器","slug":"容器","permalink":"http://yoursite.com/tags/容器/"},{"name":"阿里云","slug":"阿里云","permalink":"http://yoursite.com/tags/阿里云/"},{"name":"kubenetes","slug":"kubenetes","permalink":"http://yoursite.com/tags/kubenetes/"}]},{"title":"Centos6.5升级最新内核4.18的坑","slug":"centos6-5升级最新内核4-18的坑","date":"2018-08-25T03:34:59.000Z","updated":"2018-09-29T01:30:24.000Z","comments":true,"path":"2018/08/25/centos6-5升级最新内核4-18的坑/","link":"","permalink":"http://yoursite.com/2018/08/25/centos6-5升级最新内核4-18的坑/","excerpt":"","text":"升级流程开发童鞋要搞BBR，然后让我在他的阿里云服务器上升级一下内核。我登进去一看，centos 6.5，内核还是2.6的。 之前我曾经搞过centos 7升级内核到最新版，文章在此：https://rorschachchan.github.io/2018/06/11/阿里云centos7升级内核过程/ 。centos6升级内核有几个地方不太一样，但是过程差不多。整个升级内核步骤如下： 12345先备份镜像，很重要！！！ 而且备份镜像成功之前，云服务器不可以重启。yum update -yrpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org #导入ELRepo GPG keyrpm -Uvh https://www.elrepo.org/elrepo-release-6-8.el6.elrepo.noarch.rpm #安装 6版本的ELRepoyum --enablerepo=elrepo-kernel install kernel-ml -y #截至本文，最新的是4.18，lt版本是4.4 如果yum的时候有提示Warning: RPMDB altered outside of yum，只需要删除一下yum的历史记录即可：rm -rf /var/lib/yum/history/*.sqlite 。 安装完毕之后，vim /etc/grub.conf，把default改成0，即指定使用第一个内核启动，如图： 然后在阿里云控制台重启一下这个服务器即可。 无法启动？可能有的人直接就启动成功了，因为网络上很多文章到此就结束了。但是我这台服务器，很不幸，出现了问题。在控制台上看服务器是“运行中”，但是无法ssh连接，而且ping也是失败。不一会，控制台的服务器就显示“已停止”，可见是内核出了问题。 联系了阿里的后台，他们反馈这个机器现在的状态是Module scsi_wait_scan not found，那知道了原因就对症下药吧，这个问题解决方法不止一个，我亲测以下的方法好使。 首先先用刚刚做的那个磁盘快照回滚到之前正常的状态，重新执行上面整个安装4.18的内核的所有操作，然后还要补充如下： 123echo 'add_drivers+=\"virtio_blk\"' &gt;/etc/dracut.conf.d/force-vitio_blk-to-ensure-boot.confcp /boot/initramfs-4.18.5-1.el6.elrepo.x86_64.img /boot/initramfs-4.18.5-1.el6.elrepo.x86_64.img-bak #把新下载的4.18的img文件备份dracut -f initramfs-4.18.5-1.el6.elrepo.x86_64.img 4.18.5-1.el6.elrepo.x86_64 #编译生成新的img，4.18.5-1.el6.elrepo.x86_64这个文件在/lib/modules/下 重新在阿里云控制台重启一下这个服务器，这一次就OK了。 发生异常的原因是：更新内核后,在写dracut程序时无法检测KVM&#39;s virtual disk driver &quot;virtio_blk&quot;，此驱动被用于访问KVM虚拟磁盘,dracut没有正常添加新的initramfs module,导致系统没有磁盘访问驱动无法正常启动。 参考资料https://bugzilla.kernel.org/show_bug.cgi?id=60758https://opengers.github.io/linux/linux-source-code-compile-kernel-rpm/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"内核","slug":"内核","permalink":"http://yoursite.com/tags/内核/"},{"name":"BBR","slug":"BBR","permalink":"http://yoursite.com/tags/BBR/"}]},{"title":"Kubectl使用的简单举例","slug":"安装并且配置kubectl","date":"2018-08-22T08:39:41.000Z","updated":"2018-09-10T03:38:06.000Z","comments":true,"path":"2018/08/22/安装并且配置kubectl/","link":"","permalink":"http://yoursite.com/2018/08/22/安装并且配置kubectl/","excerpt":"","text":"安装kubectl在阿里云的Kubernetes界面生成一个新的集群，如图： 但是这个集群是无法通过ssh登陆云服务器那样登录的，这个时候要操作k8s就有两个招数，第一个招数就是用kubectl这个工具去连接到集群。但是kubectl很难搞，因为它所在的storage.googleapis.com在大陆是无法访问的，如果效仿https://www.kubernetes.org.cn/installkubectl 里面的方式去下载kubectl是无法成功的，如图： 为了应付这个办法，就要去kubernete的github界面里下载代码包，然后手动上传到云服务器里安装。 首先到https://github.com/kubernetes/kubernetes/blob/master/CHANGELOG-1.11.md#v1112 里的Client Binaries下载1.11版本的kubectl的包，如图： 将这个包上传到云服务器之后解压缩，然后把kubernetes安装包里的/client/bin/kubectl做一个/usr/local/bin/kubectl的软连接，如图： 如果所在的网络也无法打开github，那么只好用国内的源https://mirrors.ustc.edu.cn/kubernetes/apt/pool/ ，下载相应的包之后手动上传到云服务器里也能达到一样的效果，缺点就是国内源没有github更新的那么快。 配置kubectl阿里云在生成kubernetes集群后，点击管理，最下面会有一个配置文件，将整个文件内容写入/root/.kube/config，然后再一次使用kubectl cluster-info就能看到配置成功了，如图： 再用kubectl config view能进一步看到细节： 这样就证明可以通过kubectl连接到kubenetes集群了。 kubectl基本操作 kubectl get nodes：查看master和worker的基本情况，如图： kubectl run ngx-test --image=nginx:latest --port=8080 --restart=Never：部署一个以nginx最新镜像为底的叫ngx-test的部署，并且开放下面容器的8080端口，每个部署的名称不能重复。部署会自动生成pod，如果加上了--restart=Never，那么pod生成一次失败就不再生成； kubectl delete deployment chen-test:删除一个叫chen-test的部署，注意，使用kubectl命令，要删除拥有该pod的Deployment。如果我们直接删除pod，Deployment将会重新创建该pod； kubectl get deployments：查看部署情况，如图： kubectl proxy: 每个pod在kuber集群里都是一个封闭的网络环境里，可以通过这个命令使API server监听在本地的8001端口上； kubectl get pods：获取每一个pods的基本情况，如图: kubectl describe pods:查看每一个pods的运行细节，可以出来为什么pods没有正常的运行，如果要特别制定具体的pod，那就是kubectl describe pods pod的名称； kubectl exec -it POD_NAME bash:连接到对应的pod里； kubectl get pods -n kube-system:查看NAMESPACE是kube-system的所有pod； 10.kubectl delete pods/kubernetes-dashboard-7b9c7bc8c9-q8425 -n kube-system:删除掉kube-system这个NAMESPACE里kubernetes-dashboard-7b9c7bc8c9-q8425这个pod； 参考资料https://help.aliyun.com/document_detail/64940.html?spm=a2c4g.11186623.4.1.2c4652f3qdpMed （这个是通过ssh访问k8s负载均衡的方法）https://kubernetes.io/cn/docs/tutorials/kubernetes-basics/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"阿里云","slug":"阿里云","permalink":"http://yoursite.com/tags/阿里云/"},{"name":"kubernetes","slug":"kubernetes","permalink":"http://yoursite.com/tags/kubernetes/"}]},{"title":"使用gitlab搭配阿里云容器镜像服务构建镜像","slug":"使用gitlab搭配阿里云容器镜像服务构建镜像","date":"2018-08-15T02:15:44.000Z","updated":"2018-08-23T06:42:56.000Z","comments":true,"path":"2018/08/15/使用gitlab搭配阿里云容器镜像服务构建镜像/","link":"","permalink":"http://yoursite.com/2018/08/15/使用gitlab搭配阿里云容器镜像服务构建镜像/","excerpt":"","text":"工作思路本次北京AWS技术峰会里看到了很多公司在运维上使用容器部署和扩容的实例，一天下来感受良多。现在比较流行部署办法就是“云镜像”：即开发把新的代码提交到gitlab上，然后gitlab与云厂家的镜像服务相关联，然后每一次commit提交都会触发一次镜像的构建，然后再根据这个镜像部署到实际的服务器里，同时将此服务器作一个快照，同时再搭配上容器监控，如果服务吃紧，就用此快照购买实例扩容；如果服务闲余，那么也会自动将最老的服务器实例关机，进而释放退款。 用图像来说就是这个意思： 勾连gitlab与云镜像本文使用的镜像厂家是阿里云，gitlab版本是10.7.3。 进入阿里云的“容器镜像”页面，如果你是第一次使用这个产品需要先建立一个仓库密码，然后点击左侧的代码源，如图： 在gitlab地方选择“绑定账号”，就需要填写对应的栏目： 前两项很好写，最后一个token需要在gitlab里创建：在gitlab的页面，点击个人的头像，然后settings—Access Tokens，填写好名字（生产环境一般都是填运维的账号）然后在api处打勾，生成的那个东东就是token，直接复制填写到阿里云的页面即可。如图： 配置镜像仓库在阿里云容器镜像界面点击“创建镜像仓库”，填写好名字摘要仓库类型之后，在代码源里选择gitlab，由于刚刚填写了token所以是可以看得到gitlab用户下所有的project名的，如图： 然后点击新创建的那个仓库，在构建一栏默认已经选择好了“代码变更时自动构建镜像”，点击“添加规则”，如图： 这里我选择了master分支，然后指明了dockerfile文件名和路径，最后版本号就先写一个version，这个可以通过gitlab在commit时特殊指定。 右侧栏里的Webhook是用来发送提示的，可以在钉钉里创建一个机器人，在创建机器人时会生成webhook，然后把机器人的webhook添加到这个webhook即可。如果在添加的时候提示“当前请求失败，请重试”，这个情况是因为Webhook的名称里有中文，要全英文才可以。 编写dockerfile如果没有dockerfile是无法构建镜像的，于是就在上面“规则”的目录里创建对应的dockerfile文件，注意!“规则”里的根目录就是代码文件夹的顶目录，而不是整个服务器的根目录。写dockerfile的基础知识和语法这里不多说了，网络上有的是，我就随便写一个nginx dockerfile，内容如下： 123456789101112131415############################################################# Dockerfile to build Nginx container images# Based on Debian############################################################FROM debian:latestMAINTAINER ChrisChan \"Chris@jjfjj.com\"RUN apt-get updateRUN apt-get install -y nginx RUN apt-get install -y vim RUN apt-get install -y procps #安装ps命令RUN echo 'HI!WARRIOR is the champion!!!' &gt; /var/www/html/index.nginx-debian.htmlEXPOSE 8080 #开放8080端口COPY /file/kubernetes.tar.gz /mnt/#CMD service nginx start &amp;&amp; nginx -g \"daemon off;\"ENTRYPOINT [ \"/usr/sbin/nginx\", \"-g\", \"daemon off;\" ] 注意！使用上面注释的CMD语句作为结尾的话，那么这个镜像docker run的时候就会马上退出，这是因为把command做为容器内部命令，那么nginx程序将后台运行，这个时候nginx并不是pid为1的程序，而是执行的bash，这个bash执行了nginx指令后就挂了，所以容器也就退出了。简而言之，Docker容器后台运行,就必须有一个前台进程。因为Docker容器仅在它的1号进程（PID为1）运行时，会保持运行。如果1号进程退出了，Docker容器也就退出了。 在gitlab触发之后，阿里云就自动把这个dockerfile build成了镜像保存在阿里云的容器仓库里，如图： 想用这个镜像就可以直接去阿里云的仓库里下载并启动，这样就节省了本地的硬盘容量。最后就是把这个镜像部署到对应的kubernetes集群里，这样就完成了“gitlab代码提交触发阿里云构建镜像”的过程，而如何使用kubernetes的内容将在以后细说。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"http://yoursite.com/tags/gitlab/"},{"name":"持续集成","slug":"持续集成","permalink":"http://yoursite.com/tags/持续集成/"},{"name":"阿里云","slug":"阿里云","permalink":"http://yoursite.com/tags/阿里云/"},{"name":"docker镜像","slug":"docker镜像","permalink":"http://yoursite.com/tags/docker镜像/"}]},{"title":"阿里云Centos7开启swap虚拟内存","slug":"阿里云Centos7开启swap虚拟内存","date":"2018-08-13T03:21:27.000Z","updated":"2018-08-13T06:27:40.000Z","comments":true,"path":"2018/08/13/阿里云Centos7开启swap虚拟内存/","link":"","permalink":"http://yoursite.com/2018/08/13/阿里云Centos7开启swap虚拟内存/","excerpt":"","text":"出差归来，几个开发反馈说gitlab网页卡的不行，上传代码也非常吃力。我登入服务器一看，原来是内存已经耗尽了。 修改配置文件gitlab本身就是一个特别吃内存的软件，服务器还是2核4G的配置。于是我就登陆到gitlab容器里，修改一下/etc/gitlab/gitlab.rb，把unicorn[&#39;worker_processes&#39;]手动改成了3，也就是比CPU大一个，这样可以少开一点进程。但是注意，这个参数最小值是2，如果设置成1，那么gitlab就会崩坏。 保存文件之后，gitlab-ctl reconfigure，看一下内存的情况，嗯，比刚才好一点点。如图： 开启虚拟内存上面那个方法毕竟效果有限，时间长了还是会把内存一点点蚕食光，于是就要使用Swap分区，但是阿里云虚拟服务器默认是不带swap分区的，如何手动创建swap分区才是本文的要点。 这里我用了一个非生产环境的机器做实验。 创建swap分区主要的中心思想就是“创建一个文件，然后将这块文件格式化为swap格式”，首先先看一下当前的磁盘容量： 当前已用磁盘容量是16G，使用cat /proc/swaps看一下当前虚拟内存的情况： 这个情况说明没开启swap，于是就手动建立一个文件夹，比如叫/swaps，在/swaps这个路径下执行dd if=/dev/zero of=swaps bs=512 count=8388616，在这里创建swap大小为bs*count=4294971392(4G)，这个过程需要一点时间，稍等片刻： 通过mkswap swaps命令将上面新建出的swaps文件做成swap分区： 此时使用cat /proc/sys/vm/swappiness查看数值应该是0，需要sysctl -w vm.swappiness=60把它改成60，这里60的含义是：100%-60%=40%，即物理内存剩下40%的时候时启用虚拟内存。若想永久修改，则编辑/etc/sysctl.conf文件，改文件中有vm.swappiness变量配置。 再swapon /swaps/swaps： 最后就是添加开机自动挂载，即在/etc/fstab文件添加如下一句： 1/swaps/swaps swap swap defaults 0 0 再用cat /proc/swaps命令检查一下swap分区是否启动： 最后，重启一下服务器，看一下开机是否正常挂载上这个虚拟分区了： 可见原来使用了16G容量，现在用了20G，这中间差的4G就是拿来做了swap，于是内存就这样多了4个G…","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"http://yoursite.com/tags/gitlab/"},{"name":"虚拟内存","slug":"虚拟内存","permalink":"http://yoursite.com/tags/虚拟内存/"},{"name":"阿里云服务器","slug":"阿里云服务器","permalink":"http://yoursite.com/tags/阿里云服务器/"}]},{"title":"爬取当前IP并且修改阿里云安全组的脚本","slug":"爬取当前IP并且修改阿里云安全组的脚本","date":"2018-08-07T07:01:07.000Z","updated":"2018-10-29T06:00:52.000Z","comments":true,"path":"2018/08/07/爬取当前IP并且修改阿里云安全组的脚本/","link":"","permalink":"http://yoursite.com/2018/08/07/爬取当前IP并且修改阿里云安全组的脚本/","excerpt":"","text":"动机与脚本我工位所用的网络是公司特批的海外专线，速度OK还能翻墙出去看看，自从有了这条线爽的飞起，但缺陷就是每周IP地址都会变，IP一变很多的阿里云ecs安全组就要重新配置，因为有一些公网端口比如grafana或者跳板机是只能公司运维人员访问的。这样每周都要手动改一次IP地址太烦了，于是乎，写了下面这个脚本，一劳永逸的解决这个问题： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#coding=utf-8#这个脚本在python3.6下自验通过，用途是去爬当前的IP地址然后给阿里云安全组添加新的IP，并且删除掉老的IPfrom aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import AuthorizeSecurityGroupRequestfrom aliyunsdkecs.request.v20140526 import RevokeSecurityGroupRequestfrom aliyunsdkcore.profile import region_providerimport requests,sys,re,osfrom bs4 import BeautifulSoupclt = client.AcsClient('这里是AK', '这里是SK', 'cn-hangzhou') #鉴权file = \"F:\\\\ip.txt\"def checkDIR(): global file if os.path.exists(file) == True: #先判断文件是否存在 with open(file, \"r\") as f: old_ip = f.read() return (old_ip) #获取旧ip else: print(\"ip.txt文件不存在，请手动生成！\") sys.exit() #文件不存在直接退出def getIP(): global file r = requests.get('http://www.ip111.cn/') #这里输入要爬的网站域名 soup = BeautifulSoup(r.text, \"lxml\") context = [] for link in soup.find_all('td'): #获取所有td标签内容 context.append(link.get_text()) #添加一个列里 str = context[4] ip = re.split(r'[\\n\\s]\\s*', str)[1] #多符号分割字符串 with open(file, \"w\") as f: f.write(ip) return ipdef addnewRULE(func): global clt # 设置参数 for port in ['3000/3000', '34872/34872']: #这里是端口 request = AuthorizeSecurityGroupRequest.AuthorizeSecurityGroupRequest() request.set_accept_format('json') request.add_query_param('RegionId', 'cn-hangzhou') request.add_query_param('SecurityGroupId', '目标安全组ID') request.add_query_param('IpProtocol', 'tcp') request.add_query_param('PortRange', port) request.add_query_param('SourceCidrIp',func()) request.add_query_param('NicType', 'intranet') #如果不加这句话就是公网添加 if port == '3000/3000': request.add_query_param('Description', 'Grafana使用端口') else: request.add_query_param('Description', 'Zabbix和堡垒机使用端口') # 发起请求 response = clt.do_action(request) print (response)def deloldRULE(func): global clt # 设置参数 for port in ['3000/3000','34872/34872']: request = RevokeSecurityGroupRequest.RevokeSecurityGroupRequest() request.set_accept_format('json') request.add_query_param('RegionId', 'cn-hangzhou') request.add_query_param('SecurityGroupId', '目标安全组ID') request.add_query_param('IpProtocol', 'tcp') request.add_query_param('PortRange', port) request.add_query_param('SourceCidrIp', func()) request.add_query_param('NicType', 'intranet') #如果不加这句话就是公网删除 # 发起请求 response = clt.do_action(request) print (response)if __name__ == '__main__': checkDIR() deloldRULE(checkDIR) getIP() addnewRULE(getIP) 整个脚本的逻辑就是先在F盘下有ip.txt里面就保存当前IP地址，然后执行脚本的时候就会先在目标安全组里删除掉这个IP相关的3000端口和34872端口，然后去www.ip111.cn里爬取当前的网址，把新IP写入到ip.txt的同时，再去目标安全组里添加这个新IP相关的3000端口和34872端口。 新的知识点 把上一个函数结果当作参数在下一个函数里执行的方法： python的退出有两个：os._exit()和sys.exit()：os._exit()会直接将python程序终止，之后的所有代码都不会执行；sys.exit()会抛出一个异常: SystemExit，如果这个异常没有被捕获，那么python解释器将会退出。如果有捕获该异常的代码，那么这些代码还是会执行。使用sys.exit()来退出程序比较优雅，一般情况下也用这个，os._exit()可以在os.fork()产生的子进程里使用。 在windows里定时执行python脚本的方法：打开控制面板—&gt;系统和安全—&gt;计划任务。如图： 点击右侧的创建基本任务，输入任务名称和可选的描述。点击下一步，设置任务的开始时间，可以选择每日执行、每周执行或每月执行。点击下一步，操作选择启动程序，点击下一步输入参数。如图： 123程序或脚本：python.exe 添加参数：输入要执行的python脚本路径（包括文件名）起始于：输入python.exe的目录（不包括文件名） 最后点击下一步，整个过程搞定。 目前http://www.ip111.cn/网站已经更改了网页格式，上述的代码有一段已经不好使了，需要将getIP()这个函数改成如下的方法: 123456789101112def getIP(): global file r = requests.get('http://2018.ip138.com/ic.asp') #改用这个域名 soup = BeautifulSoup(r.text, \"lxml\") context = [] for link in soup.find_all('body'): #获取body内容 context.append(link.get_text()) #添加一个列里 str = context[0] ip = re.split(r'[\\[\\]]',str)[1] #进行分割 with open(file, \"w\") as f: f.write(ip) return ip","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"阿里云","slug":"阿里云","permalink":"http://yoursite.com/tags/阿里云/"},{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"},{"name":"python3.6","slug":"python3-6","permalink":"http://yoursite.com/tags/python3-6/"}]},{"title":"获取网站title的脚本","slug":"获取网站title的脚本","date":"2018-07-31T07:48:40.000Z","updated":"2018-08-13T07:13:26.000Z","comments":true,"path":"2018/07/31/获取网站title的脚本/","link":"","permalink":"http://yoursite.com/2018/07/31/获取网站title的脚本/","excerpt":"","text":"脚本在此公司的商城需要添加一个脚本，这个脚本就是观察首页页面是否正常，虽然已经配置了zabbix监控网站是否200，但是有一些特殊的情况，比如网页可以打开但是页面是“file not found”，类似这样就需要被运维第一时间监控到然后通知开发。 原本我打算直接爬取整个首页然后与服务器里的index.html对比一下，如果不符合就报警，但是跟前端同事说了这个思路之后，前端说服务器上是没有index.html的，因为这个index.html是结合其他的php拼接的。前端说“只要能检测title正常就OK，一般来说title能获取到就证明系统是OK的，如果titleOK但是html内容获取不到就是前段代码的问题，跟系统无关”。于是我就写了这么一个爬虫脚本来获取网站title，如下： 12345678910111213#!/usr/bin/env python#coding=utf-8#这个脚本的用途是用来爬取商城首页title，然后判断是否正常import requests,sysfrom bs4 import BeautifulSoupreload(sys)sys.setdefaultencoding('utf-8') #不然就会UnicodeEncodeError: 'ascii' codec can't encode characters in position 0-4: ordinal not in range(128)r = requests.get('https://www.lechange.com') #这里输入要爬的网站域名r.encoding = requests.utils.get_encodings_from_content(r.content)[0]soup = BeautifulSoup(r.text,'lxml') #这一步需要事前pip install lxmlprint soup.title.string 说一下，如果在from bs4 import BeautifulSoup爆出ImportError: No module named &#39;bs4&#39;是因为安装的库装错了，应该是pip install beautifulsoup4而不是pip install beautifulsoup。启动脚本效果如下： 编码问题上面那个脚本里的soup.title.string的类型是bs4.element.NavigableString，如果不用print那么它的形式是unicode的，如图： 这种现象并不新鲜，比如list在python2里一直都不是正常输出中文的，如图： 可见只有for in的时候才会正常编码，那么这样的情况怎么办？ 最简单的方法，改用python3。不过上面那个脚本是可以直接把中文放到soup.title.string进行判断的。 安装python 3.6.4首先要先安装相关依赖包yum install zlib-devel bzip2-devel openssl-devel ncurses-devel sqlite-devel readline-devel tk-devel gcc make，其中readline-devel这个很重要，他是管方向键的，如果python运行的时候方向键不好使，那么就要yum install readline-devel安装，安装完毕后重新configure和make。 然后过程如下： 1234567891011121314151617yum -y install epel-release #运行这个命令添加epel扩展源#安装pipyum install python-pippip install wgetwget https://www.python.org/ftp/python/3.6.4/Python-3.6.4.tar.xz#解压xz -d Python-3.6.4.tar.xztar -xf Python-3.6.4.tar#进入解压后的目录，依次执行下面命令进行手动编译./configure prefix=/usr/local/python3make &amp;&amp; make install#将原来的链接备份mv /usr/bin/python /usr/bin/python.bak#添加python3的软链接ln -s /usr/local/python3/bin/python3.6 /usr/bin/python#测试是否安装成功了python -V 更改yum配置，因为其要用到python2才能执行，否则会导致yum不能正常使用，需要分别修改/usr/bin/yum和/usr/libexec/urlgrabber-ext-down这两个文件，把他们的#! /usr/bin/python修改为#! /usr/bin/python2。 然后还要给python3的pip3做一个软连接: ln -s /usr/local/python3/bin/pip3 /usr/bin/pip3。 注意！如果你用了python3那么上面那个脚本就会有很大的变动。 参考资料https://www.crummy.com/software/BeautifulSoup/bs4/doc/index.zh.htmlhttp://scrapy-chs.readthedocs.io/zh_CN/1.0/intro/tutorial.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"爬虫","slug":"爬虫","permalink":"http://yoursite.com/tags/爬虫/"}]},{"title":"云服务器的内存竟然少了500M...","slug":"算算内存的这一笔糊涂帐","date":"2018-07-27T07:28:35.000Z","updated":"2018-08-03T05:54:18.000Z","comments":true,"path":"2018/07/27/算算内存的这一笔糊涂帐/","link":"","permalink":"http://yoursite.com/2018/07/27/算算内存的这一笔糊涂帐/","excerpt":"","text":"故障发现今天发现有一台阿里云线上环境的服务器内存在告急，使用free -m一看，果然剩余的内存不多了，而且buffers和cached也都不高，如图： 用top一看，里面的情况是这样的: 很奇怪，top里的res即物理内存加起来也就2200M多一点，但是free命令里显示已经用掉了几乎3.4个G，那这1.2G的空头内存去哪了？要知道，free命令会把Slab缓存统计到了used memory里，那就看看slab缓存有多少吧。 yum install -y nmon，使用nmon看一下，如图： 发现里面有几乎650MB的slab内存，这样还是少了大约550MB，那么使用slabtop查看细节，如图： 再用cat /proc/meminfo去查看一下内存详细情况，如图： https://blog.famzah.net/2014/09/22/know-your-linux-memory-usage/ 这里提到内存的计算公式： 1234MemTotal = MemFree + (Buffers + Cached + SwapCached) + AnonPages + (Slab + PageTables + KernelStack)MemTotal = MemFree + (Active + Inactive) + (Slab + PageTables + KernelStack)MemTotal = MemFree + (Buffers + Cached + SwapCached) + AnonPages + ((SReclaimable + SUnreclaim) + PageTables + KernelStack)MemTotal = MemFree + ((“Active(anon)” + “Active(file)”) + (“Inactive(anon)” + “Inactive(file)”)) + ((SReclaimable + SUnreclaim) + PageTables + KernelStack) 虽然作者说他测试的机器内核是3.2的，但是这几个公式对我这个服务器（内核2.6）都可以用，虽然肯定不能严丝合缝但是相差值并不大，我用前两个公式算了一下我这个机器的情况： 12MemTotal（3495620） = MemFree（251396） + Buffers（11456） + Cached（292324） + SwapCached（0） + AnonPages（2302484） + Slab（627068） + PageTables（8972） + KernelStack（1920） MemTotal（3495592） = MemFree（251396） + Active（2450960） + Inactive（155276） + Slab（627068） + PageTables（8972） + KernelStack（1920） 猜测一下我特么的法克，这个memtotal跟3921112差距很远啊！相差了412MB！为什么会少了这么多？会不会这412MB就是那used memory减去slap内存的那部分神秘内存？他为什么没有统计在/proc/meminfo里？ 于是果断给阿里云提工单，截图发锤，让他们给一个完美的解释。 等待阿里云回复的时间里，我又找了几个其他的机器，各种型号的都算了一下，发现一个现象：凡是装了这个模块的服务器都出现了MemTotal不相符的问题，大约误差值都是400M~500M，而除了这个模块，MemTotal的误差值基本就是50M以内。 呃…这好像不能怪阿里云了…不过的确MemTotal是有误差的啊！ 找开发了解了一下，这个服务器里用了大量的tcp长连接，而且是https的，使用netstat -na|grep ESTABLISHED|wc -l一看，有95000个左右。 而在开发环境的机器里查看，MemTotal的相差率很小，而tcp连接数则不到20个。那用排除法可以确定是TCP长连接的锅，于是我猜测TCP长连接占用掉了一部分内存，而这部分内存又没有在meminfo（SLAB）里体现出来，进而导致free命令与top命令相差过大。 小心求证未完待续… 参考资料http://farll.com/2016/10/high-memory-usage-alarm/#comment-9881http://lday.me/2017/09/02/0012_a_memory_leak_detection_procedure/ （虽然跟本文没啥关系，但是强力推荐）http://blog.yufeng.info/archives/2456http://lovestblog.cn/blog/2015/08/21/rssxmx/https://www.mawenbao.com/research/linux-ate-my-memory.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"内存泄漏","slug":"内存泄漏","permalink":"http://yoursite.com/tags/内存泄漏/"}]},{"title":"使用tqdm制作下载进度条","slug":"使用tqdm添加下载的进度条","date":"2018-07-24T13:04:48.000Z","updated":"2018-07-26T05:55:10.000Z","comments":true,"path":"2018/07/24/使用tqdm添加下载的进度条/","link":"","permalink":"http://yoursite.com/2018/07/24/使用tqdm添加下载的进度条/","excerpt":"","text":"制作进度条既然接手了国内专有云，就要写一个“自动化部署脚本”。于是我就把整个部署的安装包放到阿里云的bucket，用脚本去wget这个部署包，然后进行脚本部署。但是由于这个安装包比较大，`于是就打算在脚本里添加一个“下载进度条”，这样就能了解到当前的下载情况。 google了一下，就发现了tqdm这个库，它声称比老版的progressbar库的单次响应时间提高了10倍以上，安装的方法很简单：pip install tqdm。 具体的用途和参数可以去看https://lorexxar.cn/2016/07/21/python-tqdm/ 这篇文章。 从tqdm的几个参数可见要使用tqdm做下载进度条首先需要整个文件的大小。整个文件的大小可以用requests.get方法获取，获取到header里就有目标的大小。在使用requests模块下载大文件/数据时，建议使用使用stream模式。如果是stream=False，它会立即开始下载文件并放到内存中，如果文件过大，有可能导致内存不足。然后就是把目标文件拆成一个一个的小块，逐步的写入一个文件，这样达到了下载文件的目的。整个脚本如下： 123456789101112131415161718192021#!/usr/bin/env python# -*- coding: utf-8 -*-import requestsfrom tqdm import tqdmdef downloadFILE(url,name): resp = requests.get(url=url,stream=True) #stream=True的作用是仅让响应头被下载，连接保持打开状态， content_size = int(resp.headers['Content-Length'])/1024 #确定整个安装包的大小 with open(name, \"wb\") as f: print \"安装包整个大小是：\",content_size,'k，开始下载...' for data in tqdm(iterable=resp.iter_content(1024),total=content_size,unit='k',desc=name): #调用iter_content，一块一块的遍历要下载的内容，搭配stream=True，此时才开始真正的下载 #iterable：可迭代的进度条 total：总的迭代次数 desc：进度条的前缀 f.write(data) print name + \"已经下载完毕！\"if __name__ == '__main__': url = \"需要下载的文件的地址\" name = url.split('/')[-1] #截取整个url最后一段即文件名 downloadFILE(url,name) 注意！下载文件所在的bucket要设置成“公有读”而不能是“私有”。 补充 解压缩的脚本： 12345import zipfilefilename = '要解压包的路径'fz = zipfile.ZipFile(filename, 'r')for file in fz.namelist(): fz.extract(file, path) 这个脚本即使没有unzip命令也可以执行的。 获取本地IP地址的脚本： 12345678def get_local_ip(ifname = 'eth0'): import socket, fcntl, struct s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) inet = fcntl.ioctl(s.fileno(), 0x8915, struct.pack('256s', ifname[:15])) ret = socket.inet_ntoa(inet[20:24]) return retprint get_local_ip() bpython，这是一个好东西，可以在linux环境下实现类似pycharm的提示功能,搭配tab键补全。安装方法就是pip install bpython，然后启动python的时候直接bpython即可。效果如图： 参考资料https://blog.csdn.net/qq_40666028/article/details/79335961http://blog.topspeedsnail.com/archives/9075https://www.168seo.cn/python/24286.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"可视化","slug":"可视化","permalink":"http://yoursite.com/tags/可视化/"}]},{"title":"将Redhat的yum更换成免费版本","slug":"将radhat的yum更换成免费版本","date":"2018-07-20T06:40:06.000Z","updated":"2018-07-24T01:38:22.000Z","comments":true,"path":"2018/07/20/将radhat的yum更换成免费版本/","link":"","permalink":"http://yoursite.com/2018/07/20/将radhat的yum更换成免费版本/","excerpt":"","text":"RedHat替换yum源这次给吉林移动做一个项目，他们的服务器必须要用IE浏览器登陆堡垒机进行环境部署。我登陆上去一看，是redhat，在使用yum的时候会有如下报错： 这句话的意思是“redhat自带的yum源是需要注册才是更新下载软件的，如果必须注册才能使用”，换而言之就是要收费。卧槽，怎么可能，我们向来是“要钱没有，要命一条”。于是就要用CentOS源来替代yum源，而CentOS源是免费的。 首先先删除掉redhat自带的yum：rpm -qa | grep yum | xargs rpm -e --nodeps。 然后用cat /etc/redhat-release命令去查看一下系统版本，我这个机器的版本是Red Hat Enterprise Linux Server release 6.5 (Santiago)，就去http://mirrors.163.com/centos/6/os/x86_64/Packages/ 下载如下几个文件： 123http://mirrors.163.com/centos/6/os/x86_64/Packages/yum-metadata-parser-1.1.2-16.el6.x86_64.rpmhttp://mirrors.163.com/centos/6/os/x86_64/Packages/yum-3.2.29-81.el6.centos.noarch.rpmhttp://mirrors.163.com/centos/6/os/x86_64/Packages/yum-plugin-fastestmirror-1.1.31-45.el7.noarch.rpm 如果想下载centos 7的就去http://mirrors.163.com/centos/7/os/x86_64/Packages/ 这个网站下，文件名字是一样的就是版本号不一样，需要自己找一下。 然后就是安装这几个包： 123456789rpm -ivh yum-metadata-parser-1.1.2-16.el6.x86_64.rpmrpm -ivh yum-3.2.29-81.el6.centos.noarch.rpmrpm -ivh yum-plugin-fastestmirror-1.1.31-45.el7.noarch.rpmcd /etc/yum.repos.d/wget http://mirrors.163.com/.help/CentOS6-Base-163.repo #最好先备份旧文件sed -i 's#$releasever#6#g' ./CentOS6-Base-163.repoyum clean all #清除原有的缓存yum makecache #重建缓存yum update -y #更新系统 大功告成！可以使用免费的yum去装装装了！ 修复Python-urlgrabber版本过低当执行到rpm -ivh yum-3.2.29-81.el6.centos.noarch.rpm这一步的时候，可能会出现一个python的错误： 1Python-urlgrabber &gt;= 3.9.1-10 is needed by yum-3.2.29-73.el6.centos.noarch 要求python-urlgrabber版本必须大于等于3.9.1-10，而用rpm -qa|grep python查看当前的版本是python-urlgrabber-3.9.1-9.el6.noarch，于是就rpm -e python-urlgrabber-3.9.1-9.el6.noarch卸载掉，wget http://mirrors.163.com/centos/6/os/x86_64/Packages/python-urlgrabber-3.9.1-11.el6.noarch.rpm之后，执行rpm -ivh python-urlgrabber-3.9.1-11.el6.noarch.rpm命令安装即可。 安装完毕，再用rpm -ivh --force yum-*安装后面的内容。如图: 无法解析yum源如果在yum makecache的时候出现了http://mirrors.163.com/centos/6/os/x86_64/repodata/repomd.xml: [Errno 14] PYCURL ERROR 6 - &quot;Couldn&#39;t resolve host &#39;mirrors.163.com&#39;&quot;的错误，如图： 就修改一下/etc/resolv.conf，然后在里面添加一句nameserver 8.8.8.8，保存即可。 NOKEY？？？如果出现Header V3 RSA/SHA1 Signature, key ID c105b9de: NOKEY，可以使用如下方法解决： 123cd /etc/pki/rpm-gpg/ wget http://mirrors.163.com/centos/RPM-GPG-KEY-CentOS-6 rpm --import /etc/pki/rpm-gpg/RPM-GPG-KEY-CentOS-6","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"redhat","slug":"redhat","permalink":"http://yoursite.com/tags/redhat/"},{"name":"yum源","slug":"yum源","permalink":"http://yoursite.com/tags/yum源/"}]},{"title":"Centos7编码安装php7.2和node.js8.11","slug":"centos7编码安装php7-2-7","date":"2018-07-17T07:47:18.000Z","updated":"2018-11-24T05:53:08.000Z","comments":true,"path":"2018/07/17/centos7编码安装php7-2-7/","link":"","permalink":"http://yoursite.com/2018/07/17/centos7编码安装php7-2-7/","excerpt":"","text":"安装php7.2首先先做准备工作： 123yum install -y libpng libpng-develyum install -y bzip2 bzip2-develyum install -y curl curl-devel 编译安装步骤在此： 12345678910111213141516171819cd /root/wget http://101.96.10.64/cn2.php.net/distributions/php-7.2.7.tar.gztar -zxvf php-7.2.7.tar.gzcd php-7.2.7sudo ./configure /--prefix=/usr/local/php727 / #PHP7安装的根目录--with-config-file-path=/usr/local/php727/etc / #PHP7的配置目录--with-apxs2=/usr/bin/apxs #如果用的是nginx就不要这句话--with-gd / #PHP gd模块--with-bz2 / #包含BZip2支持--with-zlib / #包含ZLIB支持--with-curl / #包含cURL支持--enable-mbstring / #启用多字节字符串支持--enable-zip / #包含Zip读写支持--enable-fpm / #启用PHP-FPM进程管理--enable-mysqlnd / #Enable mysqlnd explicitly--with-mysqli / #包含mysql支持--with-pdo-mysql/ #包含mysql支持make &amp;&amp; make install 如果出现了configure error xml2-config not found. please check your libxml2 installation错误，要执行如下两个： 12yum install libxml2yum install libxml2-devel -y 重新去执行./configure那步和make &amp;&amp; make install，整个编译完成之后，再把原带的php.ini拷贝到源码安装的文件夹里： 1cp /root/php-7.2.7/php.ini-development /usr/local/php727/lib/php.ini 设置环境变量，修改/etc/profile文件使其永久性生效，并对所有系统用户生效，在文件末尾加上如下两行代码： 123PATH=$PATH:/usr/local/php/binexport PATHsource /etc/profile 设置php-fpm开机自动启动 1234chmod +x /etc/init.d/php-fpmchkconfig php-fpm oncp /usr/local/php727/etc/php-fpm.conf.default /usr/local/php727/etc/php-fpm.confservice php-fpm start 安装gcc 8.1.0安装node.js需要先安装gcc，但是这个gcc不能用yum install gcc-c++装，因为centos7的gcc版本太低（4.8.5）不满足，在node.js编译的时候会报错：WARNING: C++ compiler too old, need g++ 4.9.4 or clang++ 3.4.2 (CXX=g++)。所以要去https://ftp.gnu.org/gnu/gcc/ 下载一个高版本的，我选择了目前最牛逼的8.1.0。 12345sudo yum install glibc-headers gcc-c++ #编译软件装上，少很多麻烦wget https://ftp.gnu.org/gnu/gcc/gcc-8.1.0/gcc-8.1.0.tar.gztar -zxvf gcc-8.1.0.tar.gzcd gcc-8.1.0./contrib/download_prerequisites #如果tar (child): lbzip2: Cannot exec: No such file or directory，就yum -y install bzip2 此时进入漫长的等待，一会就会出现如下的字样，代表成功安装了! 此时进行编译安装： 12./configure --enable-checking=release --enable-languages=c,c++ --disable-multilib #执行这一步之前系统是有gcc的，虽然版本很低make &amp;&amp; make install 又要进行漫长的等待…这一次非常非常漫长，我当时几乎用了大约2个小时… 然后使用gcc -v检查一下版本： 安装node.js 8.11先去https://nodejs.org/en/download/ 下载新的版本包: 直接下载到linux里解压缩，如下： 12345wget https://ftp.gnu.org/gnu/gcc/gcc-8.1.0/gcc-8.1.0.tar.gztar zxvf node-v8.11.3.tar.gzcd node-v8.11.3./configure --prefix=/usr/local/node/8.11.3make &amp;&amp; make install 此时在make这一步可能会有这样的错误： 这个原因是“升级gcc时，生成的动态库没有替换老版本gcc动态库”，所以要将gcc最新版本的动态库替换系统中老版本的动态库。 使用find / -name &quot;libstdc++.so*&quot;查找编译gcc时生成的最新动态库，发现最近的动态库是这个： 于是就进行替换并作一个软连接: 123456cp /root/gcc-8.1.0/stage1-x86_64-pc-linux-gnu/libstdc++-v3/src/.libs/libstdc++.so.6.0.25 /usr/lib64cd /usr/lib64ll libstdc++.so.6lrwxrwxrwx 1 root root 19 Jul 17 09:59 libstdc++.so.6 -&gt; libstdc++.so.6.0.19 #把原来的记住，防止有回滚的现象rm -rf libstdc++.so.6ln -s libstdc++.so.6.0.25 libstdc++.so.6 然后重新返回到node-v8.11.3文件夹里去make就OK了！ 设定环境变量，vim /etc/profile，在export PATH USER LOGNAME MAIL HOSTNAME HISTSIZE HISTCONTROL一行的上面添加如下内容： 123#set for nodejsexport NODE_HOME=/usr/local/node/8.11.3export PATH=$NODE_HOME/bin:$PATH 保存退出之后，source /etc/profile，再node --version看一下版本是v8.11.3就是OK了！","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"php","slug":"php","permalink":"http://yoursite.com/tags/php/"},{"name":"nodejs","slug":"nodejs","permalink":"http://yoursite.com/tags/nodejs/"},{"name":"gc++","slug":"gc","permalink":"http://yoursite.com/tags/gc/"}]},{"title":"世界杯的一些感悟","slug":"世界杯的一些新感悟","date":"2018-07-12T02:21:00.000Z","updated":"2018-07-16T05:53:44.000Z","comments":true,"path":"2018/07/12/世界杯的一些新感悟/","link":"","permalink":"http://yoursite.com/2018/07/12/世界杯的一些新感悟/","excerpt":"","text":"传控已死？今早英格兰加时赛输给了克罗地亚，至此就剩下一名曼城球员还在本届世界杯继续前进了，那就是法国队的边后卫门迪。再加上之前小组出局的德国和1/8赛输球的西班牙，不得让人怀疑是否“传控已死”？ 传控被瓜迪奥拉发扬光大已经10年了，2008年的西班牙也是靠着传控和巴萨的班底拿下两次欧洲杯和一次世界杯。传控虽然在理论上是一个完美的战术，但是战术也需要人来执行，球员水平有高低状态有起伏，裁判的尺度也不一样，这都会影响传控的比赛结果。这几年的传控逐渐被各路教练针对性研究，他们用“高压迫，快速反击，大巴防守”的套路击败传控的经典战役已经屡见不鲜。所以这几年的传控可谓是磕磕绊绊，风光不再。 传控对中场球员要求很高，一旦球员失去了往前传球的机会，那么就成了无效控球，倒脚来倒脚去时间就走光了。而传统打法对球员的要求相对简单但是对球员身体素质和纪律要求很高，所以更多球队选择了传统打法，而他们也很有针对性的对强队进行了部署，或打高空球或者摆大巴打反击。 我个人通过今年的世界杯和以往的几次欧冠来得到这样的结论：传控没有死，但是传控在杯赛的统治力已经大幅下滑，仅但在联赛和小型杯赛还有一定的优势。原因很简单，联赛是三十多场比赛，容错率要远大于杯赛，这就是传控的好处—虐菜相对来说比较稳。但是最近的足坛趋势是世界杯/欧洲杯/欧冠最大，拿不到上面几个锦标，球员就很难得到金球奖。所以在成绩的压力下，足坛也会慢慢将传控降温，改走传统打法。 即使是442也要有能一脚长传功力的中场做炮台，合适的球员搭配合适的战术才会得到胜利。任何战术本身也要自我修复漏洞，现在的传控队伍也开始慢慢放弃无用的控制，讲究定位球破门和远射破门，但是如何破密集防守还是世界教练共同面对的难题。 决赛怎么看？世界杯决赛肯定是防守为主的低比分比赛。法国那边进攻肯定还是“吉鲁吸引炮火，格里兹曼见缝插针，有反击找姆巴佩，角球任意球上大个子”的常规进攻路线。而克罗地亚也是慢节奏抓定位球的方法。我觉得克罗地亚中场并不虚法国，但是莫德里奇这几年没有跟坎特交手过，可以通过这场决赛看看双方谁更技高一筹。法国这批球员相对年轻，虽然这场比赛他们输不起，但是他们已经有了2016年欧洲杯亚军的惨痛经验，而克罗地亚虽然有些球员没有决赛经验，但是他们心态更放松，比较明显的隐患就是克罗地亚的体能是否能支持他们再一次顶得住法国的炮火。 从2006年至今，三届世界杯都踢了延长赛，所以我个人推荐买常规时间法国赢或者平。 至于季军赛，我觉得凯恩会进球，但是比利时3：2赢下英超内战。 世界杯让足彩也跟着热闹起来。我也跟着潮流买了几场比赛，但是我发现凡是“我跟别人说自己没买的”比赛，结果真中了；凡是我“下注买”的比赛都输了，且不用说德国输墨西哥，日本赢哥伦比亚的冷门战，英格兰打哥伦比亚那场的常规时间最后一分钟，米纳进了一个头球，我直接损失100块… 由此我坚信了，我就不是一个特别有好运气的人，而且也比较害怕成为赌徒，完全符合毛主席对知识分子和小资产阶级的定义，一辈子就是老婆孩子热炕头的命。 中国足球怎么办？每到这种重大足球赛事，国足就要被当作反面典型来说嘴。前几天黄西发了微博调侃遭到国足及相关人士的狂喷，其实喷来喷去，主题就是一个“国足那些球员拿钱多，成绩却这么烂，如何能提高国足成绩？” 其实这个主题是老生常谈，每次都说改革但是也没什么进步，哪怕输给泰国1-5，全国上下一片骂，几天之后涛声依旧… 我个人认为中国足球在20年时间内是不可能强大的，因为这与中国国情有关。 第一，在中国传统教育里，中高阶级就没有那种“把孩子培养成运动员”的想法，毕竟丁俊晖父亲和张玉宁父亲才是少数，更多的父母希望孩子去当医生当公务员做生意，这不仅仅是大陆家庭，香港家庭和台湾家庭也是如此。只有贫苦家庭才会把孩子送去专门搞体育； 第二，为什么中产家庭不希望孩子只是把体育当作兴趣爱好而不是职业？首先现在独生子女太多，家长担心吃苦；其次，搞职业体育是从小开始的，万一踢不出来光阴就白白浪费了，而在发达国家，比如日本，贫富差距没有那么大，而且球员素养相对较高，即使不能大红大紫也不至于饿死，而比如南美部分贫困国家，家里不是独生子女，本来很穷上不起学，踢不出来就继续去搬砖，所以这两种国家的足球成绩不会太烂；再其次，足球青训部分教练素质不高，家长担心孩子跟着学坏； 第三，足球需要青训，而青训需要几代人的时间，但是足协更喜欢速成的方法，这与足球规律相悖，所以搞来搞去钱花了不少却始终原地转圈； 记得“诗人”贺炜在日本与比利时之战之后，发微博羡慕日本足球的同时也说“不多说了，说多了反动”。的确，如果潜规则少一点，贫富差距均衡一点，或许不止是足球，全中国体育的市场化就会有更加显著的改善了。","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"足球","slug":"足球","permalink":"http://yoursite.com/tags/足球/"},{"name":"世界杯","slug":"世界杯","permalink":"http://yoursite.com/tags/世界杯/"}]},{"title":"Mycat读写分离测试","slug":"Mycat读写分离简单测试","date":"2018-07-10T07:31:47.000Z","updated":"2018-07-10T08:48:00.000Z","comments":true,"path":"2018/07/10/Mycat读写分离简单测试/","link":"","permalink":"http://yoursite.com/2018/07/10/Mycat读写分离简单测试/","excerpt":"","text":"配置文件解析前文说了schema.xml文件的前两块内容，真正与读写分离有关的是第三块dataHost内容： 123456&lt;dataHost name=\"mycatTEST\" maxCon=\"1000\" minCon=\"10\" balance=\"3\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\" slaveThreshold=\"100\"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;writeHost host=\"hostM1\" url=\"rm-bp1099x0552q92edr.mysql.rds.aliyuncs.com:3306\" user=\"mycat\" password=\"这里是密码\"&gt; &lt;readHost host=\"hostS1\" url=\"rr-bp1x35g0w6r767eu4.mysql.rds.aliyuncs.com:3306\" user=\"mycat\" password=\"这里是密码\"&gt; &lt;/writeHost&gt; &lt;/dataHost&gt; 这里主要描述的就是逻辑库需要映射的后端真实数据库的情况。某些选项含义如下： maxCon:指定每个读写实例连接池的最大连接。也就是说，标签内嵌套的writeHost、readHost标签都会使用这个属性的值来实例化出连接池的最大连接数; minCon:指定每个读写实例连接池的最小连接，初始化连接池的大小; balance:负载均衡类型，目前的取值有4种： balance=“0”, 所有读操作都发送到当前可用的writeHost上。 balance=“1”，所有读操作都随机的发送到readHost。 balance=“2”，所有读操作都随机的在writeHost、readhost上分发。 balance=”3”，所有读请求随机的分发到wiriterHost对应的readhost执行，writerHost不负担读压力 writeType:负载均衡类型，目前的取值有3种： writeType=“0”, 所有满足规则的写操作轮询的发送到可用的writeHost上。 writeType=“1”，所有满足规则的写操作随机的发送到readHost。 writeType=“2”，所有满足规则的写操作随机的在writeHost、readhost分发。（这一点我很怀疑，写操作怎么在readhost上进行） dbType:指定后端连接的数据库类型，目前支持二进制的mysql协议，还有其他使用JDBC连接的数据库。例如：mongodb、oracle、 spark等; dbDriver:指定连接后端数据库使用的Driver，目前可选的值有native和JDBC，当使用JDBC时则可以这么写：jdbc:mysql://mycatTEST:3306/; switchType:主库切换算法，目前的取值有3种： switchType=”-1”,表示不自动切换 switchType=”1”, 默认值，自动切换 switchType=”2”, 基于MySQL主从同步的状态决定是否切换,心跳语句为show slave status switchType=”3”,基于MySQL galary cluster的切换机制（适合集群）（1.4.1），心跳语句为show status like &#39;wsrep%&#39; heartbeat:这个标签内指明用于和后端数据库进行心跳检查的语句; writeHost &amp; readHost:这两个标签都指定后端数据库的相关配置给mycat，用于实例化后端连接池。唯一不同的是，writeHost指定写实例、readHost指定读实例，组着这些读写实例来满足系统的要求。在一个dataHost内可以定义多个writeHost和readHost(我这里就配了一对，其实可以配很多对)。但是，如果writeHost指定的后端数据库宕机，那么这个writeHost绑定的所有readHost都将不可用。 Demo测试先登陆主库，然后show slave status \\G;命令看一下状态，重点是Slave_IO_Running、Slave_SQL_Running和Seconds_Behind_Master这三个字段，如图： 关注这三个字段的原因是“Mycat心跳机制通过检测他们来确定当前主从同步的状态”，如果Seconds_Behind_Master的数值大于slaveThreshold，读写分离筛选器会过滤掉此Slave机器，防止读到很久之前的旧数据，而当主节点宕机后，切换逻辑会检查Slave上的Seconds_Behind_Master是否为0，为0时则表示主从同步，可以安全切换，否则不会切换。 确认完之后，再去log4j2.xml文件把日志级别改成debug。如下： 123456 &lt;Loggers&gt; &lt;asyncRoot level=\"debug\" includeLocation=\"true\"&gt; &lt;AppenderRef ref=\"Console\" /&gt; &lt;AppenderRef ref=\"RollingFile\"/&gt; &lt;/asyncRoot&gt;&lt;/Loggers&gt; 改完之后重启mycat。登陆到8066端口的mycat逻辑库，先创建一个库，再执行一个写的操作： 12345CREATE TABLE `travelrecord` ( `id` int(11) NOT NULL, `name` varchar(255) NOT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert into travelrecord (id,name) values(5000010,'bengbeng'); 在日志一看，发现这条记录已经被写入了dn2这个datanode里，如下： 日志的意思是：逻辑库收到了insert命令，然后与真实库连接成功并且执行同步命令，con need syn ,total syn cmd 1 commands，之后发送查询sql，因为插入的那个数据是5000000，按照auto-sharding-long的规则，只会记录到db2的分片里。执行完后，会释放mycat逻辑库与真实Mysql连接也就是release connection MySQLConnection和release channel MySQLConnection。 再执行一个读的操作，比如SELECT * FROM travelrecord;，日志是这样记录的： 与schema.xml里的readhost字段对比，的确是从hostS1上读取到的，由于balance=”3”，所以只会从读库读取，由于读的操作db1、db2、db3这3个分片都会操作（需要把他们的内容拼接在一起才是完整的内容），于是日志会打印三遍，实验结束。至于其他的更改参数情况，可以去看参考资料里的第二篇文章，说的很详尽了。 参考资料http://valleylord.github.io/post/201601-mycat-log-analysis/http://codingo.xyz/index.php/2018/03/08/mycat2/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"读写分离","slug":"读写分离","permalink":"http://yoursite.com/tags/读写分离/"},{"name":"数据库中间件","slug":"数据库中间件","permalink":"http://yoursite.com/tags/数据库中间件/"},{"name":"mycat","slug":"mycat","permalink":"http://yoursite.com/tags/mycat/"}]},{"title":"博客评论改用来必力","slug":"博客评论改用来必力","date":"2018-07-09T11:01:09.000Z","updated":"2018-07-09T11:27:24.000Z","comments":true,"path":"2018/07/09/博客评论改用来必力/","link":"","permalink":"http://yoursite.com/2018/07/09/博客评论改用来必力/","excerpt":"","text":"原来我的博客评论用的是hypercomments，但是这几天发现评论已经不能用了，变成了Close discussion，如图： 去https://www.hypercomments.com/en/pricing 发现已经没有免费版了，或者是我这个google邮箱里的免费版hypercomments到期了，于是就琢磨换成来必力吧。 首先先去https://livere.com 注册一个账号，这个来必力是韩国的软件，但是用google翻译就不用怕了，注册很简单，找回密码也很简单。 再去https://livere.com/insight/communite 里选择免费版，然后填写博客的地址和名称，选择个人网站。这个时候会得到一个data-uid，如图： 打开NexT主题的配置文件_config.yml中，搜索livere_uid，将livere_uid前面的#号去掉，将id填写到livere_uid：后面。再找到Hypercomments，把hypercomments_id这一行注释掉即可。","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"http://yoursite.com/categories/博客搭建/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"博客搭建","slug":"博客搭建","permalink":"http://yoursite.com/tags/博客搭建/"}]},{"title":"Mycat配置文件解析与分表存储测试","slug":"Mycat配置文件解析与读写分离测试","date":"2018-07-06T11:51:18.000Z","updated":"2018-07-10T07:42:28.000Z","comments":true,"path":"2018/07/06/Mycat配置文件解析与读写分离测试/","link":"","permalink":"http://yoursite.com/2018/07/06/Mycat配置文件解析与读写分离测试/","excerpt":"","text":"前文已经部署了mycat并且启动，此时登陆到mycat的8066端口，可以看到有一个database，这个database里有几个tables，如图： 这些库和表根本不是我数据库里的啊，那它是从哪里来的呢？前文说了，mycat有一个虚拟库（逻辑库），它会把逻辑库上的操作映射到真实库里，现在8066这个端口就是虚拟库，里面有几个逻辑表，但是这些表其实不是真正存在的。而mycat主要有三个配置文件，分别是schema.xml、rule.xml和server.xml，server.xml就是配置虚拟数据库的账号密码的地方，很简单没什么好说的，rule.xml是分片规则的配置文件，没事别动它。而schema.xml里是主要配置逻辑库和逻辑表的配置文件。 配置文件解析去除掉注释的schema.xml文件是这样的： 可以看到整个配置文件分为三大块，第一块是schema，第二块是dataNode，第三块是dataHost，其中第三块是跟读写分离相关的，所以这里就说前两个部分，先说第二块dataNode： 123&lt;dataNode name=\"dn1\" dataHost=\"mycatTEST\" database=\"db1\" /&gt;&lt;dataNode name=\"dn2\" dataHost=\"mycatTEST\" database=\"db2\" /&gt;&lt;dataNode name=\"dn3\" dataHost=\"mycatTEST\" database=\"db3\" /&gt; 这一段表示该数据库有哪些数据节点，以及这些数据节点实际对应的数据服务器（这个节点跟dataHost的块有关）和数据库名，这里配置了3个节点dn1,dn2,dn3，都是在mycatTEST服务器上，也就是说我们需要在mycatTEST那个服务器，也就是下面writeHost的机器里先创建三个database，分别叫db1,db2,db3。我们在逻辑库上的操作都会分别下发到这三个db里，具体的下发算法在上面schema里有写。 再看第一块schema的内容： 12345678910111213&lt;schema name=\"TESTDB\" checkSQLschema=\"false\" sqlMaxLimit=\"100\"&gt; &lt;table name=\"travelrecord\" dataNode=\"dn1,dn2,dn3\" rule=\"auto-sharding-long\" /&gt; &lt;table name=\"company\" primaryKey=\"ID\" type=\"global\" dataNode=\"dn1,dn2,dn3\" /&gt; &lt;table name=\"goods\" primaryKey=\"ID\" type=\"global\" dataNode=\"dn1,dn2\" /&gt; &lt;table name=\"hotnews\" primaryKey=\"ID\" autoIncrement=\"true\" dataNode=\"dn1,dn2,dn3\" rule=\"mod-long\" /&gt; &lt;table name=\"employee\" primaryKey=\"ID\" dataNode=\"dn1,dn2\" rule=\"sharding-by-intfile\" /&gt; &lt;table name=\"customer\" primaryKey=\"ID\" dataNode=\"dn1,dn2\" rule=\"sharding-by-intfile\"&gt; &lt;childTable name=\"orders\" primaryKey=\"ID\" joinKey=\"customer_id\" parentKey=\"id\"&gt; &lt;childTable name=\"order_items\" joinKey=\"order_id\" parentKey=\"id\" /&gt; &lt;/childTable&gt; &lt;childTable name=\"customer_addr\" primaryKey=\"ID\" joinKey=\"customer_id\" parentKey=\"id\" /&gt; &lt;/table&gt;&lt;/schema&gt; 这一段主要描述了虚拟数据库的schema即TESTDB中有哪些表，以及每个表分布在哪些数据节点上、分布的方法采用哪种算法。其他的选项含义如下： checkSQLschema:当该值设置为true时，如果我们执行语句select * from TESTDB.travelrecord;则MyCat会把语句修改为select * from travelrecord;。即把表示schema的字符去掉，避免发送到后端数据库执行时报（ERROR 1146 (42S02): Table ‘testdb.travelrecord’ doesn’t exist）。这里最好是采用默认的false； sqlMaxLimit:当该值设置为某个数值时。每条执行的SQL语句，如果没有加上limit语句，MyCat也会自动的加上所对应的值。例如设置值为100，执行select fromTESTDB.travelrecord;的效果为和执行select from TESTDB.travelrecord limit 100;相同。需要注意的是，如果运行的schema为非拆分库的，那么该属性不会生效。需要手动添加limit语句； primaryKey:该逻辑表对应真实表的主键，例如：分片的规则是使用非主键进行分片的，那么在使用主键查询的时候，就会发送查询语句到所有配置的DN上，如果使用该属性配置真实表的主键； type:该属性定义了逻辑表的类型，目前逻辑表只有“全局表（global）”和”普通表”两种类型； autoIncrement:mysql对非自增长主键，使用last_insert_id()是不会返回结果的，只会返回0。所以，只有定义了自增长主键的表才可以用last_insert_id()返回主键值。使用autoIncrement=“true”指定这个表有使用自增长主键，这样mycat才会不抛出分片键找不到的异常。这里最好是采用默认的false； rule:该属性用于指定逻辑表要使用的规则名字，规则名字在rule.xml中定义，必须与tableRule标签中name属性属性值一一对应； joinKey:插入子表的时候会使用这个列的值查找父表存储的数据节点； parentKey: 属性指定的值一般为与父表建立关联关系的列名。程序首先获取joinkey的值，再通过parentKey属性指定的列名产生查询语句，通过执行该语句得到父表存储在哪个分片上。从而确定子表存储的位置； 举个例子方便理解，&lt;table name=&quot;employee&quot; primaryKey=&quot;ID&quot; dataNode=&quot;dn1,dn2&quot; rule=&quot;sharding-by-intfile&quot; /&gt;，意思就是“这个employee的表，主键是ID，只在dn1和dn2以sharding-by-intfile的规则存储”。 举个例子按照上面修改了配置文件之后，重启一波mycat，登陆mycat的9066管理端口，使用show @@datanode;和show @@datasource;可以查看到数据库源和datanode已经成功建立了，如图： 手动在阿里云的RDS的读库上创建db1、db2、db3这三个databases，如图： 由于阿里云读写同步，所以只读实例上也有了db1、db2、db3这三个databases。 此时再开一个窗口，登陆mycat的8066端口，看到里面有了TESTDB这个逻辑库以及里面的逻辑表，但是这些逻辑表实际是不存在的，如图： 这时创建employee表，插入数据： 12345create table employee (id int not null primary key,name varchar(100),sharding_id int not null);insert into employee(id,name,sharding_id) values(1,'leader us',10000);insert into employee(id,name,sharding_id) values(2, 'me',10010);insert into employee(id,name,sharding_id) values(3, 'mycat',10000);insert into employee(id,name,sharding_id) values(4, 'mydog',10010); 检查一下数据已经被成功插入，并且如果使用select * from查看的话，会从两个datanode上去查，而且都自动加上了limit 100的字样，这一点符合我们在schema.xml里配置的&lt;table name=&quot;employee&quot; primaryKey=&quot;ID&quot; dataNode=&quot;dn1,dn2&quot;/&gt;和sqlMaxLimit=&quot;100&quot;，如图： 再来到阿里云只读RDS数据库里，检查一下刚刚在虚拟数据库里操作的动作是否被正确映射过来。如图: 可见writeType=“0”已经成功，这就是分表存储。 参考资料https://blog.csdn.net/wangshuang1631/article/details/62898469https://sylvanassun.github.io/2016/07/09/2016-07-09-MyCat/http://codingo.xyz/index.php/2018/02/27/mycat1/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"读写分离","slug":"读写分离","permalink":"http://yoursite.com/tags/读写分离/"},{"name":"数据库中间件","slug":"数据库中间件","permalink":"http://yoursite.com/tags/数据库中间件/"},{"name":"mycat","slug":"mycat","permalink":"http://yoursite.com/tags/mycat/"}]},{"title":"Mycat 1.6.5的部署与启动","slug":"Mycat的部署与简单测试","date":"2018-07-05T03:19:29.000Z","updated":"2018-07-10T06:17:34.000Z","comments":true,"path":"2018/07/05/Mycat的部署与简单测试/","link":"","permalink":"http://yoursite.com/2018/07/05/Mycat的部署与简单测试/","excerpt":"","text":"准备工作先说一下硬件： mycat服务器:阿里云ECS,centos7.4,2核2G1M带宽,外网带宽主要是为了yum安装方便； 数据库主库:阿里云RDS; 数据库读库:阿里云RDS只读实例; 登陆阿里云ECS之后，首先先进行如下操作： 12345678wget http://dl.mycat.io/1.6.5/Mycat-server-1.6.5-release-20180122220033-linux.tar.gz #下载1.6.5版本yum install java-1.8.0-openjdk* -y #安装java 1.8yum install -y mysql #安装mysql客户端useradd mycat #创建mycat用户passwd mycat #更改这个用户的密码tar -zxvf Mycat-server-1.6.5-release-20180122220033-linux.tar.gz -C /usr/local #解压缩/usr/localcd /usr/local/chown -R mycat.mycat /usr/local/mycat/ #设置mycat目录的属主和属组 然后登陆到阿里云RDS读库和写库，看一下大小写是否是“不敏感”,否则可能会发生表找不到的问题，阿里云的RDS默认是不敏感的： 12345678MySQL [(none)]&gt; show global variables like '%lower_case%';+------------------------+-------+| Variable_name | Value |+------------------------+-------+| lower_case_file_system | OFF | #这个是“当前系统文件是否大小写敏感”，只读参数，无法修改| lower_case_table_names | 1 | #这个是“表名是否大小写敏感”，可以修改，改完了重启生效+------------------------+-------+2 rows in set (0.00 sec) Mycat原理和文件结构Mycat的原理跟Atlas查不多，都是用一个虚拟的数据库作为前端，后面是挂上真实的写库和读库。如图： mycat文件夹的文件结构很简单： conf：配置文件； lib：服务依赖的一些jar文件.； logs：日志存储文件夹； bin：可执行命令的地方： mycat的配置文件主要在/usr/local/mycat/conf文件夹里，里面有很多文件，但是主要的配置文件是如下几个： server.xml用来配置虚拟数据库的信息； schema.xml用来配置真实读库写库的信息； rule.xml是分片规则的配置文件，分片规则的具体一些参数信息单独存放为文件；注意！在这个目录下，配置文件修改，需要重启Mycat或者通过9066端口reload才会生效。 首先在打开server.xml，在如下的地方做修改: 123456789&lt;user name=\"root\" defaultAccount=\"true\"&gt; &lt;!-- 这里是给虚拟库设定一个账号叫root，并且作为默认账号 --&gt; &lt;property name=\"password\"&gt;chenx1242&lt;/property&gt; &lt;!-- 账号root的密码 --&gt; &lt;property name=\"schemas\"&gt;TESTDB&lt;/property&gt; &lt;!-- 账号root对应的虚拟库,这个库保持默认比较好 --&gt;&lt;/user&gt;&lt;user name=\"test\"&gt; &lt;!-- 这里是给虚拟库设定一个账号叫test，并且作为默认账号 --&gt; &lt;property name=\"password\"&gt;26e9p69r&lt;/property&gt; &lt;!-- 账号test的密码 --&gt; &lt;property name=\"schemas\"&gt;TESTDB&lt;/property&gt; &lt;!-- 账号test对应的虚拟库,这个库保持默认比较好 --&gt; &lt;property name=\"readOnly\"&gt;true&lt;/property&gt; &lt;!-- 说明这个账号是只读账号 --&gt;&lt;/user&gt; 然后打开schema.xml，编辑如下地方： 12345678910&lt;dataHost name=\"localhost1\" maxCon=\"1000\" minCon=\"10\" balance=\"0\" writeType=\"0\" dbType=\"mysql\" dbDriver=\"native\" switchType=\"1\" slaveThreshold=\"100\"&gt; &lt;heartbeat&gt;select user()&lt;/heartbeat&gt; &lt;!-- can have multi write hosts --&gt; &lt;writeHost host=\"hostM1\" url=\"阿里云RDS:3306\" user=\"账号\" password=\"对应密码\"&gt; &lt;!-- can have multi read hosts --&gt; &lt;readHost host=\"hostS1\" url=\"阿里云只读RDS:3306\" user=\"账号\" password=\"对应密码\"/&gt; &lt;/writeHost&gt; &lt;!-- &lt;writeHost host=\"hostS2\" url=\"localhost:3316\" user=\"root\" password=\"123456\"/&gt; --&gt; &lt;!-- &lt;writeHost host=\"hostM2\" url=\"localhost:3316\" user=\"root\" password=\"123456\"/&gt; --&gt; &lt;/dataHost&gt; 检查好格式并保存之后，就到mycat目录下的/bin/里./mycat start就启动mycat了。启动成功之后，8066和9066都是被监听的，如图： 启动故障排错如果启动mycat失败，可以去logs文件夹里看日志，这里举例几个有代表性的错误： wrapper.log日志：Caused by: io.mycat.config.util.ConfigException: SelfCheck### schema mycat refered by user test is not exist!server.xml里schema最好选择默认的TESTDB，而不是错误里的自己起名的mycat。 wrapper.log日志：org.xml.sax.SAXParseException; lineNumber: 23; columnNumber: 3; The content of elements must consist of well-formed character data or markup去检查一下server.xml的第23行，看一下是不是多了一个’&lt;’或者’&gt;’。 wrapper.log日志：Caused by: io.mycat.config.util.ConfigException: user root duplicated!server.xml里普通账号root，只读账号也叫root，冲突了。 wrapper.log日志：Caused by: org.xml.sax.SAXParseException; lineNumber: 16; columnNumber: 101; Element type &quot;WriteHost&quot; must be declared.schema.xml配置中writeHost写成了WriteHost导致报错。 mycat.log日志如下： 12018-07-06 15:53:22.894 WARN [$_NIOREACTOR-8-RW] (io.mycat.backend.mysql.nio.MySQLConnectionAuthenticator.handle(MySQLConnectionAuthenticator.java:91)) - can't connect to mysql server ,errmsg:Access denied for user '数据库账号'@'本地IP' (using password: YES) MySQLConnection [id=8, lastTime=1530863602566, user=数据库账号, schema=db3, old shema=db3, borrowed=false, fromSlaveDB=false, threadId=4555911, charset=utf8, txIsolation=3, autocommit=true, attachment=null, respHandler=null, host=阿里云写库地址, port=3306, statusSync=null, writeQueue=0, modifiedSQLExecuted=false] schema.xml里把真实库的配置写错了。 mycat.log日志：(io.mycat.net.NIOConnector.finishConnect(NIOConnector.java:155)) - error: java.net.ConnectException: Connection refusedschema.xml的&lt;dataHost&gt;字段是否写入了多余的数据库。 参考资料http://valleylord.github.io/post/201601-mycat-install/https://www.jianshu.com/p/f15d64fcb2f3","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"读写分离","slug":"读写分离","permalink":"http://yoursite.com/tags/读写分离/"},{"name":"数据库中间件","slug":"数据库中间件","permalink":"http://yoursite.com/tags/数据库中间件/"},{"name":"mycat","slug":"mycat","permalink":"http://yoursite.com/tags/mycat/"}]},{"title":"写在阿根廷出局之后","slug":"写在阿根廷出局之后","date":"2018-07-03T01:49:33.000Z","updated":"2018-07-03T02:15:22.000Z","comments":true,"path":"2018/07/03/写在阿根廷出局之后/","link":"","permalink":"http://yoursite.com/2018/07/03/写在阿根廷出局之后/","excerpt":"","text":"桑保利的无奈阿根廷在俄罗斯世界杯的征程结束了，3:4输给法国看上去好像不那么糟糕，但是在姆巴佩下半场的2球时间里，阿根廷的后防线的的确确崩溃了。 一天之后的凌晨，俄罗斯靠点球大战送西班牙回家。很多阿根廷的球迷说阿根廷应该效仿俄罗斯，跟法国摆大巴，靠着偷鸡或者点球胜利。 我个人认为，此方法不可取。虽然阿根廷2014年是靠防守进了决赛，但是这支阿根廷老人更老，新人不牛，而且整支队伍缺乏磨合，纪律性也不够。桑保利深知阿根廷无法保持90分钟的高质量大巴，最多三十分钟。而且大巴阵需要一个高点去压迫对方的后卫，比如穆里尼奥的德罗巴、科斯塔、卢卡库，至少也得有一个能跳又壮的C罗在禁区里搅合，但是伊卡尔迪这次没来，所以桑保利无论是防守还是进攻都无法选择大巴。 所以说，“攻出去”是桑保利无奈的选择，至少这样能死的还壮烈一点。当然，桑保利换上法齐奥是一个败笔，但是最根本的原因还是阿根廷人才断档造成的阵容畸形。 梅西的困局梅西在国家队是不是过得不爽？这是必然的。因为他在巴萨得到的支持远大于他在国家队得到的支持，但是这种支持差以肉眼可见的速度缩小。而且阿根廷的媒体对梅西也是比较苛刻，这就吃了没有好公关团队的亏。 让梅西去踢中场是很暴殄天物的行为，但是现在中场式微，梅西不得不去后撤拿球，甚至还要在边路拿球。我曾经说过，梅西后撤拿球就是慢性自杀，首先他不靠近禁区就无法高质量的射门，其次后撤拿球会让对手更多的容错率去包夹他进而消耗他的体力。这样下来不仅场面不好看，梅西的数据更难看，难免被人黑。不过我还是不明白为什么迪巴拉与梅西无法共存，他俩是位置冲突没错，但是梅西可以踢边路，让迪巴拉去踢前腰/影锋，这个从理论上来说是可行的。 反正在俱乐部解决梅西的问题很简单，砸钱买人即可，但是在国家队，估计要费桑保利的脑细胞了（前提是他不下课），所以说足球是和平年代的战争，表面拼的是场上比分，实际拼的是场下准备。 很多球迷反应说梅西在世界杯上没什么笑容，这让我想起来中日甲午战争的时候，中国船上的洋水手回忆说“中国的海员战斗前摩拳擦掌跃跃欲试，但是中国的军官则是一脸忧虑、若有所思”。事实说明，其实军官是更了解敌我实力差距的，梅西也是如此。但是没有办法，他必须要做打一个很难打赢的战争。 梅罗之争可以说这两个人在俄罗斯的表现都是他们各自在俱乐部七层左右的功力（C罗要高一点），但是这两个人都踢飞了点球，而那个点球原本都可以把他们队伍带到下半区去面对较弱对队伍从而提高晋级的概率，可以说国家队过早出局跟他们有直接关系。 梅西在淘汰赛表现还可以但是在0:3输克罗地亚那一场太过失常，但是C罗这一边也是“高开低走”，不过同样四届世界杯，梅西世界杯6球3助攻，C罗是7球1助攻，大家都没有在淘汰赛进球，的确很巧合。 不过皇马三连冠外加葡萄牙拿到了欧洲杯冠军，让C罗的生涯看起来比梅西完美了很多。明年是巴西美洲杯，现在美洲杯的竞争完全不逊于欧洲杯，小马哥离开的阿根廷想夺冠并不乐观，梅西估计注定无法作为领袖为阿根廷带来一个洲际冠军了。 这两个人都是超级射手，而且不可否认的是他们都需要优秀的中场作为火力支持，以前梅西有“哈白布”大杀四方，而C罗现在有了“克卡莫”也逆转了金球奖总数，所以作为球迷，要认识到这一点：现代足球单打一场或许可以，连续独斗五场以上就是天神下凡了。 不过客观的说，除非内马尔等人能拿到世界杯，不然今年的金球奖还是C罗的，梅西和巴萨需要尽快加油，而加油最有效的方法就是补强中场，加强控制。","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"足球","slug":"足球","permalink":"http://yoursite.com/tags/足球/"},{"name":"世界杯","slug":"世界杯","permalink":"http://yoursite.com/tags/世界杯/"},{"name":"阿根廷","slug":"阿根廷","permalink":"http://yoursite.com/tags/阿根廷/"}]},{"title":"使用xshell做代理查看无公网服务器的WEB界面","slug":"使用xshell做代理查看无公网服务器的WEB界面","date":"2018-06-30T09:28:56.000Z","updated":"2018-07-02T02:17:56.000Z","comments":true,"path":"2018/06/30/使用xshell做代理查看无公网服务器的WEB界面/","link":"","permalink":"http://yoursite.com/2018/06/30/使用xshell做代理查看无公网服务器的WEB界面/","excerpt":"","text":"在工作中经常有一些服务器是高机密的，那么这样的服务器就要与外网隔离。但是没有公网的服务器如果也没有连入到局域网的话，按常理来说是无法打开程序的Web界面。这里则分享一个黑科技—使用xshell做代理然后用浏览器去查看Web界面。 首先要在Xshell顶端菜单栏选择查看—隧道窗格。如图： 此时Xshell的底端就出来一个窗口，然后选择转移规则，如图： 在转移规则右键，选择添加，在添加的窗口里，类型(方向）选择Dynamic(SOCKS4/5)，端口就用默认的1080，备注爱写不写，如图： 来到windows桌面，点击我的电脑—控制面板—Internet选项，打开连接这个标签页，选择下面的局域网设置。如图： 在局域网（LAN）设置里，先在为LAN使用代理服务器前面打勾，然后点击高级，在套接字那里输入127.0.0.1，端口就是刚刚默认的1080，点击确定保存，如图： 此时在浏览器里输入内网的IP地址就能打开这个服务器里Web界面了，比如我公司内部的云存储界面： 不过此时你是完全属于LAN环境，公网是无法访问的。如果要恢复访问公网，那么就要返回到局域网（LAN）设置里，把为LAN使用代理服务器前面的勾点掉就OK。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"},{"name":"xshell","slug":"xshell","permalink":"http://yoursite.com/tags/xshell/"}]},{"title":"Nginx配置防盗链","slug":"Nginx配置防盗链","date":"2018-06-27T06:08:04.000Z","updated":"2018-06-27T06:43:50.000Z","comments":true,"path":"2018/06/27/Nginx配置防盗链/","link":"","permalink":"http://yoursite.com/2018/06/27/Nginx配置防盗链/","excerpt":"","text":"为什么网站们都要限制流量？无论是网站服务器亦或是游戏服务器还是邮件服务器，说穿了也是一台电脑，也有CPU和内存。只不过服务器的CPU功能比个人电脑的CPU功能强大，比如个人电脑的CPU一秒钟能算1亿个数，那么服务器的CPU一秒钟就能算十亿个数。毕竟个人电脑只针对个人，但是服务器是要“接客”的，有了强大的硬件做后盾，网页/游戏/邮箱才不会那么轻易的Down掉。 但是CPU不是人类大脑，人脑是越用越聪明，CPU是越用越磨损，毕竟始终在连电的环境下。于是乎，没有必要的运算能省就省，一个人省一次，十万个人就省十万次，一千万个人就省一千万次，这样达到积少成多的目的。 CPU计算的是各种数据，而这些数据也叫作流量。有用的流量、有价值的流量通过CPU计算无可厚非，但是出现了没有用的流量或者是别人盗用我们的资源，那么这种情况能避免都要避免。什么叫盗用我们的资源，比如自己网站（网站A）上的图片或者视频，被其他人直接复制网站然后粘贴到他们的主页（网站B）上，其他用户登录了B网站，然后点击了那个图片和视频，由于是网址重链接，里外里提供数据的还是我们的服务器。也就是说B网站就是一个中介，而真正提供服务的是网站A，但是广告费和点击率都要网站B赚走了，这事儿实在是叔可忍婶不可忍。 什么是盗链？如何发现被盗链？什么叫盗链，上面已经说的差不多了，如果上面的文字没有看懂的话，举个例子，如果您看到了这两个图片，证明这个网站就是在盗链。 这两个就是一个盗取的是QQ空间的图片，另一个就是百度的图片。用其他网站的图片这事儿本身是无所谓的，只要不涉及版权问题，都希望自己的作品能广泛传播，但是请不要直接通过网址重定向，厚道一点的行为应该是：“图片另存为”，然后到目标网站上去重新上传一下。 这里再多说一点网站的基础知识。 PV值：PV=page view，网站是有少则一个网页多则N多网页组成的一个整体，PV值就是统计用户访问网站的总页数。比如www.JQK.com这个网站，今天有100个用户登录，平均每个用户翻阅了里面5个网页。那么这个网站的PV值就是500。若一个IP地址，对一个页面刷新10000次，PV值也是1.要查询网站的PV值登陆http://www.alexa.cn就行。 Hit值：这个就是对网页里每个元素的点击量，一个网页里的图片就是一个元素，一个flv文件也是一个元素，一首歌曲也是一个元素。这些的总量就是hit值，hit值越高就证明这个网站被人查看的情况越高，那么也证明网站的高人气，那么自然广告也会卖出去很多钱。 因为建网站这事儿关心到了金钱利益，网站越被人关注，自然价值也越大。于是会有一个公式来评判网站的“每日贡献”：总流量=访问流量+下载流量= Page view值 x 页面大小+下载文件大小 x 下载次数。 作为管理者，每天观察一下自己一亩三分地儿的网站数据情况是本职工作。但是有时候也会遇到网站流量很惊人的情况，一般来说，网站流量过大（CPU运转很多）的原因如下： 网站是一个很大的网站：比如说淘宝，京东，网易，youtube，facebook那种大网站，里面成万上亿的网页，而且每天又有那么多人登陆，自然浏览量很大。虽然这些大集团的服务器也是少则几千，多则上万，甚至在不同地区也会有不少的服务器集群，但是这几万台服务器需要提供的数据会很多也是不争的事实。这种现象是正常的。 网页内容太大：可能本身网站是一个小网站，加起来也就十页二十页的内容，但是每一天的流量依旧很惊人，那么很有可能是单页或者某几页的字节太大。比如网页里有太多的图片，太多的视频，太多的其他链接，也有可能是前端码农们给这个网页的规划不合理。导致这个网页每一次被点击都要大费周折（hit值和PV值不高，但是日流量很高），长此以往不仅会耽误用户的整体体验，对服务器也是一个重大伤害。 搜索引擎产生了大量的数据流量：网站需要推广，于是就在各种搜索引擎上打广告，也有自己网站的很多图片用于外部调用。这样的结果就是本身来观摩网站的人很少，但是“借着引擎经过”的人很多，所以就会有PV值不高，但是Hit值和日流量很高的现象出现。 图片或者其他元素被盗链：第一部分就说过了，别人拿我们的图片去吸引别人关注，然后别人想要深入了解，还要来使用我们的服务器去提供详细数据。这种“用我们的牌子住我们的房，吃我们的饭却不给我们钱”的现象实在应该被弄死。这种现象的特征也是PV值不高（没人真正点击网站），但是Hit值和日流量很大（自己服务器的数据都给别的网站提供了）。 网站被DDos攻击了：被一些恶意的IP地址频繁登陆，来回的刷流量。这样迫使CPU做出运算的行为其实就是在远程的破坏服务器的硬件CPU，遇到这种现象，之前Nginx文章里有写，要么通过access.log找到这些IP封掉，要么就在配置文件里加上限制（limit-rate)。 服务器是如何知道图片是从站外而来的呢？在http协议里有一个重要的选项叫refer，这个选项的内容就是该元素的来源地址。如果这个元素是服务器自己提供的，那么头文件里是没有refer这个选项的。通过refer这个信息，我们也可以知道登陆网站的客户是从哪个网站点击链接而来的。这样方便进行一个统计和规划。 假如，我在QQ空间里面发现一个图，然后右键图片，选择在新标签栏里打开图片，这时候通过浏览器审查元素的功能，能查查看请求头信息和响应头信息，发现响应头信息里多了一个refer，里面的内容就是图片的源地址： 我在QQ空间里看腾讯的照片自然是可以的，但是如果我在别的网站里看腾讯的照片，加重了腾讯服务器的负担，自然腾讯公司会不满意。于是腾讯服务器发现当前要引用这个图片的地址与refer头信息不是一个来源之后，就不会把这个图片的数据传送过来，于是就看到那个此图片来自QQ空间，未经准许不可饮用的警告图片。 既然知道了服务器是如何判断文件是否盗链，那么只要伪装一个refer就可以欺骗服务器达到“反防盗链”的目的了。至于这部分，可以自己单独研究。 如何使用Nginx反盗链？同样的使用Nginx.conf，在http的大括号下面，新建一个location，加入如下信息： 12345678910111213141516location ~ .*\\.(wma|wmv|asf|mp3|mmf|zip|rar|jpg|gif|png|swf|flv)$ &#123;#指定对以上几种类型的文件建立防盗链 valid_referers none blocked *.alala.com alala.com;#盗链的范围不包括alala.com和alala.com下的二级网站， if($invalid_referer) &#123; #rewrite ^/ http://www.alala.com/error.html; return403;#如果发现有引用以上文件的地址与refer头信息不符的情况，直接重定向成error.html这个网页，服务器返回403，forbidden。 &#125;&#125; 或者使用第三方模块ngx_http_accesskey_module实现Nginx防盗链。实现方法如下： 下载NginxHttpAccessKeyModule模块文件：http://wiki.nginx.org/File:Nginx-accesskey-2.0.3.tar.gz； 解压此文件后，找到nginx-accesskey-2.0.3下的config文件。编辑此文件：替换其中的$HTTP_ACCESSKEY_MODULE为ngx_http_accesskey_module； 用一下参数重新编译nginx：./configure --add-module=Nginx目录/to/nginx-accesskey,然后执行:make &amp;&amp; make install; 修改nginx.conf文件，添加以下几行： 123456location /download &#123; accesskey on; accesskey_hashmethod md5; accesskey_arg &quot;key&quot;; accesskey_signature &quot;mypass$remote_addr&quot;;&#125; 其中：accesskey为模块开关；accesskey_hashmethod为加密方式MD5或者SHA-1；accesskey_arg为url中的关键字参数；accesskey_signature为加密值，此处为mypass和访问IP构成的字符串。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"防盗链","slug":"防盗链","permalink":"http://yoursite.com/tags/防盗链/"}]},{"title":"给非root开放tcpdump命令权限","slug":"给非root开放tcpdump命令权限","date":"2018-06-22T08:24:11.000Z","updated":"2018-11-06T14:34:18.000Z","comments":true,"path":"2018/06/22/给非root开放tcpdump命令权限/","link":"","permalink":"http://yoursite.com/2018/06/22/给非root开放tcpdump命令权限/","excerpt":"","text":"这周给开发们上了堡垒机，使用的是开源的jumpserver，官网是http://www.jumpserver.org/ 。 注册了账号下发给各位开发之后，开发反馈了一个问题：无法用tcpdump抓包。因为tcpdump默认是只能被root调用的，如果是非root用户使用就会报错：You don&#39;t have permission to capture on that device。 如果要让普通用户也能顺利用上tcpdump，方法很简单，就是对tcpdump这个文件修改成u+s即可。整个过程如下图： 在堡垒机的web界面试一下： 但是jstack这个命令不能按照上面的方法配置给非root用户，因为jstack命令只能是当前java进程的用户才能用。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"},{"name":"安全","slug":"安全","permalink":"http://yoursite.com/tags/安全/"}]},{"title":"Centos6安装git1.9安装过程","slug":"Centos6安装git1-9安装过程","date":"2018-06-13T11:57:55.000Z","updated":"2018-08-06T02:54:58.000Z","comments":true,"path":"2018/06/13/Centos6安装git1-9安装过程/","link":"","permalink":"http://yoursite.com/2018/06/13/Centos6安装git1-9安装过程/","excerpt":"","text":"安装过程Centos 6.x用yum安装git的话，默认是1.7.1。它在执行git push的时候会报错:error: The requested URL returned error: 401 Unauthorized while accessing。这种情况升级git可破。 具体的升级方法如下： 123456789yum install -y curl-devel expat-devel gettext-devel openssl-devel zlib-devel perl-devel #先准备一下环境cd /rootwget https://storage.googleapis.com/google-code-archive-downloads/v2/code.google.com/git-core/git-1.9.0.tar.gz #下载1.9的包tar -zvxf git-1.9.0.tar.gzcd git-1.9.0make prefix=/usr/local/git all #安装到/usr/local里make prefix=/usr/local/git installln -s /usr/local/git/bin/* /usr/bin/ #建立软连接git --version 常用命令随便列举几个常用命令： 123456789git remote add origin http://xxxxxxx #将后面那个网址作为remote的源站git remote rm origin #将刚刚建立的那个源站删了 git pull origin master #把remote的master分支的内容down到本地git reset --hard HEAD #撤销未提交的文件git fetch -p #更新最新的远程分支，如果远程分支已删除，则删除本地对应标记的远程分支git branch -a #查看所有分支git checkout -b feature/test origin/feature/test #在本地新增对应的远程分支并切换到 新增的分支上git branch -D feature/test #删除本地feature/test分支 这个命令慎用，生产环境后期一般留个4,5个版本的release开头的分支,可以通过此命令删除一些早期版本的分支git branch checkout feature/test #通过此命令可以来回切换本地分支，当存在线上代码需要回滚的时候，可以进行次命令切换到之前的release分支 配置忽视文件每一个项目肯定都会有一些不会变的文件，比如日志等，那么这种“不想要加入版本库”的文件就要做一个忽视，这样每一次push或者pull都回节约一点时间。 要对这种“被忽视”文件进行配置，首先要先在git的文件夹里打开.gitignore，把要忽视的文件或者文件夹路径写进去，注意，这里的根目录是git文件夹而不是传统的根目录。然后git add .gitignore，此时git commit -m &#39;添加忽视文件&#39;和git push给远程gitlab提交一个版本，然后到目标文件夹去，git rm -r --cached 要忽视的文件名，然后git status看一下这个文件是否已经被gitlab上删除了，如果真的删除掉了同时本地文件也没有丢失，就可以再一次的git commit + git push，去gitlab网页检查时候这个文件应该就不会出现在网页里了，以后这个文件也不会参与任何的更改。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"Jenkins搭配ansible部署","slug":"Jenkins搭配ansible部署","date":"2018-06-12T08:19:00.000Z","updated":"2018-06-13T11:45:12.000Z","comments":true,"path":"2018/06/12/Jenkins搭配ansible部署/","link":"","permalink":"http://yoursite.com/2018/06/12/Jenkins搭配ansible部署/","excerpt":"","text":"架构流程现在运维组工具里加入了gitlab这个版本控制工具，再加上原有的jenkins和ansible，整个代码模块部署流程如下：1.在代码服务器上push更改的代码到gitlab；2.gitlab通过webhook推送事件到jenkins,触发构建任务；3.jenkins从gitlab将最新代码拉取下来；4.jenkins通过ansible将最新的代码部署到应用服务器；5.推送构建状态到gitlab； 安装ansiblejenkins虽然支持ansible，但是前提是jenkins所在的主机上要有ansible程序，安装ansible的方法如下： 123pip install --upgrade pippip install paramiko PyYAML Jinja2 httplib2 sixpip install ansible #安装的是2.5.4版本 然后需要jenkins服务器与代码服务器之间建立ssh免密码登陆的关系，这里就不说细节了，可以去看一下http://blog.51cto.com/chenx1242/1763978 这个文章。 再去/etc/ansible/hosts手动输入一下授信服务器的IP地址，启动一下ansible看效果： 如果在启动ansible的时候出现了如下的错误： 12/usr/lib/python2.7/site-packages/requests/__init__.py:80: RequestsDependencyWarning: urllib3 (1.21.1) or chardet (2.2.1) doesn&apos;t match a supported version! RequestsDependencyWarning) 那就是python库中urllib3 (1.21.1) or chardet (2.2.1)的版本不兼容，解决办法如下： 123pip uninstall urllib3pip uninstall chardetpip install requests 安装插件登陆jenkins的web页面，选择系统管理—&gt;管理插件，安装如下三个插件：Ansible plugin、Ansible Tower Plugin、AnsiColor。如图： 安装插件并且重启了ansible之后，还是系统管理-–&gt;全局工具配置，找到ansible安装，分别把ansible的路径根据实际情况填写进去，如图： 填写完毕之后保存即可。 配置工程打开某一个project，就用之前在https://rorschachchan.github.io/2018/05/25/Gitlab-Jenkins搭建持续集成系统/ 这个文章里用到的jicheng-test，因为它已经跟gitlab集成了，所以只要gitlab有commit变化，就会webhook到jenkins进行操作。 配置jicheng-test，选择构建这个标签页。在增加构建步骤选择Invoke Ansible Ad-Hoc Command，这里我为了做实验随便写了一点命令，如图： 上面的配置就是先让jenkins输出这个是来自jenkins机器的信息！！，然后启动ansible，对/etc/ansible/hosts里的所有ip机器执行hostname和cd /mnt ; echo &quot;我是你大爷！&quot; &gt;&gt; 321.txt这两个命令。 测试结果前文说了，这个jicheng-test已经做了gitlab+jenkins的配置，所以只要在代码服务器的git文件夹里，执行commit，代码被push到gitlab服务器上的同时也会触发jenkins打包。 于是操作如图： 在gitlab的网页端查看代码已经上传： 再去jenkins里确认是否被成功触发了： 这次操作显示蓝灯，就是OK，点击选择控制台输出，查看一下执行细节： 效果达到！试验成功！ 如果需要回滚，就在jenkins新建一个与gitlab相连的project，切换gitlab的分支，然后重新commit，触发jenkins打包并且ansible部署即可。 故障排错可能在jenkins集成的时候出现如下错误: 12345 代码服务器ip | UNREACHABLE! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;Failed to connect to the host via ssh: Host key verification failed.\\r\\n&quot;, &quot;unreachable&quot;: true&#125; 这是因为jenkins在执行ansible是通过jenkins用户去操作的，虽然我们在安装ansible那一步的时候已经构建了服务器之间的ssh关系，但是那只是root用户的，所以如果没配置jenkins用户的ssh免密码登录，那么sudo su -s /bin/bash jenkins切换到jenkins用户在ssh jenkins@目标IP这一步的时候，会出现如下的提示： 1234The authenticity of host &apos;目标IP(目标IP)&apos; can&apos;t be established.ECDSA key fingerprint is SHA256:Nerx/EZH+ul0/qeb21+ii5EctQ0mO8hijIDlAWEGje8.ECDSA key fingerprint is MD5:6e:d8:6d:17:ca:79:9c:5e:bc:7e:9e:e6:33:41:08:25.Are you sure you want to continue connecting (yes/no)? 因为ansible不会主动帮你输入yes，所以还需要在jenkins用户下把id_dsa.pub文件添加到代码服务器的authorized_keys里，制作一个ssh免密码登录。如果这时候你手动执行一下ssh jenkins@目标IP并且输入yes之后，再重新构建这个project就会发现错误变样了： 12345 代码服务器ip | UNREACHABLE! =&gt; &#123; &quot;changed&quot;: false, &quot;msg&quot;: &quot;Failed to connect to the host via ssh: Permission denied (publickey,gssapi-keyex,gssapi-with-mic,password).\\r\\n&quot;, &quot;unreachable&quot;: true&#125; 原因还是上面的话，由于目标机器上是没有jenkins这个用户的，所以自然也不会存在登录密码，即使用了jenkins用户制作了authorized_keys也是没用，所以需要指定ssh到目标IP的用户，如果是ansible的命令就是ansible all -i /etc/ansible/hosts -u root -m shell -a &quot;具体的shell命令&quot;，但是jenkins里配置root的地方很难找，所以就可以在/etc/ansible/hosts里更改一下，改成如下的样子： 1目标ip地址 ansible_ssh_user=root #指定用root用户登录到目标IP， 这样执行命令就没有障碍了，不过root用户权限过大，实际生产环境还是建立一个更加保险的账号最佳。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://yoursite.com/tags/ansible/"},{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/tags/jenkins/"}]},{"title":"阿里云centos7升级内核到4.17过程","slug":"阿里云centos7升级内核过程","date":"2018-06-11T02:25:59.000Z","updated":"2018-08-25T02:41:52.000Z","comments":true,"path":"2018/06/11/阿里云centos7升级内核过程/","link":"","permalink":"http://yoursite.com/2018/06/11/阿里云centos7升级内核过程/","excerpt":"","text":"docker对内核的支持要求很高，详情可以看：https://www.szyhf.org/2017/01/07/%E9%98%BF%E9%87%8C%E4%BA%91%E4%B8%8Ecentos%E5%86%85%E6%A0%B8%E9%97%AE%E9%A2%98/#comment-54 。文中也有阿里云容器的工程师亲自回复的升级内核的方法，不过他那套是升级内核到4.4，现在已经是4.17了，这里写一下如何升级到最新内核的过程。 而阿里云默认的centos7的内核是3.10的，如图： 首先，安装elrepo的yum源，命令如下： 1234567[root@iZ23pg8sy5bZ ~]#rpm --import https://www.elrepo.org/RPM-GPG-KEY-elrepo.org[root@iZ23pg8sy5bZ ~]#rpm -Uvh http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpm Retrieving http://www.elrepo.org/elrepo-release-7.0-2.el7.elrepo.noarch.rpmRetrieving http://elrepo.org/elrepo-release-7.0-3.el7.elrepo.noarch.rpmPreparing... ################################# [100%]Updating / installing... 1:elrepo-release-7.0-3.el7.elrepo ################################# [100%] 其次是安装最新的内核，命令是yum -y --enablerepo=elrepo-kernel install kernel-ml，如果是要安装长期支持的内核，命令是yum –enablerepo=elrepo-kernel -y install kernel-lt，在一顿噼里啪啦之后，就会出现如下的字样，提示我们已经安装了4.17的kernel内核了： 123456789101112Downloading packages:kernel-ml-4.17.0-1.el7.elrepo.x86_64.rpm | 45 MB 00:00:03 Running transaction checkRunning transaction testTransaction test succeededRunning transactionWarning: RPMDB altered outside of yum. Installing : kernel-ml-4.17.0-1.el7.elrepo.x86_64 1/1 Verifying : kernel-ml-4.17.0-1.el7.elrepo.x86_64 1/1 Installed: kernel-ml.x86_64 0:4.17.0-1.el7.elrepo Complete! centos7内核升级完毕后，还需要我们修改内核的启动顺序，vim /etc/default/grub，修改一处地方： 12345678GRUB_TIMEOUT=5GRUB_DISTRIBUTOR=&quot;$(sed &apos;s, release .*$,,g&apos; /etc/system-release)&quot;GRUB_DEFAULT=saved #把这里的saved改成0GRUB_DISABLE_SUBMENU=trueGRUB_TERMINAL_OUTPUT=&quot;console&quot;GRUB_CMDLINE_LINUX=&quot;crashkernel=auto rhgb quiet net.ifnames=0&quot;GRUB_DISABLE_RECOVERY=&quot;true&quot;~ 接下来还需要运行grub2-mkconfig命令来重新创建内核配置，命令是grub2-mkconfig -o /boot/grub2/grub.cfg，如下： 12345678910Generating grub configuration file ...Found linux image: /boot/vmlinuz-4.17.0-1.el7.elrepo.x86_64Found initrd image: /boot/initramfs-4.17.0-1.el7.elrepo.x86_64.imgFound linux image: /boot/vmlinuz-3.10.0-693.2.2.el7.x86_64Found initrd image: /boot/initramfs-3.10.0-693.2.2.el7.x86_64.imgFound linux image: /boot/vmlinuz-3.10.0-693.el7.x86_64Found initrd image: /boot/initramfs-3.10.0-693.el7.x86_64.imgFound linux image: /boot/vmlinuz-0-rescue-f0f31005fb5a436d88e3c6cbf54e25aaFound initrd image: /boot/initramfs-0-rescue-f0f31005fb5a436d88e3c6cbf54e25aa.imgdone 执行完毕之后，回到阿里云控制台重启一下这个机器，然后查看一下内核情况： 12uname -r4.17.0-1.el7.elrepo.x86_64","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"内核","slug":"内核","permalink":"http://yoursite.com/tags/内核/"}]},{"title":"Grafana配置smtp邮件","slug":"Grafana配置smtp邮件","date":"2018-06-06T11:05:43.000Z","updated":"2018-06-14T01:32:12.000Z","comments":true,"path":"2018/06/06/Grafana配置smtp邮件/","link":"","permalink":"http://yoursite.com/2018/06/06/Grafana配置smtp邮件/","excerpt":"","text":"配置smtp如果要通过grafana接收告警邮件，都需要配置邮箱。而相关配置文件就是grafana.ini，分别要修改如下几个地方： 1234567891011121314151617181920#################################### SMTP / Emailing ##########################[smtp]enabled = truehost = smtp.163.com:465user = 邮箱前缀@163.com# If the password contains # or ; you have to wrap it with trippel quotes. Ex \"\"\"#password;\"\"\"password = 客户端授权密码;cert_file =;key_file =skip_verify = truefrom_address = 邮箱前缀@163.comfrom_name = Grafana # EHLO identity in SMTP dialog (defaults to instance_name);ehlo_identity = dashboard.example.com#################################### Alerting ############################[alerting]# Disable alerting engine &amp; UI features;enabled = true# Makes it possible to turn off alert rule execution but alerting UI is visibleexecute_alerts = true 我采用了网易邮箱，把文件保存退出之后，重启一下grafana-server。然后在页面的alatm页面里配置Notification channels，如图： 如果发送不成功，去查看一下日志，日志地址是/var/log/grafana/grafana.log。如果发送成功了，那么邮箱会收到这样的一个邮件： 邮箱密码问题问题这里要注意几个问题！ 阿里云的服务器出于安全考虑默认是不会开放25端口的，如果你非要用阿里云的服务器去打开25端口，请移步https://www.alibabacloud.com/help/zh/doc-detail/56130.htm ； 如果不想麻烦阿里云那么就要使用其他端口，比如我配置文件里面写的加密的465端口，这个端口不能使用登陆邮箱的普通密码，而是需要填写“授权码”； 以网易邮箱为例，首先先要打开POP3/SMTP服务，如图： 其次然后在客户端授权密码里设置一个新的密码，如图： 然后把这个授权码填写到grafana.ini里，填邮箱的登录密码是错误的。 参考资料http://www.kubiops.com/blog/2017/02/27/Grafana%E5%91%8A%E8%AD%A6%E9%85%8D%E7%BD%AE.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"grafana","slug":"grafana","permalink":"http://yoursite.com/tags/grafana/"}]},{"title":"Gitlab给分支设定权限","slug":"Gitlab给分支设定权限","date":"2018-06-06T06:41:09.000Z","updated":"2018-06-06T11:39:22.000Z","comments":true,"path":"2018/06/06/Gitlab给分支设定权限/","link":"","permalink":"http://yoursite.com/2018/06/06/Gitlab给分支设定权限/","excerpt":"","text":"给gitlab的各位开发设置权限是很重要的，不然他们就可能会偷偷的把执行分支合并甚至git pull来破坏线上环境。 首先先确定在project下各位人员的身份，在设置（setting）–成员(members)里面，可以看到projects现有的用户和用户组，如图： 由于我这个gitlab已经是汉化版的了，这里做一个简单的中英对比：Master是“主程序员”、Developer是“开发人员”、Reporter是“报告者”，这个身份只有读权限可以创建代码片段，一般来说都给测试人员，而Guest就是“访客”了，它只能提交问题和评论。 然后再到版本库（Repository）里选择保护分支（Protected Branches），如图： Allowed to merge就是分支合并权限，Allowed to push就是推送权限，这两个可以根据不同人的身份进行控制。如果受保护，除了master权限的人员，其余人都不可以push、delete等操作。默认情况下master分支是处于被保护状态下的，developer角色的人是无法提交到master分支的。 如果是docker的话，那么gitlab权限问题修复会用到如下命令： 12docker exec -it gitlab update-permissionsdocker restart gitlab容器的ID","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"}]},{"title":"解决Waiting(TTFB)过长的问题","slug":"解决Waiting-TTFB-过长的问题","date":"2018-06-04T08:51:13.000Z","updated":"2019-03-13T09:37:28.000Z","comments":true,"path":"2018/06/04/解决Waiting-TTFB-过长的问题/","link":"","permalink":"http://yoursite.com/2018/06/04/解决Waiting-TTFB-过长的问题/","excerpt":"","text":"正文电商平台整套系统是从上海商派公司（ecshop）那里购买的整套代码，结合我们公司自己的二开功能的3.0版本在上周几经波折终於部署上去了，经过了一个周末之后，今天市场运营的人在微信群里叫：“官方网站打开速度好慢。”果然整个官网首页要5~6秒钟才打得开，这个显然是不能忍受的，使用F12查看细节，发现Waiting(TTFB)的时间非常长，如图： 正常来说TFFB时间通常建议在200ms以下，如果超过推荐值，会引起队列中其他资源下载都跟着变慢。TFFB高主要有两个原因：一是客户端和服务器之前网络情况比较差；二是服务器应用响应比较慢；第三：重定向太多，重定向跟TFFB时间成正比。 于是乎检查网络情况以及各应用负载情况，都是OK的，重定向也很少。那么就减少DNS查询，把所有能用IP的地方都替换了域名，比如nginx的localhost里使用对应服务器的域名而不是127.0.0.1，比如在配置文件里的阿里云的数据库和redis都用IP地址替代。然而收效甚微，该慢依旧是慢。 这个时候就返回到后台去查看，左翻翻右翻翻，最后找到了这个地方，如图： 启动全页缓存，一切就都好了… 补充故障前端妹子跑来问一个问题，界面上一个1.1k的js文件，为什么加载用248ms？如图： 可见大量时间都用在了Content Download上，但是这个文件明明已经很小了。况且旁边还有150K左右的文件也用了不到80ms，可见应该不全是网络传输慢那么简单。 看了一下这个js的细节，发现这个js需要去访问阿里云的OSS资源。如图： 是不是时间花费在访问资源上了呢，于是我单独访问一下这个png图片，发现单独访问的时间根本不长： 这个js已经没有压缩的余地了，那么究竟是什么这么消耗时间？这个我要慢慢查，先把问题记录一下… 参考资料https://www.oschina.net/question/244077_221319","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"}]},{"title":"Centos7安装zabbix3.4全过程","slug":"Centos7安装zabbix3-4全过程","date":"2018-06-04T03:15:14.000Z","updated":"2019-10-21T14:12:30.000Z","comments":true,"path":"2018/06/04/Centos7安装zabbix3-4全过程/","link":"","permalink":"http://yoursite.com/2018/06/04/Centos7安装zabbix3-4全过程/","excerpt":"","text":"安装zabbix-server 3.4本文以centos 7为例。 123456789101112131415161718systemctl stop firewalld.service #关闭防火墙systemctl disable firewalld.service #开机不启动防火墙setenforce 0 #清空selinux的配置 yum install mariadb-server mariadb –ysystemctl enable mariadb #设置开机启动systemctl start mariadb #启动MariaDBrpm -Uvh http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-agent-3.4.5-1.el7.x86_64.rpmyum install zabbix-server-mysql zabbix-web-mysql -yzcat /usr/share/doc/zabbix-server-mysql-3.4.9/create.sql.gz |mysql -uzabbix -pzabbix zabbix #这里是设定zabbix数据库账号密码和database的地方，create.sql.gz这个文件位置要根据实际情况来vim /etc/httpd/conf.d/zabbix.conf #这里要修改文件里的时区，改成Asia/Shanghaisystemctl start zabbix-serversystemctl enable zabbix-server setsebool -P httpd_can_connect_zabbix onsetsebool -P httpd_can_cetwork_connect_db onsystemctl start httpd systemctl enable httpdchkconfig zabbix_agent onsystemctl start zabbix-agent 然后就是在浏览器输入外网IP/zabbix/进行页面安装了，剩下的就不多写了。 如果打开WEB网页是如下的样子： 请检查php-fpm的版本。 安装zabbix-agent 4.0如果是centos 6: 123rpm -Uvh https://repo.zabbix.com/zabbix/4.0/rhel/6/x86_64/zabbix-release-4.0-2.el6.noarch.rpmyum install -y zabbix-agentchkconfig zabbix-agent on;service zabbix-agent start #如果不对就使使zabbix_agent 如果是centos 7: 123rpm -Uvh https://repo.zabbix.com/zabbix/4.0/rhel/7/x86_64/zabbix-release-4.0-2.el7.noarch.rpmyum install -y zabbix-agentchkconfig zabbix-agent on;service zabbix-agent start #如果不对就使使zabbix_agent 安装Graphtree虽然官方说Graphtree只维护到3.2版本，但是经过我测试3.4依旧可用。安装方法如下： 12345首先进入到zabbix的html页面的文件夹yum install patch -ywget https://raw.githubusercontent.com/OneOaaS/graphtrees/master/graphtree3.0.4.patchpatch -Np0 &lt;graphtree3.0.4.patchchown -R apache.apache oneoaas #如果是nginx，那就是www.www 刷新一下zabbix-server即可发现Monitoring下面多了一个Graphtree，如图： 点击即可查看。 其他资料https://www.kaijia.me/2014/11/zabbix-report-lack-of-free-swap-space-issue-on-server-without-swap-solved/https://blog.csdn.net/sinat_15955423/article/details/76685878 (centos6.x安装php5.6+gd库+bcmath库)https://www.sundayle.com/zabbix-monitor/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"}]},{"title":"记录一次阿里云负载均衡端口监听不正确的过程","slug":"记录一次阿里云负载均衡端口监听不正确的过程","date":"2018-05-30T19:49:06.000Z","updated":"2018-05-30T20:28:46.000Z","comments":true,"path":"2018/05/31/记录一次阿里云负载均衡端口监听不正确的过程/","link":"","permalink":"http://yoursite.com/2018/05/31/记录一次阿里云负载均衡端口监听不正确的过程/","excerpt":"","text":"在阿里云上新配置了一个负载均衡，后面挂载的服务器上安装了一个nginx，分别开启了80端口和8080端口，其中80端口是给http访问的，8080端口是给https访问的，同时在8080端口上做了http跳转https的配置。 但是在负载均衡配置完毕之后，发现tcp的80转8080是OK的，但是https的443转80却始终不OK，网页也自然打不开，但是在nginx上看80端口的确是在stand by： 而且安全组都做了配置，telnet端口也是完全没有问题的，如图： 执行了一下time curl -I -X HEAD SLB的域名 -x http://本机IP地址:80看一下效果，如图： 可见命令执行OK，但是耗时需要7秒，而默认的阿里云SLB在https监听的超时时间设定是5秒，怀疑是后端ECS上对head头响应慢导致的健康检查失败。然后在网页上使用“检查”功能，发现有几个js、css文件耗时很长，于是就叫前端的码农们配合查一下，在几位前端吭哧吭哧解决了这个问题之后，https访问恢复正常。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"阿里云","slug":"阿里云","permalink":"http://yoursite.com/tags/阿里云/"}]},{"title":"苹果手机无信用卡注册区美国apple store的办法","slug":"苹果手机无信用卡注册区美国apple-store的办法","date":"2018-05-30T12:14:46.000Z","updated":"2018-05-30T20:11:26.000Z","comments":true,"path":"2018/05/30/苹果手机无信用卡注册区美国apple-store的办法/","link":"","permalink":"http://yoursite.com/2018/05/30/苹果手机无信用卡注册区美国apple-store的办法/","excerpt":"","text":"这次去霓虹国在心斋桥Apple体验店买了一个256G的iphone X，由于政府政策的原因，中国区的apple store有很多应用是没有的，于是乎我就打算注册一个美国版的账号，从而登录美国版的apple store去下载那些“你懂得”的app。 首先先登录https://www.apple.com/ ，在网页最下面先确定国家是United States，然后点击Manage Your Apple ID，如图： 在https://appleid.apple.com/#!&amp;page=signin页面里，点击Create your Apple ID建立一个新的apple账号，名称正常写，国家还是United States不要动，生日如实填写，但是如果是未成年人的话，有些成人的app是不可以被下载的。然后就是写好自己的登陆问题，这个问题已经要记住，每次登陆都要输入，忘记的话就麻烦了。注册账号这里其他部分我就不多说了。 账号注册完毕之后，就直接在苹果网站上登录，登录之后，就会看到账号的详细信息，在Payment &amp; Shipping的地方点击Add Payment Method…，如图： 这里有一个PAYMENT METHOD的地方，要填写none，如果你用apple手机上登录这个账号的话，这里是不能选none的，无论是Dr.还是Mr.都没有none这个选项，所以说一定要在网页登录账号。然后就是需要你填写一些用户地址、邮编等信息，由于是账号注册时候选择的是美国，那么也需要填写美国的地址，可以在http://www.haoweichi.com/Index/random里生成一个身份信息填写。如图： 下面那个SHIPPING ADDRESS就是账单邮寄的地址，想填就填，不想填就放那。填写好了之后点击save，但是目前这个账号还是不能通过的，如果你在apple手机登录了这个账号然后登录apple store的话，会有一个提示：该账号没有被使用过，请填写细节。 这里如果你还手机上操作填写细节，发现你刚刚在电脑上填写的地址和邮编已经同步到手机的账号了，但是支付卡那一栏还是没有none，也就是说依旧要一个信用卡。此时请在电脑上下载itunes，然后在电脑的itunes里登录这个美国区账号，由于电脑itunes里的支付渠道依旧可以选择none，所以我们可以在这里绕一个弯，使用itunes这个渠道来完成这个美国区账号的彻底注册。 在itunes把整个账号完整过程都注册完毕之后，再登录到手机端，就可以在美国的apple store里尽情的下载app了！","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"apple","slug":"apple","permalink":"http://yoursite.com/tags/apple/"}]},{"title":"超赞的京都大阪五日游","slug":"超赞的京都大阪五日游","date":"2018-05-25T07:34:25.000Z","updated":"2018-08-25T08:47:20.000Z","comments":true,"path":"2018/05/25/超赞的京都大阪五日游/","link":"","permalink":"http://yoursite.com/2018/05/25/超赞的京都大阪五日游/","excerpt":"","text":"说来惭愧，活了30年了这是我第一次出国旅行，借着公司有一次旅游的机会就跟女朋友一起到京都和大阪玩5天。 搞定了签证，在网上买好了USJ的快速通行票，又预定了随身WIFI，简单在穷游、知乎和马蜂窝上做了做自由行的攻略，18号晚上6点半从杭州萧山机场出发，两个小时后到达关西机场。之前在《miss pilot》里看到过ANA的航空，这一次亲自乘坐感觉还是不错，飞机场有吃有玩还有葡萄酒喝。 到关西机场之后，又按指纹又照相的通过了一连串的海关检查，就跟公司其他小伙伴兵分两路，他们去奈良看鹿，我跟女票直接去京都。凭借女票的三脚猫日语功力和她以前来过大阪的经验，我俩先办理了地铁卡，又购买了一日游行卡，最后坐上了从大阪出发到京都的新干线。 从大阪到京都大约花了一个半小时左右，抵达京都已经是晚上11点了。路上下着细细小雨，再加上两人拖着箱子有点肚饿，就在路边的seven-eleven里简单买了一点水和东西，买东西之余发现在超市里有成人书籍出售。从便利店出来顺着google地图找之前在爱彼迎上预订的民宿，那是一个公寓型民宿，凭借店主之前在邮件里写的密码，我们从信箱里拿到房间钥匙，顺利入住。 日本的庙京都是一个充满寺庙和神社的地方，京都的旅行也就是“从这个庙出来，到下一个庙去”，而清水寺正是京都众多庙里人气很旺的景点之一，日本的庙和神社有一个习惯，入寺前先用竹勺洗手，如果要入室参拜的话还要脱鞋。在京都穿和服是一个很常见的事情，而且我觉得一群人穿和服是一个蛮cool的风景，不过女票没有租，但是在寺里买了很多的御守。 昨晚到京都太晚，无法注意天空，到了白天才发现京都的天真的很蓝，看见远方的山轻而易举。从清水寺出来下一站是八坂神社，巧的是遇到了一对新婚夫妇在这里结婚拍照，不得不说日本新郎传统的黑和服加扇子的形象还是很帅的。 日本的玩水族馆是我非常喜欢的地方，而大阪海游馆也是这次游玩里安排的重要环节之一，但是比较让我失望的是它的海底隧道很短，大约也就杭州水族馆的一半长度。我俩没有看到喂食节目，而且海游馆也没有海豹顶球，海豚跳舞这样的节目。不过海游馆的鱼种类还是很多的，有些品种还可以亲手去摸一摸它们。出了海游馆就是一个蛮大的摩天轮，用一日通票的话可以免费上去坐一圈。 大阪的USJ是我们这次日本之行的最后一站也是最高潮的部分，去年圣诞节我跟女票在上海的迪士尼度过的。从迪士尼回来她就一直碎碎念大阪的环球影城，我俩还特意挑选了一个工作日去玩就是为了尽可能的少排队，但是那天依旧很多很多人，真的超火爆。 环球影城的运营模式跟迪士尼差不多，通过IP分主题区，可以购物也有花车游行。但是整个乐园的玩法相对单一—-都是过山车：哈利波特是过山车、蜘蛛侠是过山车、小黄人是原地晃晃过山车、侏罗纪公园是水上过山车，至于翼龙飞行和好莱坞美梦更是超刺激的过山车… 这一次环球影城的特殊项目有四个：怪物猎人、美少女战士（看动画片）、柯南（密室逃脱）和最终幻想。我跟女票还有公司同事都选择了柯南，虽然通篇日语对白，不过还是能猜出来一个大概剧情，所以一个半小时玩下来感觉就像看了一遍柯南的剧场版，里面的解密就不剧透了，机关真的很难，想要在一个小时内完全逃脱几乎是一个不可能的任务。 上面把正经的娱乐说完了，下面来说一点不正经的娱乐。我和女票在大阪住在日本桥地铁站附近，那里距离道顿堀走路也就10分钟的路程，而道顿堀附近有一个街叫宗右卫门町，那里就是大阪有名的牛郎街，一路走过去各种牛郎宣传大海报和在路边搭讪的小哥，甚至那附近的小吃店里还有牛郎哥的宣传单。除了铺天盖地的牛郎哥哥外还有站街的妹妹，大多数都是黄发浓妆，但是仔细看脸都不算太好看的。这些人会跟过往的单身男女搭讪，邀请他们去店里坐坐喝点酒说说话，至于有没有更进一步的皮肉关系，那就不好说了。而且据说他们是不做不懂日语人的生意的，所以如果他们真的纠缠你了，就直接说我是外国人就好。 日本的购物到了日本，买东西是必然的。不过当地的大商场关门很早，基本晚上八点半左右就开始关门。在伏见稻荷大社甚至有的商铺五点半就打烊了，我很好奇，商场这么早关门，那日本人晚上的娱乐是什么呢？他们除了去居酒屋喝酒和广场溜达再加上回家看电视难道就没有其他的娱乐了吗？ 不过，各大药妆店的营业时间很晚，甚至唐吉坷德是24小时营业。这种地方里充满了大陆人、香港人、台湾人、韩国人还有泰国人，在人群和背包中穿梭，拎着篮子买买买，买到5000就可以退税。我女票这次买了很多的卸妆水乳液面膜眼霜口红还有零食，作为一个在旁边无事可做的男人，深深地觉得陪女人逛街是一个很遭罪的事情。 日本的吃我是看过《深夜食堂》和《孤独的美食家》的，所以对日本的食物有一点好感，而且在杭州吃到日本料理也不是一个难事。不过这次到了日本，连续吃了五天当地的饭，发现日本的菜其实很单一。 日本普通的餐就是“米饭+猪肉\\牛肉\\鸡肉+沙拉+味增汤”，日本的米饭是很好吃的，但是他们的肉做法基本就是炸，炒是很少的。如果不是米饭的话就是炒面、拉面、寿司或者是煎饺。期间我跟女票吃了一次烤肉，里面有“最强牛里脊和牛肠”给我留下了很深的印象。此外在海游馆还吃到了我梦寐已久的大阪烧，插播一句话，吃大阪烧的时候还看到足球运动员郑大世，我女票一眼就认出他来了… 日本的消费能力不低，五天下来，基本上每一顿饭都大约花费了3000多日元，在吉野家吃算比较便宜的，2000不到就能搞定。在烤肉店要了套餐，每人是5000日元。这次在日本，觉得最好吃的是牛里脊，然后就是烤蟹壳。 说完了吃再说说喝，大阪和京都随处可见自动售卖机，售卖机里面基本就是五样饮品—水、绿茶、优酸乳、可乐和咖啡，价钱还都差不多。日本的水果很贵，一个不到6斤重的西瓜就要2200日元左右，橘子大约五块钱一个，但是他们的酒却相比较便宜。在日本我可没少喝梅子酒、气泡果酒和啤酒。 日本的电视我俩住的民宿有一个小电视，里面有12个频道，其中三个是购物频道…我想可能日本的免费电视就这么点，大多数都是收费频道。这九个电视台白天有新闻，有韩剧，有街头采访；晚上有芭蕾舞片段、有综艺节目、还有打着圣光的肉番！说到综艺节目，里面有一个片段就是把秃头用毛巾擦的锃亮，然后用遥控板去对着秃头摁键，结果信号经过秃头的折射，竟然能顺利的操纵电视。再后来叫来两个秃头，尝试多次折射，依旧可以准确遥控电视…就这么一个环节把我之前从来不看日本综艺节目的同事笑翻了，回国后就开始恶补这种日本综艺。 游玩的tips1.日本路边的垃圾箱很少，据说是因为他们没有边走路边吃喝东西的习惯，所以随处带一个塑料袋来装垃圾；2.USJ的快速通行证只有日语区的页面才有，请准备好visa和master卡；3.办理的地铁充值卡不要扔，下一次再来日本，直接储值依旧可以使用；4.到了USJ别上来先买东西，要先排队玩，东西可以放到最后出院的时候再买；5.不会日语在一般情况下没问题，但是如果看不懂车站的话，就难免要问路了，这样会比较头疼，准备一个google翻译。6.champion在日本的地摊也有卖，人民币大约100多，所以淘宝上那些200左右的champion完全不需要考虑… 这次的遗憾这次玩的蛮爽的，但是大阪仅仅只有三天只能玩一个皮毛，比如本次出游的遗憾如下： 1.据说大阪有一个棒球场，20日元一个球，然后通过发球机器发射，游客可以轮棒尝试一下本垒打的快感，但是由于时间太紧没有打上棒球…2.没有去游戏机厅，以前常在漫画里看到日本有那种弹子机，如果赢的多，可以用塑料筐装满小弹子去换钱，这种游戏机厅在大阪的商场很常见，而且门口都有大广告，上面写“新品到店，欢迎畅玩”；3.在龟梨和也和山下智久主演的《我命中注定的人》里，龟梨和也手工雕刻了一个王将的木牌，这次到了大阪逛了很多店，都没有发现这款木雕，不仅没有这个木雕，连战国时期各大将的头盔纺织品也没有看到，这一点很遗憾；4.USJ里的变形金刚和终结者2都暂时停业，不过我后来在B战上看了视频，还是过山车… 等下一次如果有机会能去东京的话，就尝试把上面几个弥补上，再顺便去一趟秋叶原。","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"旅游","slug":"旅游","permalink":"http://yoursite.com/tags/旅游/"},{"name":"日本","slug":"日本","permalink":"http://yoursite.com/tags/日本/"}]},{"title":"Gitlab+Jenkins搭建持续集成系统","slug":"Gitlab-Jenkins搭建持续集成系统","date":"2018-05-25T07:33:46.000Z","updated":"2018-06-13T11:41:50.000Z","comments":true,"path":"2018/05/25/Gitlab-Jenkins搭建持续集成系统/","link":"","permalink":"http://yoursite.com/2018/05/25/Gitlab-Jenkins搭建持续集成系统/","excerpt":"","text":"前言gitlab是一个应用很广泛的版本控制工具，他也有自带的持续集成工具—gitlab cli，但是这个工具不如jenkins那么好用。本文的目的要把gitlab和jenkins进行结合，当我们更新了代码并且把代码push到gitlab的时候，gitlab会把代码的变化通知到jenkins，然后jenkins就会自动构建project。 说一下实验环境：Jenkins所在服务器IP：121.41.37.251(10.168.173.181)，版本是2.124(查看jenkins的版本语句java -jar /usr/lib/jenkins/jenkins.war --version);Gitlab所在服务器IP：114.55.224.158(10.25.85.175)，使用容器安装，版本是10.7.3; jenkins添加gitlab插件通过浏览器登陆jenkins界面，然后在系统管理里面选择管理插件，如图： 然后在可选择插件里搜索gitlab hook插件，但是没想到我这个版本提示”目前的1.4.2版本的gitlab hook目前存在安全隐患”，如图： 具体的安全隐患细节是这样的： 这个风险请自己把握，然后我选择了继续安装，如图： 安装完了gitlab hook插件后，还要安装GitLab Plugin和Gitlab Authentication plugin这两个插件，方法跟上面的一样。 创建测试工程在jenkins上建立一个新的任务，比如叫jicheng-test，这是一个自由风格的软件项目： 然后在源码管理里面选择git，然后输入gitlab里面仓库的地址，比如我在gitlab上新建了一个project叫jenkinstest，那么就复制这个仓库的地址填到jenkins的Repositories里，如图： 还要在Credentials这里面写上gitlab的用户和密码，然后保存即可： 配置 GitLab 用户浏览器切换到gitlab界面，在用户头像点击，User settings —&gt; Access Tokens，这里的Personal Access Tokens写入一个账号，这个账号是用来让Jenkins和GitLab API交互。这个用户将需要是全局的管理员或添加进每个组／工程，并作为成员。需要开发者权限来报告构建状态。如图： 输入账号和账号有效时期之后，会生成一个Private token，如图： 拷贝它，稍后在配置Jenkins服务器时会用到。 配置 Jenkins 服务器需要配置 Jenkins 服务器来与 GitLab 服务器通信。 在 Jenkins 中，选择系统管理 -&gt;系统设置，在系统设置中找到GitLab的部分： 在Connection name后的输入框中输入连接名称，在Gitlab host URL后的输入框中输入GitLab服务器的URL地址。点击Credentials行最后面的Add -&gt; Jenkins按钮，弹出如下对话框，在Kind 后的下拉列表中选择GitLab API token，并把上一步拷贝的Private token粘贴到API token后面的输入框中。 随后在Credentials的下拉框中选择GitLab API token。 配置 Jenkins 工程来到刚刚建立的那个工程jicheng-test，点击构建触发器，先勾选Build when a change is pushed to GitLab，点击高级，然后再点击一下Generate就会生成一个Secret Token，如下： 点击左下角的保存按钮，保存前面所做的配置。这个时候要记录两个东西，一个是Build when a change is pushed to GitLab那一行中，GitLab CI Service URL:后面的 URL；还有一个就是刚刚生成的Secret Token，这俩在后面配置GitLab工程时需要用到。 配置 GitLab 工程在gitlab进入那个叫jenkinstest的project，然后在settings---&gt;Integrations，在URL里填写刚刚记下来的URL，在Secret Token里填写刚刚记下来的Secret Token，如图： 然后点击下面绿色的add webhook，就会生成一个Webhooks，如图： 去代码服务器上提交一个commit，然后push到gitlab里，再返回到Integrations，对刚刚生成的webhooks点击test，选择push events，如图： 然后就会出现200的成功字样，如图： 如果你再点击一下test上面的edit，就会看到webhook最近调用情况，再点击view details的话，就会看到具体的调用细节，如图： 验证测试此时我在代码服务器上做了一些简单的改动，然后重新把代码push到gitlab服务器上，在jenkins里的相关project里，就会看到已经自动开始build了，如图： 再在具体的某次build里选择控制台输出，就会看到构建的详细过程，如图： 横向扩展如果是多个gitlab的project去对应同一个jenkins，那么需要在jenkins创建任务的时候就选择是根据一个已经存在的任务创建，如图： 在这里写上作为模板的任务的名称，然后在新生成的任务配置的源码管理里添加一个新的Repositories，如图： 如果想要限制分支的话，就要更改Branches to build，现在默认是“只要master分支有push就会触发jenkins构建”。然后再回到gitlab的新project里，进入Integrations，输入配置 Jenkins 工程那个环节里的URL就OK了，Secret Token不用单独填写，因为在复制任务那一步的时候直接把Secret Token全部拷贝过来了。 参考资料http://www.cnblogs.com/bugsbunny/p/7919993.htmlhttps://www.wolfcstech.com/2018/03/26/gitlab_trigger_jenkins_build/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"},{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/tags/jenkins/"}]},{"title":"使用yum安装软件爆No such file or directory","slug":"使用yum安装软件爆No-such-file-or-directory","date":"2018-05-17T09:25:09.000Z","updated":"2018-05-17T11:03:30.000Z","comments":true,"path":"2018/05/17/使用yum安装软件爆No-such-file-or-directory/","link":"","permalink":"http://yoursite.com/2018/05/17/使用yum安装软件爆No-such-file-or-directory/","excerpt":"","text":"今天开发反馈说yum install redis报错-bash: /usr/bin/yum: /usr/bin/python: bad interpreter: No such file or directory，于是我就登上服务器，使用python一看，反馈-bash: python: command not found，原来这个机器的python被人改动了，用whereis python查了一下，原来python的地址被人改成了/usr/bin/python2.7，于是就手动更改了一下/usr/bin/yum，把#!/usr/bin/python改成了#!/usr/bin/python2.7。但是使用yum install -y redis发现虽然可以连接到库但是会报No such file or directory，如图： 原来光改了/usr/bin/yum还没用，还要改/usr/libexec/urlgrabber-ext-down这个文件，同样也是把python改成/usr/bin/python2.7说明python的路径才可以。 改了上面两个文件之后，又加上了yum clean all和yum makecache，清除一下缓存，一切恢复了正常。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"yum","slug":"yum","permalink":"http://yoursite.com/tags/yum/"}]},{"title":"使用zabbix去监控docker容器","slug":"使用zabbix去监控docker容器","date":"2018-05-17T06:06:46.000Z","updated":"2018-05-17T11:35:28.000Z","comments":true,"path":"2018/05/17/使用zabbix去监控docker容器/","link":"","permalink":"http://yoursite.com/2018/05/17/使用zabbix去监控docker容器/","excerpt":"","text":"前言现在容器技术越来越普遍，那么搭建了容器肯定要监控起来，监控方法有两种，一种是做一个zabbix-agent容器去监控容器，还有一个是升级原有的zabbix-agent，这里说第一种。 这里先交代一下环境：zabbix-server的ip是10.244.48.42，要监控的机器ip是10.244.34.79，这个机器里面装了一个容器在运行gitlab，如图： 事前检查两台服务器是否互通，而且10050和10051端口是否standby。还要在zabbix-server端做好auto-discovery，等等等等准备工作。 使用Zabbix Agent Docker进行监控在10.244.34.79这个机器上先安装zabbix-agent容器： 12345678910docker run \\ --name=dockbix \\ #这个是容器的名称 --net=host \\ #容器可以直接访问主机上所有的网络信息 --privileged \\ #容器内的root拥有真正的root权限 -v /:/rootfs \\ #这个是对应宿主机的映射盘 -v /var/run:/var/run \\ --restart unless-stopped \\ #不管退出状态码是什么始终重启容器，不过当daemon启动时，如果容器之前已经为停止状态，不要尝试启动它。 -e &quot;ZA_Server=10.244.48.42&quot; \\ #这里就填写zabbix-server的ip地址 -e &quot;ZA_ServerActive=10.244.48.42&quot; \\ -d hub.c.163.com/canghai809/dockbix-agent-xxl-limited:latest #这里使用了网易蜂巢镜像 但是反馈给我docker: invalid restart policy unless-stopped.这样的错误信息，原来这个gitlab这台服务器的docker版本较老，而unless-stopped这个是在1.9.0版本才加入的，所以对于旧版的docker环境需要改成always。 更改docker run的命令之后重新执行效果如下： 可见容器启动成功，docker logs -f 容器ID号看一下日志是否正常。如果正常的话，应该在zabbix-server端是可以看到这个10.244.34.79已经被添加到控制台里了，如图： 导入监控docker的模版在zabbix server上导入监控docker的模版，一共2个模版,下载后解压。模版下载地址: https://dl.cactifans.com/zabbix/Zabbix-Template-App-Docker.tar.gz 。 我使用主动模式，因此导入Zabbix-Template-App-Docker-active.xml这个模版，如图： 此时可以去zabbix-server这个机器上验证一下是否监控成功，在zabbix-server上执行zabbix_get -s 10.244.34.79 -k docker.discovery，效果如下： 可见已经成功获取到了那两个容器的名称，这就代表zabbix-server已经监控到位了。 验证数据首先现在10.244.34.79里执行docker stats 容器1的ID 容器2的ID...，看一下当前运行的所有容器的状态，如下： 与zabbix-server的latest data做一下对比，由于被监控机的docker版本较老，docker stats结果不是那么的精准，不过用来监控参考还是OK的…如果docker是最新版的，那么监控值是很准的。 剩下的就是慢慢添加triggers了… 补充一句，zabbix-agent 3.2的rpm安装方法： 1234rpm -ivh http://repo.zabbix.com/zabbix/3.2/rhel/7/x86_64/zabbix-release-3.2-1.el7.noarch.rpm yum -y install zabbix-agent zabbix-senderservice zabbix-agent startchkconfig zabbix-agent on 参考资料https://github.com/monitoringartist/zabbix-docker-monitoring （墙裂推荐！）https://blog.codeship.com/ensuring-containers-are-always-running-with-dockers-restart-policy/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"gitlab","slug":"gitlab","permalink":"http://yoursite.com/tags/gitlab/"}]},{"title":"Gitlab的配置备份","slug":"Gitlab配置备份","date":"2018-05-16T07:02:50.000Z","updated":"2018-08-13T06:57:10.000Z","comments":true,"path":"2018/05/16/Gitlab配置备份/","link":"","permalink":"http://yoursite.com/2018/05/16/Gitlab配置备份/","excerpt":"","text":"备份正文我这个gitlab是容器安装的，直接使用最新的gitlab镜像，gitlab版本是10.7.3。 要备份数据的话，就要进入容器里，执行gitlab-rake gitlab:backup:create，效果如下： 执行完毕之后，在/var/opt/gitlab/backups文件夹里就会生成一个备份文件，我这里生成的文件叫：1526454102_2018_05_16_10.7.3_gitlab_backup.tar，这个就是备份的文件。 如果要还原的话，命令如下： 1234567891011# 先关闭连接数据库的进程sudo gitlab-ctl stop# 通过指定时间戳来执行restore操作，这个操作会复写gitlab的数据库sudo gitlab-rake gitlab:backup:restore BACKUP=1526454102 #BACKUP后面的是备份文件开头的那串数字# 再次启动gitlabsudo gitlab-ctl start# 通过下面命令检查gitlabsudo gitlab-rake gitlab:check SANITIZE=true 注意！利用backup机制进行备份的话，对gitlab的版本是要求严格一致的。例如用8.6版的gitlab生成的备份文件，拿到8.7版的gitlab上进行恢复，是会报错的。 同时除了要导入备份文件之外，还要备份以下几个文件： 123/etc/gitlab/gitlab.rb 配置文件须备份/var/opt/gitlab/nginx/conf nginx配置文件/etc/postfix/main.cfpostfix 邮件配置备份 如果要设置这个备份文件的生命周期和备份文件存储的位置，编辑/etc/gitlab/gitlab.rb，修改如下的地方： 1234gitlab_rails[&apos;backup_path&apos;] = &quot;/var/opt/gitlab/backups&quot; #这里改新路径gitlab_rails[&apos;backup_archive_permissions&apos;] = 0644 #这里可以设定文件的权限# limit backup lifetime to 7 days - 604800 secondsgitlab_rails[&apos;backup_keep_time&apos;] = 604800 #文件存储时间一周 然后重启一下gitlab即可。 参考资料http://eimsteim.github.io/2017/12/12/%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%9D%91%E7%88%B9%E7%9A%84Gitlab%E6%95%B0%E6%8D%AE%E8%BF%81%E7%A7%BB%E4%B9%8B%E6%97%85/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"http://yoursite.com/tags/gitlab/"}]},{"title":"Gitlab的简单应用","slug":"Gitlab的简单实用","date":"2018-05-16T01:30:52.000Z","updated":"2019-08-27T12:27:26.000Z","comments":true,"path":"2018/05/16/Gitlab的简单实用/","link":"","permalink":"http://yoursite.com/2018/05/16/Gitlab的简单实用/","excerpt":"","text":"gitlab跟svn的区别我就不多说了，这里直接说具体应用。 建立一个project先登陆到gitlab的网页，我这里使用了root用户，选择create a project，然后就是填写project的名称以及它所属的用户，这里由于只有root用户，所以这个叫jjfjj的project就是root自己的，如果建立了一个组的话，那么这里就填写那个组，如下： 下面这个Visibility Level ，就是权限等级，它分三种： Private：私有的，只有你自己或者组内的成员能访问 Internal：所有登录的用户 Public：公开的，所有人都可以访问 这个东西和project的名称都是可以后期更改的。 然后就是create project，就创建了这个jjfjj。如图: 将本地代码上传建立好了gitlab，就要把开发的代码传进去，我在另外一个机器里，创建一个目录code，这个目录就是专门用来放置代码的，假设现在里面有一个文件叫testcode.py，如图： 具体操作如下： 注意！如果在创建project的时候勾选同时创建README.md的话，第一次提交本地代码需要是git pull origin master。 如果在两个不同的文件夹里执行上面的过程，会传输到两个不同的project里。说明一下上面几个命令的意思：git init：初始化git仓库git add .：添加整个目录里的所有文件到仓库git rm --cached 某个文件名：将某个文件从gitlab上撤除，如果想当前文件夹恢复成一个普通的文件夹，那就把文件夹路径下的.git文件删除掉即可git commit -m &#39;这里是要写的注释&#39;：提交代码到仓库git remote add origin +gitlab的地址(上上图里红色框的内容)：链接到gitlab服务器git push origin master：push代码到服务器git remote -v：查看当前文件夹的目标project 此时刷新一下gitlab的project页面，就看到刚刚的那个testcode.py已经传上来了。如图： 如果代码有所更改或者出现Everything up-to-date，那么就按顺序执行git add .，git commit -m &#39;这里是要写的注释&#39;，git push origin master即可。 免密码push代码在上面的git push origin master的时候需要输入gitlab的用户密码，如要需要免密码push，有两种方法。 第一种方法是ssh，请看 https://blog.whsir.com/post-1749.html/comment-page-1#comment-3425 。 第二种方法是用http的方式传送，先打开.git/config这个配置文件，修改url = http://账号:密码@以.git结尾的项目地址,保存之后重新去执行git add .，git commit -m &#39;这里是注释&#39;，git push origin master，就不再需要输入密码了。 从gitlab上垃取代码在要部署的机器上找到要部署的文件夹，我这里用/gitlab为例，操作如下： 12345678910[root@pass-mixnumbus-001 /GITLAB] # git init #将这个文件夹进行初始化 Initialized empty Git repository in /GITLAB/.git/ #提示现在已经安装了.git文件[root@pass-mixnumbus-001 /GITLAB(master)] # git remote add origin http://114.55.224.158/root/JJFJJ.git #确定库[root@pass-mixnumbus-001 /GITLAB(master)] # git pull origin master #制定要把master分支的代码全拉取到这个文件夹里Username for 'http://114.55.224.158': root #输入账号和密码Password for 'http://root@114.55.224.158': From http://114.55.224.158/root/JJFJJ * branch master -&gt; FETCH_HEAD[root@pass-mixnumbus-001 /GITLAB(master)] # ls #看一下效果admin.py looksql.py models.py syncECS.py testsyncECS.py 再与gitlab界面的代码比较一下，果然都过来了！如图： 在gitlab上建立分支gitlab上有很多个分支，主要的分支是master，它也是默认的分支，但是实际工作中是需要其他的开发去新建一些测试的分支，到时候可以先把这些测试的分支拿来部署，如果有问题就回滚回master分支。 分支相关的语句如下： 123456git branch #查看本地分支git branch -r #查看远程分支git branch -a #查看所有分支git branch develop #本地创建新的分支，此时刷新gitlab的页面的话就会有这个叫develop的分支建立了git checkout develop #切换到新的develop分支git checkout -b develop #上面两步可以合成一个命令，这个的意思就是：创建+切换分支 这个时候在代码机上新增或者改变文件，然后执行git add .，git commit -m &#39;这里是要写的注释&#39;，git push origin develop，就把新增的变化上传到了develop分支，如图： 1234567891011[root@iZ23pg8sy5bZ ~/GITLAB(develop)] # git push origin developCounting objects: 4, done.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 325 bytes | 0 bytes/s, done.Total 3 (delta 1), reused 0 (delta 0)remote: remote: To create a merge request for develop, visit:remote: http://114.55.224.158/root/JJFJJ/merge_requests/new?merge_request%5Bsource_branch%5D=developremote: To http://114.55.224.158/root/JJFJJ.git fc8d456..8a97b58 develop -&gt; develop 而在部署的机器上，直接执行git pull origin develop，输入账号密码之后，就会把develop分支的内容全部垃取下来了。 如果不想要这个develop分支了，就git branch -d develop，如果要删除远程的分支，就是git push origin :develop，注意这个冒号。 如果gitlab的地址发生了改变，那么在git pull之前需要git remote set-url origin 新的git地址，不过设定完毕之后，免输账号密码的效果会消失。 在windows里使用gitlab首先先安装git，然后在目标文件夹里点击右键—Git Bash Here，在命令行里输入git clone 远程目标.git。同时在project页面里的develop分支（开发分支）里新开一个分支比如叫feature/chenshuo。待目标全部下载完毕之后，cd到代码文件夹里： 1234567git branch -a #此时应该是master分支git checkout -b feature/chenshuo origin/feature/chenshuo #将本地的分支feature/chenshuo与远程的分支origin/feature/chenshuo关联git branch -a #此时应该由master切换到了本地分支...修改代码...git add . git commit -m \"提交信息\" #将代码提交到本地分支 git push #将本地分支push到远程 如果在git clone那一步密码输入错误了，可以在我的电脑–控制面板–用户账户–管理您的凭据 里面修改。 普通用户访问docker让普通用户访问docker的方法其实就是把该用户添加到docker组里即可。 先切换root用户给予普通用户（比如叫lcshop）免sudo权限：使用sudoedit /etc/sudoers添加这样的语句： 1lcshop ALL=(ALL) ALL 然后还是root状态下，执行gpasswd -a lcshop docker，将lcshop添加到docker组里，此时应该若反馈Adding user lcshop to group docker则添加成功。 然后就是重启一下docker进程，同时lcshop也重新连接ssh，此时lcshop就可以正常使用docker ps -a等命令了。若要查看某个用户组下有哪些用户，可以通过grep &#39;组名&#39; /etc/group获取。 参考资料https://blog.cnbluebox.com/blog/2014/04/15/gitlabde-shi-yong/https://zhang759740844.github.io/2016/08/27/git%E6%8A%80%E5%B7%A7/https://www.restran.net/2016/02/23/git-and-gitlab-guide/https://www.jianshu.com/p/f54053afecf2","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"http://yoursite.com/tags/gitlab/"}]},{"title":"Gitlab的汉化过程","slug":"Gitlab的汉化过程","date":"2018-05-15T02:17:51.000Z","updated":"2019-08-26T03:46:18.000Z","comments":true,"path":"2018/05/15/Gitlab的汉化过程/","link":"","permalink":"http://yoursite.com/2018/05/15/Gitlab的汉化过程/","excerpt":"","text":"gitlab的容器安装方法部署前的第一句话，gitlab是不支持32位系统的！ gitlab用容器部署的话非常的简单，首先docker pull gitlab/gitlab-ce:latest下载镜像，然后docker run --detach --hostname 本机外网IP --publish 443:443 --publish 80:80 --publish 2222:22 --name gitlab --restart always gitlab/gitlab-ce:latest建立一个容器，如图： 然后在浏览器的地址栏里输入服务器的外网IP地址，就到了一个更换密码的页面(如果打开页面是Whoops, GitLab is taking too much time to respond.请检查内存是否小于2G)，这个密码就是root的密码，如图： 设定密码之后，就可以通过root账号登陆gitlab了，如图： 至于“使用ldap方式登录”、“配置域名”和“关闭注册功能”请移步去看：https://rorschachchan.github.io/2018/05/10/在已经运行的docker容器里面使用中文/ 。 gitlab的汉化方法汉化之前，要确定gitlab的版本，先docker exec -it 容器ID env LANG=C.UTF-8 /bin/bash登陆到容器里，执行cat /opt/gitlab/embedded/service/gitlab-rails/VERSION，由于当时镜像是最新的，所以gitlab的版本是10.7.3。 还是在容器里，执行git clone https://gitlab.com/xhang/gitlab.git，克隆获取汉化版本库(这里要感谢辛苦的汉化工作者，向你们致敬！)，默认是获取最新的。如果需要下载老版本的汉化包，则要加上老版本的分支，如：git clone https://gitlab.com/xhang/gitlab.git -b v10.2.5-zh。 然后gitlab-ctl stop先停止gitlab服务，cd gitlab/进入到刚刚下载的那个git包里，执行如下代码： 123456root@10 gitlab]# git fetchroot@10 gitlab]# git diff v10.7.3 v10.7.3-zh &gt; ../10.7.3-zh.diffroot@10 gitlab]# cd ..root@10 ~]# patch -d /opt/gitlab/embedded/service/gitlab-rails -p1 &lt; 10.7.3-zh.diffroot@10 ~]# #如果提示没有patch，请执行apt-get update &amp;&amp; apt-get install patchroot@10 ~]# gitlab-ctl start 重新返回到浏览器里，就能看到汉化后的gitlab了，大功告成！ 参考资料https://xuanwo.org/2016/04/13/gitlab-install-intro/https://www.jianshu.com/p/6606aed59a56http://adairjun.github.io/2016/12/20/gitlab/https://github.com/marbleqi/gitlab-ce-zh/blob/v10.5.1-zh-patch/Nginx.md","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"http://yoursite.com/tags/gitlab/"}]},{"title":"浅析django里models.py、views.py与网页之间的爱恨纠葛","slug":"浅析django里models-py、views-py、page之间的纠葛","date":"2018-05-14T14:04:16.000Z","updated":"2018-10-12T01:41:48.000Z","comments":true,"path":"2018/05/14/浅析django里models-py、views-py、page之间的纠葛/","link":"","permalink":"http://yoursite.com/2018/05/14/浅析django里models-py、views-py、page之间的纠葛/","excerpt":"","text":"前言Django + Boostrap现在是运维开发的必备技能，因为他俩是运维可视化的关键技术，而本文就是简单说一下整个Django的数据库---后台---前端的工作原理。其实所谓Django开发，就是熟悉了 Django的规则之后，按照它的规则去填空，填你自己想要展现的东西。 环境：django 2.0 + python 3.6 + pycharm 2018 django建立一个app之后就会有models.py、views.py、admin.py这几个文件，他们三个分别的用途如下： models.py主要是用来设置数据在数据库的存储格式（比如默认值，字段类型和字段长度等等）; admin.py是用来设置在/admin/后台里面的显示样式; views.py是用来设置在前台网页里的显示样式； urls.py是用来编辑域名规则； 上面4个文件里，重中之重的就是views.py，说它是整个django的灵魂都不为过！所以要是掌握了它，基本就明白了大半个django了。 举个例子假设有一个models.py，内容如下： 1234567from django.db import models from django.contrib.auth.models import User class BlogType(models.Model): type_name = models.CharField(max_length=15) #规定type_name是一个最大为15字节的charfield def __str__(self): return &apos;&lt;BlogType:%s&gt;&apos; % self.type_name 然后随便加入一些内容，如图： 而在views.py里，要求在前端网页里如此的显示： 1234567from django.shortcuts import render_to_response,get_object_or_404 from .models import BlogType #这里引用了models.py里的那个class def blog_list(request): context = &#123;&#125; context[&apos;blog_types&apos;] = BlogType.objects.all() return render_to_response(&apos;pageblog/blog_list.html&apos;,context) 在views.py里规定，如果有访问域名是/blog_list/的网页，就返回pageblog/blog_list.html这个页面，而这个blog_list.html只是一个框架，里面的内容是context。context本身是一个字典，里面的key对应的value是用ojbects这个函数获得的，objects.all()就是获取全部的意思。用来填充blog_list.html的context里面有blog_types这个key。 那么现在就可以在blog_list.html里使用blog_types这个key了，如下： 1234&lt;!-- 前面略 --&gt; &lt;h4&gt;博客分类&lt;/h4&gt; &lt;h3&gt; &#123;&#123; blog_types &#125;&#125; &lt;/h3&gt; &lt;!-- html文件要用views.py里的变量要加上&#123;&#123;&#125;&#125; --&gt;&lt;!-- 后面略 --&gt; 这样的效果如下： 返回的是QuerySet类型，QuerySet是Django的查询集，可以通过QuerySet条件查询得到对应模型的对象集合。由此看出blog_types已经成功的引入到了blog_list.html里。 至于拆成每一个“博客类型”就很简单了，html部分如下： 12345678910&lt;h4&gt;博客分类&lt;/h4&gt; &lt;!-- ul是无项目的标签 --&gt; &lt;ul&gt; &#123;% for blog_type in blog_types%&#125; #开始一个for循环 &lt;li&gt;&lt;a href=&quot;&#123;% url &apos;blogs_with_type&apos; blog_type.pk %&#125;&quot;&gt;&#123;&#123; blog_type.type_name &#125;&#125; &lt;/a&gt;&lt;/li&gt; #对每一个类型加上一个a链接 &#123;% empty %&#125; #如果为空就说“暂无分类” &lt;!-- li是具体的项目 --&gt; &lt;li&gt; 暂无分类 &lt;/li&gt; &#123;% endfor %&#125; &lt;/ul&gt; 再说urls.py上面说过了，urls.py是配置域名路由规则的。它的格式比较简单，就是path(&#39;域名&#39;，views.py里的函数，name=&#39;自定义名称&#39;)。比如下面这个urls.py： 123456789from django.contrib import adminfrom django.urls import include,pathfrom article.views import blog_list #article是django项目里自己创建的一个appurlpatterns = [ path('',blog_list,name='home'), #这里的name可写可不写，如果写的话，在href跳转的时候就可以直接用 path('admin/', admin.site.urls), path('blog/',include('article.urls')), #引用的的include方法用在这里] 上面这个是总的路由文件，当然可以把所有的app的路由都写到里面去，也可以在各自的app下写各自的路由，这样方便管理。比如我就在article这个app文件夹下面又单独了一个urls.py，这里面所有的域名就会自动添加blog/这个路径，而整个urls.py内容如下： 1234567from django.urls import pathfrom . import viewsurlpatterns = [ path('&lt;int:blog_pk&gt;',views.blog_detail,name='blog_detail'), path('type/&lt;int:blog_type_pk&gt;',views.blogs_with_type,name='blogs_with_type'),] 在上面的第一个path里，目的就是传入一个值blog_pk，而这个blog_pk就是在views.py里的blog_detail函数需要传入的参数，跟request一样。上面也说过了，这个两个path都会自动在前面加上/blog/路径。 views.py与前端如何把数据库里的内容映射到前端页面呢？就是用views.py里的render_to_response，它是负责渲染的。render_to_response的用法是后面要加上对应的html页面和要映射的内容，比如下面这个views.py: 1234567from django.shortcuts import render_to_response,get_object_or_404from .models import Blog #这里引用了models.py里面的类：Blogdef blog_detail(request,blog_pk): #每一次使用这个函数都要传入一个参数：blog_pk context = &#123;&#125; context['blog'] = get_object_or_404(Blog,pk=blog_pk) #通过get_object_or_404这个方法生成一个字典 return render_to_response('blog_detail.html',context) #这个blog_detail.html就是对应的前端页面 从上面可以看到，views.py先引入了数据库文件models.py里的Blog这个class，然后设定一个空字典，将这个字典按照对应数据库默认的主键pk与浏览器输入的pk一一对应填满，最后就是按照blog_detail.html为前端框架，里面赋予整个填满值的context字典。 而对应的前端页面blog_detail.html如下： 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset='UTF-8'&gt; &lt;title&gt;&#123;&#123; blog.title &#125;&#125;&lt;/title&gt; &lt;!-- 这里的blog就是views.py里context['blog']里的blog --&gt;&lt;/head&gt;&lt;body&gt; &lt;div&gt; &lt;a href=\"&#123;% url 'home' %&#125;\"&gt; &lt;!-- 这里就是返回首页，home是在urls.py里设定的 --&gt; &lt;h2&gt;BACK TO HOMEPAGE&lt;/h2&gt; &lt;/a&gt; &lt;/div&gt; &lt;h3&gt;&#123;&#123; blog.title &#125;&#125;&lt;/h3&gt; &lt;p&gt;作者：&#123;&#123; blog.author &#125;&#125;&lt;/p&gt; &lt;p&gt;分类： &lt;a href=\"&#123;% url 'blogs_with_type' blog.blog_type.pk %&#125;\"&gt; &lt;!-- 就是将blog.blog_type.pk作为views.py里blog_detail函数的传入值 --&gt; &#123;&#123; blog.blog_type &#125;&#125; &lt;/a&gt; &lt;/p&gt; &lt;p&gt; &#123;&#123; blog.blog_type.pk &#125;&#125;&lt;/p&gt; &lt;p&gt;发表时间：&#123;&#123; blog.created_time|date:\"Y-m-d H:i:s\"&#125;&#125;&lt;/p&gt; &lt;!-- 这里将输出时间做了规范化 --&gt; &lt;hr&gt; &lt;p&gt;&#123;&#123; blog.content &#125;&#125;&lt;/p&gt;&lt;/body&gt;&lt;/html&gt;","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"}]},{"title":"加载css样式的两个方法","slug":"加载css样式的两个方法","date":"2018-05-12T07:27:19.000Z","updated":"2018-11-05T07:16:22.000Z","comments":true,"path":"2018/05/12/加载css样式的两个方法/","link":"","permalink":"http://yoursite.com/2018/05/12/加载css样式的两个方法/","excerpt":"","text":"背景说明环境： django 2.0+python 3.6+pycharm 2018project名称: blog 普通的网页加载css网页使用了css才会更好看更炫酷，一般情况下的网页是这样的： 上面这个html文件里用到了模板，而且又对div和 a标签做了class定义，最后分别对各自的class进行了css说明。整个文档看下来比较直观。 但是这样就会有一个问题，就是把html内容和css内容写到了一起，一般来说为了后期维护，都会把css单独写到一个文件夹里，然后让这个html来引用这个css文件夹的具体某个css文件。 于是，我们就在blog这个project目录下建立一个叫static的文件夹，用它来专门装css\\js这样的静态文件。 首先，建立了这个static文件，肯定就涉及到引用的问题，而如何让django可以识别static呢？ 打开blog/settings.py这个文件，这个文件是整个project的配置文件，在文件末尾加上这样的话，如下： 1234 #将项目根目录里的static制定成项目的静态文件夹,这样django就可以识别 #注意，static前面没有'/' STATICFILES_DIRS = [os.path.join(BASE_DIR, 'static'),]​ 这样blog这个根目录就可以识别了static文件夹了。 然后在pycharm里新建一个css文件叫base.css，如果是专业版的pycharm是可以直接建立css类型文件的，免费社区版是没有这个功能。再将原文里面的所有关于css的内容拷贝到这个base.css里，如下： 1234567891011121314151617181920*&#123;margin: 5px;padding: 10px;&#125; div.nav &#123;background-color: gold;border-bottom: 2px solid #ccc;&#125; div.nav a&#123;text-decoration:none;color: blue;padding: 5px 10px;&#125; div.nav a.logo&#123;display: inline-block;font-size: 120%;&#125; 保存之后，为了验证django是否成功的识别此文件，可以在浏览器里输入外网IP：端口号/static/base.css查看是否返回就是上面内容，如果是就代表识别成功，如果是404就要重新检查settings.py了。 在原有的html里删除掉&lt;style&gt;标签内css内容，还要在head里添加一句话：&lt;link rel=&quot;stylesheet&quot; href=&quot;/static/base.css&quot;&gt;,如下： 这样就达到了引用css所在的static文件夹的目的。 Django内部的加载css方法上面说的是普通html加载css的方法，而django内部也有自己的一套方法，再次打开settings.py里看到有如下的内容： 123456789INSTALLED_APPS = [ 'django.contrib.admin', 'django.contrib.auth', 'django.contrib.contenttypes', 'django.contrib.sessions', 'django.contrib.messages', 'django.contrib.staticfiles', 'blog',] 上面的django.contrib.staticfiles就是django的css加载方法，使用这个方法也很简单。 首先要在html文件最上面先声明要调用这个方法: 12&#123;% load staticfiles %&#125;&#123;# 这个staticfiles是django自带的，可以在settings文件里看到 #&#125; 然后把link标签改成如下： 1&lt;link rel=&quot;stylesheet&quot; href=&quot;&#123;% static &apos;base.css&apos; %&#125;&quot;&gt; 保存文件刷新即可，而且用了这种方法，在chrome浏览器里F12 查看，会解析成普通模式的方法，如图： 在django项目里，还是更推荐用django的方法。 额外补充如果html文件开头声明引用了某个模板，比如： 12&#123;% extends &apos;base.html&apos; %&#125; #声明引用了base.html这个模板&#123;% load staticfiles %&#125; 那么extends语句必须在最上面，不然就会报错：TemplateSyntaxError at /&lt;ExtendsNode: extends &#39;base.html&#39;&gt; must be the first tag in the template.","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"前端技术","slug":"前端技术","permalink":"http://yoursite.com/tags/前端技术/"}]},{"title":"创建Mysql容器过程","slug":"创建Mysql容器过程","date":"2018-05-12T02:28:46.000Z","updated":"2018-05-15T03:28:58.000Z","comments":true,"path":"2018/05/12/创建Mysql容器过程/","link":"","permalink":"http://yoursite.com/2018/05/12/创建Mysql容器过程/","excerpt":"","text":"过程记录先docker pull mysql，当前最近的版本是8.0，然后docker images查看一下效果。 然后就是启动一个容器，命令是：docker run --name test-mysql -p 3306:3306 -e MYSQL\\_ROOT\\_PASSWORD=123456 -d mysql,这句话的意思是：启动一个叫test-mysql的容器， 端口影射是3306到宿主机的3306，同时设置root的密码是123456，然后以守护进程的形式启动。 但是如果在宿主机上使用mysql -h127.0.0.1 -uroot -p123456可能会报错，报错内容是：Authentication plugin ‘caching_sha2_password’ cannot be loaded: 那么就docker exec -it 容器ID号 env LANG=C.UTF-8 /bin/bash进入到容器里，使用mysql -uroot -p123456，看一下在容器里是否可以正常登录，如果可以的话，那么就在mysql的命令行里执行ALTER USER &#39;root&#39;@&#39;%&#39; IDENTIFIED WITH mysql_native_password BY &#39;123456&#39;;。 退出容器在宿主机上重新连接，这样就OK了。至于原因就是，mysql的客户端是yum安装的，虽然是centos 7，但是安装的版本也是5.5版本的，所以8.0的客户端有一个新的密码加密方式：caching_sha2_password，客户端不支持，所以需要手动到命令行里更改一下。 mysql存储的坑先思考一个问题：假如某mysql容器里存储了100G的数据，那么这个容器关闭了，这100G的数据还在么？从宿主机是可以找到这100G的数据么？ docker inspect mysql-container-id，找到里面的volume字段，这里也显示挂载的host路径，可以通过这个路径来备份数据。或者使用docker cp mysql-container-id:/path/to/db-backup-file ./，把容器内数据放到当前目录下。如果是生产环境，必须使用Volume或数据容器。 参考资料http://binary-space.iteye.com/blog/2412769http://dockone.io/question/108","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"docker容器","slug":"docker容器","permalink":"http://yoursite.com/tags/docker容器/"}]},{"title":"python报错：importError: No module named bz2","slug":"python报错：'importError-No-module-named-bz2'","date":"2018-05-12T02:08:07.000Z","updated":"2018-05-12T04:19:34.000Z","comments":true,"path":"2018/05/12/python报错：'importError-No-module-named-bz2'/","link":"","permalink":"http://yoursite.com/2018/05/12/python报错：'importError-No-module-named-bz2'/","excerpt":"","text":"每日统计阿里云同步延迟的邮件早就编写完毕了，现在要放到专门跑脚本的服务器里，进去到这个服务器里发现这个机器已经被人装了两个python，分别是python 2.7.5（默认路径）和python 2.7.13（路径是/usr/local/python/bin/python），说实话我个人不太明白这么做的原因何在。 但是既然已经被人搞成这样了，那就适应环境吧，把脚本拷贝过来，把依赖库都安装好，但是在执行matplotlib的库的时候，爆了一个错误：ImportError: No module named bz2。 这就是因为两个python，但是启动的那个python文件夹里面是没有bz2.so这个文件的，于是就需要把系统里默认的2.7.5的bz2.so拷贝到2.7.13的lib路径里。 首先find / -name bz2.so找一下文件，如下： 1234[root@dvl-stun-002 GETDTS]# find / -name bz2.so/usr/local/aegis/PythonLoader/lib/python2.7/lib-dynload/bz2.so/usr/local/aegis/SecureCheck/lib/python2.7/lib-dynload/bz2.so/usr/lib64/python2.7/lib-dynload/bz2.so 然后cd /usr/local/python/lib/python2.7/，把/usr/lib64/python2.7/lib-dynload/bz2.so复制到这个文件夹里即可。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"在已经运行的docker容器里面使用中文","slug":"在已经运行的docker容器里面使用中文","date":"2018-05-10T14:52:57.000Z","updated":"2018-06-11T12:55:46.000Z","comments":true,"path":"2018/05/10/在已经运行的docker容器里面使用中文/","link":"","permalink":"http://yoursite.com/2018/05/10/在已经运行的docker容器里面使用中文/","excerpt":"","text":"配置ldap公司搭建的gitlab现在需要开启ldap服务，也就是这样就可以用公司的域账号登陆gitlab，而不用开发一个一个去注册账号了。 开启ldap登陆的任务光荣的落到了我身上，于是我就登陆到gitlab服务器一看，嚯，这还是在容器下启动的，如图： 于是我就docker exec -it 容器ID号 /bin/bash登陆到这个容器里，编辑/opt/gitlab/embedded/service/gitlab-rails/config/gitlab.yml，如下： 1234567891011121314ldap: enabled: true sync_time: host: '公司域账号服务器IP地址' port: 389 uid: 'sAMAccountName' method: 'plain' # \"tls\" or \"ssl\" or \"plain\" bind_dn: 'dahuatech\\Ldap_System' password: '对应的密码' active_directory: allow_username_or_email_login: lowercase_usernames: base: user_filter: 但是在填写到base的时候发现了一个问题，公司的base是中文的，是&#39;OU=大数据研究院,OU=研发中心,OU=大华技术,DC=dahuatech,DC=com&#39;，但是在文件里输入中文却是乱码，如图： 容器默认是不支持中文的，在容器里的命令行输入中文也是空白。那么面对一个已经运行的容器，如何正常的输入中文呢？ 答案是：使用docker exec -it 容器ID号 env LANG=C.UTF-8 /bin/bash登陆，这样就能正常使用中文了，如图： gitlab-ctl restart之后，登陆到gitlab页面一看，已经添加ldap访问方式： 取消“注册”功能修改好配置文件gitlab.yml之后，现在就要把“注册”功能去掉，这样以后都统一用公司的域账号登陆，避免一些乱七八糟的用户来注册乱七八糟的账号。 首先用root账号登陆到gitlab里，在网页里进入到admin area，如图： 然后再点击最下面的settings，选择Sign-up restrictions，然后把Sign-up enabled前面的勾点掉，如图： 保存改变之后，退出root账号，重新看一下，gitlab的注册功能就暂时被取消了，需要的时候再开即可。 配置域名为了方便记忆，给gitlab服务配置一个域名，在阿里云的域名解析控制台给gitlab配置了域名之后，还要在gitlab.yml手动更改hostname，把hostname改成域名的样子，如图： 这样没有结束，因为网页里的url还是显示外网IP而非域名,如下： 此时需要重启，重启的命令是gitlab-ctl restart，重启完了之后url也会发生变化。这样才算完整的配置了域名：","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]},{"title":"通过阿里云服务器ID添加服务器资料到django的脚本","slug":"通过阿里云服务器ID添加服务器资料到django的脚本","date":"2018-05-07T13:48:29.000Z","updated":"2018-05-12T06:13:56.000Z","comments":true,"path":"2018/05/07/通过阿里云服务器ID添加服务器资料到django的脚本/","link":"","permalink":"http://yoursite.com/2018/05/07/通过阿里云服务器ID添加服务器资料到django的脚本/","excerpt":"","text":"本文的环境是：centos 7 + django 2.0 + python 3.6 先给django里的project创建了models.py，里面内容如下： 123456789101112131415from django.db import models# Create your models here.class ecs(models.Model): name = models.CharField(verbose_name='云服务器名称',max_length=30) ecsid = models.CharField(verbose_name='云服务器ID',max_length=30,default='') inIP = models.GenericIPAddressField(verbose_name='云服务器内网地址') outIP = models.GenericIPAddressField(verbose_name='云服务器外网地址') osname = models.CharField(verbose_name='操作系统',max_length=50,default='') networktype = models.CharField(verbose_name='网络类型',max_length=20) CPU = models.IntegerField(verbose_name='云服务器CPU',default='2') memory = models.IntegerField(verbose_name='云服务器内存',default='2048') netwidth = models.IntegerField(verbose_name='云服务器外网带宽',default='0M') signtime = models.DateField(auto_now_add=True) remark = models.CharField(verbose_name='备注',max_length=255,blank=True) 可以看出这个就是一个很简单的云服务器的配置统计，但是要录入的阿里云服务器很多，一个一个手动输入实在太累，于是就要写一个脚本来达到django同步的效果！ 脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#!/usr/bin/env python#coding=utf-8#这个脚本通过查询阿里云服务器ID来达到同步django的目的import json,pymysqlfrom aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import DescribeInstancesRequestclt = client.AcsClient('这里是ak','这里是sk','这里是地域名')# 设置参数request = DescribeInstancesRequest.DescribeInstancesRequest()request.set_accept_format('json')request.add_query_param('RegionId', 'cn-hangzhou')request.add_query_param('InstanceIds', ['这里是服务器ID']) #如果是多个服务器ID，可以继续往下写# 发起请求response = clt.do_action(request)#print(response) #这里可以看一下返回的response，但是它是byte格式的data=str(response, encoding = \"utf-8\")ecs = json.loads(data) #转换成str格式name = str(ecs['Instances']['Instance'][0]['InstanceName'])ecsid = str(ecs['Instances']['Instance'][0]['InstanceId'])inIP = str(ecs['Instances']['Instance'][0]['VpcAttributes']['PrivateIpAddress']['IpAddress'])[1:-1] #如果不加[1:-1]的话，得到的是一个IP外面还有中括号outIP = str(ecs['Instances']['Instance'][0]['PublicIpAddress']['IpAddress'])[1:-1]networktype = str(ecs['Instances']['Instance'][0]['InstanceNetworkType'])CPU = int(ecs['Instances']['Instance'][0]['Cpu'])memory = int(ecs['Instances']['Instance'][0]['Memory'])osname = str(ecs['Instances']['Instance'][0]['OSName'])#创建数据库连接，注意这里我加入了charset和cursorclass参数conn = pymysql.connect( host = \"127.0.0.1\", user = \"数据库账号\", password = \"数据库密码\", database = \"数据库名称\", charset = 'utf8', cursorclass = pymysql.cursors.DictCursor)#获取游标cursor = conn.cursor()#三个引号里如何加入变量sql = \"\"\"INSERT INTO ecs_ecs (name,ecsid,inIP,outIP,networktype,CPU,memory,netwidth,signtime,osname) VALUES (%(name)s,%(ecsid)s,%(inIP)s,%(outIP)s,%(networktype)s,%(CPU)d,%(memory)d,%(netwidth)d,NOW(),%(osname)s);\"\"\" % dict(name='\\''+name+'\\'',ecsid= '\\''+ecsid+'\\'',inIP=inIP,outIP=outIP,networktype='\\''+networktype+'\\'',CPU=CPU,memory=memory,netwidth=1,osname='\\''+osname+'\\'')#print (sql) #在这里可以先看看sql输出的是否正确cursor.execute(sql)# 关闭数据库连接conn.close() 正常来说应该是先建立一个def来获取阿里云服务器配置，再来一个def来将各配置录入到数据库里，同时让阿里云服务器的id作为变量，而且还要加上如果sql执行失败就回滚的语句。而我由于是临时使用，所以这个脚本按照流水式写下来的，不过不影响阅读。 ps.进化之后的脚本在我的github里，地址是： https://github.com/RorschachChan/chenWORK/blob/master/通过阿里云ID号将服务器信息同步到django.py 比如现在要添加一个服务器，这个服务器的id是：i-bp12ego6x9srzsytxeqo，如图： 那么对应填写好脚本里的ak/sk之后，就把i-bp12ego6x9srzsytxeqo填写到“服务器ID”的位置 ，执行这个脚本，结果如下： 不过这个脚本有两个缺点：第一：如果阿里云服务器是中文名称，那么使用api查询出现的是十六进制的符号；第二：如果服务器里没有外网IP或者是后开的临时带宽，那么在outIP的地方得到的值是空，sql语句会因为少一项而报错；第三：这个api没有查询服务器带宽值的功能，还需要另外写一个脚本搭配。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python3","slug":"python3","permalink":"http://yoursite.com/tags/python3/"},{"name":"django2","slug":"django2","permalink":"http://yoursite.com/tags/django2/"}]},{"title":"记一次nginx负载均衡配置问题","slug":"记一次nginx负载均衡配置问题","date":"2018-04-28T13:48:40.000Z","updated":"2018-06-21T01:53:40.000Z","comments":true,"path":"2018/04/28/记一次nginx负载均衡配置问题/","link":"","permalink":"http://yoursite.com/2018/04/28/记一次nginx负载均衡配置问题/","excerpt":"","text":"故障背景公司有三个实体服务器，内网IP分别是10.1.82.83、10.1.82.84、10.1.82.113，这三个作为源站使用专线连接到了阿里云的一台nginx服务器上，并且通过这个nginx做负载均衡展示这三个服务器里面的网页。负载均衡使用的是nginx 1.12版本，最外面在上一个CDN起到静态页面加速的作用。整个架构如图： CDN的配置界面如下： 但是现在很奇怪的是，所有节点启动之后，外网用户通过负载后访问均指向了10.1.82.84这一台服务器，nginx.conf配置是最小连接数的配置，如下： 123456789101112131415161718192021222324252627upstream eln.dahuatech.com &#123; #ip_hash; #hash $http_x_forwarded_for; #sticky; least_conn; server 10.1.82.83 max_fails=2 fail_timeout=30s; server 10.1.82.84 max_fails=2 fail_timeout=30s; server 10.1.82.113 max_fails=2 fail_timeout=30s;&#125;server &#123; server_name eln.dahuatech.com; listen 80; listen 443 ssl; access_log logs/eln.dahuatech.com.access.log main; error_log logs/eln.dahuatech.com.error.log; proxy_set_header Host $host:$server_port; proxy_set_header X-Real-IP $remote_addr; proxy_set_header REMOTE-HOST $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; location / &#123; proxy_pass http://eln.dahuatech.com; &#125;&#125; 测试的时候发现，即使绑定美国和香港的节点去curl，是能正常解析到其他机器上的。如下： 然而源站过来的请求IP集中到了只有一个，这太奇怪了。 故障解决后来发现ngnix后端会把http1.1转换成1.0变成短连接，这个连接存在的时间非常短，因为后端响应非常快。所以即使配上了least_conn，其实是没有任何效果的。这样负载均衡的nginx看到所有源站其实一直都是没有连接的，所以也就一直在给第一个转。 既然这样，就取消了least_conn改用轮询，nginx.conf也改成如下的样子： 最后终于均衡了，大功告成！ 后来琢磨了一下，是用sticky其实也是OK的。 所以说，有些情景使用域名不通的情况下，可以考虑直接使用IP，这样就绕过nginx了，不会破坏原来的长连接。 几个主流负载均衡软件配置cookie的方法1.Apache的话首先打开httpd.conf配置文件，确保如下配置没有被注释。 1LoadModule usertrack_module modules/mod_usertrack.so 再在virtual host中添加以下配置。 1234CookieName nameCookieExpires \"1 days\"CookieStyle CookieCookieTracking on 2.Nginx参考以下配置，设置Cookie。 123456789server &#123; listen 8080; server_name wqwq.example.com; location / &#123; add_header Set-Cookie name=xxxx; root html; index index.html index.htm; &#125;&#125; 3.Lighttpd参考以下配置，设置Cookie。 12345server.modules = ( \"mod_setenv\" )$HTTP[\"host\"] == \"test.example.com\" &#123; server.document-root = \"/var/www/html/\" setenv.add-response-header = ( \"Set-Cookie\" =&gt; \"name=XXXXXX\" &#125;&#125; 扩展阅读https://cloud.tencent.com/document/product/214/2736http://blog.text.wiki/2015/08/01/nginx-sticky-problem.htmlhttps://cloud.tencent.com/developer/article/1004547","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"负载均衡","slug":"负载均衡","permalink":"http://yoursite.com/tags/负载均衡/"}]},{"title":"记一次阿里云oss云存储删除失败的问题","slug":"记一次阿里云oss云存储删除失败的问题","date":"2018-04-27T14:24:58.000Z","updated":"2018-04-27T14:49:34.000Z","comments":true,"path":"2018/04/27/记一次阿里云oss云存储删除失败的问题/","link":"","permalink":"http://yoursite.com/2018/04/27/记一次阿里云oss云存储删除失败的问题/","excerpt":"","text":"公司每天云存储都要删除过期的内容，工作细节是这样的：每天零点，采集模块开始收集应该删除掉的内容，然后把这个消息传给阿里云MQ，阿里云MQ又把消息传给删除模块，删除模块拿到名单之后，开始调用阿里云OSS的删除API进行删除。架构如图： 但是今天登陆监控平台发现，昨天oss没有删除，上涨了80多个T，如图： 老板一看，卧槽这怎么可以，80多个T的云存储费用可是不容小视的，于是责令追查一下为啥会发生这样的情况。 昨天我的手机又没有收到任何阿里云消息队列告警的信息，可见MQ应该是没问题的，查看一下是否有MQ的产生和消费情况，如下图： 产生的消息基本都消费掉了，由此推断之前的过程都应该是OK的。再查看一下会不会是删除模块外网带宽到期的问题，此时发现两天的流量有显著的不同： 流量明显减少，可以说是删除模块执行任务少了。于是到执行OSS删除API的模块上去抓了几个包，里面情况如下： 但是跑到阿里云对应的bucket里看一下文件情况，比如https://lechangecloud.oss-cn-hangzhou.aliyuncs.com/lechange/4B01F1FPAGE4E9D_img/Alarm/20180427000913997_0_fa62bec6dee24cc0bee42e1ee3e75743_thumb_qcif.dav这个文件，这个文件明明还在里面躺着好好的。如图： 文件00：27的时候就在了，但是2：53分的时候调用阿里云OSS的API去删除，明明返回了200，但是文件却没有真正的从OSS删除掉。 我觉得这样就拿去跟阿里云撕逼还是有点不太妥当，又回到刚刚的那个包里，我发现里面还有一些返回的内容是这样的： 这个图跟之前的图明显路径上不同，而这些文件在OSS上确认是被成功删除掉的，可见的确是文件路径的问题：失败的文件路径是完全路径，而成功的都是相对路径。于是就告诉开发赶快整改代码，把路径统一…","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"阿里云","slug":"阿里云","permalink":"http://yoursite.com/tags/阿里云/"}]},{"title":"在安装docker私有仓库的时候遇到的openssl问题","slug":"在安装docker私有仓库的时候遇到的openssl问题","date":"2018-04-20T16:45:39.000Z","updated":"2018-04-26T15:30:54.000Z","comments":true,"path":"2018/04/21/在安装docker私有仓库的时候遇到的openssl问题/","link":"","permalink":"http://yoursite.com/2018/04/21/在安装docker私有仓库的时候遇到的openssl问题/","excerpt":"","text":"按照http://wiki.jikexueyuan.com/project/docker-technology-and-combat/local_repo.html 的方法本地安装一个私有仓库，在执行sudo pip install docker-registry这一步的时候，出现了这样的一个错误： 既然说我没有swig，于是我yum install swig -y，安装的是2.0.10-5.el7版本。然后再次pip install docker-registry，一顿噼里啪啦之后，这次成了这样： 又说没有openssl的文件，那执行yum install openssl-devel，OK了之后再次pip install docker-registry，再一次噼里啪啦，如下： 反馈我：/usr/include/openssl/opensslconf.h:44: Error: CPP #error &quot;&quot;This openssl-devel package does not work your architecture?&quot;&quot;. Use the -cpperraswarn option to continue swig processing.,这个提示大意是说openssl-devel版本不适合你的系统架构，也就是x86的去找x86的头文件，x86_64的去找x86_64文件，但现在是互相找不到对方。 既然说/usr/include/openssl/opensslconf.h这个第44行有错误，那我们就打开这个文件去看看第44行写的是啥： 123456741 #elif defined(__x86_64__)42 #include \"opensslconf-x86_64.h\"43 #else44 #error \"This openssl-devel package does not work your architecture?\"45 #endif46 47 #undef openssl_opensslconf_multilib_redirection_h 这里我把第44行改成了这样： 123456741 #elif defined(__x86_64__)42 #include &quot;opensslconf-x86_64.h&quot;43 #else44 #include &quot;opensslconf.h&quot; #去掉了原来的error提示，改成了安装opensslconf.h文件。45 #endif46 47 #undef openssl_opensslconf_multilib_redirection_h 这一次重新执行sudo pip install docker-registry，终于成功…","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"容器技术","slug":"容器技术","permalink":"http://yoursite.com/tags/容器技术/"}]},{"title":"在国王杯前夕评巴萨","slug":"在国王杯前夕评巴萨","date":"2018-04-20T16:44:17.000Z","updated":"2018-07-19T01:49:06.000Z","comments":true,"path":"2018/04/21/在国王杯前夕评巴萨/","link":"","permalink":"http://yoursite.com/2018/04/21/在国王杯前夕评巴萨/","excerpt":"","text":"今天凌晨的马竞在西甲意外输给了皇家社会，巴萨的积分优势扩大到了12分。这个周末巴萨要跟塞维利亚打国王杯决赛，4月30号对拉科鲁尼亚的西甲联赛巴萨只要获胜，就会拿到今年的西甲联赛冠军，从而以冠军姿态在诺坎普迎接本赛季第二场国家德比。 巴尔韦德的困境巴萨今年可以说是低姿态开始：从内马尔突然的离开到西超杯被皇马灌了5个，不可为说不惨。但是巴尔韦德在联赛却目前保持不败，这个成绩单可以说是相当不错的，这中间还有在伯纳乌的三球胜利。 赛季中前段，巴萨三线顺风顺水，前有塞梅多惊艳开场，后有大祭司维尔马伦扎实顶上，主教练巴尔韦德也给了阿奈斯这样小将出场机会，哪怕登贝莱那时候养伤，报纸媒体一片其乐融融。如果保利尼奥再有进球，更是一片狂欢。 然后巴尔韦德的保守开始慢慢让人所诟病，他是一个重视防守的教练，这很好，但是他有了库迪尼奥也有了归来的登贝莱，结果反而不敢搞轮换，甚至坚持让布教授打封闭出场，虽然不少人抱怨，但是由于球队整体战绩还算平稳，所以没有大规模的重视。可是巴萨欧冠的结果跟恩里克的第二个赛季一样，倒在了与罗马的第二回合比赛里，连续三年没有闯入欧冠四强。 其实对战罗马的第一回合，巴萨的4：1已经是靠意志拼下来的比赛，球员难免在第二回合的心态上有所轻敌，这种心态上的轻敌难免会影响到身体，但是巴尔韦德的临场指挥也让人严重不满。落下这耻辱一战，媒体和球迷之前的“忍气吞声”一并爆发，狂轰滥炸，直到现在依旧有人说“哪怕真的赛季双冠，也会因为欧冠的失利而让那两冠索然无味”。 所以，巴尔韦德要在这个周日的国王杯决赛和对阵拉科鲁尼亚的西甲联赛里稳扎稳打，把国王杯和西甲冠军彻底拿到手里，这样整个人也能轻松一些。可是说来说去罗马一役这一个跟头摔得太疼了，在那么重大的比赛里失败，肯定需要在一个同样重大的比赛里胜利以挽回颜面，第二回合的国家德比无疑就是一个好的机会，如果巴尔韦德成功捍卫了诺坎普，“联赛双杀皇马+国内双冠”也能成为一个功劳。但是如果那场比赛，一心要打破巴萨不败金身的皇马真的成功了，那巴尔韦德势必在巴萨主帅的位置上也是飘摇。 所以巴帅，请务必要拿下国王杯冠军+西甲冠军！在第二个国家德比里也请拼尽全力！这样才能多少挽回一点“罗马之耻”的颜面。 夏季转会展望我个人认为，巴萨很有可能在今年夏天卖掉如下几个人：西莱森、戈麦斯、小苏亚雷斯、艾尔卡塞尔、比达尔，自由走人的可能会是小白。这些人能套现7000万应该就满足了。 巴萨后卫现在四个人皮克和维尔马伦属于潜藏的伤员病号，米纳技术还是太糙，稍微让人放心的就是乌姆蒂蒂，他的续约问题肯定是休赛期的一个大事。不过我觉得米纳其实可以再留一年看看，他身体素质很好，而且人还年轻没伤病，只要心态练得沉稳，当一个合格的中后卫不难。 至于中场，个人希望小白再踢一年，现在我也觉得一个满血的小白应付普通的联赛、欧冠小组赛和杯赛都不是什么难事。但是目前的媒体趋势是小白赛季结束会来中超重庆队，即使这样巴萨也需要一个山寨的坎特和一个山寨的埃里克森，而罗贝托集这两个属性于一身，所以他就是一个“奉献的砖”，但是这样如果比达尔真的不留下来的话，巴萨还需要补进一个右后卫跟塞梅多良性竞争，这个右后卫的人选就比较挠头了。贝莱林？或许是一个选择，但是这个选择跟当年小法一样—要是双输就不好了。 前场如果能拿下格里兹曼肯定是好的，艾尔卡塞尔这种“躲着后卫”的踢法，虽然进球效率可以，但是没有真正起到轮换苏亚雷斯的作用。这样巴萨还需要在板凳上补充一个中锋（不用多能进球，哪怕搅屎棍也可以），同时也做好登贝莱/苏亚雷斯/梅西/格里兹曼（假设他真的来）的轮换。 总而言之，现在巴萨还是回归433比较好，配合442和4312的变化。那么休赛期最重要的补强就是格里兹曼+能抗中卫的前锋+一个中场+一个优秀的边后卫。 我个人希望的引援名单如下：中场是魏格尔和B队的阿莱尼亚，埃里克森、博格巴和维拉蒂这三个不算是好的选择，要么太贵，要么节奏太慢。至于伊斯科、大卫席尔瓦、皮亚尼奇，那想都别想了，母队不会放人的。至于格雷茨卡，拜仁不是善茬；边后卫可以考虑贝莱林，这个要看一下阿森纳的新教练是谁，摩纳哥的法比尼奥也可以，我知道他现在改中场了，也不耽误来一下跟罗贝托交叉换位…前锋的话，我个人推荐B队阿奈斯试试看，其他的人选估计就是在西甲联赛内部找了；这几个位置，最重要就是中场！梅西当初在哈白布的配合下威力无穷，一旦巴萨的中场重新掌握了控制力，不用频繁回撤的梅西依旧会进球如麻，这一点毋庸置疑。 温格会来？我个人首先不希望巴尔韦德下课，毕竟现在巴萨联赛冠军十拿九稳，国王杯如果也揽入怀中，这样一个成绩单也是一个80分，如果这个分数都炒掉主教练，那么继任者的压力势必很大，所以我个人倾向巴尔韦德留任，好好想一下，等阿图尔以及可能会来的格里兹曼到位了，巴萨应该怎么打。 不过如果温格真的来了，我个人也是赞成的，因为阿森纳的球风本来跟巴萨相似，相信温格跟梅西等人也会无缝接入，到时候教授或许真的可以在巴萨圆了欧冠梦想，不过这个想法成真的可能性低于5%，想想就得了。 下赛季的任务1.进攻体系依旧围绕梅西建队，让梅西继续火力全开的同时保证休息，欧冠要他有大用；2.新球员（包括库蒂尼奥和登贝莱）适应巴萨的风格和体系，让皮克和布教授也能轮换得到休息；3.欧冠一定要进入四强；4.欧冠四强的基础上，西甲联赛冠军和国王杯能拿还是要拿，同时最好也能阻击皇马；","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"国际足坛","slug":"国际足坛","permalink":"http://yoursite.com/tags/国际足坛/"},{"name":"巴塞罗那","slug":"巴塞罗那","permalink":"http://yoursite.com/tags/巴塞罗那/"}]},{"title":"国内Docker的加速方法","slug":"国内Docker的加速方法","date":"2018-04-19T16:00:04.000Z","updated":"2018-04-19T16:17:10.000Z","comments":true,"path":"2018/04/20/国内Docker的加速方法/","link":"","permalink":"http://yoursite.com/2018/04/20/国内Docker的加速方法/","excerpt":"","text":"由于大陆政府的特殊政策，国内想访问一些国外的资源是非常的曲折和痛苦，比较有代表性的就是亚马逊的云存储以及docker，尤其在docker pull一些镜像的时候，更是心惊胆战，祈求不要出现timout，然而现实往往很骨感。如下图： 那么应该如何达到加速的效果呢？ 在CentOS 7里，对于使用systemd的系统，请在/etc/docker/daemon.json中写入如下内容：（如果文件不存在请新建该文件） 12345&#123; \"registry-mirrors\": [ \"https://registry.docker-cn.com\" ]&#125; 注意，一定要保证该文件符合 json 规范，否则 Docker 将不能启动。 之后重新启动服务。 12$ sudo systemctl daemon-reload$ sudo systemctl restart docker 注意：如果您之前查看旧教程，修改了docker.service文件内容，请去掉您添加的内容（–registry-mirror=https://registry.docker-cn.com）。 配置加速之后，如果拉取镜像仍然十分缓慢，请手动检查加速器配置是否生效，在命令行执行docker info |grep &#39;Registry Mirrors&#39; -A，如果从结果中看到了如下内容，说明配置成功。 现在再重新尝试一下docker pull training/webapp，看看效果： 仅用17秒就pull了几乎400MB的镜像，高下立判！","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]},{"title":"在Grafana里添加worldping插件","slug":"在Grafana里添加worldping插件","date":"2018-04-19T02:41:18.000Z","updated":"2018-04-19T03:53:36.000Z","comments":true,"path":"2018/04/19/在Grafana里添加worldping插件/","link":"","permalink":"http://yoursite.com/2018/04/19/在Grafana里添加worldping插件/","excerpt":"","text":"安装插件worldping是一个监控网站的dns、ping、http响应、https响应的插件，要安装它很简单，在granafa服务器里执行如下命令： 12grafana-cli plugins install raintank-worldping-appsystemctl restart grafana-server.service 执行完毕之后在grafana的界面里选择Plugins，然后在APP里找到worldping，启动它，但是此时发现需要一个api，如图： 此时你需要登录grafana的官网，然后点击api keys和ADD API KEY，就可以生成一个API KEY，名字可以随便起，如下： 将生成的api key保存好，并且填回到grafana的api key里，这样worldping插件就可以使用了，如图： 监控网站节点此时点击黄色旋涡，发现多了worldping的选项，点击worldping Home，如图： 然后点击+ New Endpoint，这里我输入我公司的官网域名，然后begin auto-discovery，如图： 生成了结果之后，点击add，此时开始检查几个大城市，如芝加哥、东京、纽约、巴黎等大城市连接到刚刚输入的域名的情况，如图： 大约需要1~2分钟后，数据检查完成，可以点击GO to Summary Dashboard，就会看到图像了： 为什么我这个图里没有http?因为在nginx里我们做了http强制rewrite跳转到https，所以是读不到值的。 删除网站节点如果要删除网站节点，还是在worldping里点击要删除网站后面的齿轮图标，如图： 然后选择configuration，这里可以修改网站域名，要删除的话，选择最下面的destory，输入DELETE确认，然后就可以点击DELETE删除了，如图：","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"grafana","slug":"grafana","permalink":"http://yoursite.com/tags/grafana/"},{"name":"图像监控","slug":"图像监控","permalink":"http://yoursite.com/tags/图像监控/"}]},{"title":"用非root用户启动tomcat进程","slug":"使用普通用户启动tomcat","date":"2018-04-18T14:19:34.000Z","updated":"2018-04-19T14:05:06.000Z","comments":true,"path":"2018/04/18/使用普通用户启动tomcat/","link":"","permalink":"http://yoursite.com/2018/04/18/使用普通用户启动tomcat/","excerpt":"","text":"使用非root用户启动进程是运维安全的一个主要环节，拿tomcat进程来说，如果是使用root用户去启动了tomcat，那么有一个严重的问题，那就是tomcat具有root权限。这意味着你的任何一个jsp脚本都具有root权限，所以那些不怀好意的人可以轻易地用jsp脚本去搞破坏，甚至删除你整个硬盘里的东西！所以为了活着，我们要极力避免这种现象。很多的软件都自带的用户/用户组，比如nginx、zabbix、elasticsearch，但是也有很多的软件没有这么贴心的服务，这就需要我们手动的更改了。 使用非root用户启动tomcat以tomcat为例，打算用chris账号(属于chen这个group)启动。那么首先先创建账号和组，如下： 12345[root@chen-docker ~]groupadd chen #创建chen这个组[root@chen-docker ~]useradd -s /bin/bash -g chen chris #在这个组里面添加chris这个用户[root@chen-docker ~]passwd chris #给这个用户设定密码[root@chen-docker ~]# id chrisuid=1000(chris) gid=1002(chen) groups=1002(chen) #可见添加成功 su chris切换到chris用户，在/home/chris里使用wget http://apache.fayea.com/tomcat/tomcat-9/v9.0.7/bin/apache-tomcat-9.0.7.tar.gz下载tomcat。然后解压缩在/home/chris里，因为chris用户在这里是有权限的。然后进行如下的操作： 12345cd ~/ 代表用户所在目录mkdir -p ~/shell-scriptcd ~/shell-script/touch start.shtoush stop.sh 这个start.sh的内容很简单，如下： 12345678#/bin/bashif [ \"root\" == \"$USER\" ] #不让root启动then echo \"can't start with user 'root',retry after change user!\" exit 1else cd /home/chris/apache-tomcat-9.0.7/bin/ &amp;&amp; ./start.shfi shutdown.sh的内容同理： 12345678#/bin/bashif [ \"root\" == \"$USER\" ] #不让root启动then echo \"can't start with user 'root',retry after change user!\" exit 1else cd /home/chris/apache-tomcat-9.0.7/bin/ &amp;&amp; ./shutdown.shfi chmod +x *.sh给上面两个脚本可执行权限，但是现在执行startup.sh或者shutdown.sh会出现一个问题： 12Neither the JAVA_HOME nor the JRE_HOME environment variable is definedAt least one of these environment variable is needed to run this program 这是因为chris用户没有权限去启动java这个可执行程序，如果使用java -version回答是bash: java: command not found，这个时候怎么办？ 编辑~/.bash_profile，在末尾处加上如下的内容： 然后source .bash_profile，再使用java -version确认一下应该是OK了。这个时候也是可以使用chris用户去启动刚刚的那个start.sh和shutdown.sh的。 由于我们的tomcat是源码解压缩，所以要使用root用户去创建一下/etc/init.d/tomcat。里面内容如下： 123456789#!/bin/bashcase $1 instart)su - chris -lc \"sh /home/chris/shell-script/start.sh\";; #如果要root启动，那就是su - root -lc \"sh /home/utomcat/shell-script/start.sh\";;stop)su - chris -lc \"sh /home/chris/shell-script/shutdown.sh\";;*)echo \"parameter error, usage:(start|stop)\";;esac 保存之后，执行一下service tomcat start看看效果。 如果要设置开机自启动，别忘了chkconfig --add tomcat和chkconfig tomcat on，在浏览器打开ip:8080看见汤姆猫~ 当普通用户要使用1024以下的端口众所周知，linux默认是不准许普通用户调用1024以下的端口的，那么遇到这样的需求怎么办呢？最好的方法是使用iptables。 首先让程序运行在非root帐户下，并绑定高于1024的端口，在确保能正常工作的时候，将低端口通过端口转发，将低端口转到高端口，从而实现非root运行的程序绑定低端口。要使用此方法可以使用下面的方式： 1234sysctl -w net.ipv4.ip_forward=1 #要长久保存，需要在/etc/sysctl.conf文件内修改，然后sysctl -p /etc/sysctl.confiptables -F -t natiptables -t nat -A PREROUTING -p tcp --dport 80 -j DNAT --to:8088 #将80端口转发到8088iptables -t nat -A PREROUTING -p tcp --dport 80 -j REDIRECT --to-port 8080 #这句话也可以 这么操作在速度上没有任何影响。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"centos","slug":"centos","permalink":"http://yoursite.com/tags/centos/"},{"name":"运维安全","slug":"运维安全","permalink":"http://yoursite.com/tags/运维安全/"}]},{"title":"用非root启动进程以及启动docker","slug":"用非root启动进程以及启动docker","date":"2018-04-18T14:19:34.000Z","updated":"2018-05-15T06:28:46.000Z","comments":true,"path":"2018/04/18/用非root启动进程以及启动docker/","link":"","permalink":"http://yoursite.com/2018/04/18/用非root启动进程以及启动docker/","excerpt":"","text":"使用非root用户启动普通进程使用非root用户启动进程是运维安全的一个主要环节，拿tomcat进程来说，如果是使用root用户去启动了tomcat，那么有一个严重的问题，那就是tomcat具有root权限。这意味着你的任何一个jsp脚本都具有root权限，所以那些不怀好意的人可以轻易地用jsp脚本去搞破坏，甚至删除你整个硬盘里的东西！所以为了活着，我们要极力避免这种现象。 很多的软件都自带的用户/用户组，比如nginx、zabbix、elasticsearch，但是也有更多的软件没有这么贴心的服务，这就需要我们手动的更改了。 docker不应该使用root启动1.8版本之前的docker是不支持user namespace的，所以那样的话，如果在docker容器内部使用root运行app，那么不可否认，这个root和宿主机的root是同一个UID。但是，需要特别注意的是，容器内的root与宿主机上的root权限并不一定是相等的。 但是为了绝对的安全，还是推荐把docker升级到1.8以上，然后彻底避免用root去启动容器，在http://www.projectatomic.io/docs/docker-image-author-guidance/里最下面一段也明文说了---生产环境里不要用root用户去启动docker!!! 使用非root用户启动docker的办法如下：创建docker组：sudo groupadd docker将当前用户加入docker组：sudo gpasswd -a ${USER} docker重新启动docker服务：sudo service docker restart或sudo systemctl restart docker当前用户退出系统再重新登陆。 参考资料https://www.zhihu.com/question/25580965","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"安全","slug":"安全","permalink":"http://yoursite.com/tags/安全/"}]},{"title":"使用docker做一个主从同步的redis集群","slug":"使用docker做一个主从同步的redis集群","date":"2018-04-17T16:14:44.000Z","updated":"2018-04-19T03:51:28.000Z","comments":true,"path":"2018/04/18/使用docker做一个主从同步的redis集群/","link":"","permalink":"http://yoursite.com/2018/04/18/使用docker做一个主从同步的redis集群/","excerpt":"","text":"查看容器内部信息之前用docker run -it --name redis-master redis /bin/bash创建了一个redis的docker，现在登陆发现状态已经是exit，于是就使用docker container start 容器ID号or容器名称来重新启动。如图： 然后书里说到要用docker inspect来查看所挂载volume的情况，使用命令: 1[root@chen-docker ~]# docker inspect --format &quot;&#123;&#123; .Volumes &#125;&#125;&quot; f391531120b0 但是很不幸，系统反馈给我一个错误： 1Template parsing error: template: :1:3: executing &quot;&quot; at &lt;.Volumes&gt;: map has no entry for key &quot;Volumes&quot; 没有这个Volumes，那就干脆查看一下这个容器的所有信息：docker inspect f391531120b0，这个命令里面有Config、Mounts、HostConfig、NetworkSettings等等整个容器的所有信息，比如看一下NetworkSettings相关的内容，如图： 此时使用如下命令： 1234[root@chen-docker ~]# docker inspect --format &quot;&#123;&#123; .NetworkSettings.IPAddress &#125;&#125;&quot; f391531120b0 #注意前面的.192.168.0.2[root@chen-docker ~]# docker inspect --format &quot;&#123;&#123; .NetworkSettings.MacAddress &#125;&#125;&quot; f391531120b002:42:c0:a8:00:02 这样就可以获取到内网IP和mac地址，同理换成docker inspect f391531120b0 | grep Mounts -A 10，看一下挂载信息，如图： 原来容器里的/data其实就是宿主机的/var/lib/docker/volumes/94b3c20a6d269c7498ab59ee45c560e84fed64a636767a4baa54fa7befbcd4ff/_data这个文件夹。为了验证这一点，我先到宿主机去创建一个叫aaa文件，如下： 12root@f391531120b0:/data# cat aaa 123123 再返回到宿主机上看： 12345[root@chen-docker ~]# cd /var/lib/docker/volumes/94b3c20a6d269c7498ab59ee45c560e84fed64a636767a4baa54fa7befbcd4ff/_data[root@chen-docker _data]# lsaaa[root@chen-docker _data]# cat aaa 123123 这就搞定了！ 主从同步排错就是按书里写的开始配置和启动redis-slave，但是却发现同步没有成功，在redis-slave日志里发现这样的话： 12332677:S 08 Feb 16:14:40.952 * Connecting to MASTER 172.168.10.70:637932677:S 08 Feb 16:14:40.952 * MASTER &lt;-&gt; SLAVE sync started32677:S 08 Feb 16:14:40.953 # Error condition on socket for SYNC: Connection refused 这个的原因就是redis主服务器绑定了127.0.0.1，那么跨服务器IP的访问就会失败，从服务器用IP和端口访问主的时候，主服务器发现本机6379端口绑在了127.0.0.1上，也就是只能本机才能访问，外部请求会被过滤。所以需要修改redis-master的redis.conf，注释掉bind 127.0.0.1，如果是线上生产环境建议绑定IP地址。 重新启动redis之后，发现同步依然失败，日志变成了这样： 12345690:S 17 Apr 09:27:35.906 * Non blocking connect for SYNC fired the event.90:S 17 Apr 09:27:35.907 # Error reply to PING from master: &apos;-DENIED Redis is running in protected mode because protected mode is enabled, no bind address was specified, no authentication password is requested to clients. In this mode connections are only accepted from the loopback interface. If you want to connect&apos;90:S 17 Apr 09:27:36.908 * Connecting to MASTER 192.168.0.2:637990:S 17 Apr 09:27:36.909 * MASTER &lt;-&gt; SLAVE sync started90:S 17 Apr 09:27:36.909 * Non blocking connect for SYNC fired the event.90:S 17 Apr 09:27:36.909 # Error condition on socket for SYNC: Connection reset by peer 这个日志的意思是说redis在没有开启bind和密码的情况下，保护模式被开启。然后Redis的只接受来自环回IPv4和IPv6地址的连接。于是还是要修改redis-master的redis.conf关闭保护模式：portected-mode no，然后重启redis-master即可。 容器内安装ping先检查你的容器是使用什么系统的景象，如果是ubantu那就是apt-get，安装ping的命令如下： 12apt-get updateapt-get install inetutils-ping 如何让容器一直启动如果用了一段时间的docker就会发现，我们的容器经常用了一段时间就自动退出了，docker ps已经找不到了，在docker ps -a里面了，如图： 然后我们docker start containerId想重新开启这个容器，可能这次来的更快，没几分钟容器又自己关了，由这个问题又可能引发其它很多的问题。 docker run指定的命令如果不是那些一直挂起的命令（比如运行top，不断echo），就是会自动退出的。-d命令是设置detach为true，根据官方的文档，意思是让这个命令在后台运行，但并不是一直运行，Docker容器后台运行,就必须有一个前台进程。主线程结束，容器会退出。 我们启动容器的时候不要-d命令启动，用-dit就好了，例如： 12docker run -d hello-world(不要这么做)docker run -dit hello-world(推荐)","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"},{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"主从同步","slug":"主从同步","permalink":"http://yoursite.com/tags/主从同步/"}]},{"title":"使用zabbix监控memcache","slug":"使用zabbix监控memcache","date":"2018-04-03T11:00:58.000Z","updated":"2018-04-03T11:05:48.000Z","comments":true,"path":"2018/04/03/使用zabbix监控memcache/","link":"","permalink":"http://yoursite.com/2018/04/03/使用zabbix监控memcache/","excerpt":"","text":"监控memcache的原理跟监控redis差不多，都是通过一个类似info的东西可以查询到memcache的状态值，然后通过脚本去获取这些值给zabbix，当发现某值不正常就发出告警。 查询当年memcache状态的命令是echo stats |nc 127.0.0.1 11211，如果没有nc命令，那就yum install -y nc。 获得到的结果是这个样子的： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[root@lconline-ec2 ~]# echo stats |nc 127.0.0.1 11211STAT pid 1859 memcache服务进程IDSTAT uptime 491093 服务器已运行秒数STAT time 1522740969 服务器当前Unix时间戳STAT version 1.4.25 memcache版本STAT libevent 1.4.13-stableSTAT pointer_size 64 操作系统指针大小STAT rusage_user 14.321822 进程累计用户时间STAT rusage_system 14.095857 进程累计系统时间STAT curr_connections 5 当前连接数量STAT total_connections 51010 Memcached运行以来连接总数STAT connection_structures 8 Memcached分配的连接结构数量STAT reserved_fds 20STAT cmd_get 0 get命令请求次数STAT cmd_set 0 set命令请求次数STAT cmd_flush 0 flush命令请求次数STAT cmd_touch 0 touch命令请求次数STAT get_hits 0 get命令命中次数STAT get_misses 0 get命令未命中次数STAT delete_misses 0 delete命令未命中次数STAT delete_hits 0 delete命令命中次数STAT incr_misses 0 incr命令未命中次数STAT incr_hits 0 incr命令命中次数STAT decr_misses 0 decr命令未命中次数STAT decr_hits 0 decr命令命中次数STAT cas_misses 0 cas命令未命中次数STAT cas_hits 0 cas命令命中次数STAT cas_badval 0 使用擦拭次数STAT touch_hits 0STAT touch_misses 0STAT auth_cmds 0 认证命令处理的次数 STAT auth_errors 0 认证失败数目STAT bytes_read 357040 读取总字节数 STAT bytes_written 60197691 发送总字节数STAT limit_maxbytes 1073741824 分配的内存总大小（字节）STAT accepting_conns 1 服务器是否达到过最大连接（0/1）STAT listen_disabled_num 0 失效的监听数STAT time_in_listen_disabled_us 0STAT threads 4 当前线程数STAT conn_yields 0 连接操作主动放弃数目STAT hash_power_level 16STAT hash_bytes 524288 当前存储占用的字节数STAT hash_is_expanding 0STAT malloc_fails 0 STAT bytes 0 当前存储占用的字节数STAT curr_items 0 当前存储的数据总数STAT total_items 0 启动以来存储的数据总数STAT expired_unfetched 0 STAT evicted_unfetched 0STAT evictions 0 LRU释放的对象数目STAT reclaimed 0 已过期的数据条目来存储新数据的数目STAT crawler_reclaimed 0STAT crawler_items_checked 0STAT lrutail_reflocked 0 END 修改zabbix_agentd.conf，添加一个新的自定义项： 1UserParameter=memcached.stat[*],(echo stats; sleep 1) | telnet 127.0.0.1 11211 2&gt;&amp;1 | awk '/STAT $1 / &#123;print $NF&#125;' 然后重启zabbix-agent，模板就用github里的就好，看到的效果如下：","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"memcached","slug":"memcached","permalink":"http://yoursite.com/tags/memcached/"}]},{"title":"使用zabbix去监控网站和tcp连接","slug":"使用zabbix去监控网站","date":"2018-04-02T01:42:45.000Z","updated":"2018-04-03T11:58:24.000Z","comments":true,"path":"2018/04/02/使用zabbix去监控网站/","link":"","permalink":"http://yoursite.com/2018/04/02/使用zabbix去监控网站/","excerpt":"","text":"网页状态码监控在zabbix的web界面，配置–主机–选择一个有外网权限的服务器，比如选择zabbix server–Web检测，如图： 然后点击右上角的创建Web场景，然后依次填入名称，间隔，客户端等等，如图： 然后编辑步骤，先添加，填入对应的url，然后写上200状态码，意思就是返回200是OK的。保存即可，如果还有http认证，那么就继续填写认证。 至此，一个简单的监控官网状态码的配置过程就结束了，剩下就是增添一下触发器，如下： tcp连接监控首先在zabbix-agentd.conf里添加一个新的自定义监控项： 1UserParameter=tcp.status[*],netstat -a | awk '/^tcp/ &#123;++y[$NF]&#125; END &#123;for(i in y) print i,y[i]&#125;' | grep $1 | awk '&#123;print $NF&#125;' 然后service zabbix-agent restart重启客户端，模板就是https://gitee.com/careyjike_173/zabbix/tree/master/template 里的zbx_tcp_status_templates.xml，直接导入即可。如图： 然后自己配置一下time_wait/close_wait的告警阈值。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"web监控","slug":"web监控","permalink":"http://yoursite.com/tags/web监控/"},{"name":"tcp连接","slug":"tcp连接","permalink":"http://yoursite.com/tags/tcp连接/"}]},{"title":"使用zabbix去监控php-fpm","slug":"使用zabbix去监控php-fpm","date":"2018-04-02T01:42:36.000Z","updated":"2018-08-02T02:37:32.000Z","comments":true,"path":"2018/04/02/使用zabbix去监控php-fpm/","link":"","permalink":"http://yoursite.com/2018/04/02/使用zabbix去监控php-fpm/","excerpt":"","text":"开启状态统计nginx有一个status来获取nginx处理信息的总览情况，php-fpm也有一个状态统计。要打开这个状态统计，需要先打开php-fpm.conf，将pm.status_path = /status前面的注释去掉。 然后跑到nginx里，在nginx.conf里添加一个location： 1234567 location ~ ^/(status|ping) &#123; fastcgi_pass 127.0.0.1:9000; include fastcgi.conf; access_log off; allow 127.0.0.1; deny all;&#125; 然后重启一下php-fpm和nginx，在命令行里输入curl -s http://127.0.0.1:80/status，就会看到php的状态统计，如下图： php-fpm status详解pool - fpm池子名称，大多数为wwwprocess manager – 进程管理方式,值：static, dynamicstart time– 启动日期,如果reload了php-fpm，时间会更新start since – 运行时长accepted conn – 当前池子接受的请求数listen queue – 请求等待队列，如果这个值不为0，那么要增加FPM的进程数量max listen queue – 请求等待队列最高的数量listen queue len – socket等待队列长度idle processes – 空闲进程数量active processes – 活跃进程数量total processes – 总进程数量max active processes – 最大的活跃进程数量（FPM启动开始算）max children reached - 大道进程最大数量限制的次数，如果这个数量不为0，那说明你的最大进程数量太小了，请改大一点。slow requests – 启用了php-fpm slow-log，缓慢请求的数量 配置监控跑到zabbix-agentd.conf里添加一个自定义监控项，如下： 1UserParameter=php-fpm.status[*],/usr/bin/curl -s \"http://127.0.0.1/php-fpm_status?xml\" | grep \"&lt;$1&gt;\" | awk -F'&gt;|&lt;' '&#123; print $$3&#125;' 然后重启一下zabbix-agent，模板就是https://gitee.com/careyjike_173/zabbix/tree/master/template 里的zbx_php-fpm_templates.xml，直接导入即可！ 效果如下图： 没有监控到进程？zabbix有时候会在监控进程出现不太准的情况，比如我这个机器的php。配置了proc.num[php-fpm,,,]这个key，但是在zabbix-server死活都取不到值，如图： 但是在被监控机器里，进程是明明存在的： 这特么的是为啥？ 这就是因为proc.num[进程名,,,]里面的进程名是在/proc/进程PID/status里的name一栏获得的，比如我这个机器的php情况： name里写的是php-fpm56，所以key也要改成proc.num[php-fpm56,,,]，这个时候在zabbix-server就成功取值了，如图： 注意！/proc/进程PID/status的name会被截断为15个字符。所以在配置时要事前检查一下。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"php-fpm","slug":"php-fpm","permalink":"http://yoursite.com/tags/php-fpm/"}]},{"title":"使用zabbix去监控nginx","slug":"使用zabbix去监控nginx","date":"2018-04-02T01:42:24.000Z","updated":"2018-04-03T11:58:02.000Z","comments":true,"path":"2018/04/02/使用zabbix去监控nginx/","link":"","permalink":"http://yoursite.com/2018/04/02/使用zabbix去监控nginx/","excerpt":"","text":"准备工作zabbix监控nginx，首先要确认nginx里是否有http_stub_status_module这个模块，一般来说，这个模块是自动安装的，nginx -V如下图： 如果你的nginx没有这个模块，请去看https://rorschachchan.github.io/2018/01/03/Nginx动态编译新的模块/ 。 然后在nginx.conf里添加一段话： 1234 location = /nginx-status &#123; stub_status on; access_log off;&#125; nginx -s reload一下，然后在命令行输入curl http://127.0.0.1/nginx-status，就会看到如下的界面： 这样就可以通过http_stub_status_module检查nginx情况了！ nginx status详解以上图的nginx status来做例子说明一下各个数字的意思：active connections – 活跃的连接数量accepts — 总共处理了3832000个连接handled — 成功创建3832000次握手requests — 总共处理了3295877个请求reading — 读取客户端的连接数writing — 响应数据到客户端的数量waiting — 开启keep-alive的情况下,这个值等于active – (reading+writing), 意思就是 Nginx 已经处理完正在等候下一次请求指令的驻留连接 配置监控有了模块，还需要添加一个脚本，然后就可以获取上面的数值了，脚本如下： 1234567891011121314151617181920212223242526272829303132#!/bin/bash# Method of useHOST=\"127.0.0.1\"PORT=\"80\" #这个根据实际情况填写URL=\"http://$&#123;HOST&#125;:$&#123;PORT&#125;/nginx-status\"active() &#123; curl \"$&#123;URL&#125;\" 2&gt;/dev/null | grep \"Active\" | awk '&#123;print $NF&#125;'&#125;reading() &#123; curl \"$&#123;URL&#125;\" 2&gt;/dev/null | grep \"Reading\" | awk '&#123;print $2&#125;'&#125;writing() &#123; curl \"$&#123;URL&#125;\" 2&gt;/dev/null | grep \"Writing\" | awk '&#123;print $4&#125;'&#125;waiting() &#123; curl \"$&#123;URL&#125;\" 2&gt;/dev/null | grep \"Waiting\" | awk '&#123;print $NF&#125;'&#125;accepts() &#123; curl \"$&#123;URL&#125;\" 2&gt;/dev/null | awk NR==3 | awk '&#123;print $1&#125;'&#125;handled() &#123; curl \"$&#123;URL&#125;\" 2&gt;/dev/null | awk NR==3 | awk '&#123;print $2&#125;'&#125;requests() &#123; curl \"$&#123;URL&#125;\" 2&gt;/dev/null | awk NR==3 | awk '&#123;print $NF&#125;'&#125;ping() &#123; ps -ef | grep nginx | grep -v grep -c&#125;$1 然后再去zabbix_agentd.conf里添加一句话: 1UserParameter=nginx.status[*],/usr/local/zabbix/script/nginx_status.sh $1 然后service zabbix-agent restart，自定义项就搞定了。 如果要导入模板，https://gitee.com/careyjike_173/zabbix 这个朋友的模板已经非常全面了，根据实际情况修改之后再导入他的xml就好，感谢前人付出！","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"金山云api调用的几个例子","slug":"金山云api调用的两个例子","date":"2018-03-29T14:55:09.000Z","updated":"2018-11-13T03:16:52.000Z","comments":true,"path":"2018/03/29/金山云api调用的两个例子/","link":"","permalink":"http://yoursite.com/2018/03/29/金山云api调用的两个例子/","excerpt":"","text":"今天另外一个运维要看一下金山云API返回的格式，于是就临时写了两个demo，也顺便记录下来，说不定以后开发脚本的时候可能用的着。 金山云跟阿里云的sdk不一样，阿里云有一个总的sdk，然后不同的服务还需要去分别下载对应具体的sdk；而金山的不是，他绝大多数的服务都是用那个总sdk。 查询数据库的脚本需要先获取https://github.com/kscdb/krds_openapi_sdk.git，然后执行python setup.py install安装所用的金山库。 这个脚本是查询某个数据库的具体情况： 脚本如下： 1234567891011121314#!/usr/bin/env python# -*- encoding:utf-8 -*-from kscore.session import get_sessionfrom krds_client import *#密钥ACCESS_KEY_ID = \"这里填写ak\"SECRET_ACCESS_KEY = \"这里填写sk\"#连接s = get_session()krds_client = KRDSClient(ACCESS_KEY_ID, SECRET_ACCESS_KEY, '地域名')r = krds_client.DescribeDBInstances(DBInstanceIdentifier='5c664b16-fbfe-4373-8a00-67c9476e7386',DBInstanceType='HA') #DBInstanceIdentifier后面是实例IDprint r 执行脚本之后，可以看到返回的结果包括数据库里很多的资料，如图： 如果不加参数的话，就是返回账号内所有的数据库情况。 查询服务器的脚本需要先获取https://github.com/KscSDK/ksc-sdk-python.git，然后执行python setup.py install安装所用的金山库。 这个脚本是查询下面这个服务器的情况： 脚本如下： 123456789101112#!/usr/bin/env python# -*- encoding:utf-8 -*-from kscore.session import get_session#密钥ACCESS_KEY_ID = \"这里填写ak\"SECRET_ACCESS_KEY = \"这里填写sk\"#连接s = get_session()client = s.create_client(\"kec\", \"地域名\", use_ssl=True,ks_access_key_id=ACCESS_KEY_ID, ks_secret_access_key=SECRET_ACCESS_KEY)print client.describe_instances(Search=['js-online-hlsproxy-20']) #Search后面接实例名 执行脚本之后，可以看到返回的结果包括数据库里很多的资料，如图： 如果不加参数的话，就是返回账号内所有的服务器情况。 弹性IP相关的脚本脚本如下： 12345678910111213141516171819202122#!/usr/bin/env python#coding=utf-8#这个脚本是用来修改金山云的eip带宽import json,pprintfrom kscore.session import get_session# 密钥ACCESS_KEY_ID = \"这里是ak\"SECRET_ACCESS_KEY = \"这里是sk\"s = get_session()region='cn-shanghai-2'eipClient = s.create_client(\"eip\",region, use_ssl=False,ks_access_key_id=ACCESS_KEY_ID,ks_secret_access_key=SECRET_ACCESS_KEY)#allEips=eipClient.get_lines() #这是获取LineID#allEips=eipClient.allocate_address(LineId:\"a2403858-2550-4612-850c-ea840fa343f9\",BandWidth:5,ChargeType:\"PostPaidByDay\") #这是创建eip#print allEips#allEips=eipClient.describe_addresses(MaxResults=7) #这是查询eip，一次输出7次for line in open(\"/具体路径/金山云eip名单.txt\"): line = line.strip('\\n') #去掉回车 eipClient.modify_address(**&#123;'AllocationId':line,'BandWidth':1&#125;) #将文件里的所有的eip带宽改成1M print (\"带宽已经调整完毕！\") 总体来说金山云的sdk文档还是比较挫。 参考资料https://github.com/KscSDK/ksc-sdk-pythonhttps://github.com/kscdb/krds_openapi_sdk","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"金山云","slug":"金山云","permalink":"http://yoursite.com/tags/金山云/"}]},{"title":"使用pandas来做html表格","slug":"使用pandas来做html表格","date":"2018-03-27T15:31:28.000Z","updated":"2018-03-27T15:56:18.000Z","comments":true,"path":"2018/03/27/使用pandas来做html表格/","link":"","permalink":"http://yoursite.com/2018/03/27/使用pandas来做html表格/","excerpt":"","text":"前言最近电子商城慢sql问题引了小BOSS的重视，于是就打算给开发们搞一个表格，在表格里可以看到前一天阿里云数据库的慢sql。这一次我不打算用html邮件了，因为慢sql数量不固定，今天可能三个，明天可能五个，后天抽风可能就一百个。而html邮件的格式是要事先写死的，于是我就用pandas来做这个表格，直接生成一个html文件，通过访问浏览器去让开发看慢sql。 慢日志脚本我要承认，阿里云自带的api在线调试工具真是一个好东西，有了它，脚本demo可以直接生成，地址是：https://api.aliyun.com/?spm=a2c4g.750001.952925.6.1QrDYe ，于是乎，阿里云获取慢日志脚本test.py如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/usr/bin/env python#coding=utf-8import json from aliyunsdkcore import clientfrom aliyunsdkrds.request.v20140815 import DescribeSlowLogRecordsRequest clt = client.AcsClient('这里是ak','这里是sk','这里是地域')# 设置参数request = DescribeSlowLogRecordsRequest.DescribeSlowLogRecordsRequest()request.set_accept_format('json')request.add_query_param('DBInstanceId', 'RDS的ID号')request.add_query_param('StartTime', '2018-03-26T08:00Z') #3月26日早上8点开始request.add_query_param('EndTime', '2018-03-27T08:00Z') #3月27日早上8点结束request.add_query_param('DBName', '对应的数据库名')request.add_query_param('PageSize', 100) #这个值只能是30/50/100# 发起请求response = clt.do_action_with_exception(request)print response#把json格式的返回值改成dict格式slow_log=json.loads(response)num = slow_log['TotalRecordCount']Hostaddress = []LockTimes = []ParseRowCounts = []QueryTimes = []SQLText = []#将有用的值做成listif num &lt; 100: for i in range(0,num): Hostaddress.append(slow_log['Items']['SQLSlowRecord'][i]['HostAddress']) LockTimes.append(slow_log['Items']['SQLSlowRecord'][i]['LockTimes']) ParseRowCounts.append(slow_log['Items']['SQLSlowRecord'][i]['ParseRowCounts']) QueryTimes.append(slow_log['Items']['SQLSlowRecord'][i]['QueryTimes']) SQLText.append(slow_log['Items']['SQLSlowRecord'][i]['SQLText'])else: for i in range(0,100): Hostaddress.append(slow_log['Items']['SQLSlowRecord'][i]['HostAddress']) LockTimes.append(slow_log['Items']['SQLSlowRecord'][i]['LockTimes']) ParseRowCounts.append(slow_log['Items']['SQLSlowRecord'][i]['ParseRowCounts']) QueryTimes.append(slow_log['Items']['SQLSlowRecord'][i]['QueryTimes']) SQLText.append(slow_log['Items']['SQLSlowRecord'][i]['SQLText']) 这个response的格式是一个json，在www.json.cn里查看是这个样子： 可以看到返回值里面TotalRecordCount就是总返回值，如果这个值大于PageSize，那么就会有第二篇，需要手动翻篇。所以我这里直接最大值就是100，一篇100已经够开发看了… 脚本如下在上面的脚本里可以获取到所有慢sql的json格式，那么就可以再写一个脚本把json转化成html格式并且生成一个html文件，然后在nginx里直接把这个文件展示出来。既然用到了pandas库，那么就要先安装pandas,方法如下： 1234pip install --upgrade pippip install pandas如果有“Please upgrade numpy to &gt;= 1.9.0 to use this pandas version”的反应，那么执行下一句pip install -U numpy 生成html的整个脚本如下： 123456789101112131415161718192021222324252627#!/usr/bin/env python#coding=utf-8from test import Hostaddress,LockTimes,ParseRowCounts,QueryTimes,SQLText #从刚写的test.py里得到那些list变量import pandas as pddef convertToHtml(result,title): #将数据转换为html的table #result是list[list1,list2]这样的结构 #title是list结构；和result一一对应。titleList[0]对应resultList[0]这样的一条数据对应html表格中的一列 d = &#123;&#125; index = 0 for t in title: d[t]=result[index] index = index+1 pd.set_option('max_colwidth',200) #默认的行长度是50，这里我调成了200 df = pd.DataFrame(d) df = df[title] h = df.to_html(index=False) return hif __name__ == '__main__': result = [Hostaddress,LockTimes,ParseRowCounts,QueryTimes,SQLText] title = [u'HostAddress',u'LockTimes',u'ParseRowCounts',u'QueryTimes',u'SQLText'] #生成一个叫biaoge.html with open('/nginxhtml路径/biaoge.html', 'w') as f: f.write(convertToHtml(result,title)) print \"html文件已经生成！\" 执行效果将这个biaoge.html直接生成到nginx的html文件夹里，在浏览器里打开这个html就看到效果了，如图：","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"pandas","slug":"pandas","permalink":"http://yoursite.com/tags/pandas/"},{"name":"大数据分析","slug":"大数据分析","permalink":"http://yoursite.com/tags/大数据分析/"}]},{"title":"记录一次nginx出现了502的问题","slug":"记录一次nginx出现了502的问题","date":"2018-03-26T11:01:24.000Z","updated":"2018-03-26T11:12:30.000Z","comments":true,"path":"2018/03/26/记录一次nginx出现了502的问题/","link":"","permalink":"http://yoursite.com/2018/03/26/记录一次nginx出现了502的问题/","excerpt":"","text":"背景交待市场运营在手机APP端推送了一个“家装节，部分商品优惠打折”消息，用户可以通过点击这个消息，在APP进入到商城界面，如果是已经登录的用户将通过免登陆直接跳转，如果是没有登录的用户会登陆到登陆界面。但是刚推送就发现，通过这个推送点击，没有正常登陆到商城界面，而是返回了502。 nginx 502的错误，一般来说就是php-fpm的问题，我登陆到电商服务器发现，php-fpm运行正常而且php-fpm的进程数也很正常。但是查看到mysql，发现mysql的CPU飙升，如图： 于是登陆到数据库里，使用show processlist一看，数据库里有大量的语句处于sending data状态，而且执行时间令人发指（command项处于Sleep状态的进程表示其正在等待接受查询，因此它并没有消耗任何资源，是无害的）： 先赶快通知运营先把推送的消息界面停用掉，不要让更多的用户登陆失败。然后写了一个脚本批量的kill掉这些进程，看看能不能让数据库恢复正常，过程如下。 首先先得到show processlist展现的所有的情况: 1mysql -uroot -p密码 -h数据库地址 -e \"show processlist\" | grep -i 'Locked' &gt; locked_log.txt 然后获得前面的进程号，并且加上kill的指令: 12345#/bin/bashfor line in `cat locked_log.txt | awk '&#123;print $1&#125;'`do echo \"kill $line;\" &gt;&gt; kill_thread_id.sqldone 在登陆到数据库，然后执行上面生成的kill_thread_id.sql：: 1mysql&gt;source kill_thread_id.sql 但是发现，kill掉一批之后，又有了新的慢sql出现，CPU依旧高居不下，于是只能跟产品经理说明情况，在征得了产品经理无奈的同意之后，重启了数据库，幸好时间没有很长，就耽误二三分钟而已。重启了之后，CPU就降下去了。赶快叫开发童鞋在线补充一个索引给用户登录的表来解决这个慢sql问题，没有了慢sql就没有了502。 补充nginx499nginx如果爆错499的话，代表客户端主动关闭连接，原因就是后端脚本执行的时间太长了or数据库有慢mysql，调用方超出了timeout的时间，关闭了连接。 这个时候需要更改一下nginx.conf: 12proxy_read_timeout 10s;proxy_send_timeout 10s; 把上面两个值适度调大然后重启nginx即可。或者就是proxy_ignore_client_abort on;，这话就是让代理服务端不要主动关闭客户端的连接。 参考资料https://blog.csdn.net/zhuxineli/article/details/14455029https://segmentfault.com/a/1190000012326158","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"使用python调用redis的基本操作","slug":"使用python调用redis的基本操作","date":"2018-03-26T10:52:37.000Z","updated":"2018-05-15T08:32:54.000Z","comments":true,"path":"2018/03/26/使用python调用redis的基本操作/","link":"","permalink":"http://yoursite.com/2018/03/26/使用python调用redis的基本操作/","excerpt":"","text":"前言最近有一个需求，里面涉及到把python获取到的数值存储到redis里，于是就简单研究一下python调用redis的方法。 python要调用redis的时候，需要先安装redis模块，有两个方法。第一个方法就是pip install redis，第二个方法就是easy_install redis，模块装完之后，就可以创建redis连接了。 redis-py提供两个类Redis和StrictRedis来实现Redis的命令，StrictRedis用于实现大部分官方的命令，并使用官方的语法和命令（比如，SET命令对应与StrictRedis.set方法）。 Redis是StrictRedis的子类，用于向后兼容旧版本的redis-py。 官方推荐使用StrictRedis方法，所以我这里只说StrictRedis。 如何连接连接的代码如下： 123456789101112&gt;&gt;&gt; import redis#这里是redis的基本情况&gt;&gt;&gt; host = '这里填写redis的host地址'&gt;&gt;&gt; port = 6379 #根据实际情况更改端口&gt;&gt;&gt; password = 'redis对应的密码'#使用StrictRedis去连接到目标redis&gt;&gt;&gt; r = redis.StrictRedis(host=host, port=6379, password=password, db=0) #db为选定的数据库，db=0代表选择了0号数据库。redis默认有16个数据库，在conf里面可以配置。如果没有指定的数据库，可以不写。&gt;&gt;&gt; r.set('age', '88')&gt;&gt;&gt; r.get('age')'88' 关系型数据库都有一个连接池的概念：对于大量redis连接来说，如果使用直接连接redis的方式的话，将会造成大量的TCP的重复连接，所以，就引入连接池来解决这个问题。在使用连接池连接上redis之后，可以从该连接池里面生成连接，调用完成之后，该链接将会返还给连接池，供其他连接请求调用，这样将减少大量redis连接的执行时间，那么使用StrictRedis的连接池的实现方式如下： 12pool = redis.ConnectionPool(host=host, port=6379, password=password)r = redis.StrictRedis(connection_pool=pool 或者使用pipeline（管道），通过缓冲多条命令，然后一次性执行的方法减少服务器-客户端之间TCP数据库包，从而提高效率，方法如下： 1234567891011接上文pipe = r.pipeline()#插入数据&gt;&gt;&gt; pipe.hset(\"hash_key\",\"leizhu900516\",8)Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.hset(\"hash_key\",\"chenhuachao\",9)Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.hset(\"hash_key\",\"wanger\",10)Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.execute()[1L, 1L, 1L] 批量读取数据的方法如下: 123456789&gt;&gt;&gt; pipe.hget(\"hash_key\",\"leizhu900516\")Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.hget(\"hash_key\",\"chenhuachao\")Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; pipe.hget(\"hash_key\",\"wanger\")Pipeline&lt;ConnectionPool&lt;Connection&lt;host=192.168.8.176,port=6379,db=0&gt;&gt;&gt;&gt;&gt;&gt; result = pipe.execute()&gt;&gt;&gt; print result['8', '9', '10'] #有序的列表 pipeline的命令可以写在一起，如p.set(&#39;hello&#39;,&#39;redis&#39;).sadd(&#39;faz&#39;,&#39;baz&#39;).incr(&#39;num&#39;).execute()，其实它的意思等同于是： 12345&gt;&gt;&gt; p.set('hello','redis')&gt;&gt;&gt; p.sadd('faz','baz')&gt;&gt;&gt; p.incr('num')&gt;&gt;&gt; p.execute()[True, 1, 1] 利用pipeline取值3500条数据，大约需要900ms，如果配合线程or协程来使用，每秒返回1W数据是没有问题的，基本能满足大部分业务。 如何存储上面已经举了一个age：88的例子，可见创建一个string类型的key并放入value是使用set方法，比如再多存几个名字： 123456789101112131415161718192021222324&gt;&gt;&gt; r.set('name', 'lilei')True&gt;&gt;&gt; r.get('name')'lilei'&gt;&gt;&gt; r.set('name2', 'zhaowei')True&gt;&gt;&gt; r.set('name3', 'james')True&gt;&gt;&gt; r.set('name4', 'yaoming')True#列出以name开头的所有key&gt;&gt;&gt; print r.keys(\"name*\")['name3', 'name4', 'name2', 'name']#列出所有key&gt;&gt;&gt; print r.keys()&gt;&gt;&gt; r.dbsize() #当前数据库包含多少条数据 4L&gt;&gt;&gt; r.delete('name')1&gt;&gt;&gt; r.save() #执行“检查点”操作，将数据写回磁盘。保存时阻塞True&gt;&gt;&gt; r.get('name')&gt;&gt;&gt; r.flushdb() #清空r中的所有数据True 还有其他类型的存储方法，简单举例子如下： 1234567891011121314151617#创建一个hashr.hset('abc:def', 'name', \"abcde\")#获取一个hash的所有值print r.hgetall('abc:def')#获取一个hash的所有key print r.hkeys('abc:def') #创建listr.sadd('abcd:ef','nihao')r.sadd('abcd:ef','hello')r.sadd('xxxx','nihao')r.sadd('xxxx','good')#打印出该key中的值 listprint r.smembers('abcd:ef')#查询两个list中相同的值print r.sinter('abcd:ef', 'xxxx')#给两个list取并集print r.sunion('abcd:ef', 'xxxx') setnx是SET if Not eXists的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。python要使用它也是r.setnx(key,value)，当发现没有这个key的时候，就会插入这个新的key以及对应的value，如果发现有了个这个key了，那这条就等于没加。 如何删除py-redis中有个delete接口，既可以删除单个key，也可以全删除key，如果要删除几个key，用法是:r.delete(&#39;age&#39;)、r.delete(&#39;sex&#39;, &#39;age&#39;)，如果要全删除，那就是 12keys = r.keys()r.delete(*keys) 执行之后的效果等于flushall。 redis里默认情况下是不支持通配符的，那么要批量删除key怎么做呢？答案就是搭配xargs，比如要删除掉所有2018-03-开头的key： 1redis-cli -hredis地址 -a密码 keys \"2018-03-*\"|xargs redis-cli -hredis地址 -a密码 del python将两个list元素一一对应转换为dict使用python的zip函数和强大的集合操作可以方便的将两个list元素一一对应转换为dict，如下示例代码： 1234names = ['n1','n2','n3']values = [1,2,3] nvs = zip(names,values)nvDict = dict( (name,value) for name,value in nvs) 参考资料https://github.com/andymccurdy/redis-pyhttp://xiaorui.cc/2014/11/10/%E4%BD%BF%E7%94%A8redis-py%E7%9A%84%E4%B8%A4%E4%B8%AA%E7%B1%BBredis%E5%92%8Cstrictredis%E6%97%B6%E9%81%87%E5%88%B0%E7%9A%84%E5%9D%91/http://debugo.com/python-redis/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"使用python调用echart画图","slug":"使用python调用echart画图","date":"2018-03-22T15:24:32.000Z","updated":"2018-03-23T11:02:48.000Z","comments":true,"path":"2018/03/22/使用python调用echart画图/","link":"","permalink":"http://yoursite.com/2018/03/22/使用python调用echart画图/","excerpt":"","text":"前言之前说了如何使用阿里云的SDK获取云存储的值然后发送表格邮件，但是最近领导又发话了，说这个邮件每天一封看的有点审美疲劳，要顺应“数据可视化”的趋势，于是就要求画图，力求直观，要做到“从众多数据中突出特别数据，从特别数据中突出高价值数据”。我之前用python的matplotlib画过，这一次尝试用echart来做图！ echart是不太良心的百度良心的开源作品，提供各种各样精美的作图方案，分分钟把图片做的高大上，吸引周围人的目光。不过我对前端的了解非常浅薄，但是没关系。这次使用pyechart插件！这个插件可以让python直接调用echart接口，选择需要的图形之后，直接往里查数据就好，简单粗暴见效快，而且支持3D，可以说是居家旅行常备物品。可以说，有了它，作图能力顶呱呱。感谢开发者大神们的辛苦工作！ 作图首先先需要安装pyecharts插件，命令是pip install pyecharts。 然后我们就可以写一个简单的案例，如下： 123456789101112131415#!/usr/bin/env python#coding=utf-8from pyecharts import Bar #导入第三方库#attr = [\"&#123;&#125;day\".format(i) for i in range(1, 8)] #这样的话X坐标就是1day、2day、3day...attr = [\"Mon\", \"Feb\", \"Wed\", \"Thu\", \"Fri\", \"Sat\", \"Sun\"] #这样X坐标就是星期v1 = [1.49, 2.09, 4.03, 2.23, 5.26, 7.71, 7.56] v2 = [0.3, 0.9, 0.2, 0.4, 0.7, 0.7, 0.6]v3 = [18.15, 13.22, 11.28, 17.99, 18.7, 19.7, 15.6]bar = Bar(\"乐橙云存储情况总览\", \"本图表展示过去一周的云存储情况\") #这里是主标题和副标题bar.add(\"录像分享文件\", attr, v1, mark_line=[\"average\"], mark_point=[\"max\", \"min\"]) #每一个值的名称以及要展现平均值和最大最小值bar.add(\"视频直播文件\", attr, v2, mark_line=[\"average\"], mark_point=[\"max\", \"min\"])bar.add(\"云录像、报警图片、全景图片\", attr, v3, mark_line=[\"average\"], mark_point=[\"max\", \"min\"]) bar.render('/tmp/111.html') #在/tmp文件夹里生成一个111.html文件 如果服务器里有nginx，那么把这个html文件放到nginx/html路径里，再在浏览器里打开就会看到这样的图： 而且还可以通过点击网页上“A值”、“B值”、“C值”就可以达到屏蔽相应值的效果，而且如果点击红色箭头的“数据视图”，还可以直接看到对应的数据，非常贴心非常屌，如图： 如果你觉得图片有点小，那么可以修改这个地方：bar = Bar(&quot;XXX情况总览&quot;, &quot;本图表展示过去一周的ABC情况&quot;，width=1000,height=900)，我这里把宽和高分别从默认值调成了1000和900。 如果想要在一个html里做多个图，比如要做三个柱状图，那么example如下： 123456789101112131415161718192021222324252627282930#!/usr/bin/env python#coding=utf-8from pyecharts import Bar, Gridattr = [\"一班\", \"二班\", \"三班\", \"四班\"]v1 = [54, 81, 32, 32] v2 = [68, 69, 27, 32] bar = Bar(\"赞成票\",\"本图表展示赞成票情况\")bar.add(\"年纪长\", attr, v1, mark_point=[\"max\", \"min\"])bar.add(\"副年纪长\", attr, v2, mark_point=[\"max\", \"min\"])attr2 = [\"一班\", \"二班\", \"三班\", \"四班\"]x1 = [2, 0, 0, 1]x2 = [1, 3, 0, 2]bar2 = Bar(\"反对票\",\"本图表展示反对票情况\",title_top='bottom',title_color='#1d12eb') #title_color是标题颜色，这个跟html的颜色取值一样bar2.add(\"年纪长\", attr2, x1, mark_point=[\"max\", \"min\"])bar2.add(\"副年纪长\", attr2, x2, mark_point=[\"max\", \"min\"])attr3 = [\"一班\", \"二班\", \"三班\", \"四班\"]y1 = [2, 0, 0, 1]y2 = [2, 0, 0, 1]bar3 = Bar(\"弃权票\",\"本图表展示弃权票情况\",title_pos='right',title_color='#eb1212') #title_pos是标题的位置，如果不特殊说明，会重叠bar3.add(\"年纪长\", attr3, y1, mark_point=[\"max\", \"min\"]) bar3.add(\"副年纪长\", attr3, y1, mark_point=[\"max\", \"min\"])grid = Grid() grid.add(bar, grid_width=\"40%\", grid_height=\"30%\", grid_bottom=\"60%\", grid_right=\"55%\") #grid_height和grid_width是每一个小图的大小grid.add(bar2, grid_width=\"40%\", grid_height=\"30%\", grid_bottom=\"60%\", grid_left=\"55%\") #grid_bottom和grid_top是垂直位置grid.add(bar3, grid_width=\"40%\", grid_height=\"30%\", grid_top=\"60%\", grid_right=\"55%\") #grid_right和grid_left是水平位置grid.render('/tmp/grid.html') #在/tmp文件夹里生成一个grid.html文件 例子中的数字都是我虚拟的，实际情况中，这些数字都应该是存储在redis这样的数据库里，然后取出来使用。 上面的两个例子仅仅是pyechart使用的冰山一角，如果想更多的了解，请去看一下文末pyechart的中文说明文档，无论是柱状图、雷达图、曲线图、3D图都有相关的使用讲解，内容特别丰富！ 参考资料http://echarts.baidu.comhttp://pyecharts.org/#/zh-cn/prepare","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"echart","slug":"echart","permalink":"http://yoursite.com/tags/echart/"}]},{"title":"RabbitMQ的安装、配置与启动","slug":"RabbitMQ的安装、配置与启动","date":"2018-03-19T01:59:05.000Z","updated":"2018-03-19T03:35:50.000Z","comments":true,"path":"2018/03/19/RabbitMQ的安装、配置与启动/","link":"","permalink":"http://yoursite.com/2018/03/19/RabbitMQ的安装、配置与启动/","excerpt":"","text":"前言环境介绍：Centos 7 + RabbitMQ：3.6.12 + Erlang：20.0 安装erlang由于RabbitMQ使用erlang语言编写的，所以要先安装erlang语言环境。但是yum源里的erlang版本太老了，于是这里选择手动安装，使用Erlang官方推荐的Erlang Solutions安装方法如下： 1234yum install gcc gcc-c++ glibc-devel make ncurses-devel openssl-devel autoconf java-1.8.0-openjdk-devel git wget wxBase.x86_64 #先把其他模块准备好wget https://packages.erlang-solutions.com/erlang-solutions-1.0-1.noarch.rpmrpm -Uvh erlang-solutions-1.0-1.noarch.rpmrpm --import https://packages.erlang-solutions.com/rpm/erlang_solutions.asc 此时，查看/etc/yum.repos.d/erlang_solutions.repo，应该是这个样子： 123456[erlang-solutions]name=CentOS $releasever - $basearch - Erlang Solutionsbaseurl=https://packages.erlang-solutions.com/rpm/centos/$releasever/$basearchgpgcheck=1gpgkey=https://packages.erlang-solutions.com/rpm/erlang_solutions.ascenabled=1 这个时候可以yum安装了： 1yum install -y esl-erlang 此时得到的erlang就是20.0版本的了，如图： 如果不想使用这个办法，可以使用源码安装的方式，https://packages.erlang-solutions.com/erlang/ 这里面有Erlang官方的下载包，拆包解压缩然后make &amp;&amp; make install即可。 安装RabbitMQ安装RabbitMQ跟其他普通软件差不多，先去官网下载目前较稳定的rpm包，然后安装，步骤如下： 12wget https://dl.bintray.com/rabbitmq/all/rabbitmq-server/3.7.4/rabbitmq-server-3.7.4-1.el7.noarch.rpmyum install -y rabbitmq-server-3.7.4-1.el7.noarch.rpm 如果出现了Transaction Check Error的错误： 可见是要安装的包与已有的包相冲突，此时需要yum list|grep erlang，如图： 再yum remove esl-erlang.x86_64，然后重新执行yum install那一步即可。 如果出现Requires: socat的错误，如图： 此时需要执行如下命令即可： 12yum -y install epel-releaseyum -y install socat 配置RabbitMQRabbitMQ安装完毕，先chkconfig rabbitmq-server on设置开机启动。然后，配置一下用户名。我这个机器的用户名不规范，需要把hostname里的中文去掉，比如改成：3-dvl-hlsproxy-001，那么就要在/etc/hosts里添加一句： 内网IP地址 3-dvl-hlsproxy-001 然后执行rabbitmq-plugins enable rabbitmq_management来安装WEB图形界面，然后拷贝rabbitmq.config.example到/etc/rabbitmq/里，并且改名叫rabbitmq.config，命令如下： 123cp /usr/share/doc/rabbitmq-server-3.7.4/rabbitmq.config.example /etc/rabbitmq/cd /etc/rabbitmq/mv rabbitmq.config.example rabbitmq.config 编辑rabbitmq.config这个文件，把%%{loopback_users, []}.改成{loopback_users, []}，保存之后，执行service rabbitmq-server restart来启动RabbitMQ。 如果启动之后，执行rabbitmqctl status不断的刷Error when reading /var/lib/rabbitmq/.erlang.cookie: eacces的错误的话，执行chown rabbitmq:rabbitmq /var/lib/rabbitmq/.erlang.cookie。 在浏览器里登录外网IP:15672就会看到RabbitMQ的WEB配置界面了， 账号和密码都是guest，输入之后就会看到如下的界面，可以在界面里看到3-dvl-hlsproxy-001的情况了，如图： RabbitMQ 3.0以后版本的WEB端口是15672,服务的端口是5672,这俩都可以在配置文件里面更改。至此RabbitMQ的安装与配置结束了，但是这个仅仅是最简单的配置，RabbitMQ自身有一套很详细的用户管理规则以及它支持Python等很多语言的管理，这些内容以后再详细说明。 参考资料https://packages.erlang-solutions.com/erlang/https://laucyun.com/9849587ce75f31d534d52f906c94368f.htmlhttps://www.rabbitmq.com/access-control.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://yoursite.com/tags/消息队列/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"http://yoursite.com/tags/RabbitMQ/"}]},{"title":"使用nginx开启http2协议","slug":"使用nginx开启http2协议","date":"2018-03-16T14:34:44.000Z","updated":"2018-03-16T16:24:30.000Z","comments":true,"path":"2018/03/16/使用nginx开启http2协议/","link":"","permalink":"http://yoursite.com/2018/03/16/使用nginx开启http2协议/","excerpt":"","text":"部署过程HTTP/2是建立在TLS的基础上的，那么先要查看nginx的版本和openssl的版本，如果nginx版本在1.10.0以上且需要openssl版本在1.0.2以上那么就可以进行下一步了： 如果版本并不符合要求，可以按照https://rorschachchan.github.io/2018/01/03/Nginx动态编译新的模块/ 里的方法升级对应的模块版本。 先编辑https（443端口）对应的conf文件： 123456789101112131415161718192021server &#123; listen 443 ssl http2; #这里多加一句http2 server_name cuntao.lechange.com *.lechange.com; #这里填写实际的域名，我这里以cuntao.lechange.com为例 ssl_certificate /实际路径/server-com.crt; ssl_certificate_key /实际路径/server-com.key; ssl_session_timeout 30m; #客户端会话缓存时间 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #允许的协议 ssl_ciphers EECDH+CHACHA20:EECDH+AES128:RSA+AES128:EECDH+AES256:RSA+AES256:EECDH+3DES:RSA+3DES:!MD5; #加密算法(CloudFlare 推荐的加密套件组) ssl_prefer_server_ciphers on; #优化 SSL 加密套件 ssl_session_cache builtin:1000 shared:SSL:10m; #SSL会话缓存类型和大小 ssl_buffer_size 1400; #每个MTU大小1400b location / &#123; root html; index index.html index.htm; &#125; error_page 404 /404.html; &#125; 保存之后再编辑http（80端口）对应的conf文件： 12345server &#123; listen 80 default; add_header Strict-Transport-Security max-age=15768000; return 301 https://$host$request_uri;&#125; 然后使用nginx -t检查一下是否文件有错误，如果是OK的话，那么就nginx -s reload平滑重启一下nginx即可。 验证HTTP/2协议是否开启很简单，有两个方法：1）登陆https://tools.keycdn.com/http2-test，将你的域名填写进去，查看一下配置成功： 2)在Chrome浏览器上可以通过安装HTTP/2 and SPDY indicator插件来检验，网址是https://chrome.google.com/webstore/detail/http2-and-spdy-indicator/mpbpobfflnpcgagjijhmgnchggcjblin ，如果地址栏出现蓝色的闪电就是该网站开启了HTTP/2协议，灰色的话就是HTTP/2协议没开启。 参考资料https://www.nginx.com/blog/nginx-1-9-5/https://blog.fazero.me/2017/01/06/upgrate-nginx-and-use-http2/https://iyaozhen.com/nginx-http2-conf.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"http协议","slug":"http协议","permalink":"http://yoursite.com/tags/http协议/"}]},{"title":"关于HTTP 2.0应该知道的事","slug":"关于HTTP-2应该知道的事","date":"2018-03-16T13:44:45.000Z","updated":"2018-10-23T08:37:42.000Z","comments":true,"path":"2018/03/16/关于HTTP-2应该知道的事/","link":"","permalink":"http://yoursite.com/2018/03/16/关于HTTP-2应该知道的事/","excerpt":"","text":"HTTP 2.0的优势相比HTTP/1.x，HTTP/2在底层传输做了很大的改动和优化：1.每个服务器只用一个连接：HTTP/2对每个服务器只使用一个连接，而不是每个文件一个连接。这样，就省掉了多次建立连接的时间，这个时间对TLS尤其明显，因为TLS连接费时间;2.加速TLS交付：HTTP/2只需一次耗时的TLS握手，并且通过一个连接上的多路利用实现最佳性能。HTTP/2还会压缩首部数据，省掉HTTP/1.x时代所需的一些优化工作，比如拼接文件，从而提高缓存利用率;3.简化Web应用：使用HTTP/2可以让Web开发者省很多事，因为不用再做那些针对HTTP/1.x的优化工作了;4.适合内容混杂的页面：HTTP/2特别适合混合了HTML、CSS、JavaScript、图片和有限多媒体的传统页面。浏览器可以优先安排那些重要的文件请求，让页面的关键部分先出现、快出现，而且根本不会发生“浏览器明明在等关键的CSS和JS，而服务器还在发送黄图”的尴尬局面;5.更安全：通过减少TLS的性能损失，可以让更多应用使用TLS，从而让用户信息更安全。 HTTP 2.0性能增强之二进制分帧HTTP的定义大家都知道，叫超文本协议，也就是说http1.x的解析是基于文本。基于文本协议的格式解析存在天然缺陷，文本的表现形式有多样性，要做到健壮性考虑的场景必然很多。但是在HTTP/2里这里做了比较重大的改动—二进制分帧，HTTP/2在应用层(HTTP)和传输层(TCP or UDP)之间增加一个二进制分帧层。在这个新增的二进制分帧层里HTTP/2会将所有传输的信息分割为更小的消息和帧,并对它们采用二进制格式的编码 ，其中HTTP1.x的首部信息会被封装到Headers帧，而我们的request body则封装到Data帧里面。二进制与之前的文本不同，二进制只认0和1的组合。基于这种考虑http2.0的协议解析决定采用二进制格式，实现方便且健壮。 HTTP/2的格式定义十分高效且精简。length定义了整个frame的大小，type定义frame的类型（一共10种），flags用bit位定义一些重要的参数，stream id用作流控制，payload就是request的正文，如下图： HTTP 2.0性能增强之首部压缩虽然HTTP/2引入了二进制分帧的概念，但是试想如果所有的二进制帧都会带上Headers帧，这是多大的数据冗余传送啊。于是HTTP/2针对这个需求又搞出来一个东东—“首部表”。 “首部表”来跟踪和存储之前发送的键-值对，对于相同的数据，不再通过每次请求和响应发送；通信期间几乎不会改变的通用键-值对(用户代理、可接受的媒体类型等等)只需发送一次。事实上,如果请求中不包含首部(例如对同一资源的轮询请求)，那么首部开销就是零字节。此时所有首部都自动使用之前请求发送的首部。如果首部发生变化了，那么只需要发送变化了数据在Headers帧里面，新增或修改的首部帧会被追加到“首部表”。首部表在HTTP/2的连接存续期内始终存在,由客户端和服务器共同渐进地更新。 HTTP 2.0性能增强之TCP请求集中TCP的优势是很直白的：面向连接、提供可靠的数据传输服务、流量控制。那么有效地使用TCP连接的方法就是长时间连接传输大块数据。于是HTTP/2就尽大化的把这一特点发扬：所有HTTP/2通信都是在一个TCP连接上完成。前面说过，HTTP/2把HTTP协议通信的基本单位缩小为一个一个的帧，这些帧对应着逻辑流中的消息，并行地在同一个TCP连接上双向交换消息(注意这个“双向交换消息”)。举个例子，请求一个页面https://www.google.com，页面上所有的资源请求都是客户端与服务器上的一条TCP上请求和响应的！ 这样“单链接多资源”的方式，使到至上而下的层面都得到了好处： 1.可以减少服务链接压力,内存占用少了,连接吞吐量大了； 2.由于TCP连接减少而使网络拥塞状况得以改观; 3.慢启动时间减少,拥塞和丢包恢复速度更快。 综上所述，“资源合并减少请求”对于HTTP/2是无用的优化手段。 上面的文字说了要注意“双向交换消息”，那么啥是“双向交换消息”？ 就是把HTTP消息分解为独立的帧,交错发送,然后在另一端重新组装。专业一点说就是“一个request对应一个id，这样一个连接上可以有多个request，每个连接的request可以随机的混杂在一起，接收方可以根据request的id将request再归属到各自不同的服务端请求里面”。这是HTTP/2重要的一项增强。事实上,这个机制会在整个Web技术栈中引发一系列连锁反应, 从而带来巨大的性能提升,因为： 1234可以并行交错地发送请求,请求之间互不影响;可以并行交错地发送响应,响应之间互不干扰;只使用一个连接即可并行发送多个请求和响应;消除不必要的延迟,从而减少页面加载的时间; Keep Alive与HTTP/2集中TCP的区别HTTP1.1的keep-alive是为了尽可能使用持久链接，以消除TCP握手和慢启动。但是keep-alive使用多了同样会给服务端带来大量的性能压力，并且对于单个文件被不断请求的服务(例如图片存放网站)，keep-alive可能会极大的影响性能，因为它在文件被请求之后还保持了不必要的连接很长时间。 举个例子：下载a.js创建一个TCP链接，就会需要TCP握手和慢启动而产生了约300ms下载延迟。当a.js下载完成后这时候b.js也要下载，如果a.js创建TCP链接是keep-alive的，b.js就可以复用其TCP而不需要重新TCP握手和慢启动（没有了那300ms）。 而HTTP/2是使用一个TCP链接的，其慢启动和握手只在第一次链接的时候产生一次，其后面链接都是持久化的。并且一个TCP下载多个资源，可以将TCP吞吐量最大化来提升性能，这方面可以参考一下TCP的拥塞预防及控制。 NGINX上如何配制HTTP/2上面说了这么多HTTP/2这个好那个好，是未来的趋势blablabla，但是要实现HTTP/2，还是需要“客户端和服务器都开启了HTTP/2”这一个首要条件。不过现在客户端（浏览器）大多数都已经支持HTTP/2，那么主要就是在服务器端如何开启HTTP/2，nginx的配置方法请见：https://rorschachchan.github.io/2018/03/16/使用nginx开启http2协议/ 。 按照这样的操作下来，服务器就开了HTTP/2协议，那些支持HTTP/2的浏览器在请求页面的时候就会走HTTP/2模式，而不支持HTTP/2的浏览器会议就按照HTTP/1.X的方式发送请求，如图： 支持HTTP/2的Web Server基本都支持HTTP/1.1。这样，即使浏览器不支持HTTP/2，双方也可以协商出可用的HTTP版本，没有兼容性问题。 参考资料http://www.alloyteam.com/2015/03/http2-0-di-qi-miao-ri-chang/comment-page-1/#commentshttps://segmentfault.com/a/1190000007637735https://github.com/creeperyang/blog/issues/23https://www.nginx.com/blog/nginx-1-9-5/https://ye11ow.gitbooks.io/http2-explained/content/part6.html","categories":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/categories/大牛之路/"}],"tags":[{"name":"http协议","slug":"http协议","permalink":"http://yoursite.com/tags/http协议/"}]},{"title":"centos 7里安装zsh来提升shell的高逼格","slug":"centos-7里安装zsh来提升shell的高逼格","date":"2018-03-15T13:52:13.000Z","updated":"2018-03-16T16:14:06.000Z","comments":true,"path":"2018/03/15/centos-7里安装zsh来提升shell的高逼格/","link":"","permalink":"http://yoursite.com/2018/03/15/centos-7里安装zsh来提升shell的高逼格/","excerpt":"","text":"zsh本体的安装先用chsh -l查看当前的bash情况，如下： 123456789 [root@zabbix ~]# chsh -l/bin/sh/bin/bash/sbin/nologin/bin/dash/bin/tcsh/bin/csh/usr/bin/tmux[root@zabbix ~]# 如果是centos的话，使用yum install -y zsh来安装zsh，装完了zsh然后就是装oh my zsh，使用wget方法安装： 1wget https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh -O - | sh 再使用which zsh查看安装的zsh在/usr/bin/zsh，这个时候使用chsh -s /usr/bin/zsh，出现了Shell changed.这样就切换到了zsh界面，需要logout退出连接重进。 重新连接就会发现bash界面就变了，原本是路径的地方变成了一个小图标。界面主题是可以变化的，比如我个人比较喜欢af-magic这个模板，于是乎就把/root/.zshrc里的ZSH_THEME=&quot;robbyrussell&quot;改成ZSH_THEME=&quot;af-magic&quot;，保存文件，再一次退出连接重新进入就能看见模板变化了。 如果在使用vim的时候发现了tab键的补全爆错_arguments:451: _vim_files: function definition file not found，如下图： 这个时候需要把/root/.zcompdump改一个名字，比如叫.zcompdump-bak，然后重新ssh连接即可。 autojump插件安装autojump这个插件安装之后，zsh会自动记录你访问过的目录，通过j + 目录名可以直接进行目录跳转，而且目录名支持模糊匹配和自动补全，例如你访问过hadoop-1.0.0目录，输入j hado即可正确跳转。j –s可以看你的历史路径库，安装方法如下： 1git clone git://github.com/joelthelion/autojump.git 然后在autojump目录里执行./install.sh，此时屏幕会出现如下的显示： 把上面那个[[ -s /root/.autojump/etc/profile.d/autojump.sh ]] &amp;&amp; source /root/.autojump/etc/profile.d/autojump.sh autoload -U compinit &amp;&amp; compinit -u复制到/root/.zshrc的文件里，最好复制在source $ZSH/oh-my-zsh.sh这句话上面，保存之后source ~/.zshrc即可。 zsh-syntax-highlighting插件安装这个插件安装之后主要效果就是命令高亮，如果是错误的命令，颜色是红色，正确的命令是绿色的，安装方法如下： 12345cd .oh-my-zsh/pluginsyum install -y git #如果已经安装了git就不用执行的git clone git://github.com/zsh-users/zsh-syntax-highlighting.gitsource /root/.oh-my-zsh/plugins/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh添加到 .zshrc 的最后面source ~/.zshrc 效果立竿见影。 尾声至此，你现在的zsh应该具备如下几个特性：1、各种补全：路径补全、命令补全，命令参数补全，插件内容补全等等。触发补全只需要按一下或两下tab键，补全项可以使用ctrl+n/p/f/b上下左右切换。比如你想杀掉java的进程，只需要输入kill java + tab键，如果只有一个java进程，zsh会自动替换为进程的pid，如果有多个则会出现选择项供你选择。ssh + 空格 + 两个tab键，zsh会列出所有访问过的主机和用户名进行补全；2、即使你没有安装autojump，只要输入d，就会列出你在这个回话中访问的目录，输入前面的序号，就可以直接跳转；3、可以忽略cd命令, 输入..或者…和当前目录名都可以跳转；当然，除了上面几点，zsh还有很多丰富的插件可以使用，这就需要继续的探索了… 参考资料https://github.com/robbyrussell/oh-my-zshhttp://macshuo.com/?p=676","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"},{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}]},{"title":"安装vim8.0的过程","slug":"安装vim8-0的过程","date":"2018-03-14T13:44:45.000Z","updated":"2018-03-14T14:47:22.000Z","comments":true,"path":"2018/03/14/安装vim8-0的过程/","link":"","permalink":"http://yoursite.com/2018/03/14/安装vim8-0的过程/","excerpt":"","text":"1.先卸载老的vim 1yum remove vim-* -y 2.下载第三方yum源 1wget -P /etc/yum.repos.d/ https://copr.fedorainfracloud.org/coprs/mcepl/vim8/repo/epel-7/mcepl-vim8-epel-7.repo 3.安装vim 1yum -y install vim-enhanced 4.验证vim版本 12345rpm -qa |grep vimvim-enhanced-8.0.0704-1.1.26.el7.centos.x86_64vim-common-8.0.0704-1.1.26.el7.centos.x86_64vim-minimal-8.0.0704-1.1.26.el7.centos.x86_64vim-filesystem-8.0.0704-1.1.26.el7.centos.x86_64","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"},{"name":"编辑器","slug":"编辑器","permalink":"http://yoursite.com/tags/编辑器/"}]},{"title":"使用expect来实现远程登录ssh","slug":"使用expect来实现远程登录ssh","date":"2018-03-14T13:39:49.000Z","updated":"2018-03-14T20:20:10.000Z","comments":true,"path":"2018/03/14/使用expect来实现远程登录ssh/","link":"","permalink":"http://yoursite.com/2018/03/14/使用expect来实现远程登录ssh/","excerpt":"","text":"先说说shebang我们在写一个shell脚本时，总是习惯在最前面加上一行#!/bin/bash,这个就是脚本的shebang,可以把它理解成是一种解释器。至于为什么叫这么个奇怪的名字，C语言和Unix的开发者Dennis Ritchie称它为可能是类似于“hash-bang”的英国风描述性文字； 贴一段wiki上的解释: 在计算机科学中，shebang是一个由井号和叹号构成的字符串行，其出现在文本文件的第一行的前两个字符。 在文件中存在shebang的情况下，类unix操作系统的程序载入器会分析shebang后的内容，将这些内容作为解释器指令，并调用该指令，并将载有shebang的文件路径作为该解释器的参数。 简单的说，它指示了此脚本运行时的解释器，所以，使用文件名直接执行shell脚本时，必须带上这个shebang; 此外，我们还可以在shebang后面直接附加选项，执行时默认使用选项执行； 比如test.sh的shebang为#!/bin/sh -x，那我们执行脚本时: 1./test.sh hello 相当于： 1bin/sh -x ./test.sh hello; 而expect编写的脚本，需要用到的shebang为/usr/bin/expect; 需要注意的是：在指定脚本解释器来执行脚本时，shebang会被指定的脚本解释器覆盖，即优先使用指定的脚本解释器来执行脚本（习惯性地用sh ./test.sh却提示command not found） 实例脚本expect的具体语法我这里就不说了，看一下下面的参考资料就好了。其实说来说去，就是根据命令栏上的反馈来输入对应的内容，举一个ssh登陆的例子。如图: 从这个我们非常熟悉的ssh登陆的过程就看到，在登陆的时候，页面会返回几个交互的问题，而我们就可以针对这几个问题的关键字来输入答案。最后也根据“Welcome”这个关键字认为我们已经登陆成功了，这样就直接在连接的服务器里操作命令。 于是根据这个思路，来写一个远程ssh到A机器上的脚本： 1234567891011121314151617#!/usr/bin/expect -fset timeout 30 #设定超时时间是30秒，如果是-1那就是永不超时spawn ssh root@A服务器IP地址 #这里开始ssh连接到目标服务器上expect &#123; \"*(yes/no)?\" &#123; #如果是第一次连接，那么命令栏里就会出现(yes/no)的字样 send \"yes\\r\" #此时匹配yes expect \"*password:\" &#123;send \"服务器密码\\r\"&#125; #如果命令栏出现了password的字样，直接填写密码 &#125; \"*password:\" &#123;send \"服务器密码\\r\"&#125; #如果不是第一次连接，那么就会直接出现password，所以可以直接填写密码&#125;expect \"*Welcome*\" #连接成功就会出现welcome的字样send \"echo '我就是你的爹地' &gt;&gt; /tmp/123321.txt\\r\" #此时执行第一个命令send \"df -h\\r\" #执行第二个命令send \"cp /tmp/123321.txt /tmp/123123.txt\\r\" #执行第三个命令interact #脚本fork的子进程会将操作权交给用户，允许用户与当前A服务器的shell进行交互 参考资料http://blog.sctux.com/?p=343http://www.zyy1217.com/2017/07/02/linux%20expect%E8%AF%A6%E8%A7%A3/https://github.com/jiangxianli/SSHAutoLoginhttps://peiqiang.net/2014/05/10/ssh-auto-login.htmlhttps://www.jianshu.com/p/9bee08dc3dca","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"},{"name":"expect","slug":"expect","permalink":"http://yoursite.com/tags/expect/"}]},{"title":"使用python去做一个生成随机码的页面","slug":"使用python去做一个生成随机码的页面","date":"2018-03-13T13:41:28.000Z","updated":"2018-03-13T13:43:56.000Z","comments":true,"path":"2018/03/13/使用python去做一个生成随机码的页面/","link":"","permalink":"http://yoursite.com/2018/03/13/使用python去做一个生成随机码的页面/","excerpt":"","text":"先说一下mkpasswdlinux里是自带生成密码的命令的，比较出名的一个是mkpasswd，另一个是passwdgen。 mkpasswd命令是附属在expect模块里的，如图 passwdgen的话也要手动执行一下yum install -y passwdgen来安装命令。 这里主要说说mkpasswd，它支持如下几个参数： 12345-l (length of password, default = 7) 指定密码的长度，默认是7位数-d (min # of digits, default = 2) 指定密码中数字最少位数，默认是2位-c (min # of lowercase chars, default = 2) 指定密码中小写字母最少位数，默认是2位-C (min # of uppercase chars, default = 2) 指定密码中大写字母最少位数，默认是2位-s (min # of special chars, default = 1) 指定密码中特殊字符最少位数，默认是1位 比如现在要生成一个含有“六位数字而且5位特殊字符的总共16位”的密码，那么命令就是：mkpasswd -l 16 -d 5 -s 5，再聚几个其他的例子，感受一下： 12345678[root@zabbix General_LeChange_Chn_IS_V5.8.00.R.20170814]# mkpasswd -l 16 -d 5 -s 5g]7Hu-L5,t+32%0m[root@zabbix General_LeChange_Chn_IS_V5.8.00.R.20170814]# mkpasswd -l 16 -C 5YvjtFWaV5jr8h%Wy[root@zabbix General_LeChange_Chn_IS_V5.8.00.R.20170814]# mkpasswd -l 16 -s 10qoB#^V_=/!??*59:[root@zabbix General_LeChange_Chn_IS_V5.8.00.R.20170814]# mkpasswd -l 16 -c 4 9mJOqymatvg*n9sl 脚本在此这个生成随机码的算法部分就使用上面那个mkpasswd了，省了我们不少事。 整个html界面的代码如下： 12345678910111213141516171819202122232425&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;meta charset=\"utf-8\"&gt;&lt;title&gt;随机密码生成器&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action=\"/cgi-bin/dropdown.py\" method=\"post\" target=\"_blank\"&gt;&lt;select name=\"dropdown\"&gt;&lt;h2&gt;密码长度：&lt;/h2&gt;&lt;option value=\"8\" selected&gt;8&lt;/option&gt;&lt;option value=\"16\"&gt;16&lt;/option&gt;&lt;option value=\"20\"&gt;20&lt;/option&gt;&lt;option value=\"24\"&gt;24&lt;/option&gt;&lt;option value=\"48\"&gt;48&lt;/option&gt;&lt;/select&gt; &lt;br /&gt;&lt;input type=\"checkbox\" name=\"runoob\" value=\"on\" /&gt; 包含小写字母 &lt;br /&gt;&lt;input type=\"checkbox\" name=\"google\" value=\"on\" /&gt; 包含大写字母 &lt;br /&gt;&lt;input type=\"checkbox\" name=\"runoob\" value=\"on\" /&gt; 包含数字 &lt;br /&gt;&lt;input type=\"checkbox\" name=\"google\" value=\"on\" /&gt; 包含特殊字母 &lt;br /&gt;&lt;input type=\"submit\" value=\"提交\"/&gt; &lt;br /&gt;&lt;h2&gt;密码：&lt;/h2&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 补充再分享一个python生成密码的代码，但是这个密码不含特殊字符： 12345678#!/usr/bin/env python# -*- coding: utf-8 -*- import randomimport stringsalt = ''.join(random.sample(string.ascii_letters + string.digits, 8))print salt 参考资料https://balajiommudali.wordpress.com/2015/11/27/unable-to-install-mkpasswd-on-centos-6-4/http://www.runoob.com/python/python-cgi.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"记一次mysql无法启动的解决过程","slug":"记一次mysql无法启动的解决过程","date":"2018-03-12T13:35:15.000Z","updated":"2018-04-22T14:03:12.000Z","comments":true,"path":"2018/03/12/记一次mysql无法启动的解决过程/","link":"","permalink":"http://yoursite.com/2018/03/12/记一次mysql无法启动的解决过程/","excerpt":"","text":"正文今天开发人员反馈一个问题，就是某一台开发环境机器的mysql无法启动了，但是如果这台服务器重启的话，mysql就好使，而第二天就会出现mysql死掉然后无法启动的情况。我使用service mysqld restart，命令行反馈如下的内容： 123[root@iZ2373j9xivZ data]# service mysqld restartMySQL server PID file could not be found! [FAILED] Starting MySQL........The server quit without updating PID file (/data/mysql/data/sock/mysql.pid). [FAILED] 打开错误日志看一下，里面是这么写的： 123456782018-03-10 00:26:24 25919 [Note] InnoDB: Using CPU crc32 instructions2018-03-10 00:26:24 25919 [Note] InnoDB: Initializing buffer pool, size = 4.0GInnoDB: mmap(549453824 bytes) failed; errno 122018-03-10 00:26:24 25919 [ERROR] InnoDB: Cannot allocate memory for the buffer pool2018-03-10 00:26:24 25919 [ERROR] Plugin 'InnoDB' init function returned error.2018-03-10 00:26:24 25919 [ERROR] Plugin 'InnoDB' registration as a STORAGE ENGINE failed.2018-03-10 00:26:24 25919 [ERROR] Unknown/unsupported storage engine: INNODB2018-03-10 00:26:24 25919 [ERROR] Aborting 爆InnoDB: mmap(549453824 bytes) failed; errno 12，然后我就free -m查看一下，当前服务器的内存已经不够用了。 12345[root@iZ2373j9xivZ sock]# free -m total used free shared buffers cachedMem: 7869 7747 121 0 16 15-/+ buffers/cache: 7716 152Swap: 0 0 0 那么是什么在占用这台服务器的内存？使用ps aux | sort -k4nr |head -5 这个命令查找当前占用内存最大的五个进程一看，全是php-fpm，同时也发现服务器里面运行大量的php-fpm，在征得开发人员的同意之后，重启php-fpm进程，内存空出来很多。 此时再次service mysqld restart，发现mysql的错误日志改成如下的样子了： 12342018-03-12 10:53:42 28238 [Note] InnoDB: Highest supported file format is Barracuda.2018-03-12 10:53:42 28238 [Note] InnoDB: The log sequence numbers 16939991440 and 16939991440 in ibdata files do not match the log sequence number 16940121908 in the ib_logfiles!2018-03-12 10:53:42 28238 [Note] InnoDB: Database was not shutdown normally!2018-03-12 10:53:42 28238 [Note] InnoDB: Starting crash recovery. 这次变成了The log sequence numbers 16939991440 and 16939991440 in ibdata files do not match the log sequence number 16940121908 in the ib_logfiles!，我打开my.cnf，适当的调小了max_connections和innodb_buffer_pool_size，然后service mysqld restart的时候发现错误又变了： 123456782018-03-12 11:03:57 29190 [Note] InnoDB: 5.6.27 started; log sequence number 169401219182018-03-12 11:03:57 29190 [Note] Server hostname (bind-address): '*'; port: 33062018-03-12 11:03:57 29190 [Note] IPv6 is not available.2018-03-12 11:03:57 29190 [Note] - '0.0.0.0' resolves to '0.0.0.0';2018-03-12 11:03:57 29190 [Note] Server socket created on IP: '0.0.0.0'.2018-03-12 11:03:57 29190 [ERROR] Can't start server : Bind on unix socket: Permission denied 2018-03-12 11:03:57 29190 [ERROR] Do you already have another mysqld server running on socket: /data/mysql/data/sock/mysql.sock ?2018-03-12 11:03:57 29190 [ERROR] Aborting 这就是文件权限问题了，我再次打开my.cnf发现里面的user填写的是mysql，那么把/data/mysql/data/sock/mysql.sock这一系列的文件的所属人都改成了mysql用户，这一次重启mysql就OK了。 为什么这个mysql会好好的突然自动死掉呢？我发现日志里面有这样的字样：InnoDB: Database was not shutdown normally!，于是我猜想很有可能是php-fpm这进程不断地增长，占用的内存太大，导致mysql被linux的内核杀死了。于是查看/var/log/message的文件，结合mysql的错误日志时间找到了如下的字样： 12345Mar 10 00:26:22 iZ2373j9xivZ kernel: Out of memory: Kill process 1883 (mysqld) score 53 or sacrifice childMar 10 00:26:22 iZ2373j9xivZ kernel: Killed process 1883, UID 501, (mysqld) total-vm:6849508kB, anon-rss:429368kB, file-rss:176kBMar 10 04:11:38 iZ2373j9xivZ kernel: php-fpm invoked oom-killer: gfp_mask=0x201da, order=0, oom_adj=0, oom_score_adj=0Mar 10 04:11:38 iZ2373j9xivZ kernel: php-fpm cpuset=/ mems_allowed=0Mar 10 04:11:38 iZ2373j9xivZ kernel: Pid: 4375, comm: php-fpm Not tainted 2.6.32-431.23.3.el6.x86_64 #1 证据确凿，php-fpm的无休止增长导致服务器的可用内存变小，最后内核把mysql杀死，修改php-fpm的文件之后，暂时好了点… 参考资料http://robinchen.me/tech/2016/03/14/tech-aliyun-centos-mysql-shutdown-itself-irregularly.htmlhttp://www.wisedream.net/2017/12/20/traps/mysql-corrupt/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"}]},{"title":"关于HTTP-Alive应该知道的事","slug":"关于HTTP-Alive应该知道的事","date":"2018-03-11T03:23:08.000Z","updated":"2018-06-27T02:47:18.000Z","comments":true,"path":"2018/03/11/关于HTTP-Alive应该知道的事/","link":"","permalink":"http://yoursite.com/2018/03/11/关于HTTP-Alive应该知道的事/","excerpt":"","text":"总体概述七层协议是一个广为人知的协议，tcp协议是在传输层，http协议是在应用层，也就是说客户端与服务器端先建立tcp连接，然后在tcp连接的基础上传送http报文。 http协议是一个请求-应答的模式，也就是当没有启动keep-alive的时候，每一次建立http连接都是现用现建立，用完就断开的工作样式。而如果开启了keep-alive模式的话，客户端和服务器之间http连接就会被保持，不会断开（超过Keep-Alive规定的时间，意外断电等情况除外），当客户端发送另外一个请求时，就使用这条已经建立的连接。 Keep-Alive的规定时间在客户端（浏览器里）是如何确定的呢？例如Keep-Alive: timeout=5, max=100，表示这个TCP通道可以保持5秒，max=100表示这个长连接最多接收100次请求就断开。 Keep-alive在http 1.1版本里是默认开启的，只有加入Connection: close才会关闭，现在大部分浏览器都是使用http 1.1协议，所以说在客户端已经是默认发起keep-alive的连接请求。但是能否会完成一个完整的keep-alive还要看服务器端的具体配置情况。 在nginx里就直接支持keepalive_timeout指令，其使用0值来停用keep-alive，举例配置如下: 12345location /XXX/ &#123; alias /url/var/www/html/; keepalive_timeout 75; expires 5m; &#125; 使用长连接之后，客户端和服务端怎么知道本次传输结束呢？两部分：1. 判断传输数据是否达到了Content-Length指示的大小，这个是最简单的最傻瓜的，普遍应用于静态的图片或者页面；2. 往往动态生成的文件没有Content-Length，它是分块传输（chunked），这时候怎么办呢？就要根据chunked编码来判断，chunked编码的数据在最后有一个空chunked块，表明本次传输数据结束，这种情况更多应用于动态的页面。 进一步的说chunkedHTTP请求报文的格式是这样的： 1234&lt;method&gt; &lt;request-URL&gt; &lt;version&gt;&lt;headers&gt;&lt;entity-body&gt; 其中在请求头的地方有一个叫Content-Length的字段，如果没有这个字段那么就会有叫Transfer-encoding的字段，它用来表示http报文的传输格式，这个字段的取值有很多，但是真正有意义的只有一个—chunked。 如果一个HTTP消息（请求消息或应答消息）的Transfer-Encoding消息头的值为chunked，那么，消息体由数量未定的块组成，并以最后一个大小为0的块为结束。 每一个非空的块都以该块包含数据的字节数（字节数以十六进制表示）开始，跟随一个CRLF（回车及换行），然后是数据本身，最后块CRLF结束。在一些实现中，块大小和CRLF之间填充有白空格（0x20）。 最后一块是单行，由块大小（0）、一些可选的填充白空格、以及CRLF组成。最后一块不再包含任何数据，但是可以发送可选的尾部，包括消息头字段。消息最后以CRLF结尾。 注意1.chunked和multipart两个名词在意义上有类似的地方，不过在HTTP协议当中这两个概念则不是一个类别的。multipart是一种Content-Type，标示HTTP报文内容的类型，而chunked是一种传输格式，标示报头将以何种方式进行传输； 注意2.chunked传输不能事先知道内容的长度，只能靠最后的空chunk块来判断，因此对于下载请求来说，是没有办法实现进度的。在浏览器和下载工具中，偶尔我们也会看到有些文件是看不到下载进度的，即采用chunked方式进行下载； 注意3.chunked的优势在于，服务器端可以边生成内容边发送，无需事先生成全部的内容。HTTP/2不支持Transfer-Encoding: chunked，因为HTTP/2有自己的streaming传输方式。 http keep-alive与tcp keep-alivehttp的keep-alive与tcp的keep-alive可不是同一回事，意图也不一样。http的keep-alive是为了让tcp活得更久一点，以便在同一个连接上传送多个http，提高socket的效率。而tcp的keep-alive是tcp的一种检测tcp连接状况的保鲜机制。tcp的keep-alive是一个保鲜定时器，支持三个系统内核配置参数： 123echo 1800 &gt; /proc/sys/net/ipv4/tcp_keepalive_timeecho 15 &gt; /proc/sys/net/ipv4/tcp_keepalive_intvlecho 5 &gt; /proc/sys/net/ipv4/tcp_keepalive_probes keepalive是TCP保鲜定时器，当网络两端建立了tcp连接之后，闲置idle（双方没有任何数据流发送往来）了tcp_keepalive_time后，服务器内核就会尝试向客户端发送侦测包，来判断TCP连接状况(有可能客户端崩溃、强制关闭了应用、主机不可达等等)。如果没有收到对方的回答(ack包)，则会在tcp_keepalive_intvl后再次尝试发送侦测包，直到收到对对方的ack,如果一直没有收到对方的ack,一共会尝试tcp_keepalive_probes次，每次的间隔时间在这里分别是15s、30s、45s、60s、75s。如果尝试tcp_keepalive_probes,依然没有收到对方的ack包，则会丢弃该TCP连接。TCP连接默认闲置时间是2小时，一般设置为30分钟足够了。 也就是说，仅当nginx的keepalive_timeout值设置高于tcp_keepalive_time，并且距此tcp连接传输的最后一个http响应，经过了tcp_keepalive_time时间之后，操作系统才会发送侦测包来决定是否要丢弃这个TCP连接。一般不会出现这种情况，除非你需要这样做。 keep-alive与TIME_WAIT使用http的keep-alive，可以减少服务端TIME_WAIT数量(因为由服务端httpd守护进程主动关闭连接)。道理很简单，相较而言，启用keep-alive，建立的tcp连接更少了，自然要被关闭的tcp连接也相应更少了。 补充建议在服务器提供Web站点服务时(一个页面除了动态内容，还包含非常多的JS、图片、css文件等)开启keep-alive。在“服务器提供的是一个接口服务，除了动态内容，几乎没有引用任何静态内容”这样的场景，不建议开启keep-alive。 参考资料http://www.cnblogs.com/skynet/archive/2010/12/11/1903347.htmlhttps://hit-alibaba.github.io/interview/basic/network/HTTP.htmlhttp://51write.github.io/2014/04/09/keepalive/http://www.nowamagic.net/academy/detail/23350305","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/tags/大牛之路/"},{"name":"http协议","slug":"http协议","permalink":"http://yoursite.com/tags/http协议/"}]},{"title":"ssh连接port22:Socket error Event:32 Error:10053","slug":"ssh连接port22-Socket-error-Event-32-Error-10053","date":"2018-03-07T10:51:31.000Z","updated":"2018-03-07T11:41:50.000Z","comments":true,"path":"2018/03/07/ssh连接port22-Socket-error-Event-32-Error-10053/","link":"","permalink":"http://yoursite.com/2018/03/07/ssh连接port22-Socket-error-Event-32-Error-10053/","excerpt":"","text":"今天遇到了一个奇怪的现象，据开发人员反馈，有一台阿里云服务器在控制台重启了之后，发现无法登陆了。我先使用阿里云的控制台打算远程登陆到这台机器发现，远程登陆总是显示密码错误。然后我使用xshell登陆对应的外网IP和22端口的时候发现爆出如下的错误： 12345678Connecting to X.X.X.X:22...Connection established.To escape to local shell, press 'Ctrl+Alt+]'.Socket error Event: 32 Error: 10053.Connection closing...Socket close.Connection closed by foreign host. 这种情况很罕见，google了一下也没有对于我有用的处理办法，于是我就只好给阿里云后台发了一下工单。授权给阿里云让他们登陆一下这台机器看一下里面发生了什么，阿里云的售后人员过了一会打过电话过来说，发现这台机器里面有人操作了chmod -R 777 /，破坏了比如/etc/passwd和/etc/shadow的权限，所以会爆出这样的错误。如图： 阿里的售后说他们也把几个跟登陆有关的文件暂时恢复权限，这样这个机器就可以成功登陆了，如图：","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"ssh","slug":"ssh","permalink":"http://yoursite.com/tags/ssh/"}]},{"title":"孤儿进程和僵尸进程","slug":"孤儿进程和僵尸进程","date":"2018-03-07T08:07:35.000Z","updated":"2018-03-08T14:55:10.000Z","comments":true,"path":"2018/03/07/孤儿进程和僵尸进程/","link":"","permalink":"http://yoursite.com/2018/03/07/孤儿进程和僵尸进程/","excerpt":"","text":"原理与定义首先要知道，linux有父进程和子进程这样的说法。那父进程如何创建子进程呢？fork。 子进程的进行和父进程的进行是异步的，但是父进程就像父母一样对自己的小孩也有一定的控制欲，这个控制欲就表现在如果子进程如果结束了，它释放了之前占用的资源、内存、文件等等，但是它还保留了一点信息：进程号PID、退出状态、运行时间等等。而这些残留信息是父进程通过wait/waitpid来获取，如果父进程一直不获取，那么子进程就会一直保留这些信息直到海枯石烂。 孤儿进程：父进程退出，子进程继续进行，那么此时子进程就是孤儿进程。这个时候init进程（进程号为1）来作为子进程的监护人，发出wait/waitpid来完成状态收集工作； 僵尸进程：父进程没有退出，但是它迟迟不发出wait/waitpid来回收子进程的资源。就好比儿子死了，当爹的不给收尸，这个儿子就成了孤魂野鬼成了僵尸。 影响与危害孤儿进程是没有什么大的危害，虽然他虽然没有了亲生父亲，但是也有init进程来通过循环的wait()来处理它的善后工作，所以迟早会把占用的资源释放掉。 甚至有的用户可以把进程弄成孤儿进程，以使之与用户会话脱钩，并转至后台运行。这一做法常应用于启动需要长时间运行的进程，也即守护进程。另外，nohup命令也可以完成这一操作。 但是僵尸进程不一样，要是父进程对子进程一直不使用wait/waitpid，那么pid就会不回收，可是系统内的pid总是是有限的，这样久而久之就是对pid的一个霸占，新的进程也无法生成，这就是僵尸进程的危害。 如何处理僵尸进程僵尸进程是杀不死的，怎么办？杀他爹，把父进程杀掉了，那么这些僵尸就成了孤儿进程，然后再由init收养，最后入土为安。 查看当前服务器僵尸进程的方法： 1ps -A -o stat,ppid,pid,cmd | grep -e '^[Zz]' 如果服务器上的僵尸进程不是出自一个父进程之手，那么就用下面这个命令批量解决： 1ps -A -o stat,ppid,pid,cmd | grep -e '^[Zz]' | awk '&#123;print $2&#125;' | xargs kill -9 但是如果父进程是init进程，那么这样的僵尸进程怎么办？答案，不用刻意管他，相信init的能力，它迟早会被init回收的，成为僵尸进程也是暂时的。 参考资料https://zh.wikipedia.org/wiki/%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8Bhttps://zh.wikipedia.org/wiki/%E5%AD%A4%E5%84%BF%E8%BF%9B%E7%A8%8Bhttp://blog.csdn.net/YuZhiHui_No1/article/details/53011390","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"蚂蚁金服运维面试全纪录","slug":"蚂蚁金服运维面试全纪录","date":"2018-03-07T03:33:01.000Z","updated":"2018-03-19T07:30:46.000Z","comments":true,"path":"2018/03/07/蚂蚁金服运维面试全纪录/","link":"","permalink":"http://yoursite.com/2018/03/07/蚂蚁金服运维面试全纪录/","excerpt":"","text":"早上接到蚂蚁金服的运维面试电话，有点突然袭击，下面是整个的面试记录。 首先，面试官先向我讲述了一下他们平时运维的工作内容，然后结合我的简历开始提问。 1）都用过我们的什么产品？这一阶段老老实实、正常回答工作中所用到的阿里云产品和使用情景。 2）VPC网络有哪些好处？我就答出来更加安全…面试官说其他方面呢，我就不知道了。【事后补充】VPC网路的灵活性更高，可以自由定义网段划分、IP地址和路由网络。 3)一个vpc的服务器如何与外网交互？我说可以改写路由或者通过iptables转发。 4）iptables里PREROUTING和POSTROUTING都是啥？PREROUTING处理刚到达本机并在路由转发前的数据包；POSTROUTING处理即将离开本机的数据包。 5）问：RDS在什么操作下会CPU飙升，任举一例？答：在我实际工作中，比较明显的是在数据同步的时候会飙升。 6）RDS为什么会在DTS的时候有飙升的现象？这个我答的不好，有点东拉西扯…（尴尬） 7）mysql备份的时候使用过什么参数？答：--skip-opt 防止运行中的MYSQL锁库加速数据备份的参数是什么？-q 提高导出性能-e 提高导入性能，使用包括几个VALUES列表的多行INSERT语法；--max_allowed_packet=XXX 客户端/服务器之间通信的缓存区的最大大小；--net_buffer_length=XXX TCP/IP和套接字通信缓冲区大小，创建长度达到net_buffer_length的行； 注意！max_allowed_packet和net_buffer_length在mysql里有参数值，不能超过参数值！查看方法：show variables like &#39;max_allowed_packet&#39;; 8）cache和buffer有什么区别？cache是缓存，弥补高速设备与低速设备的鸿沟引入的中间层，达到数据快取的目的（救火车与蓄水池）；buffer是缓冲区，用户流量整形，把大量的小的io整理一个平稳的大io，减少磁盘响应次数；buffer是即将要写入磁盘的，cache是要被从磁盘里读出来的。当然这只是普通用途，buffer用来读、cache用来写也是有可能的。具体问题具体分析。 9）他俩的调用有什么区别？我问是要说“块读取”什么的么，面试官说是。我就蒙说cache是块读取，buffer我不清楚…（尴尬 again）【事后补充】 10）谈一谈time_wait和close_wait，各自在什么情况下出现？time_wait和close_wait是出现在“四次挥手”的环节里，time_wait是服务器接收到客户端发来的断开TCP连接的请求，并且服务器发送确认断开的包给客户端，此时服务器处于time_wait状态，如果服务器等待两个msl的话，就会默认断开连接，如果想修改msl可以通过修改/etc/systl.conf文件；close_wait是客户端已经发送了断开TCP请求，但是服务器端没有接收到，也就是time_wait的上一步，此时这个资源就一直被程序霸占。 11）为什么time_wait需要等待两个msl?1.99行不行？2.01行不行？我当时说防止上一次连接中的包，迷路后重新出现，影响新连接。面试官好像觉得不是很满意…（尴尬 again）【事后补充】MSL是指一个片段在网络中的最大存活时间，2MSL是一个发送和一个回复所需的最大时间，如果直到2MSL，客户端都没有收到fin包，那么客户端就可以断定他发出去的ack已经被服务端接收，结束TCP连接。 12）说出一个你使用过的python库。我说我前两天用matpoltlib画图，就谈了谈这个画图的库。 13）python装饰器了解么？没什么深入的了解，就没敢答，怕被问死。 14）僵尸进程和孤儿进程，了解么？马蛋，这个让我给说反了…(闹心啊啊啊啊啊啊啊)【事后补充】孤儿进程：父进程退出，而它的一个或者多个子进程还在运行，这些子进程就叫孤儿进程，孤儿进程被init进程收养，由init进程对它们完成状态收集工作；僵尸进程：一个进程用fork创建了子进程，然后这个子进程退出了，而父进程并没有调用wait或者waitpid去获取子进程的状态信息，那么这个子进程的进程描述符还在系统中，这种进程叫僵尸进程； 孤儿进程不怕，由于孤儿虽然没有父母，但是有民政局（init进程）收养，孤儿进程退出后也有init做一切善后工作；而僵尸进程会一直霸占其PID号，但是系统总共的PID是有限的，这样就会让可用的PID越来越少，所以僵尸进程是要避免的。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/tags/大牛之路/"}]},{"title":"Zookeeper的选举原理","slug":"Zookeeper的选举原理","date":"2018-03-05T13:30:10.000Z","updated":"2018-03-05T16:38:52.000Z","comments":true,"path":"2018/03/05/Zookeeper的选举原理/","link":"","permalink":"http://yoursite.com/2018/03/05/Zookeeper的选举原理/","excerpt":"","text":"前言Zookeeper是一款比较常见的式应用程序协调服务软件，如果配置了多台zookeeper自然要选择一个头头，这个头头就是leader，很明显不能所有的zookeeper都是leader，那样就失控了；也不能所有的zookeeper都是follower，那就群龙无首无法协调。 插播一句，这种一老大N跟班的模式是过去分布式软件里很常见的工作模式，而最近比较火热的区块链不同，它是一种去中心化的工作模式，大家人人都当节点，然后放在一起整合，有点原始社会的意思。所以说，算法有时候来自于人类学，也会在一定程度反过来上影响人类。 选举leader的方式是一种叫FastLeaderELection的算法，以3.4.6版本为例，它被保存在/usr/zookeeper/src/java/main/org/apache/zookeeper/server/quorum/这个文件夹下。 选举的中心思想实际上FastLeaderELection说的中心思想无外乎以下几个关键点： 全天下我最牛！在我没有发现比我牛的推荐人的情况下，我就一直推举我当leader，第一次投票那必须推举我自己当leader。 每当我接收到其它的被推举者，我都要回馈一个信息，表明我还是不是推举我自己。如果被推举者没我大，我就一直推举我当leader，是我是我还是我！ 我有一个票箱， 和我属于同一轮的投票情况都在这个票箱里面。一人一票重复的或者过期的票，我都不接受。 一旦我不再推举我自己了（这时我发现别人推举的人比我推荐的更牛），我就把我的票箱清空，重新发起一轮投票（这时我的票箱一定有两票了，都是选的我认为最牛的人）。 一旦我发现收到的推举信息中投票轮要高于我的投票轮，我也要清空我的票箱。并且还是投当初我觉得最牛的那个人（除非当前的人比我最初的推荐牛，我就顺带更新我的推荐）。 不断的重复上面的过程，不断的告诉别人“我的投票是第几轮”、“我推举的人是谁”。直到我的票箱中“我推举的最牛的人”收到了不少于N/2 + 1的推举投票。这也回答了为什么zookeeper在少于N/2 + 1的节点处于工作状态的情况下会崩溃了。因为，无论怎么选也没有任何节点能够获得N/2 + 1的票数。 这时我就可以决定我是flower还是leader了（如果至始至终都是我最牛，那我就是leader咯，其它情况就是follower咯）。并且不论随后收到谁的投票，都向它直接反馈“我的结果”。 判断依据上面第二步里说了，如果接收到其他被推举者的消息，而且判断出这个被推举者比我牛，我就要推举他，那么判断依据是啥呢？答案是依次比较epoch、zxid、serverid。 先说说啥是epoch、zxid、serverid： epoch: 表示选举轮数。 zxid: 事务zxid包含了本地数据的最后更新时间相关的信息。 serverid: 当前server的 ID, 通过配置文件指定(echo &#39;1&#39; &gt; myid)。 具体的判断过程是：接收到的消息中，有epoch比我大的，则选epoch大的消息中确定的server；如果epoch相等，则选zxid最大的server；如果zxid也相等，则选serverid最大的server(有的节点生来就是当leader的）。 为什么要有epoch呢？这样是为了防止中途有选举者掉线，他们错过了选举，再次连上来的时候，他们发现自己的投票轮已经小于现有的投票轮了，那么他们比如要清空自己的投票箱然后无条件的改为推荐接收到的最新选举中大家推荐的最牛的那个人（如果没有人比我牛，那还是推荐我自己）。由于有最后一条serverid大的最后压阵，而且serverid又不能重复，所以基本上都能最后选出一台作为leader。 参考资料http://blog.csdn.net/yinwenjie/article/details/47613309https://mozillazg.com/2017/03/zookeeper-fastleader-elect-leader.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"},{"name":"zookeeper","slug":"zookeeper","permalink":"http://yoursite.com/tags/zookeeper/"}]},{"title":"从韩国民主电影三部曲浅谈我对民主的认识","slug":"韩国民主电影三部曲","date":"2018-03-04T13:07:08.000Z","updated":"2018-03-04T15:51:40.000Z","comments":true,"path":"2018/03/04/韩国民主电影三部曲/","link":"","permalink":"http://yoursite.com/2018/03/04/韩国民主电影三部曲/","excerpt":"","text":"这个周末周五晚上看了《出租车司机》，周六下午看了《1987：黎明到来的那一天》，再加上之前就在B站看过又被下架的《辩护人》，韩国民主运动三部曲都看完了。 韩国民主运动电影还有一部叫《华丽的假期》，这个片子是2007年公映的，也是讲光州事件，但是这部片从电影角度上不如上面这三者，所以影响力和传播程度相对有限。 一直以来我对韩国的政治采取一种“黑”的态度，因为他们的总统基本没有好下场，哪怕是我个人比较喜欢的卢武铉总统也是以自杀结束了自己的一生，而且他们的演艺圈和体育圈也是以各种“黑”和“潜规则”出名。但是我不得不佩服韩国正直电影人的精神以及韩国正直记者们的精神，他们坚持了自己的操守而且履行了自己的职责，用骨气和勇气记录了他们能接触到的真相并且在日后拍成电影反思历史。 论民主化运动，韩国可以说是亚洲里第一档的存在，大型示威的次数加起来比越南、缅甸、柬埔寨加起来还要多，远超于同样是发达国家的日本。韩国民主化运动主要集中在1980-1987年全斗焕执政那一段时间，那时韩国人民虽然经历了初期经济水平腾飞的甜蜜，但是对后期经济调控不力和政府打压言论表示不满和愤怒。暴动的人民反抗意识比较强，不仅有大规模游行，甚至有这几部电影里没有提到的抢劫军火库的行为。而这些抢劫军火的行为日后也成了全斗焕在法庭上力图脱罪的一个辩控点。 这几部电影虽然被部分人影评“有明显的韩国特色，会导致审美疲劳”，但是并不耽误它们一次又一次的刷新票房记录，可见参与政治追求民主和公平其实是公民的一种本能。但是说实话，截止至今，光州事件虽然被平反但是没有得到彻底的清算。新闻说现任韩国总统文在寅先后观看了《出租车司机》和《1987：黎明到来的那一天》，会不会重审当年的光州罪犯，我们拭目以待。 民主可能本身不是一个效率很高的政治制度，因为它要坚持“少数服从多数”的原则，在具体条款颁布和施行的时候，由于不同人看待事物的水平和深度有高有低，以及侧重面的不同，那么肯定会有一些不一样的声音。而独裁的“一言堂”则相对效率很快，从历史来看，独裁政府甚至有战争上打败民主政府的先例，而且独裁政府挑头并且通过集权形式搞经济的话，在国家原有经济非常落后的前提下，的确可以快速进步，但是这种进步并不是那种“可持续发展”式的，而且中后期会由于民众监督不力，导致政府腐败的先例数不胜数。所以说集权就是一个春药，服用肯定会上瘾，但是也只会用暂时的爽换来将来的无穷尽的苦。独裁无论是理论还是事实都已经被当今社会唾弃，只有民主化才是迟早的选择，因为它至少可以守得住下限。 而且我个人认为，民主是一个持续的过程而不是一个简单的结果。绝对意义上的民主和拖沓低效的民主只会害了广大的底层百姓，极力避免的同时，也要最小程度的限制人滥用民主，这些就需要政府工作的透明化和规范化。 不过韩国的民主也有它的独特性，主要就是它有特殊的外界因素—-既不能得罪美国人，又不能惹毛了朝鲜（这一点跟台湾很像），所以无论是强权政府还是抗议民众都没有把事情搞得太过火。其次还有韩国中产阶级在抗议中也扮演了“理性和保守的一面”：他们是经济发展的受益者，对秩序有相当的敏感性，一旦社会民主斗争极端化，中产阶级便会退出民主运动，这是其保守性的表现。除此之外，还有比如基督教的传播代替了原有的儒家思想更追求自由等等因素，我这里水平有限，就不展开了。 最后补充一句，各位都知道《辩护人》里宋康昊的原型是卢武铉总统，据说片里宋康昊parter的原型就是韩国现在的总统—文在寅。","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"政治","slug":"政治","permalink":"http://yoursite.com/tags/政治/"},{"name":"亚洲民主","slug":"亚洲民主","permalink":"http://yoursite.com/tags/亚洲民主/"},{"name":"影评","slug":"影评","permalink":"http://yoursite.com/tags/影评/"}]},{"title":"动手做一个网络简历并且保存成PDF","slug":"动手做一个网络简历并且保存成PDF","date":"2018-03-02T05:36:51.000Z","updated":"2018-03-02T17:43:58.000Z","comments":true,"path":"2018/03/02/动手做一个网络简历并且保存成PDF/","link":"","permalink":"http://yoursite.com/2018/03/02/动手做一个网络简历并且保存成PDF/","excerpt":"","text":"环境说明服务器:nginx浏览器:firefox 制作网页简历过程首先先下载简历的模板文件，过程如下： 1234wget http://labfile.oss.aliyuncs.com/courses/624/cv-template.zipunzip cv-templatemv cv-template/* .rm -rf cv-template* __MACOSX* 然后在浏览器里的地址栏里输入服务器外网IP，就可看到下面的界面，如图： 我们发现这个界面是可以编辑的，于是就在前人的基础上修改即可，这里感谢前人栽树！！！ 但是修改了并不是就保存了，如果你刷新这个界面发现又变成了初始的界面。所以这个时候我们要把修改过的网页的前端代码拷贝下来。 在firefox浏览器的配置里选择WEB开发者，如图： 然后选择查看器： 这个时候在页面就出现了整个网页的代码，选择复制—HTML外面： 然后把这个html代码拷贝到nginx服务器里的index.html里覆盖原有的内容，再重新刷新浏览器，就会成为已经保存过的界面了！ 将网页保存成PDF在浏览器里的配置里选择打印，然后现在页面设置里的勾选打印背景（颜色和图片）再修改一下页眉和页脚。再点击打印，默认情况就会保存成PDF文件了。 参考资料https://segmentfault.com/a/1190000006820290","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"Linux运维工程师笔试题第十五套","slug":"Linux运维工程师笔试题第十五套","date":"2018-03-01T05:50:16.000Z","updated":"2019-10-11T08:25:06.000Z","comments":true,"path":"2018/03/01/Linux运维工程师笔试题第十五套/","link":"","permalink":"http://yoursite.com/2018/03/01/Linux运维工程师笔试题第十五套/","excerpt":"","text":"正文1.粘包是什么意思？TCP和UDP是否会出现粘包？出现了粘包如何处理？[我的答案]粘包就是当客户端连续不断的往服务端发送数据包的时候，服务端接收的数据会出现两个数据包粘在一起的情况；UDP（非面向连接）是不会出现粘包的，因为UDP协议是基于报文的，UDP首部采用了16bit来指示UDP数据报文的长度，因此在应用层能很好的将不同的数据报文区分开，从而避免粘包和拆包的问题。而TCP（面向连接）是基于字节流的，它无法识别包的长度，所以会出现粘包的现象。 解决办法主要有以下三种：1）发送端给每个数据包添加包首部，首部中应该至少包含数据包的长度，这样接收端在接收到数据后，通过读取包首部的长度字段，便知道每一个数据包的实际长度了，有较高的效率而且少冗余，但是编程较复杂；2）发送端将每个数据包封装为固定长度（不够的可以通过补0填充），这样接收端每次从接收缓冲区中读取固定长度的数据就自然而然的把每个数据包拆分开来，编程简单但是效率一般甚至很低；3）可以在数据包之间设置边界，如添加特殊符号，这样，接收端通过这个边界就可以将不同的数据包拆分开； 2.time_wait是什么情况？如果出现了过多的close_wait可能是什么原因？[我的答案]TIME_WAIT是主动关闭连接的一方保持的状态，在保持这个状态2MSLmax segment lifetime时间之后，彻底关闭回收资源。遇到TIME_WAIT数过大导致的服务器异常，很容易解决，修改下/etc/sysctl.conf就ok了。 如果一直保持在CLOSE_WAIT状态，那么只有一种情况，就是在对方关闭连接之后服务器程序自己没有进一步发出ack信号。换句话说，就是在对方连接关闭之后，程序里没有检测到，或者程序压根就忘记了这个时候需要关闭连接，于是这个资源就一直被程序占着。这个情况多半是代码的问题，在服务器端是无能为力的，要检查代码。 3.epoll和select的区别？边缘触发和水平触发的区别？[我的答案]select查询速度较慢，因为他每次产生fd时候会有整体fdset的拷贝，而且每次有回送，select要查询整个fdset；epoll查询速度较快，因为他为每个fd都regist了一个单独的回调函数。 水平触发(LT)：当epoll检测到其上有事件发生并通知应用程序时，应用程序可以不立即处理，这样当应用程序再次调用epoll中调用函数时，epoll会再次通知应用程序此事件,直到被处理。 边沿触发(ET)：当epoll检测到其上有事件发生并通知应用程序时，应用程序必须立即处理，并且下一次的epoll调用，不会再向应用程序通知此事件。 所以ET模式大大得降低了同一个epoll事件被重复触发的次数，因此ET模式工作效率比LT模式更高。select、poll、epoll的默认工作模式都是水平触发(LT)模式，但是epoll是支持边沿触发(ET)模式的。 4.varchar和char的区别是什么？utf8字符集下varchar最多存多少个字符？[我的答案]前面那个问题去看http://blog.51cto.com/chenx1242/1742467，这里说后面那个。在utf-8状态下的varchar，最大只能到 (65535 - 2) / 3 = 21844 余 1。在gbk状态下的varchar, 最大只能到 (65535 - 2) / 2 = 32766 余 1。 5.primary key和unique的区别？[我的答案]首先先说明primary key = unique + not null，其次Unique Key可以是空，可以在一个表里的一个或多个字段定义，也就是爱有几个有几个，同时存在也可以；但是Primary Key不能为空不能重复，而其一个表里只能有一个Primary Key。 6.乐观锁是啥，悲观锁是啥？[我的答案]悲观锁Pessimistic Lock, 顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。 乐观锁Optimistic Lock, 顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号等机制。乐观锁适用于多读的应用类型，这样可以提高吞吐量，像数据库如果提供类似于write_condition机制的其实都是提供的乐观锁。 两种锁各有优缺点，不可认为一种好于另一种，像乐观锁适用于写比较少的情况下，即冲突真的很少发生的时候，这样可以省去了锁的开销，加大了系统的整个吞吐量。但如果经常产生冲突，上层应用会不断的进行retry，这样反倒是降低了性能，所以这种情况下用悲观锁就比较合适。 7.如何在python的三引号里添加变量？[我的答案] 1234567891011121314151617~$ pythonPython 2.7.3 (default, Jan 2 2013, 16:53:07) [GCC 4.7.2] on linux2Type \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; &gt;&gt;&gt; context = \"\"\"Here is an example block template:... name: %(name)s... age: %(age)d... job: %(job)s... \"\"\"&gt;&gt;&gt; &gt;&gt;&gt; print context % dict(name=\"Tim Wang\", age=45, job=\"Coder\")Here is an example block template: name: Tim Wang age: 45 job: Coder &gt;&gt;&gt; 8.redis满了会怎么样？[我的答案]默认情况下redis满了就不会存储新的数据了，不过这个可以调整，redis在达到指定内存的时候可以通过设定的策略来做不同的动作，常见策略如下：1）noeviction:返回错误当内存限制达到并且客户端尝试执行会让更多内存被使用的命令（大部分的写入指令，但DEL和几个例外）2）allkeys-lru: 尝试回收最少使用的键（LRU），使得新添加的数据有空间存放。3）volatile-lru: 尝试回收最少使用的键（LRU），但仅限于在过期集合的键,使得新添加的数据有空间存放。4）allkeys-random: 回收随机的键使得新添加的数据有空间存放。5）volatile-random: 回收随机的键使得新添加的数据有空间存放，但仅限于在过期集合的键。6）volatile-ttl: 回收在过期集合的键，并且优先回收存活时间（TTL）较短的键,使得新添加的数据有空间存放。 9.啥是“脏读”、“不可重复读”、“幻读”？[我的答案]脏读又称无效数据的读出，是指在数据库访问中，事务T1将某一值修改，然后事务T2读取该值，此后T1因为某种原因撤销对该值的修改，这就导致了T2所读取到的数据是无效的。 不可重复读是指在数据库访问中，一个事务范围内两个相同的查询却返回了不同数据。这是由于查询时系统中其他事务修改的提交而引起的。比如事务T1读取某一数据，事务T2读取并修改了该数据，T1为了对读取值进行检验而再次读取该数据，便得到了不同的结果。 幻读是指当事务不是独立执行时发生的一种现象，例如第一个事务对一个表中的数据进行了修改，比如这种修改涉及到表中的“全部数据行”。同时，第二个事务也修改这个表中的数据，这种修改是向表中插入“一行新数据”。那么，以后就会发生操作第一个事务的用户发现表中还有没有修改的数据行，就好象发生了幻觉一样。 10.ext2、ext3、ext4的区别是啥？[我的答案]ext3和ext2的主要区别在于，ext3引入Journal。ext2和ext3的格式完全相同，只是在ext3硬盘最后面有一部分空间用来存放Journal（日志）的记录；在ext2中，写资料到硬盘中时，先将资料写入缓存中，当缓存写满时才会写入硬盘中；在ext3中，写资料到硬盘中时，先将资料写入缓存中，待缓存写满时系统先通知Journal，再将资料写入硬盘，完成后再通知Journal，资料已完成写入工作；在ext3中，也就是有Journal机制里，系统开机时检查Journal的资料，来查看是否有错误产生，这样就快了很多； ext4和ext3的主要区别在于:首先ext4与ext3兼容,ext3只支持32,000个子目录，而额ext4支持无限数量的子目录;ext3所支持的16TB文件系统和最大的2TB的文件，而ext4分别支持1EB（1,048,576TB，1EB=1024PB，1PB=1024TB）的文件系统，以及16TB的文件;ext3的数据块分配策略是尽快分配，而ext4是尽可能地延迟分配，直到文件在cache中写完才开始分配数据块并写入磁盘;ext4允许关闭日志，以便某些有特殊需求的用户可以借此进一步提升性能等等等等。 11.简述一下A记录与NS记录的区别1.A记录是名称解析的重要记录，它用于将特定的主机名映射到对应主机的IP地址上。你可以在DNS服务器中手动创建或通过DNS客户端动态更新来创建。2.NS记录此记录指定负责此DNS区域的权威名称服务器。3.A记录和NS记录的区别是，A记录直接给出目的IP，NS记录将DNS解析任务交给特定的服务器，NS记录中记录的IP即为该特定服务器的IP地址。4.NS记录优先于A记录，A记录优先于CNAME记录。 参考资料https://blog.insanecoder.top/tcp-packet-splice-and-split-issue/http://blog.csdn.net/tiandijun/article/details/41961785http://www.redis.cn/topics/lru-cache.htmlhttp://blog.csdn.net/d_guco/article/details/53166722http://www.hollischuang.com/archives/934http://zhaodedong.leanote.com/post/Linux%EF%BC%9AExt2-Ext3-Ext4%E7%9A%84%E5%8C%BA%E5%88%AB","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/tags/大牛之路/"},{"name":"面试经验","slug":"面试经验","permalink":"http://yoursite.com/tags/面试经验/"}]},{"title":"调用阿里云api获取阿里云数据同步服务（DTS）并且作图发送邮件的整个流程","slug":"调用阿里云api获取阿里云数据同步服务（DTS）并且作图发送邮件的整个流程","date":"2018-02-28T15:00:20.000Z","updated":"2018-02-28T15:27:56.000Z","comments":true,"path":"2018/02/28/调用阿里云api获取阿里云数据同步服务（DTS）并且作图发送邮件的整个流程/","link":"","permalink":"http://yoursite.com/2018/02/28/调用阿里云api获取阿里云数据同步服务（DTS）并且作图发送邮件的整个流程/","excerpt":"","text":"前言在https://rorschachchan.github.io/2018/02/24/阿里云获取DTS服务延迟的脚本/ 文章里已经说了“领导要求每天查看阿里云dts同步的延迟情况和同步速率情况”，并且在https://rorschachchan.github.io/2018/02/27/使用matplotlib画图的一个脚本/ 里面也放了一个使用python matplotlib画图的demo，这篇文章的目的就是把整个过程实现，并且把dts图形以每日邮件的形式发送给领导的效果！ 实现需求的思路本次需求有四个动作，分别是获取一天以内的DTS延迟和同步速率、将获取到的DTS值做成PNG图像、将生成的PNG图像上传到阿里云云存储OSS、把图片展示到邮件里并发送给相关领导。由于第一步获取一天以内的DTS延迟和同步速率需要将这个脚本每小时执行一次，执行24次，才可以执行生成png图像这一步，所以后三个其实可以写成一个大脚本。不过在本文为了表述的清楚，就把各自不同用途写成了不同的脚本。 获取阿里云DTS延迟和同步速率的脚本这个脚本之前写过了，这里再拿出来晒一遍： 123456789101112131415161718192021222324252627282930313233#!/usr/bin/env python#coding=utf-8#这个脚本是用来获取dts延迟数字的from aliyunsdkcore import clientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionimport time,json,syssys.path.append('/解压缩路径/aliyunsdkdts/request/v20160801/') #这里看不懂去看https://rorschachchan.github.io/2018/02/24/阿里云获取DTS服务延迟的脚本/import DescribeSynchronizationJobStatusRequest# 创建 Client 实例clt = client.AcsClient('这里填写ak','这里填写sk','cn-shenzhen')# 创建 request，并设置参数request = DescribeSynchronizationJobStatusRequest.DescribeSynchronizationJobStatusRequest()request.set_SynchronizationJobId(\"这里填写DTS的ID号\")response = clt.do_action_with_exception(request)delay = json.loads(response)rate = str(delay[\"Performance\"][\"FLOW\"])[0:4] #由于同步速率默认是带单位的，这里就取前四位#用A.txt来存储延迟时长fd = open(\"/存储路径/A.txt\",\"a\")fd.write(str(delay[\"DataSynchronizationStatus\"][\"Delay\"]))fd.write('\\n')fd.close()#用B.txt来存储同步速率 fr = open(\"/存储路径/rate.txt\",\"a\")fr.write(rate)fr.write('\\n')fr.close() 将获取到的值做成图片的脚本由于脚本执行环境是无图像的阿里云服务器，系统是centos 7，ps.slow这一步会爆错RuntimeError: could not open display，所以只能采取把生成的PNG图像文件保存到本地路径里的方法。脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445#!/usr/bin/env python# -*- coding: utf-8 -*-import matplotlib as mplmpl.use('Agg') #在无法生成图像的环境下要添加了上面两句话import matplotlib.pyplot as pltimport numpy as npimport pylab as plx=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]#横坐标的内容labels=['10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','1','2','3','4','5','6','7','8','9']#y1是delay延迟时长with open('/存储路径/A.txt', 'r') as f: y1 = [] for line in f: lst = line.split('\\n') #增加一个换行符，不然数字是不换行的 y1.append(float(lst[0]))#y2是rate同步速率with open('/存储路径/B.txt', 'r') as f: y2 = [] for line in f: lst = line.split('\\n') y2.append(float(lst[0]))#输入对应的坐标，后面是颜色plot1,=pl.plot(x,y1,'r')plot2,=pl.plot(x,y2,'b')pl.xticks(x,labels)pl.title('这里写标题',size=20) #中文会显示乱码，推荐还是英文pl.xlabel('这里是X轴标题', size=14)pl.ylabel('这里写Y轴标题', size=14)pl.ylim(0.0,5.0)#曲线对应注释pl.legend([plot1,plot2],('Delay','Sync rate'),'best',numpoints=1)#开启网格pl.grid()#图片保存路径plt.savefig('/保存路径/图片名称.png', format='png') 将生成的图片上传到阿里云OSS的脚本由于不想让“领导去手动点开附件查看图像”，所以我们干脆把图片作为邮件的正文展示出来，那么就在html里就需要img src=图片的网络地址的方法。于是就把刚刚生成的图片上传到阿里云OSS里，这样就可以获得图片的网络地址。而且阿里云OSS是“相同文件名会覆盖”，所以不用再去删除。整个脚本内容如下： 1234567891011121314151617# -*- coding: utf-8 -*-import osimport shutilimport oss2access_key_id = os.getenv('OSS_TEST_ACCESS_KEY_ID', '这里填写ak')access_key_secret = os.getenv('OSS_TEST_ACCESS_KEY_SECRET', '这里填写sk')bucket_name = os.getenv('OSS_TEST_BUCKET', '这里填写bucket名称')endpoint = os.getenv('OSS_TEST_ENDPOINT', '这里填写内网end-point')# 确认上面的参数都填写正确了for param in (access_key_id, access_key_secret, bucket_name, endpoint): assert '&lt;' not in param, '请设置参数：' + param# 创建Bucket对象，所有Object相关的接口都可以通过Bucket对象来进行bucket = oss2.Bucket(oss2.Auth(access_key_id, access_key_secret), endpoint, bucket_name)bucket.put_object_from_file('上传到OSS的图片名称.png', '/服务器保存路径/图片名称.png') 将图片作为内容发邮件的脚本整个脚本内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#!/usr/bin/env python# -*- coding: UTF-8 -*-import os,time,re,smtplib,loggingfrom email.mime.text import MIMETextfrom email.header import Headerdef send_mail(to_list, cc_list, html, sub): me = mail_user msg = MIMEText(html, _subtype='html', _charset='utf-8') # 格式化邮件内容为html，编码为utf-8 msg['Subject'] = sub # 邮件主题 msg['From'] = me # 发件人 msg['To'] = \";\".join(to_list) # 收件人，将列表转换为字符串 msg['Cc'] = \";\".join(cc_list) # 抄送人，将列表转换为字符串 try: send_smtp = smtplib.SMTP() # 实例化 send_smtp.connect(mail_host) # 连接smtp服务器 send_smtp.login(mail_user, mail_pass) # 使用定义的账号密码进行登录 send_smtp.sendmail(me, to_list+cc_list, msg.as_string()) # 发送邮件 send_smtp.close() # 关闭连接 return True except Exception, e: logging.basicConfig(filename='logger.log', level=logging.DEBUG) logging.debug(e) print (\"ERROR!!!!\") return Falseif __name__ == '__main__': mail_host = 'mail.dahuatech.com' mail_user = '这里填写发件人地址' mail_pass = '填写对应的密码' mailto_list = ['收件人邮箱地址'] mailcc_list = ['抄送人1的邮箱地址'，'抄送人2的邮箱地址'] html = \"\"\" &lt;body&gt; &lt;br&gt;&lt;img src=\"这里填写的是图片的http地址\"&gt;&lt;/br&gt; &lt;table color=\"CCCC33\" width=\"800\" border=\"1\" cellspacing=\"0\" cellpadding=\"5\" text-align=\"center\"&gt; &lt;tr&gt; &lt;td test-align=\"center\"&gt;上图是阿里云深圳VPC区数据同步过去24小时的情况。&lt;br /&gt; 注意事项 1:dts的延迟时间是5秒计算一次，api请求会取到最新的延迟时间，而控制台是每隔20秒才刷新一次； 注意事项 2:api在延迟时间取值为整数，即1.x显示为2，请知悉; 注意事项 3:此邮件是系统自动发出，如果有任何疑问请联系运维人员； &lt;/tr&gt;&lt;/br&gt; &lt;/table&gt; &lt;/body&gt; \"\"\" sub = \"阿里云深圳VPC数据同步情况\" if send_mail(mailto_list,mailcc_list,html,sub): logging.debug(\"Send mail succed!\") else: logging.debug(\"Send mail failed\") 上面四个脚本整个执行下来，效果如下，至此大功告成！ 参考资料https://github.com/aliyun/aliyun-oss-python-sdk/blob/master/examples/object_basic.pyhttps://hk.saowen.com/a/fe355cb5cc3ab17dbc84e9489621d2ab31da72b511092839832bc9e89d63bf71http://blog.csdn.net/baoli1008/article/details/47980779https://www.digglife.net/articles/html-mail-with-inline-images-python-perl.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"一个监控挂载盘的python脚本","slug":"一个监控挂载盘的python脚本","date":"2018-02-27T15:08:09.000Z","updated":"2018-02-27T15:19:50.000Z","comments":true,"path":"2018/02/27/一个监控挂载盘的python脚本/","link":"","permalink":"http://yoursite.com/2018/02/27/一个监控挂载盘的python脚本/","excerpt":"","text":"前言公司产品线有一个公用的挂载盘，主要是用来方便各位开发人员去放置他们自己的一些工作材料，比如异常的日志或者tcpdump的抓包等等杂七杂八的东西，但是这个挂载盘由于使用人众多，容量自然要有监控，于是就有了写这个脚本的动机。 在这里我写了两个脚本，上面这个是用来监控磁盘容量，然后通过df -h的排序生成前十名占容量最大的文件夹，把这个文件夹的名字和对应的大小重定向到一个叫alarm.txt这个文件里，这个文件就是邮件正文。然后在确定他们的主人，统一加上公司邮箱后缀来得到他们主人的邮箱地址，最后对应他们各自的邮箱地址用下面那个脚本来发送文件夹容量过高的邮件。 监控挂载盘的脚本12345678910111213141516171819202122232425262728293031323334353637383940414243#!/usr/bin/env python# coding=utf-8import osimport AutoMailimport commands#设定变量判断是否挂载和挂载盘的容量mount = commands.getoutput(\"mount | grep ':.*nfs'|wc -l\")size = commands.getoutput(\"df -h | grep share | awk '&#123;print $5&#125;' | cut -d '%' -f 1\") ##建立发邮件的文本文件def Createalarm(): if os.path.exists('/root/chenscript/alarm.txt') == True: os.system(\"python /root/chenscript/weixin_sharealarm.py\") print (\"微信告警已经发送！\") os.system(\"cd /root/chenscript; echo 'share盘容量大于80%，现在将调出容量排名前十位的文件夹名字及对应的容量，请各位处理一下不需要的文件！' &gt;/root/chenscript/alarm.txt\") os.system(\"cd /挂载盘名称 ;du -s * --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹'|sort -nr |head &gt;&gt;/root/chenscript/alarm.txt\") os.system(\"echo '\\n' &gt;&gt; /root/chenscript/alarm.txt\") if os.path.exists('/root/chenscript/alarm.txt') == False: os.system(\"cd /root/chenscript;touch alarm.txt\")def Sendmail(): fp = open('/root/chenscript/alarm.txt', 'r') content = fp.read() AutoMail.send_mail('share挂载盘容量大于80%！收到邮件的各位请整理自己对应的文件夹！', content) #将邮件的文件刷新def Dellist(): os.system(\"cd /root/chenscript/;rm -f alarm.txt;touch alarm.txt\")if mount == '1' and size &gt;= '80': print (\"挂载盘存在！\") print (\"share盘容量大于80%...\") Createlist() Sendmail() Dellist()elif mount == '1' and size &lt; '80': print (\"挂载盘存在！\") print (\"share盘容量正常...\")else: print (\"挂载盘不存在，现在重新挂载...\") os.system(\"mount -t nfs -o acl,rw,intr,soft,nolock,rsize=8192,wsize=8192 10.160.43.172:/share /share \") 发送告警邮件脚本1234567891011121314151617181920212223242526272829303132333435363738394041424344#!/usr/bin/env python#coding=utf-8#这个脚本的用途是用来发送邮件import smtplibfrom email.mime.multipart import MIMEMultipartfrom email.mime.text import MIMETextfrom email.mime.application import MIMEApplicationmailto_list=[] #这里为空list，会从list.txt里一行一行的当做元素添加进来#生成list.txtif os.path.exists('/root/chenscript/list.txt') == True: os.system(\"cd /挂载盘名称;du -s * --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹' --exclude='不想要计算在内的文件夹'|sort -nr |head|awk \\'&#123;print $2\\\"@dahuatech.com\\\"&#125;\\' &gt;&gt;/root/chenscript/list.txt\")if os.path.exists('/root/chenscript/list.txt') == False: os.system(\"cd /root/chenscript/;rm -f list.txt;echo '本人的邮箱地址'&gt;list.txt\")with open('/root/chenscript/list.txt','r') as f: f=f.readlines()for i in f: i=i.strip('\\n') mailto_list.append(i)mail_host=\"这里填写邮箱主机\"mail_user=\"这里填写发送人的邮箱地址\"mail_pass=\"发送人的邮箱密码\"mail_postfix=\"dahuatech.com\"mail_sender=\"与mail_host内容相同\"def send_mail(sub, content): me=mail_sender msg = MIMEMultipart() msg['Subject'] = sub msg['From'] = me msg['To'] = \";\".join(mailto_list) content1 = MIMEText(str(content), 'plain', 'utf-8') msg.attach(content1) try: s = smtplib.SMTP() s.connect(mail_host) s.login(mail_user,mail_pass) s.sendmail(me, mailto_list, msg.as_string()) print('发送成功！\\n') s.close() except Exception as e: print(str(e))os.system(\"cd /root/chenscript/;rm -f list.txt;echo '我本人的邮件地址'&gt;list.txt\") 执行的效果如下： 隐藏的知识点1）du -s是按照字节来统计，--exclude=&#39;yunwei&#39;是在排序的时候忽略掉yunwei这个文件夹，容后再用sort -nr|head是得到从大到小前10名，如果得到后10名就是sort -nr|tail；2）如果使用的是import commands，那么commands.getoutput得到的是字符串！3）用mount | grep &#39;:.*nfs&#39;来判断挂载盘是否存在是一个很简单的方式，如果挂了多个，就用ip in的方式来进一步判断；4）python要一行一行的读取文件，就readline；5）python按行读取文件，去掉换行符\\n的方法： 12for line in file.readlines(): line=line.strip('\\n') 6）import Automail的时候，就已经把Automail.py这个脚本固定住了，这时候mailto_list已经不能变化了，所以要把添加list.txt放到这个脚本里。 发了邮件，连吼带骂一顿，终于把share盘容量下降到了69这样一个美妙的数字…","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"使用matplotlib画图的一个脚本","slug":"使用matplotlib画图的一个脚本","date":"2018-02-27T10:50:24.000Z","updated":"2018-02-27T13:33:20.000Z","comments":true,"path":"2018/02/27/使用matplotlib画图的一个脚本/","link":"","permalink":"http://yoursite.com/2018/02/27/使用matplotlib画图的一个脚本/","excerpt":"","text":"准备工作之前在https://rorschachchan.github.io/2018/02/24/阿里云获取DTS服务延迟的脚本/ 里已经可以获取到阿里云DTS服务的延迟时长和同步速率。下一步就是把这些值以24小时为周期作一个图像，然后每天在固定时间发送到领导们的邮件里。 python作图的第三方工具叫matplotlib，安装步骤如下： 1234pip install matplotlib #画图模块pip install numpy #依赖的库pip install scipy #又一个依赖的库yum install -y Tkinter #如果是python3，那么就是yum install -y tkinter 脚本内容由于我是在centos 7里进行脚本操作，而linux服务器有没有安装图像，所以在执行import matplotlib.pyplot as plt的时候可能会爆错：RuntimeError: could not open display，这个时候需要在前面改成如下样式（注意先后顺序）： 123import matplotlib as mplmpl.use('Agg')import matplotlib.pyplot as plt 举一个简单的脚本例子如下，就是给予（x,y）然后连成曲线图的效果，脚本里数字的部分不加引号也是可以识别的，当然使用变量也可以。 12345678910111213141516171819202122232425262728293031323334353637383940414243#!/usr/bin/env python# -*- coding: utf-8 -*-import matplotlib as mplmpl.use('Agg') import matplotlib.pyplot as pltimport numpy as np import pylab as pl x=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24]#横坐标的内容labels=['10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','1','2','3','4','5','6','7','8','9']a = '1'b = '2'c = '3'd = '4'#y1是延迟y1=['2','3','5','4','2','1','2','2','3','5','4','2','1','2','2','3','5','4','2','1','2','2','3','5']#y2是同步速率y2=[a,b,c,d,0.13,0.12,0.14,0.14,0.14,0.16,0.15,0.13,0.12,0.14,0.14,0.14,0.16,0.15,0.13,0.12,0.14,0.22,0.18,0.11]#输入对应的坐标，后面是颜色plot1,=pl.plot(x,y1,'r') #这里是有逗号的，用于参数解包plot2,=pl.plot(x,y2,'b') pl.xticks(x,labels)#图片的标题以及对应的字号大小pl.title('The DTS status of Shenzhen VPC',size=20)#X轴的标题和字号大小pl.xlabel('Time', size=14)#Y轴的标题，字号大小和长度pl.xlabel('Time', size=14)pl.ylim(0.0,5.0)#曲线对应注释pl.legend([plot1,plot2],('Delay','Sync rate'),'best',numpoints=1)#图片保存路径plt.savefig('/tmp/dts.png', format='png') 脚本执行效果之后，会在对应的路径里生成一个图片文件，然后把这个图片转移到windows，打开就看到效果了，如图： 这个图是全英文的，如果是中文的话，就会出现乱码，研究了半天也没搞明白，这一点让我很郁闷。 参考资料http://python.jobbole.com/81182/https://absentm.github.io/2017/03/18/Python-matplotlib-数据可视化/https://liam0205.me/2014/09/11/matplotlib-tutorial-zh-cn/https://morvanzhou.github.io/tutorials/data-manipulation/plt/1-1-why/https://www.lookfor404.com/%E8%BF%90%E8%A1%8Cggplot%E5%87%BA%E7%8E%B0%E9%97%AE%E9%A2%98no-display-name-and-no-display-environment-variable/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"解决https证书在赛门铁克认证失败的问题","slug":"解决https证书在赛门铁克认证失败的问题","date":"2018-02-26T14:40:03.000Z","updated":"2018-02-27T06:58:00.000Z","comments":true,"path":"2018/02/26/解决https证书在赛门铁克认证失败的问题/","link":"","permalink":"http://yoursite.com/2018/02/26/解决https证书在赛门铁克认证失败的问题/","excerpt":"","text":"问题描述今天电子商城的市场接到一个故障，说更换了.lechange.com的https证书（原有的证书到期了，新买了一个依旧还是.lehcange.com域名证书）之后，订单在支付宝支付的时候提示支付失败。我把request id提供给支付宝的客服请他们查看一下后台，支付宝客服说我们电商的https证书没有认证成功。于是我就登陆https://cryptoreport.websecurity.symantec.com/checker/ 去检查一下电商的域名，果不其然，赛门铁克的反馈是错误的，如图： 但是登陆网站，在浏览器里却显示https证书是OK的，如图： 然后我用symantec的那个网站测试了一下电商平台开发环境的域名，发现也是OK的，如图： 这就郁闷了，到底哪里出问题了？ 问题排查首先跟研发确认，开发环境与线上环境在涉及到证书的代码是否一致，得到研发的确认之后。就检查服务器里的nginx，发现服务器nginx的配置文件里是没有涉及到ssl，无论是开发环境和线上环境都是通过阿里云slb配置的https证书。而且两者的证书指纹一模一样，如图： 既然都是用的一样的证书，为啥一个检验通过，另一个检验不通过呢？这个时候我想到线上环境与开发环境唯一的不同就是线上环境多了一个cdn，于是就登陆到cdn的控制页面，找到对应的https证书，发现cdn的https证书指纹也是跟上面的指纹一样，如图： 既然指纹一样，那证书也应该是一样的，场面又进入了一个僵局。 于是我就到一台服务器里使用curl -vv https://www.lechange.com，看到的结果如下： 提示未配置签发者根证书，我这时候想起来了，首先证书指纹一致不能说明证书是完全一致的，只能说明key文件是一样的！其次这个https证书是中级机构证书，那么中级机构颁发的证书链规则是这样的： 12345678-----BEGIN CERTIFICATE----------END CERTIFICATE----------BEGIN CERTIFICATE----------END CERTIFICATE----- 那么我怀疑就是https证书链那部分可能在cdn配置错误了，或许在slb配置错误了，甚至两个都配置错误了！ 于是干脆删除掉线上电商原有的https证书，重新导入cdn和slb的https证书，返回到symantec刷新，这次的检验结果就OK了。 补充虽然这个问题解决了，但是我还是不明白，为什么在网页端查看证书是绿色OK的呢？在sf.gg上提问之后，一个叫Avro的朋友是这么回答我的： 以chrome为例，他信任了[所在平台的信任证书列表][1]，而这些平台集成了一系列信任的根证书，如iOS 11 中可用的受信任根证书列表可以找到你的根证书“04 00 00 00 00 01 15 4B 5A C3 94 ”(序列号)，因此验证过程中没有问题，而对于其他的工具，如果未使用这些平台根证书信任列表依然需要完整的证书链（这个证书链在ssl握手过程中被下发）进行校验。 参考资料https://openclub.alipay.com/read.php?tid=3451&amp;fid=57&amp;page=1https://www.jianshu.com/p/84af353f43c5https://help.aliyun.com/knowledge_detail/39468.html?spm=a2c4g.11186631.2.2.w2qcWT","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"https证书","slug":"https证书","permalink":"http://yoursite.com/tags/https证书/"}]},{"title":"记录Apache Storm的部署始末","slug":"记录Apache-Storm的部署始末","date":"2018-02-25T13:27:42.000Z","updated":"2018-02-25T13:56:08.000Z","comments":true,"path":"2018/02/25/记录Apache-Storm的部署始末/","link":"","permalink":"http://yoursite.com/2018/02/25/记录Apache-Storm的部署始末/","excerpt":"","text":"前言Storm是一个流式处理框架（你可以把它当成一种消息队列），开发人员开发出特定的项目，然后通过storm这个渠道下发各种任务，从而达到任务执行的效果。 Storm有两个比较重要的组件：nimbus和supervision，其中nimbus主要是承接任务和分配任务用，而每一个supervision可以有若干worker（视服务器硬件而定），而supervison的主要任务就是监控对应的worker，一旦worker死了，supervision就会把他们唤醒。 本次试验是用的是金山云服务器，storm的版本是1.0.2，配置是1个nimbus，三个supervision，每一个worker上只执行一个任务，总共三个任务。 准备工作安装storm之前需要在storm里新安装一套zookeeper，因为storm是需要一个zk集群的，nimbus和每一个supervisior是通过zk的心跳来传递存活的信息，于是我们就在每一个supervision里面安装一个zookeeper，并且启动zookeeper的server端，安装zookeeper的方法可以移步http://chenx1242.blog.51cto.com/10430133/1889715 。 上面这段话用图来说就是这样子： 启动zookeeper之后，就需要在nimbus和supervisior里安装storm，上面说过本次安装的storm是1.0.2版本，路径直接是/storm/apache-storm-1.0.2。 将storm安装完之后，需要在nimbus和supervisior里更改/etc/hosts文件，改成如下的格式： 1234567891011127.0.0.1 localhost nimbus的内网IP online-nimbus-001supervision1的内网IP supervision-001supervision2的内网IP supervision-002supervision3的内网IP supervision-003 zookeeper的内网IP zookeeper的名称 #注意，这里的zk是给模块拉取配置的zkstorm的zk1的内网IP storm的zk1 #这里的zk就是给storm集群用的zkstorm的zk2的内网IP storm的zk2 #如果storm的zk是standalone模式，这里就不要写了。storm的zk3的内网IP storm的zk3 #如果storm的zk是standalone模式，这里就不要写了。 保存完/etc/hosts之后，还有一个比较重要的步骤，就是在/etc/ld.so.conf.d/这个路径里面建立一个ffmped.conf这个文件，文件的内容如下： 12/storm/apache-storm-1.0.2/lib/storm/apache-storm-1.0.2/lib/3rd 注意，/storm/apache-storm-1.0.2是我的storm路径，在实际情况下需要根据自己的路径进行更改。 把这个ffmped.conf建立成功之后，我们可以测试一下，如果输入ldconfig的话，会出现如下的内容，就证明达到了我们的效果： storm本身的bin目录夹里也有很多命令可以直接使用，为了调用storm list方便，我们需要把bin/storm这个可执行文件作一个软连接，方法就是先cd /usr/local/bin/，然后ln -s /storm/apache-storm-1.0.2/bin/storm storm。这样的话，我们就可以直接使用storm list来查看任务列表了。 Storm的具体配置安装了storm，调整了命令行，同时也搞定了ffmpeg.conf，下面就是调整storm的配置文件了，nimbus和supervisior都要修改。 storm的配置文件叫storm.yaml，路径位于storm文件夹下的/conf/文件夹，我们需要在这个文件里面输入如下的内容： 下面对配置文件作一个简单的解释：1）storm.zookeeper.port:zk的默认端口2181；2）storm.cluster.mode:storm的集群运行模式，这里我们也是采用默认的distributed（分布式）；3）storm.local.dir:storm使用的本地文件的目录，这个目录必须存在而且storm进程可读写；4）supervisor.slots.ports：这个地方在nimbus里可以不用管，但是在supervisior里是需要改的，如果你只打开6700，那么就只放开了6700端口，即只有一个worker，如果你打开了6700、6701、6702三个端口，那么就意味这个supervisior将有三个worker在工作，由于这次试验里我们每一个supervisor只开启一个任务，所以在supervisior的storm.yaml里这个节点就只保留6700，其他的就全部注释掉；5）nimbus.task.launch.secs:task启动时的一个特殊超时设置.在启动后第一次心跳前会使用该值来临时替代nimbus.task.timeout.secs；6）worker.childopts:设定每个worker (JVM任务)的最小和最大内存； 更改完了storm.yaml之后，就要在nimbus里面安装zkclient。直接复制粘贴过来就好了。 如果你不喜欢storm自带的日志格式，想更改一下日志的内容，那么就要在/storm/apache-storm-1.0.2/log4j2文件夹里面修改worker.xml，不过在这里善意的提醒，最好在修改之前先备份原有的worker.xml。 连接具体任务这次的实验包用的是我所在的公司开发内部使用的包，先把这个包的内容复制到/storm/文件夹下，同时mkdir install和makir properties这两个文件夹，在install文件夹里有开发写的任务的jar包和启动程序，如下： 而在properties文件夹里，应该有这个任务的配置文件，如下： 由于我们已经事前在/etc/hosts里指定了zkclient需要访问的zk的ip地址了，那么如果zk项配置正确，zkclient这个时候是可以成功启动的。同时在install文件夹里./update_stormserver_config.sh也应该是反应正确的。 然后我们就可以启动storm了。 启动nimbus和supervision启动storm要先启动nimbus，在/storm/apache-storm-1.0.2/bin里面启动run_nimbus.sh，然后等一下会有一大片东西出现，再jps一下就能看到nimbus已经启动了，如图： 从上图我们可以看到，18141的进程就是zkclient，只不过在jps里它名字叫AppServerDaemon，而zkServer在jps里叫QuorumPeerMain。 如果 storm出现Did you specify a valid list of nimbus hosts for config nimbus.seeds?的错误提示，那么就是nimbus没有启动的缘故。 启动了nimbus之后，就可以在supervisor的机器里去效仿着启动supervisor，但是这里要注意，如果你开启了一个supervisior，那么按照我们上面的配置文件，就启动了一个6700端口的worker，这个时候在nimbus执行下派一个任务的命令，nimbus就会下派这个任务给这个worker。 下派命令的例子如下： 1storm jar storm-starter-0.9.2-incubating-jar-with-dependencies.jar com.lechange.recordshare.RecordShareTopology 1 这样就启动了一个叫videoshare的任务，这个任务只用1个worker。 如果在命令行里反馈这样的错误： 1Error: Could not find or load main class storm.starter.recordshare.RecordShareTopology 或者exception in thread main java.lang.NoClassDefFoundError这样的错误，那就要检查jar包和路径。 而如果你再打开一个supervisor，在nimbus端又下发了一个任务，那么这个任务就会给刚刚新启动的supervisor。这样，启动一个下发一个，就会对每一个worker具体干的任务情况有一个比较清晰的了解。 在nimbus上执行storm list，就可以获得上图的样子，可以看出，我在nimbus端下发了三个任务，就是topology_name这一栏，他们的状态也是active，而workers数量都是1，也就是说在那三台supervisor里都在工作。而跑到supervisor一看日志，也是对应有各自的任务日志。 至此整个storm和具体的模块工作的搭建就完成了。 补充如果你事前一口气把三个supervisor都打开了，即开启了3个worker，然后一口气在nimbus端，一口气输入了三个下发任务的命令，那么这三个命令会随机的到这三个worker里，没有任何顺序而言，你只能通过日志的关键词来判断具体的worker做哪些任务。 而如果你的worker数量少于nimbus下发任务的数量，会有什么反应呢？ 答案就是任务根本没有worker去干，在storm list里，多余的任务对应的num_workers的数字是0，而如果这个时候你新增一个supervisor到这个storm集群，那么这个任务就会吭哧吭哧开始工作了。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"大数据分析","slug":"大数据分析","permalink":"http://yoursite.com/tags/大数据分析/"},{"name":"storm","slug":"storm","permalink":"http://yoursite.com/tags/storm/"}]},{"title":"DockerFile创建一个nginx容器的全过程","slug":"DockerFile创建一个nginx容器的全过程","date":"2018-02-25T11:54:34.000Z","updated":"2018-08-03T02:21:16.000Z","comments":true,"path":"2018/02/25/DockerFile创建一个nginx容器的全过程/","link":"","permalink":"http://yoursite.com/2018/02/25/DockerFile创建一个nginx容器的全过程/","excerpt":"","text":"创建容器首先，随便建立一个文件夹，比如先mkdir sample，然后我在这个sample文件夹里建立一个Dockerfile，内容如下： 12345678FROM ubuntu:14.04MAINTAINER Chris Chan \"chenx1242@163.com\"ENV REFRESHED_AT 2016-12-05RUN apt-get -y update &amp;&amp; apt-get install -y nginxRUN mkdir -p /var/www/html/websiteADD nginx/global.conf /etc/nginx/conf.d/ADD nginx/nginx.conf /etc/nginx/nginx.confEXPOSE 80 从这个Dockfile里面看出：我们使用了ubuntu的基础镜像，然后下载了nginx，同时建立一个/var/www/html/website文件夹，然后又拷贝了宿主机上的两个文件，一个是global.conf，另一个是nginx.conf，这两个文件需要我们自己写。于是我们就要在sample下再建立一个叫nginx的文件夹，里面写上这两个文件，其中global.conf的内容如下： 12345678server &#123; listen 0.0.0.0:80; server_name _; root /var/www/html/website; index index.html index.htm; access_log /var/log/nginx/default_access.log; error_log /var/log/nginx/default_error.log;&#125; 而nginx.conf的内容如下： 123456789101112131415161718user www-data;worker_processes 4;pid /run/nginx.pid;events &#123; &#125;http &#123; sendfile on; tcp_nopush on; tcp_nodelay on; keepalive_timeout 65; types_hash_max_size 2048; include /etc/nginx/mime.types; default_type application/octet-stream; access_log /var/log/nginx/access.log; error_log /var/log/nginx/error.log; gzip on; gzip_disable \"msie6\"; include /etc/nginx/conf.d/*.conf;&#125; 全部搞定之后，我们就来build这个镜像，比如这个镜像名叫做chentest/nginx001，在sample文件夹里使用的命令语句就是：docker build -t=&#39;chentest/nginx001&#39; .。 一顿七七八八之后，显示OK，docker ps -a就会显示我们新建的镜像，如图： 有了镜像，再在sample文件夹里新增一个文件夹，比如就叫webiste，里面有一个文件叫index.html。而index.html的内容如下： 1this is a nginxtest page. 保存退出之后，返回到sample目录。 现在我们可以制作一个容器了，制作容器命令是docker run -d -p 8080:80 --name test02 -v $PWD/website:/var/www/html/website chentest/nginx001 nginx -g &quot;daemon off;&quot;,这句话里规定容器的8080端口映射到宿主机的80端口，同时引入了当前目录的website目录到容器的/var/www/html/website目录，nginx也默认在前台进程进行。执行之后，docker ps -a看一下： 看见port这一栏已经显示8080与80端口的相勾结成功，于是我们可以登录这台机器的80端口看一下。 而如果现在我更改一下上面的index.html，改成另外一句话。比如说改成“why so serious??”,保存文件之后，直接刷新网页，就会看到网页的内容已经发生了变化，如图： 可见引入-v这个命令在容器里，可以随时调试内容，而不是每次都要重新打包生成镜像。这一点再调试阶段为我们提供了很大的方便。 docker端口映射的问题docker run命令里指定端口的格式是-p 容器端口:宿主机端口。如果想要随机指定就是大写的P。如图： 这里就是随机分配了一个32775端口给宿主机，访问的时候也是要访问这个32775端口。 有时候port这里却不显示端口映射的情况，如图： 这个情况是因为这个容器的status是exited，docker会在容器主进程结束后自动终止容器运行，而nginx启动后就会在后台运行，docker以为nginx已经结束运行了，所以就会停止容器。 源码安装nginx如何开机自启动切换到/lib/systemd/system/目录，创建nginx.service文件,文件内容如下： 12345678910111213[Unit]Description=nginx After=network.target [Service] Type=forking ExecStart=/usr/local/nginx/sbin/nginxExecReload=/usr/local/nginx/sbin/nginx reloadExecStop=/usr/local/nginx/sbin/nginx quitPrivateTmp=true [Install] WantedBy=multi-user.target 退出并保存文件，执行systemctl enable nginx.service使nginx开机启动，systemctl restart nginx.service重启nginx。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"DockerFile创建一个redis容器的全过程","slug":"DockerFile创建一个redis容器的全过程","date":"2018-02-25T11:36:46.000Z","updated":"2018-02-25T11:47:16.000Z","comments":true,"path":"2018/02/25/DockerFile创建一个redis容器的全过程/","link":"","permalink":"http://yoursite.com/2018/02/25/DockerFile创建一个redis容器的全过程/","excerpt":"","text":"正文本次目标是用Centos 7的基础镜像做一个redis容器供开发人员在开发环境里蹂躏。 首先，创建一个叫redis-test的文件夹，在这个redis-test文件夹里建立一个Dockerfile，内容如下： 1234567FROM centos:latestMAINTAINER Chris Chan \"chenx1242@163.com\"ENV REFRESHED_AT 2017-02-16RUN yum -y update &amp;&amp; yum -y install epel-release &amp;&amp; yum -y install redis &amp;&amp; yum -y install net-toolsEXPOSE 6379ENTRYPOINT [ \"/usr/bin/redis-server\" ]CMD [] 这里我们简单说一下整个Dockerfile的内容： 首先选择了基础镜像是centos的最新版，即centos 7，然后填写作者信息； 在yum这一块要注意，如果没有安装epel-release的话，是无法正常安装redis的，这是centos与ubuntu不一样的地方。至于后面又补充安装了net-tools是因为centos 7里不自带ifconfig命令，所以需要安装一下net-tools，这样就有了ifconfig了； 随即我们又开放了6379端口； 然后就是entrypoint和cmd，这两个命令的区别很重要，具体区别请看：http://cloud.51cto.com/art/201411/457338.htm 这篇文章。 然后我们就可以依照这个Dockfile去建立一个镜像，因为目的是要在“centos环境下建立一个redis”，那么我们这个镜像的名字就叫作lccentos/redis，具体操作就是在redis-test文件夹下执行docker build -t lccentos/redis .。 然后根据这个镜像需要制作一个容器，容器的名字就叫redisforcentos，那么命令就是：docker run -d -p 6379 --name redisforcentos lccentos/redis。 然后我们docker ps -a看一下效果，如下： 可见宿主机的32774端口和容器的6379端口“融为一体”，这个时候，我们测试一下这个redisforcentos的容器是否已经正常启动了redis，如图： 而且对于Docker来说，可以多个docker对应宿主机的同一个端口，比如我这台机器搞了两个redis，两个容器都可以指向6379的端口，如图： Dockerfile的优化原则1）ADD和VOLUME应该放在Dockerfile底部，因为它们相对比yum安装那些变化的更勤；2）EXPOSE可以一口气对应多个端口，比如EXPOSE 80 2003 2004 7002的效果跟下面的效果一样； 1234EXPOSE 80 EXPOSE 2003 EXPOSE 2004 EXPOSE 7002 3）ADD的操作应该放在Dockerfile的最下面； 参考资料http://dockone.io/article/255?spm=5176.100239.blogcont40494.25.8RXqDX","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"}]},{"title":"阿里云获取DTS服务延迟值的脚本","slug":"阿里云获取DTS服务延迟的脚本","date":"2018-02-24T08:49:31.000Z","updated":"2018-03-05T16:42:56.000Z","comments":true,"path":"2018/02/24/阿里云获取DTS服务延迟的脚本/","link":"","permalink":"http://yoursite.com/2018/02/24/阿里云获取DTS服务延迟的脚本/","excerpt":"","text":"正文春节“嗖”的一下就过完了，在年前领导交代另一个任务，想要每天统计一下在阿里云DTS（数据同步）服务的延迟情况，于是我就要使用阿里云的api去写一个脚本，每小时运行一次，然后将这24个数字输出出来给领导过目。 阿里云dts的sdk包在这里：https://help.aliyun.com/document_detail/57694.html?spm=a2c4g.11186623.6.675.W811bN ，直接点击Python下载即可，不过这个地址经我测试使用非国内IP 地址是打不开的，需要使用国内IP地址下载。 下载完毕之后，上传到linux服务器并解压，解压后的样子如图： 由于我们这次只是查看同步作业状态，所用的py就是DescribeSynchronizationJobStatusRequest.py，现在我们就可以写脚本，假设这个脚本叫getDTS.py,那么整个内容如下： 12345678910111213141516171819202122232425262728#!/usr/bin/env python#coding=utf-8#auther:ChrisChan@2018-2-24#这个脚本是用来获取DTS服务的延迟值from aliyunsdkcore import clientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionimport jsonimport sys #由于这个包不是通过pip install的方式安装,要调用其它路径的python脚本就要使用sys方法sys.path.append('sdk压缩包的绝对路径')import DescribeSynchronizationJobStatusRequest # 创建Client实例clt = client.AcsClient('阿里云AK','阿里云SK','所属地域')# 创建request并设置参数request = DescribeSynchronizationJobStatusRequest.DescribeSynchronizationJobStatusRequest()request.set_accept_format('json')# 写上对应的服务IDrequest.set_SynchronizationJobId(\"这里写上DTS的ID\")response = clt.do_action_with_exception(request)print responsedelay = json.loads(response)print \"====================================================\"print \"当前延迟是：\" + str(delay[\"DataSynchronizationStatus\"][\"Delay\"])print \"当前同步速度是：\" + str(delay[\"Performance\"][\"FLOW\"]) 整个脚本执行的效果如下： dts的延迟时间是5秒计算一次，API请求会取到最新的延迟时间，控制台是每隔20秒才刷新一次。 补充getDTS.py这个脚本获取到的response是一个str字符串，这里我使用json.loads来将其转化成了dict模式。但是除了这个方法还有两个方法： 123456789101112&gt;&gt;&gt; user\"&#123;'name' : 'jim', 'sex' : 'male', 'age': 18&#125;\"&gt;&gt;&gt; b=eval(user)&gt;&gt;&gt; b&#123;'age': 18, 'name': 'jim', 'sex': 'male'&#125;&gt;&gt;&gt; print b['sex']male&gt;&gt;&gt; exec(\"c=\"+user)&gt;&gt;&gt; c&#123;'age': 18, 'name': 'jim', 'sex': 'male'&#125; &gt;&gt;&gt; print c['name']jim 但是要注意！上面这两个方法有一定的安全隐患，而且只能全是字符串可用，如果有的value是True、False、Null这样的字眼的话，eval是不支持的，所以没法正确转换，就会爆这样的错：NameError: name &#39;True&#39; is not defined。 参考资料https://help.aliyun.com/document_detail/49453.html?spm=a2c4g.11186623.6.667.sRyVqYhttps://segmentfault.com/q/1010000000174694https://www.crifan.com/resolved_in_python_using_eval_to_force_variable_to_convert_a_string_to_a_dictionary_when_the_error_nameerror_name_39null39_is_not_defined/https://segmentfault.com/q/1010000000345915","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"阿里云","slug":"阿里云","permalink":"http://yoursite.com/tags/阿里云/"}]},{"title":"Atlas的几种常见故障解决方法","slug":"Atlas的几种常见故障解决方法","date":"2018-02-23T13:39:43.000Z","updated":"2018-07-12T06:53:20.000Z","comments":true,"path":"2018/02/23/Atlas的几种常见故障解决方法/","link":"","permalink":"http://yoursite.com/2018/02/23/Atlas的几种常见故障解决方法/","excerpt":"","text":"使用atlas却发现“读库闲置，框架还是去主库读写数据”配置完atlas之后，发现使用jdbc框架的话，读库和写库各司其职，但是使用mybatis框架之后，就发现框架的读写都去了主库，把读库放置一边，那么这种情况是因为有事务存在的话，atlas就会强制走主库，遇到这种情况就检查一下是否有事务的存在，比如@Transactional，如果要解决的话，就加上@Transactional(propagation=Propagation.NOT_SUPPORTED)即可。 自动读写分离挺好，但有时候我写完马上就想读，万一主从同步延迟怎么办?SQL语句前增加 /*master*/ 就可以将读请求强制发往主库。在mysql命令行测试该功能时，需要加-c选项，以防mysql客户端过滤掉注释信息。不过这不能从本质上解决问题，使用Atlas需要考虑到这点，提高主机的IO性能，加大memory可以缓解延迟症状，但依旧不能避免延迟的出现，尤其是读多写少的应用。 resource limit的问题atlas有自己的连接池，会吃掉很多CPU, php应用端改用短链接来连接atlas, 这时候atlas对php发送来的sql只负责验证和转发的操作，后端DB的连接由atlas自己管理,未使用的连接线程进行剔除操作(DB的wait_timeout和interactive_timeout设置为300s,超时亦退出)。 1234562014-04-12 20:56:29: (warning) (libevent) event_del: event has no event_base set.2014-04-12 20:56:29: (critical) last message repeated 5 times2014-04-12 20:56:29: (critical) network-conn-pool-lua.c.144: socket() failed: Too many open files (24)2014-04-12 20:56:29: (warning) (libevent) event_del: event has no event_base set.2014-04-12 20:56:30: (debug) chassis-unix-daemon.c:168: 12951 returned: 129512014-04-12 20:56:30: (critical) chassis-unix-daemon.c:196: [angel] PID=12951 died on signal=11 (it used 16 kBytes max) ... waiting 3min before restart 如果MySQL后端的连接数也满了可能会报以下错误: 1232014-11-13 12:21:07: (critical) network_mysqld_proto_password_scramble: assertion `20 == challenge_len' failed2014-11-13 12:21:07: (warning) (libevent) event_del: event has no event_base set.2014-11-13 12:21:07: (critical) 可以临时增加MySQL connection数量: 1echo -n “Max processes=SOFT_LIMIT:HARD_LIMIT” &gt; /proc/`pidof mysqld`/limits 出现Too many open files的错误，怎么办？&gt;关于Too many open files错误，可能由两种情况引起:一、php长连接连接到atlas后，每个线程占用一个FD,直到超出系统资源限制而出现too many错误;二、php应用端发送到atlas的sql过多，大量并发的情况下，linevent维护的队列过多，每个event吃一个FD，超出系统资源限制引起Too many open files错误; 避免Too many open files错误,增加用户的ulimit值加大FD的使用量,可增加系统ulimit资源到 ~/.bash_profile文件或/etc/security/limits.conf文件: 123456# cat .bash_profile # .bash_profile......export PATHulimit -n 16384","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"atlas","slug":"atlas","permalink":"http://yoursite.com/tags/atlas/"},{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"读写分离","slug":"读写分离","permalink":"http://yoursite.com/tags/读写分离/"}]},{"title":"如何手动释放linux内存","slug":"如何手动释放linux内存","date":"2018-02-23T12:57:35.000Z","updated":"2018-02-23T13:13:56.000Z","comments":true,"path":"2018/02/23/如何手动释放linux内存/","link":"","permalink":"http://yoursite.com/2018/02/23/如何手动释放linux内存/","excerpt":"","text":"在生产过程中，一些java模块会比较残忍的吃系统内存，然后如果这个模块写的比较挫，产生的垃圾就会比较多，如果linux系统的内存释放也不会及时，然后恶性循环，最后就把进程卡死，但是服务器是不可以down机的，所以这个时候就需要我们运维出来，手动的释放内存。 首先，我们登陆一台服务器，free -m看一下目前的情况： 然后cat /proc/sys/vm/drop_caches，会看到里面的值是0，0是不释放的意思。 sync,将系统缓存区中的脏数据写入磁盘中，包括已修改的i-node、已延迟的块I/O和读写映射文件。 echo 3 &gt; /proc/sys/vm/drop_caches 为什么这里是3呢？这是因为echo 1的话代表“清理页面缓存”，echo 2的话代表“清理索引节点（inode）链接”，echo 3就是包括上面两者。 sysctl -p,这样不用重启服务器也可以生效。出现下面的一连串文字之后，再free -m看一下： 从112释放到2790，可见效果立竿见影。 上面整个过程的自动化脚本是这样的： 12345678910#!/bin/bash#Author:Chris Chan#E-mail:chen_shuo@dahuatech.comoldmemory=$(free -m|sed -n '2p'|awk '&#123;printf $4&#125;')echo \"开始的空余内存值：\"$oldmemorysyncecho 3 &gt; /proc/sys/vm/drop_cachessysctl -pcorrectmemory=$(free -m|sed -n '2p'|awk '&#123;printf $4&#125;')echo \"释放完后的空余内存值：\"$correctmemory","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"}]},{"title":"回家过年","slug":"回家","date":"2018-02-21T08:08:40.000Z","updated":"2018-02-22T14:07:38.000Z","comments":true,"path":"2018/02/21/回家/","link":"","permalink":"http://yoursite.com/2018/02/21/回家/","excerpt":"","text":"我承认我是一个很恋家的人，但是我在3年之前还不是这样。 我记得我在哈尔滨上大学的时候，虽然坐火车也就一个半小时的时间，但是是“能不回家就不回家”，哪怕自己一个人蹲在寝室也是自由舒服，后来上班，我也是有很长的时间自己独住，只有周末才回去一次。那时候我奶不止一次的批评我“都快成一个客人了”。 真的应了那句传烂了的话“只有失去的才是美好的”，现在我人在杭州，天天忙成狗。最欢喜的事情第一个是涨工资，第二个是发工资，第三个是放假，第四个就是放假回家。当初的我总是忽略家庭的温暖，在家里逗留的时间不长，现在却倍感珍惜回家的机会，唉，那几年真是简单的可笑。 这一次回家过年看到了许许多多亲人：生病的大姨夫的精神状态也好了许多，不过他这次回来又害了一次发烧；小外甥和他那婴儿肥的脸蛋，在《守望先锋》里越死越勇；我那几个弟弟们全都瘦了也更精神了，从我妈和女票看我的眼神里，我觉得我的体重是应该好好管控一下了：体型太腐败。 短短的六天时间，吃完三姨家吃四姨家，吃完老叔家吃小舅家，总之就是带着女票游走于各种亲戚家。中途还抽空跟龙南数据班的几个老同事一起吃了顿“一口猪”，主要也是带我女票看看东北菜，看上去我这几个老同事们都过得很不错，至少几杯酒下去均红光满面，依旧插科打屁、大呼小叫。这次过年唯一可惜的是，没有给四姨夫装上翻墙软件，害得他要继续挠墙忍耐。 我吃我妈的菜已经吃了30年，但是这次过年真正在家里吃饭仅仅只有一顿。我妈烧了虾，做了孜然羊肉，而且煮了酸菜馅饺子。这都是我爱吃的，杭州的确能吃到很多美味，但我妈的手艺却是独一份儿。我跟我爹依旧话不算多，但是关系却比之前好了许多倍。有可能是我现在比以前有了一点进步，让我爸看起来顺眼了一点，这一次回家没有跟我爸单独喝上酒，但是他有几顿喝的很开心。看到他俩这个年过得快乐满足，我这个做儿子的，心底涌起了最大的温暖。 离开家的时候，依旧是箱子沉沉，里面有爸妈装的许多东西，有给我的也有给我女票她妈的，每一个东西都是代表了他们的心思。其实家中长辈身体健康、心情愉悦，就是给我们这些在外的儿女最大的宽慰了。假期就这样结束了，我也马上要踏上回杭州的航班，希望家里所有长辈都平平安安，也希望我今年能够达到自己给自己定下的目标！","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"春节","slug":"春节","permalink":"http://yoursite.com/tags/春节/"},{"name":"心情","slug":"心情","permalink":"http://yoursite.com/tags/心情/"}]},{"title":"中国梦，宪政梦","slug":"中国梦，宪政梦","date":"2018-02-12T17:00:57.000Z","updated":"2018-02-13T04:26:10.000Z","comments":true,"path":"2018/02/13/中国梦，宪政梦/","link":"","permalink":"http://yoursite.com/2018/02/13/中国梦，宪政梦/","excerpt":"","text":"本文原作者：《南方周末》评论部编辑戴志勇 天地之间，时间绽放。 这是我们在2013年的第一次相见，愿你被梦想点亮。 2012年，你守护自己的生活，他们守护自己的工作。守护这份工作，就是在守护他们对生活的梦想。 2012年，庙堂之上发出的宪政强音嗡然回响：”宪法的生命在于实施，宪法的权威也在于实施。”我们期待宪法长出牙齿，宪政早日落地。惟如此，才能成就这个沧桑古国的艰难转型；惟如此，国家与人民，才能重新站立于坚实的大地之上。 今天，已是能够梦想的中国，今天，已是兑现梦想的时代。经历过宪政缺失的”文革”梦魇，我们花费三十多年的时间来逐渐回归常理与常情。从土地联产承包责任制到个体户、乡镇企业到”民企”，稍稍归还国人自主安排生活的权利，我们便创造了繁华城市，收获了满仓粮食。 我们重新体认什么是真，什么是假，是其是，非其非；我们重燃对公义的热爱，对自由的向往。面对暴虐强力，我们双手相握，一起走过艰难时刻，迎接生活转机。 今天，我们终于可以从厚厚的历史尘埃中挺起胸，从琐碎的日常生活中抬起头，重走先辈的宪政长征，重温先辈的伟大梦想。 一百七十多年前，我们开始从天朝上国的迷梦中醒来。先败于英，后败于日。百姓愈加民不聊生，耻感深深刺痛中国士人。保国！保种！由洋务而君宪，由立宪而革命。从器物到制度再至文化，激愤者不惜彻底打倒”孔家店”，决绝地将自己的文明连根拔起。 辛亥革命后，清帝退位，先辈们终于建立了亚洲第一个共和国。但是，一个自由、民主、富强的宪政中国并没有随之而来。 国家内外，战争连连；人群内外，残酷不断。 一度，人们远离仁，远离义，远离天道，远离对自由的坚守。 一度，人们认错为对，指鹿为马，万千生灵生机断绝。 美梦与山河，齐齐破碎。自由与宪政，双双消隐。 度尽人世劫波，深味人性幽暗，我们依然是能做梦的人，有颗能做梦的心。 今天，我们断断不只梦想物质丰盛，更希望性灵充盈；我们断断不只梦想国力能强盛，更希望国民有自尊。新民和新国，救亡与启蒙，谁也离不开谁，谁也不能压倒谁。而宪政便是这一切美梦的根基。 兑现宪政，坚守权利，人人才能心如日月流光溢彩；鳏寡孤独才能感受冬日暖意而非瑟瑟发抖；”城管”与小贩才能谈笑风生；房屋才能成为自己与家人的城堡； 兑现宪政，限权分权，公民们才能大声说出对公权力的批评；每个人才能依内心信仰自由生活；我们才能建成一个自由的强大国家。 兑现宪政大梦，每个人才能做好个人的美梦。而这需要我们就从手边做起，就从守护此时此刻的生活做起，而不要将重任留给子孙。 很多人一直深深懂得这一点，很多人早就努力践行这一点。 不是杰出者才做梦，是善于做梦者才杰出。 你的天赋权利就是可以梦想，并且兑现梦想！ 为你的梦想鼓掌，为这个国家的梦想加油，这就是很多新闻人的梦想，是他们不大不小的野心。他们忠于新闻，更忠于内心。愿你也有个玫瑰色的美梦；自由成就自己，完成天之所赋。 总会梦想人人都可以做一个有尊严的人，不论身居高位，还是街头卖艺； 总会梦想人人内心有爱，即使罪犯也未必穷凶极恶，总有恻隐之心自由闪动； 总会梦想阶层只是引人自由流动的动力，而不再是相互猜忌和仇视的天堑；总会梦想这五千年文明生生不息，为改善人类的现代处境，捧出一掬甘冽清泉…… 兑现这一千一万个梦想，才能抚平这一百多年的刻骨痛楚。 兜兜转转一百七十年，美梦成真何其难！一百七十年后，依然有人渴望良知萌新芽，重温天命之谓性；依然有人坚持要求权利一一落地，政治复归于正，公义自在流淌。 依然有人相信，不管多难，梦想终会落实为宪政良制，风行为敦敦美俗。 先辈们筚路蓝缕，践义成仁。如今，后人承继其志，燃灯前行。 兑现梦想，自然要借鉴前贤智慧，与古人的信仰、习俗和情感和解。儒释道法墨，百家皆是源泉；周汉唐宋明，代代皆有可取。 但这决不是要复古，古人不能给予今天所需的一切。只是不再轻易贬损先辈，平心静气地吸收转进，以让中华文明开新花，结新果。 兑现梦想，自然要吸取世界经验。所以要认真审视希腊民主，罗马法治，借鉴英美宪政，追赶现代科技文明。 但这也不是仅仅作一个西方文明的优等生，西人有西人演进的轨迹，同样未必能直接给予我们今天所需的一切。 我们要站在自己的大地上，与各国人民一起，生活出一种古今相融的新生活，文明出一种中西合璧的新文明。在古今中西的激荡中，要遵循人类共通的价值，也要不惮于做自己的新梦。 称美古人，赞扬邻居，不是因为他们足够完美，而是因为我们熟悉他们眼中洋溢的快乐，心底流淌的自由。 中国人本应就是自由人。中国梦本应就是宪政梦。 宪政之下，才能国家持续强盛，宪政之下，才有人民真正强大。兑现宪政梦想，才能更好地外争国权，维护国家的自由；才能更好地内争民权，维护人民的自由。而国家的自由最终必得落脚于人民的自由，必得落脚于人人可以我口说我心，人人可以用心做美梦。 生而为人，谁能不热爱自由？这自由，不仅是权利针对权力而言，也是宽恕针对报复而言，是般若针对无明而言，是仁爱针对暴虐而言，是有道针对无道而言。 大道之行，天下为公；万物自在，各正性命。这就是古人的梦想，先辈的梦想，也是今天很多人的梦想。 中国梦，自由梦，宪政梦。 万物速朽，但梦想永在。万物诞生，因梦想不灭。梦想就是生生之几，就是当你失败了一百次，那第一百零一次充实你内心的不死之希望。 依然有人倾听你的梦想，期待你敢于做梦。你从苦难中爬起，他们为你加油；你尝尽人世冷暖，他们为你加油；你收获美好生活，他们为你加油……他们别无所资，惟有对梦想的执着；他们别无所长，惟有对真相的追求。 一句真话能比整个世界还重，一个梦想能让生命迸射光芒！","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"中国政治","slug":"中国政治","permalink":"http://yoursite.com/tags/中国政治/"}]},{"title":"关于logrotate的额外补充","slug":"关于logrotate的额外补充","date":"2018-02-12T12:09:27.000Z","updated":"2019-02-15T07:48:16.000Z","comments":true,"path":"2018/02/12/关于logrotate的额外补充/","link":"","permalink":"http://yoursite.com/2018/02/12/关于logrotate的额外补充/","excerpt":"","text":"https://rorschachchan.github.io/2018/02/12/日志文件管理者：Logrotate/ 里面已经简单介绍了logrotate命令，这里还有一些额外补充的东西： 1）查看logrotate对log文件的具体执行情况的语句是cat /var/lib/logrotate.status，效果如图： 2）使用-v或-d参数时，显示log does not need rotating，这是因为logrotate在对status未记录的文件进行转储时，会在status添加一条该文件的记录，并将操作时间设为当天。之后程序再次对此文件进行转储时发现这个文件今天已经操作过，就不再进行相关操作。要是想解决这个问题可以使用-s指定logrotate状态文件； 3）分割日志时报错：error: skipping &quot;/var/log/nginx/test.access.log&quot; because parent directory has insecure permissions (It&#39;s world writable or writable by group which is not &quot;root&quot;) Set &quot;su&quot; directive in config file to tell logrotate which user/group should be used for rotation.这是当前用户不是root，需要添加su root list这个语句到对应的logrotate配置文件里，比如： 123456789101112131415/var/log/nginx/*.log &#123; su root list #第一句添加 daily missingok rotate 52 compress delaycompress notifempty #ifempty create 0640 www-data adm sharedscripts postrotate [ ! -f /var/run/nginx.pid ] || kill -USR1 `cat /var/run/nginx.pid` endscript&#125; 4）如果觉得使用logrotate很麻烦，而当某个文件过大的时候，要实现把该文件压缩并且拆成若干个指定大小的文件，怎么办？ 1tar -zcvf 新文件名.tar.gz 原文件名 | split -b 每个分格包大小 -d -a 1 - 新文件名.tar.gz 比如：tar -zcvf ABC.tar.gz ABC | split -b 4000M -d -a 1 - ABC.tar.gz。这个命令就是把ABC这个文件压缩成ABC.tar.gz，但是如果ABC大于4000M就会切块，切成ABC.tar.gz.0,ABC.tar.gz.1,ABC.tar.gz.2……这个样子。 123//使用split命令，-b 4000M 表示设置每个分割包的大小，单位还是可以k// -d 参数指定生成的分割包后缀为数字的形式//-a x来设定序列的长度(默认值是2)，这里设定序列的长度为1 如果要把这一堆已经切块的文件重新接压缩的命令：cat ABC.tar.gz.* | tar -zxv; 5）如果用kill -HUP来重启一个包含守护进程的进程，比如httpd，一条语句搞定： 1ps -ef | grep httpd | grep -v grep | awk '&#123; print $2; &#125;' | xargs -L 1 sudo kill -HUP 这里面首先用awk获取到httpd的pid进程号，然后把这个进程号传给了xargs，通过-L 1来一次提取一行pid值，然后分批进行kill -HUP;如果想要更改配置而不需停止并重新启动服务，请使用kill -HUP。在对配置文件作必要的更改后，发出该命令以动态更新服务配置。 6）想更多的了解守护进程，参看http://www.cnblogs.com/mickole/p/3188321.html；","categories":[{"name":"技术与工作","slug":"技术与工作","permalink":"http://yoursite.com/categories/技术与工作/"}],"tags":[{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"},{"name":"logrotate","slug":"logrotate","permalink":"http://yoursite.com/tags/logrotate/"}]},{"title":"日志文件管理者：Logrotate","slug":"日志文件管理者：Logrotate","date":"2018-02-12T11:57:18.000Z","updated":"2019-02-15T07:44:36.000Z","comments":true,"path":"2018/02/12/日志文件管理者：Logrotate/","link":"","permalink":"http://yoursite.com/2018/02/12/日志文件管理者：Logrotate/","excerpt":"","text":"前言服务器在服务运行的时候，难免会生成大量日志，一般来说遇到日志过多的情况，就会写一个看门狗：监控磁盘容量的大小，如果磁盘剩余空间小于某个值，就去日志文件夹里把一个月或者几个月之前的废弃日志删除掉以达到释放磁盘空间的目的。 但是往往有的时候过期的日志很重要，或者即使是一周的时间内，也会生成容量非常可观的日志，那么就需要使用logrotate命令来管理这些日志，这个命令是linux自带的。 logrotate这个命令的用法请看：https://linux.cn/article-8227-1-rel.html和https://linux.cn/article-4126-1.html 。 实验开始首先，假设服务器里某个日志文件夹里的日志auc.log.10是这样的： 然后在logrotate的配置文件是这么写的： 12345678/mnt/hswx/auc/logs/auc.log.10 &#123; 这里是目标日志的绝对路径 daily 每天执行一次 minsize 200M 文件容量大于200M开始处理，如果到了时间但是没有大于200M，不会处理 compress 压缩 dateext 文件会以日期为后缀 create 777 root root 新建的那个日志文件属性是777 rotate 2 保留最多2个文件&#125; 然后执行logrotate -vf /etc/logrotate.conf，看到的效果是： 命令执行后，服务器create了新的auc.log.10，而且属性变成了777，同时把原有的部分压缩成gz的格式。 上面那个测试的对象是已经过期的日志，现在我们要压缩当前的日志，目的是在压缩了auc.log并且重命名之后，可以生成新的auc.log，同时这个新的auc.log会被写入。 现在我们尝试一下，把原来的配置文件改成这样： 123456/mnt/hswx/auc/logs/auc.log &#123; weekly minsize 200M compress rotate 2&#125; 但是执行之后，我们发现变成了这样： 原来的auc.log不见了，而出现的auc.log.1里面的内容是原来auc.log的内容，可见原有的auc.log已经被顶掉了。这是因为我们上面的配置文件里面没有加上dateext，所以默认会以.1、.2、.3为后缀。 问题是我们没有生成auc.log，那么这段时间的日志就会找不到auc.log而凭空消失。可见这个方法没有达到我们的目的，需要改进。 改进之后我们这个内部模块auc只有重新启动这个进程才会生成auc.log，既然要解决这样的问题，我们很自然的就想到kill -HUP这种平滑启动的方式，但是要注意！kill -HUP对deamon会进行重新读取配置启动，但是对于普通的进程只会把其杀死！而这个auc就是一个普通的java程序，没有配套的守护进程。所以只能使用一般的重启方式来达到生成auc.log这个目的。 首先我们把原来的配置文件改成这样： 1234567891011/mnt/hswx/auc/logs/auc.log &#123; weekly #每周执行 dateext #以日期作为后缀 minsize 200M #到达了200M自动执行，不然即使到了一周的时间也不执行 compress #压缩 rotate 2 #最多保留两个文件 sharedsripts postrotate #在执行完日志压缩之后就执行如下动作 /bin/bash /root/restart.sh #动作就是执行这个绝对路径的脚本 endscript #收工&#125; 而这个restart.sh的内容很简单: 1234#!/bin/bashcd /mnt &amp;&amp; ./stopAUC.sh #停止auc进程cd /mnt &amp;&amp; ./startAUC.sh #启动auc进程echo HAHAHAHA！！！ #表示已经OK了，让我们发出杠铃一般的笑声 现在我们重新跑一下logrotate，logrotate -vf /etc/logrotate.conf。看一下效果： 可以看到先把日志改名压缩，完事后也执行了restart.sh这个脚本，再日志里一看，auc.log也顺利生成了！ 参考资料http://www.pythondev.org/post/8.htmlhttps://www.jianshu.com/p/87e2fd01393c?utm_campaign=maleskine&amp;utm_content=note&amp;utm_medium=seo_notes&amp;utm_source=recommendationhttps://segmentfault.com/q/1010000000120419","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"}]},{"title":"一个暗藏杀机的脚本","slug":"一个暗藏杀机的脚本","date":"2018-02-11T07:13:54.000Z","updated":"2018-02-11T07:19:48.000Z","comments":true,"path":"2018/02/11/一个暗藏杀机的脚本/","link":"","permalink":"http://yoursite.com/2018/02/11/一个暗藏杀机的脚本/","excerpt":"","text":"脚本背景老总最近总是发现某台relay服务器的CPU值会突然彪很高，于是勒令几位工程师检查问题，但是工程师一时半会也想不到究竟是什么程序这么耗费CPU，于是就委托运维写一个脚本，具体要求是这样的：每隔一秒钟输出一下top命令的前十二行情况（其实就是配置总览和耗费cpu前五名程序情况），将这些情况保存到一个文件里，如果这个文件大于500MB，就把这个文件删除（为啥要删除？我也不知道），重新再生成一个文件用来保存top命令结果。 分析由于脚本无法自己跳出运行并检查自己的大小，所以这个任务需要两个脚本，一个是单纯的把top命令重定向到一个文件（recordTOP.sh），另一个脚本就是一个if判断大小（checksize.sh）。再加上crontab每一天一检查（其实完全没必要，500MB足够top这个命令跑5天的），应该可以满足开发人员的需求。 脚本内容获取top.txt的脚本recordTOP.sh如下： 12345678910#!/bin/bash#written by ChenShuo @2016-8-15#Desription:每一秒钟记录一次top命令里占用cpu前五程序while true do $(top -bn 1 | head -12 &gt;&gt; /root/top.txt) echo \"------------------------------------------------\" &gt;&gt; /root/top.txt sleep 1 done 判断top.txt大小的脚本checksize.sh如下： 12345678910#!/bin/bash#written by ChenShuo @2016-8-15#Desription:当recordTOP.sh文件大小超过500MB的时候将会重新覆盖size=$(ls -l | grep top.txt |cut -d \" \" -f 5)if [[ $size -ge 536870912 ]] then $(ps -ef|grep recordTOP.sh|grep -v grep|awk '&#123;print $2&#125;'|xargs kill -9) $(rm -rf /root/top.txt) bash /root/recordTOP.sh &amp; fi crontab这一步我就略掉不写了。 补充说明1）top不可以直接重定向，如果是top &gt; 123.txt，它将会不断的导入，因为top就是一个实时更新的命令，所以这里要用top -bn 1|head 12 &gt;&gt; /top.txt； 2）shell脚本里调用shell，不能采用$()的方法了，因为$()是一个返回值，而.sh是一个不断进行的脚本，所以要用bash +脚本名的方式； 3）recordTOP.sh这个脚本是可以同时存在多个的，但是如果不小心后台启动多个，用checksize脚本ps -ef语句就会报错，因为获得到的不是一个数字，而是多个数字，没法一波kill掉。同理，直接调用checksize也会报错，因为没有ps -ef的值； 4）因为是要先关闭原来的top重定向脚本，所以才用了保守的ps -ef，然后kill的方式，这里不可以使用pkill，因为pkill是干掉整个类型程序，比如pkill -9 java，就是干掉所有java的进程。而在linux里，千万不可以pkill -9 sh，可以想象一下，这个命令的结果就是会从ssh上跳出，同时无法登陆，因为整个sh都被你杀死了。那么真的出现了这个结果怎么办？答曰：重启，重启能救命。 整个执行效果如下，可见top.txt文件是在不断的扩大，由于是测试，我把文件大小调整为20000字节，即大于20000字节就覆盖原文件，当文件大于20000字节的时候，就会把原来的top.txt删除，同时生成一个新的top.txt。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"},{"name":"top","slug":"top","permalink":"http://yoursite.com/tags/top/"}]},{"title":"http返回码是000...","slug":"http返回码是000","date":"2018-02-11T01:51:39.000Z","updated":"2018-02-11T02:08:48.000Z","comments":true,"path":"2018/02/11/http返回码是000/","link":"","permalink":"http://yoursite.com/2018/02/11/http返回码是000/","excerpt":"","text":"正文今天开发童鞋在测试往一个网站发请求的时候，发现返回码是000，如图： 众所周知，常见的返回码是以下四种： 12342XX 成功；3XX 重定向；4XX 客户端错误；5XX 服务器端错误； 但是000是啥玩意？简单的说就是没有有效的http状态码，比如连接被拒绝，连接超时等。 使用curl -w &quot;%{http_code}\\n&quot; -m 5 https://60.191.94.115:38303/cloudSignalling/events/deviceState ; echo &quot;Exit code: $?看一下详细的code，显示如图： 可以看到提示：curl: (60) Peer certificate cannot be authenticated with known CA certificates，翻译过来就是对方的证书不能用已知的CA证书验证。但是下面也说了可以用-k或者--insecure来跳过这一步。 于是我又使用curl -I -k https://60.191.94.115:38303/cloudSignalling/events/deviceState这个命令，效果如图： 里面这一下说的就很明白了，405，方法不正确，再搭配一下curl -k -w &quot;%{http_code}\\n&quot; -m 5 https://60.191.94.115:38303/cloudSignalling/events/deviceState，看一下： 这么上下一结合，明白了GET是不准许的，准许POST。于是反馈给60.191.94.115告诉他们把前后台接口请求方式、参数传递方式都拿回去整改。 参考资料http://www.1987.name/365.htmlhttps://superuser.com/questions/501690/curl-http-code-of-000","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"http","slug":"http","permalink":"http://yoursite.com/tags/http/"}]},{"title":"将redis加入到elk日志系统里","slug":"将redis加入到elk日志系统里","date":"2018-02-09T09:14:18.000Z","updated":"2018-02-09T09:40:46.000Z","comments":true,"path":"2018/02/09/将redis加入到elk日志系统里/","link":"","permalink":"http://yoursite.com/2018/02/09/将redis加入到elk日志系统里/","excerpt":"","text":"之前在https://rorschachchan.github.io/2018/01/16/记录日志系统ELKB-5-6-4的搭建过程/里面，我画的那个架构图里说了整个架构可以加入redis，但是在文章里我没有写到redis怎么加进去。为了让整个系统更好的分层，是非常建议引入Redis的，毕竟Redis服务器是logstash官方推荐的broker选择。Redis作为一个缓存，能够帮助我们在主节点上屏蔽掉多个从节点之间不同日志文件的差异，负责管理日志端（从节点）的人可以专注于向 Redis 里生产数据，而负责数据分析聚合端的人则可以专注于从Redis内消费数据。所以这一次实验要把redis加进去，同时也要部署一个nginx，让elk再去采集nginx的日志。 整个架构图图下： 部署redis安装redis的方法请去看http://blog.51cto.com/chenx1242/1793895，我这里使用的redis版本是4.0.6，在执行make test的时候可能会有如下的错误： 那就安装新一点的tcl吧，方法如下： 12345wget http://downloads.sourceforge.net/tcl/tcl8.6.1-src.tar.gztar xzvf tcl8.6.1-src.tar.gz -C /usr/local/cd /usr/local/tcl8.6.1/unix/./configuremake &amp;&amp; make install 然后重新去make test就会看到成功的字样，如图： 现在redis的漏洞比较多，大多数就是因为密码太简单导致的，所以把redis密码改一下，在redis.conf里，改成如下的样子： 123456789bind 内网IP地址 127.0.0.1 ###仅允许内网和本机访问protected-mode yes ###保护模式开启port 6379 ###端口默认为6379，按需修改daemonize yes ###守护模式开启pidfile /usr/local/redis/redis.pid ###指定pid文件路径和文件名logfile \"/usr/local/redis/redis.log\" ###指定日志文件路径和文件名dbfilename redis.rdb ###指定数据文件RDB文件名dir /usr/local/redis/ ###指定数据文件RDB文件的存放路径requirepass 『YOURPASSWORD』 ###设置访问密码，提升密码强度 保存之后启动redis即可。 如果redis是主从配置，若master配置了密码则slave也要配置相应的密码参数否则无法进行正常复制的。需要在slave的redis.conf里找到#masterauth mstpassword，去掉注释，也改成跟master一样的密码，重启一下即可。 nginx的安装这里就不写了，直接看http://www.runoob.com/linux/nginx-install-setup.html这个就行了。 安装x-packx-pack是elk官方提供的认证授权插件，安装方法很简单，分别找到下面三个文件，然后后面加上install x-pack即可： 123./elasticsearch-plugin install x-pack --batch ./logstash-plugin install x-pack ./kibana-plugin install x-pack 如果要查看已经安装的插件，那就是： 1234[root@chen-elk-001 bin]# ./elasticsearch-plugin listx-pack[root@chen-elk-001 bin]# ./kibana-plugin listx-pack@5.6.4 如果kibana-plugin要卸载x-pack，那就是：./kibana-plugin remove x-pack。 重启服务即可登录，默认的登录用户名: elastic，密码:changeme。 这里注意一下，./logstash-plugin install x-pack的时候可能是出现ruby源的错误，如图： 这是因为中国特色社会主义的网络限制访问https://rubygems.org，一般来说，可以把它更改成阿里的ruby源https://ruby.taobao.org/，不过如果你的服务器无法跨越长城的话，那么更改也是不好使的，所以在这一步，我选择离线安装x-pack。也就是先把https://artifacts.elastic.co/downloads/packs/x-pack/x-pack-5.6.4.zip这个文件下载到本地上传到服务器的root文件夹里，然后安装： 123[root@chen-logstash-001 bin]# ./logstash-plugin install file:///root/x-pack-5.6.4.zipInstalling file: /root/x-pack-5.6.4.zipInstall successful 配置filebeat由于这个nginx我们需要先让filebeat把nginx.log和error.log先推到redis存储，然后再由redis推到logstash。配置filebeat.yml的具体信息如下: 1234567891011[root@iZbp10hw6wezxmrvrcjyhlZ filebeat]# grep -iv '#' /etc/filebeat/filebeat.yml | grep -iv '^$'filebeat.prospectors:- input_type: log paths: - /usr/local/nginx/logs/*.log #这里是nginx的日志文件夹 output.redis: #以下这部分都是新加的 enabled: true hosts: [\"127.0.0.1:6379\"] key: logindexer_list #与redis配置文件里的key遥相呼应 password: 『YOURPASSWORD』 #跟上面的密码遥相呼应 配置完毕之后，启动filebeat，命令语句：/etc/init.d/filebeat start -c /etc/filebeat/filebeat.yml。 配置logstash由于这台logstash已经开启了一个logstash进程，那么再收集nginx的日志需要新开一个logstash进程，也需要新写一个conf文件，假设新的conf文件是nginx-logstash.conf，它的写法如下： 1234567891011121314151617181920212223input &#123; redis &#123; host =&gt; \"10.168.173.181\" type =&gt; \"redis-input\" data_type =&gt; \"list\" key =&gt; \"logindexer_list\" port =&gt; 6379 password =&gt; \"ChenRedi$\" &#125;&#125;# filter configration hereoutput &#123; elasticsearch &#123; hosts =&gt; [ \"10.162.80.192:9200\" ] user =&gt; elastic password =&gt; changeme index =&gt; \"nginxlogstash-%&#123;+YYYY.MM.dd&#125;\" #这个是新的索引 &#125;stdout &#123; codec =&gt; rubydebug &#125;&#125; 现在logstash不支持多个实例共享一个path.data，所以要在在启动不同实例的时候，命令行里增加--path.data PATH，为不同实例指定不同的路径。启动logstash之后，看到显示如下： 再到nginx的日志看一下，因为logstash里没有做日志的切割，所以是整个一个类似字符串的形式发送了过来： 果然有这样的日志，可见logstash与nginx的redis已经正确连接。在elasticsearch里，使用curl -u 账号密码 &#39;localhost:9200/_cat/indices?v&#39;查询索引的时候，就会看到那个nginxlogstash，如图： 参考资料https://doc.yonyoucloud.com/doc/logstash-best-practice-cn/input/redis.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"},{"name":"elk","slug":"elk","permalink":"http://yoursite.com/tags/elk/"},{"name":"大数据分析","slug":"大数据分析","permalink":"http://yoursite.com/tags/大数据分析/"}]},{"title":"Mysql-Atlas从库始终没有建立连接怎么办","slug":"Mysql-Atlas从库始终没有建立连接怎么办","date":"2018-02-09T05:45:56.000Z","updated":"2018-02-09T09:29:52.000Z","comments":true,"path":"2018/02/09/Mysql-Atlas从库始终没有建立连接怎么办/","link":"","permalink":"http://yoursite.com/2018/02/09/Mysql-Atlas从库始终没有建立连接怎么办/","excerpt":"","text":"最近发现阿里云线上环境有一台hls模块的数据库从库一直没有连接，而主库却一直连接不断。在阿里云控制后台看到连接情况如下图： 上图是主库的，下面那个是从库的，两者差距很大，可见这样的配置是错误的，因为读库根本没有使用，也就是说读库的那份钱是在浪费！ 来到对应的atlas服务器查看配置，看到atlas 的配置里规定管理接口的用户名和密码是默认的原始套餐，端口被改成了2346，如下面， 于是我们就在模块服务器（也就是图里的online-hls-001)上登录这个atlas服务器的管理端口，看一下效果： 发现mysql根本没有反应，可当我们telnet去atlas的2346端口的时候，发现端口是通的： 于是我们返回到atlas 的配置文件，把这台hls模块服务器的ip地址添加到clients-ips这个字段里。 然后再用hls服务器去测试一下atlas的管理端口，mysql -hatlas服务器ip地址 -uuser -ppwd，然后使用select * from backends;,发现里面的两个库一个连接成功，另一个是失败的： 两个库都可以ping通，state却有这样的差别。由此可见这台atlas根本没有连接到从库，导致从库的连接数始终为0。这个时候我们就要检查从库配置的账号密码是否正确，而且在阿里云控制后台给从库开启这个atlas的白名单，然后重新启动这个mysql-proxy进程，再登录atlas管理端口查看，发现从库由down转up了： 但是此时的atlas日志里却出现了很多forbidden的warning的提示： 这时候我们返回atlas的配置文件，把之前的修改过的client-ips这个字段注释掉，让所有合法ip都连接，然后重启atlas，这样这种forbidden ip的警告日志就会消失。 稍等一会，就会看到从库上也会出现连接数了，至此一切恢复到正常状态，故障排除！ 本次故障排除感谢https://highdb.com/?s=atlas这位大神的帮助！ 文末补充数据库访问使用了事务的话，从库也会建立连接，只是连接量要小于“非事务访问”，而不是一点连接都没有。 一般来说，在atlas配置文件里，主库写一个，而从库最好把主库和从库都写进去，如果希望从库承担读的任务多一点的话，可以把权重调高，比如我想从库与主库的读任务比是2：1，那么就可以这么写： 1234#Atlas后端连接的MySQL主库的IP和端口，可设置多项，用逗号分隔proxy-backend-addresses = 主库地址:3306#Atlas后端连接的MySQL从库的IP和端口，@后面的数字代表权重，用来作负载均衡，若省略则默认为1，可设置多项，用逗号分隔proxy-read-only-backend-addresses = 从库地址:3306@2,主库地址:3306@1","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"读写分离中间件","slug":"读写分离中间件","permalink":"http://yoursite.com/tags/读写分离中间件/"}]},{"title":"脚本里添加crontab的方法","slug":"脚本里添加crontab的方法","date":"2018-02-08T13:48:37.000Z","updated":"2018-02-08T13:55:56.000Z","comments":true,"path":"2018/02/08/脚本里添加crontab的方法/","link":"","permalink":"http://yoursite.com/2018/02/08/脚本里添加crontab的方法/","excerpt":"","text":"一般来说，增加计划任务都是crontab -e，然后在里面添加内容。但是在一些脚本里，需要自动添加，那么这种情况怎么办？ 第一种方法重定向crontab到其他文件： 123crontab -l &gt; crontab.bakecho \"*/1 * * * * ./yourscript &gt; /dev/null 2&gt;&amp;1\" &gt;&gt; crontab.bakcrontab crontab.bak 如果想删除某个计划任务，就进去crontab -e删除就好，crontab.bak不用管，不用担心内容会自动变成crontab.bak的样子。 第二种方法如果你觉得使用crontab 文件这种方法心里没有底的话，就选择最妥善的方式，也就是下面这样： 1echo \"*/1 * * * * ./yourscript &gt; /dev/null 2&gt;&amp;1\" &gt;&gt; /var/spool/cron/root 当crontab突然失效时，可以尝试/etc/init.d/crond restart解决问题。或者查看日志看某个job有没有执行/报错tail -f /var/log/cron。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"crontab","slug":"crontab","permalink":"http://yoursite.com/tags/crontab/"}]},{"title":"在百花之中干掉一个杂草连接...","slug":"在百花之中干掉一个杂草连接","date":"2018-02-08T12:43:12.000Z","updated":"2018-02-08T12:59:08.000Z","comments":true,"path":"2018/02/08/在百花之中干掉一个杂草连接/","link":"","permalink":"http://yoursite.com/2018/02/08/在百花之中干掉一个杂草连接/","excerpt":"","text":"正文早上接到阿里云的服务器报警，说有一台服务器的流量超标，这个服务器的外网带宽是5M，但是登陆进去使用iftop -i eth1发现里面的流量已经几乎跑满，如图： 我这个服务器的名称叫online-mts-001，为啥会有一个mail25.u.tsender.com，这个是什么鬼？莫非是通过我的服务器去连接这个“邮箱”域名？于是我就ping了一下这个mail25.u.tsender.com，结果如图： 看到这个域名对应的ip地址是115.29.177.8，嗯，115.29.177.8，哎？这个ip地址好熟悉啊，卧槽，这特么不是这个online-mts-001的外网ip么？ 也就是说我这个机器在我不知道的情况下被人绑定了一个域名！但是我这个服务器不是网页服务器，上面那个tsender.com的域名打不开，我检查了服务器一番，发现这个机器没有被人入侵的痕迹，只能说是被人有意/无意（无意的可能性更大，比如看错了阿拉伯数字）绑定了域名。 被人绑定了域名就好比被人起了外号一样，一旦非本人操作就不太好往下摘了，查了很多资料都没有办法，毕竟主动权不在我这里了。 但是回头过来，我们的重心是要解决那个占据了3M带宽的连接，netstat看了一下，发现这个连接的具体信息如下： 仅仅是干掉连接的话，方法有很多，关闭网卡再重开或者关闭相应的服务都可以，但是现在的问题是这台服务器是生产环境的服务器，它主要是给用户提供视频拉流，通过抓包分析得知，这位183.228.128.188的用户合法通过外网连接到了这台视频服务器，而且拉取的是高清视频，所以才占据了这么大的带宽。不过我们还是决定先断开这位用户的连接同时不动其他用户的连接，这位183.228.128.188的用户在客户端虽然会发觉视频断开，但是有缓存和人为刷新的客观因素，实际的体验不会差太多，至少不会投诉400… 那么如何干掉一个established连接同时保证其他连接呢？请使用tcpkill。 tcpkill的下载比较有说法，下面是安装步骤： 1234567wget http://rpm.repo.onapp.com/ramdisk-hv/centos6/dsniff/libnids-1.24-1.el6.x86_64.rpmwget http://rpm.repo.onapp.com/ramdisk-hv/centos6/dsniff/libnet-1.1.5-1.el6.x86_64.rpmwget http://rpm.repo.onapp.com/ramdisk-hv/centos6/dsniff/dsniff-2.4-0.14.b1.el6.x86_64.rpmyum install libICE libSM libXmu -yrpm -ivh libnet-1.1.5-1.el6.x86_64.rpmrpm -ivh libnids-1.24-1.el6.x86_64.rpm rpm -ivh dsniff-2.4-0.14.b1.el6.x86_64.rpm 请按顺序操作，不然的话dsniff就会报错： 1234warning: dsniff-2.4-0.14.b1.el6.x86_64.rpm: Header V3 RSA/SHA256 Signature, key ID 0608b895: NOKEYerror: Failed dependencies:libnet.so.1()(64bit) is needed by dsniff-2.4-0.14.b1.el6.x86_64libnids.so.1.24()(64bit) is needed by dsniff-2.4-0.14.b1.el6.x86_64 安装完毕之后，就会生成tcpkill命令，如图： 然后断开上面那个大带宽连接的命令是：./tcpkill -i eth0 src port 9132 and dst port 9595 and src host 115.29.177.8 dst host 183.228.128.188或者./tcpkill -s 115.29.177.8:9132 -d 183.228.128.188:9595。 但是要注意一下！tcpkill一定要运行在能接收到应答包的主机上在，最好运行在连接或半连接存在的一端主机上，因为tcpkill会发现这个连接里有数据传输进而感知并且干掉。而且tcpkill默认情况下是只能干掉established状态的连接，对于假死连接（连接在，但是数据不传输）或者半连接（由于tcp keeplive没打开而又没有数据向对端发送，导致一直无法感知次连接其实已经断开）是无法断开的。 如果遇到上述所说的假死连接和半连接就需要手动更改tcpkill的源码，更改原理在https://yq.aliyun.com/articles/59308。 如果使用的系统是ubuntu or debian，还可以使用cutter命令，apt-get install cutter下载即可。使用方法：http://www.cyberciti.biz/tips/cutting-the-tcpip-network-connection-with-cutter.html。 至于第一个问题，怎么把这台服务器上的域名撤除，我倒要好好想想了… 参考资料http://www.cyberciti.biz/howto/question/linux/kill-tcp-connection-using-linux-netstat.phphttp://www.gnutoolbox.com/tcpkill-command/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"}]},{"title":"Zabbix里item取值超时怎么办？","slug":"Zabbix里item取值超时怎么办？","date":"2018-02-08T03:02:53.000Z","updated":"2018-02-08T03:16:28.000Z","comments":true,"path":"2018/02/08/Zabbix里item取值超时怎么办？/","link":"","permalink":"http://yoursite.com/2018/02/08/Zabbix里item取值超时怎么办？/","excerpt":"","text":"正文开发同学新开发了一个模块，需要运维监控一下8683\\8682\\9002这三个端口，于是我就在zabbix里把这三个端口进行了监控，但是却无法返回值，如图： 可见其他的自定义监控项是好使的，偏偏三个监控端口的项都是not-supported。我就进去到item里看看，type of information和data type都是正常的，而且每三十秒一次更新，应该是没有什么问题的。 于是我就去zabbix的server使用zabbix-get去试试，到底是怎么回事儿，使用结果如图： 可见使用zabbix_get是可以取到值的，而且取值都正确，三个正常的端口反馈都是1，而不存在的端口（9002）的反馈是0。可是,我发现使用zabbix_get取值pid是结果秒出，而取值net.tcp.listen则是等了几乎5秒钟才获得结果。那么问题就出在这里了。 调整zabbix_agentd.conf里的Timeout值，把其设定为10，然后重启zabbix进程就OK了。 补充1）https://www.xiaomastack.com/2015/07/03/zabbix_net-tcp-listen/comment-page-1/#comment-319，很多时候端口监听会出错，于是就用自定义键值的方法，但是小马哥博客里的这个方法在centos里是无法启动，zabbix会报语法错误。由于公司的zabbix是2.2版本，等我有时间需要细化一下这个语法。 2）调整unsupport items检查时间的方法是：在Adiministration里选择General然后在右侧下拉菜单里选择Other，然后修改Refresh unsupported items (in sec)的值，这个值得意思是“每多少秒去重新检查一下那些not_supported的值”。 3)这种长时间获取key的行为，很容易导致zabbix unreachable poller processes more than 75 busy这个错误，所以尽可能的不要添加这样的监控，而换用其它的方式。导致zabbix unreachable poller processes more than 75 busy这个错误的另一个原因就是可能有某台zabbix-agent死机了。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"运维监控","slug":"运维监控","permalink":"http://yoursite.com/tags/运维监控/"}]},{"title":"十六年，九个队，一份爱","slug":"十六年，九个队伍，一份爱","date":"2018-02-07T03:21:27.000Z","updated":"2018-02-08T01:49:54.000Z","comments":true,"path":"2018/02/07/十六年，九个队伍，一份爱/","link":"","permalink":"http://yoursite.com/2018/02/07/十六年，九个队伍，一份爱/","excerpt":"","text":"原文地址：https://www.theplayerstribune.com/caron-butler-retiring/ 我妈第一次坐飞机的时候可真心把她吓得不行，我想她那时候肯定对Pat Riley有一些悄悄的不满。 那是2002年NBA选秀后的一天，我们乘Pat Riley派来的球队机飞翔在30000英尺的高空，从威斯康辛出发到佛罗里达的迈阿密热火队报到。我现在一闭上眼也能想起当时我妈妈Mattie坐在一个宽敞的椅子里，时而看看我时而看看窗外，前后张望的样子。她的脸上交织出坐飞机的恐惧，但又很自豪的复杂表情。 “这整个飞机只为我们几个服务的么?”她简直难以置信，要知道整个飞机上的乘客只有我、我的家人和两个热火队的工作代表。 我其实也是觉得如此的不可思议，但是我要管理好自己的神态，让自己显得比较酷。我坐在的位置上，平复自己的心情，保持正常的呼吸。球队代表给我展示了属于Alonzo Mourning和LaPhonso Ellis的专位，这看上去太梦幻了。 我对我母亲说“这一切太梦幻了”。 我一直在告诉我自己，现在我已经是热火队的一份子了。不是我吹牛，我也曾经在康大的时候也坐过飞机去打比赛，但是从来没做过头等舱，这在那个时刻我就坐在这架专机比头等舱还要牛逼的地方。那是Pat Riley级别的仓位。我一直让自己尝试冷静，“Caron，冷静，你很棒，你是个爷们，你要表现的就像以前那样从容。” 当我回忆起来当时的情景，觉得实在太滑稽了。我一直试图去安抚我那位紧张的老妈，而其实我内心的紧张不比她少多少。 这就是16年前我去迈阿密热火队报到的情景，从此开始了我的NBA生涯。如果那时候你跟我说我要在十多年的职业生涯里为9个队伍打球，我想我的表情会跟当时飞机上我的老妈一样。 但是事情就这么发生了，顺其自然，这16年真是一段棒极了的旅行。而今天，我宣布正式从NBA退役。 你知道，我其实很想写一封信给年轻时候的自己，不过我想12岁的我应该压根不会理会这封穿越时空的信。如果他发现信封里没有钞票，可能就会直接把它扔进垃圾桶里。然后会嘲笑我现在的光头并且补上一刀“哥们，你真老”。 但我现在就想告诉你那些让我NBA梦成真的人和故事。而这一切的一切都要从当时热火队总裁Pat Riley开始。 我出生在威斯康星州的拉辛，在18岁之前我没有踏出过那里半步，不过我有听说过芝加哥，也见过有人在迈阿密的海滩上放风筝。除了康涅狄格州那两年，拉辛就是我的全部。大城市？我只有在电影和电视里看到他们的样子。 然后就是参加NBA选秀，不久我就接到Pat Riley总裁的电话，然后我成了迈阿密的一份子，那一切的一切彷佛是发生在我身体之外的。我觉得我可牛逼了，你知道么？我那时候简直是全世界最幸福的人，我准备把人生最好的青春时光投身于职业篮球，我要让家族骄傲，要让整个拉辛骄傲。 但我第一天踏进热火队训练馆的时候迎接我的不是派对，生活也不想在海边抽雪茄那么潇洒，迎接我的是“你的更衣间在这里，你迟到了，你应该早来一个小时的，明天开始训练，对了，你叫啥来着？” 这就是我到训练馆听到的第一句话，这就是热火给我的第一感觉。它让我停止了“从专机到专车，全家在迈阿密的豪华旅行，每个人都以我为豪”的感觉，开始了真刀真枪的训练—-我看到Pat Riley就站在训练场场边，他手上带着总冠军戒指，他很正经的跟你说，马上去好好训练或者从训练馆出去。 迈阿密的纸醉金迷让很多年轻人迷失，不过那种夜生活对我没有什么侵蚀力。我14岁的时候就有了我第一个儿子，我年少的时候可没少蹲过号子，记得我16岁的时候，警察曾经在我学校的储物柜里搜出来了毒品和手枪，我也被拘留了一段时间。我出自黑人街头，小时候经历了很多哥们朋友死掉。所以我没有期待过什么幸福温暖的日子，那时候，篮球是我唯一守护的东西。我尽力的不让那些声色犬马去分散我的注意力。 不过那时候我毕竟还是一个小孩，虽然我心态还算端正，但是我却不知道如何百分百的把精力都投入到训练里去。 最开始的几个月对于我整个职业生涯来说是非常重要的，热火队从一开始培养我的比赛观和胜负观，你把它想像成是一个称之为愿望也好，意志力也好，反正就是一个坚定的信念，我想正是这个信念让我能在NBA待这么久。我们为热火队打球，为Pat Riley总裁和Stan Van教练卖命。他俩教会了我如何正确的身体训练，正确的战术训练，叮嘱我们正确的去准备比赛，告诫我们细节决定成败。而这些都是你每晚在TNT直播中看那些NBA球员时所看不见的。 幸运的是，我很早就领悟到“天赋并没有你想象的那么重要”这个道理，当然，有天赋肯定很赞，但是如果你在比赛里倾尽所有、全力以赴，哪怕你的对手比你能跳能跑，但是你也有很大的几率赢球。钻研，不断地打磨技术，这才是赢球的不二法则。如果有人说“在NBA这么高水平的比赛里，基本功并不是重要”，这话简直就是痴人说梦。 Pat Riley教练会以各种不同的方式教我事情，我永远不会忘记他会在我的更衣柜上留下字条，我会在训练前看到这些字条，上面有些写的是我技术上缺陷和需要进步的地方，有些写的是励志的话语。那虽然只是简单的一两句话的便条，但是每一句话都对我有着绝大的影响，这就是我跟我篮球教父之前所建的秘密联系通道—用我们自己的语言去彼此沟通，正是这每一张字条让我成为了一个更好的篮球选手。多年之后，我转会去了雷霆队。我开始效仿当年Pat Riley给我留字条那样的给Kevin Durant留字条，KD是我的小兄弟。我很惊讶和感激在他的MVP的获奖演讲里他特别提到了这个事儿。但是我看来，我只是做了我的篮球恩师Pat Riley做的事情。 第二年，当我得知被交易去湖人队的时候，我很受伤，我以为Pat Riley跟我在篮球层面的之间是有特殊关系的。我的意思是说，如果我当时在Pat Riley的位置上也会把自己拿去交易Shaq的。如果你看着镜子中自己，然后说你比Shaq对这个队伍更有价值，那我无话可说，因为我实在不想打击你的自尊心。 不过那种失落并没有持续很久啦，这就是在联盟里生存的学费。就像我前面说的，我在拉辛住了十多年，我也希望终老迈阿密。我还记得跟D-Wade、Brian Grant、Eddie Jones、Alonzo这些家伙一起打球的日子，那是一段令人难以置信的学习经历，我会永远记得和那些家伙一起玩的开心时光。但是这就是生意，不久后我就动身出发去洛杉矶报到，身边的人从Dwyane Wade变成了Kobe Bryant，Dwyane Wade是我的铁哥们，但是这个世界也没几个人会拒绝跟Kobe联手。当我到了洛杉矶也就大约一周的时间吧，当初到迈阿密的紧张感觉被我忘个干净。 我仅仅在湖人效力了一个球季就被交易去了华盛顿奇才，有趣的是，那个交易对我来说没什么伤害。我认为那是一个很好的决定，当时的奇才队有很多年轻的充满天赋的选手，我很高兴有机会成为他们的一员。 华盛顿的六年是我一生中最棒的时光，在奇才队我两次入选全明星赛。我和Antawn Jamison、Brendan Haywood、以及当时还没有称呼自己是“Hibachi”的Gilbert Arenas在东部打出了一片天,我永远记得华盛顿人民是多么的热爱那支奇才队。纵然迈阿密和洛杉矶都是超级大城市，但是华盛顿却是我职业生涯效力时间最长的地方，那是我第二个篮球之家。 交易帮助我学习到了篮球生意的真相，我不论到哪个球队，都试图在训练里做一个榜样，就用当初在迈阿密学到的那套。我在健身房里专注训练，总是要求自己做的更好，总是要求自己记住细节。在每一支队伍里我都与队友们打成一片，我的意思是，换做是你整天跟这帮队友们泡在一起，如果你不是太拘谨的话，会很容易融入这个集体的。 不过我毕竟辗转了九个城市，这漂泊的生活对我的家庭来说是很困难的。要知道，我那时仅仅在菲尼克斯就待了一个月左右的时间，我的妻子Andrea又不得不收拾行李搬家去下一站，所以我的孩子们总是在不停的转学转学。我妈–她一直以我为荣，即使我不是比赛中的MVP，但是只要我命中投篮但是没有拿下比赛最佳球员她都会在场边不爽（谢谢你，老妈）。但我也深知，为了我的篮球生涯，其实我的家庭牺牲了很多。 我现在感谢上苍，我依旧活着，这简直是一个奇迹。我现在想谈谈生与死，上周，我回拉辛去参加一个葬礼，那是一个26岁的小伙子，从他的车上逃离的时候被警察连开数枪。我本人不认识他，但是我理解那种感觉。因为我和那些在拉辛长大的朋友，我们都知道死亡随时都降临的恐惧感。我深深地理解被困在那里是一种什么滋味，我很幸运我走出来了。我知道那些被杀或者误入歧途的人没有离开那座城市。我参加过很多个葬礼，那很难受。不过很奇怪，在生活中你会像我一样已经达到了一定的高度，当周围人告诉你你已经挺过来了，你也会想“我真的做到了”，就是这样，但是并不是那么简单。我想我还是回回到家乡来看看的，以后也常回来。 对于现在的我来说那些拉辛的孩子就跟曾经的我一样，我也出生在这里，我也曾经是拉辛的孩子，我也做过各式各样的蠢事。但是我从中交了学费，要知道从教训里学习的确不是一个容易的事儿，我花的时间比我母亲期望的时间要长，但是我最终还收获了经验。一旦我有一个目标，就要付出全部，我不想让那些相信我的人失望。我能拥有如此多的东西，我已经很知足了。 文章的最后我想说几个人，这可能会像是一连串名单，毕竟我在联盟里摸爬滚打了这么多年，肯定有很多人要去感谢，如果我忘记了提到某人，那请准许我提前道歉。 在我开始第一场NBA比赛之前，我的妻子就对我说无论我去哪里她都会跟着，这么些年，她一直信守当初的承诺。这辈子讨到她做老婆真是我的福气，无论是现在还是将来她都会是我生命里最棒的那部分。 感谢BJ Evans、Rob Wilson、Tim Donovan、Andy Elisberg、Jay Sabol、Marjie Kates、Shivani Desai、Tim Grover 和整个Arison家族在我职业生涯初期给我的帮助。 我要感谢Buss 家族、Mitch Kupchak、Magic Johnson、Alison Bogli和Eugenia Chow在洛杉矶给我的支持。 感谢Ernie Grunfeld、Milt Newton、Tommy Amaker、Sashia Jones、Candace、Susan O’Malley在华盛顿给我的帮助。 感谢老板Mark Cuban和主教练Rick Carlisle在达拉斯给我的帮助。 还有我在快船队的队友们：Blake Griffin、DeAndre Jordan、CP3–正是你们让我从重伤中走出来，重获新生。 Matt Barnes、Lamar Odom、Chauncey Billups还有我的偶像Grant Hill，我不会忘记跟你们一起的那段日子。 我一直都梦想能穿着雄鹿队的队服打球，感谢John Hammond和Senator Kohl，你们圆了我的梦，说实话在家乡打球的感觉真好！谢谢你们。 在雷霆队，我要感谢总经理Sam Presti、KD和Russell Westbrook。 在活塞队，我要感谢Tom Gores，而且在底特律能跟Stan Van重聚，并且与我的哥们Andre Drummond、Reggie Jackson和Caldwell-Pope一起打球。 Vlade Divac，是你在2016年给那个躺在沙发里以为生涯到此结束了的我打了电话，让我再去国王队跟Rajon Rondo和DeMarcus Cousins打了一年球。 还有一个需要特别说的，那就是刚刚去世的我永远的哥们Rasual Butler，我俩同一年进入联盟。像我一样，Rasual Butler也是一个辗转多队的浪人，但他身上有我敬佩的一切特征—勤奋、专业、积极、体育精神。他是一个人民交口称赞的好队友。哥们，NBA的家人们会想你的。 我的粉丝们，你永远不会知道你们曾经带给我的快乐。谢谢你们的支持!我希望每当你想到Caron Butler这个名字的时候，你会记得我曾经是多么的热爱和尊重比赛，我也希望你们会记住我付出所有时的那个形象。我知道这是一个陈词滥调，但那个形象对我来说要比比赛还要重要–这让我可以去面对一个严峻的未来。 我现在仍然会深深地回想起2002年那次飞往迈阿密的情景，当时我和我的家人在热火队的飞机上—不是因为昂贵或奢侈，也不是因为我第一次去海边。而是因为那是我一生中第一次真的感觉要去某个地方。 在NBA打球是我的梦想，我和所有这些伟大的教练和队友们一起度过了这16年，那是一段比我想象的要好的时光。我虽然身体已经不适合打NBA的比赛，但是篮球依旧在我的生活里，我会以另外的一种形式继续跟它在一起。 我只想让你们都知道我拥有我自己的生命，但正是有了你们的帮助，这个生命才活的如此多姿多彩。","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"NBA","slug":"NBA","permalink":"http://yoursite.com/tags/NBA/"}]},{"title":"记录Uwsgi与Django成功勾搭的始末","slug":"记录Uwsgi与Django成功勾搭的始末","date":"2018-02-07T02:15:09.000Z","updated":"2018-02-07T02:37:10.000Z","comments":true,"path":"2018/02/07/记录Uwsgi与Django成功勾搭的始末/","link":"","permalink":"http://yoursite.com/2018/02/07/记录Uwsgi与Django成功勾搭的始末/","excerpt":"","text":"环境说明Uwsgi版本：2.0.14(yum install安装）django版本：1.10.6（pip install安装）python版本：2.7.5(阿里云 centos 7自带）nginx版本：1.10.2（yum install安装） 正文在https://rorschachchan.github.io/2018/02/02/Uwsgi的安装和简单使用/里面，我们已经实现了网页打开出现”good bye,logan”的效果，可见Web Client &lt;===&gt; uWSGI &lt;===&gt; Python是通畅的，现在我们要调整看看django与uwsgi是否是通畅的。 首先，我们在/django这个目录下，django-admin.py startproject logan，建立了一个叫logan的project，然后在/django/logan/logan里会有一个自动生成的wsgi.py，打开一看，里面的内容如下： 12345678910\"\"\"WSGI config for logan project.It exposes the WSGI callable as a module-level variable named ``application``.For more information on this file, seehttps://docs.djangoproject.com/en/1.10/howto/deployment/wsgi/\"\"\"import osfrom django.core.wsgi import get_wsgi_applicationos.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"logan.settings\")application = get_wsgi_application() 我们原来的目标就是测试django跟uwsgi的链接是否正常，那么返回到/django/logan，使用python manage.py runserver 0.0.0.0:8000启动django，然后打开浏览器，在地址栏里输入外网ip:8000，看到了如下的界面： 可见django已经启动成功，但是前面说过了，这种方法只能测试环境里小规模的玩玩，完全不推荐拿去生产化境里。所以现在我们用uwsgi在8000来启动一下django。 首先，先停止了原来我们启动的django。 然后，使用命令uwsgi --http :8000 --wsgi-file logan.py,反馈错误信息如下： 出现这个错误，那就yum install uwsgi-plugin-python，同时使用uwsgi --plugin python --http-socket :8001 --wsgi-file /django/logan/logan/wsgi.py，这样却又出了一个新错误： 提示说：ImportError: No module named logan.settings。可是当我使用python客户端单独测试的时候，这个语句是可以使用的，如图： 很多人都卡在了这种情况，这个时候我们需要换一个命令：uwsgi --plugin python --http-socket :8001 --chdir /django/logan/ --wsgi-file /django/logan/logan/wsgi.py。然后我们在浏览器地址栏里输入外网地址：8001就可以看到如下网页： 可见，我们已经通过uwsgi启动了原本已经关闭了的django，这样就达到了Web Client &lt;===&gt; uWSGI &lt;===&gt; Django的目的。 如果过程中出现了端口被占用的情况，比如8002端口已经被使用了： 12probably another instance of uWSGI is running on the same address (:8002).bind(): Address already in use [core/socket.c line 764] 那么就可以使用lsof -i:8002，然后把对应的进程干掉就好了。 最后附赠python脚本一个，这个脚本可以显示python的path，内容如下： 12345import osprint '===== sys.path / PYTHONPATH ====='for k in sorted(os.environ.keys()): v = os.environ[k] print ('%-30s %s' % (k,v[:70])) 参考资料http://www.python88.com/topic/101/http://www.nowamagic.net/academy/detail/1330334","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"uwsgi","slug":"uwsgi","permalink":"http://yoursite.com/tags/uwsgi/"}]},{"title":"Jenkins与钉钉机器人实现手机端获取当前服务日志","slug":"Jenkins与钉钉机器人搭配手机端获取当前服务日志","date":"2018-02-06T12:56:33.000Z","updated":"2018-02-06T15:10:44.000Z","comments":true,"path":"2018/02/06/Jenkins与钉钉机器人搭配手机端获取当前服务日志/","link":"","permalink":"http://yoursite.com/2018/02/06/Jenkins与钉钉机器人搭配手机端获取当前服务日志/","excerpt":"","text":"马上要过年了，各位运维们除了因为买不到回家的火车票而嚎嚎大哭之外也开始扩容服务器和提前调整监控值，目的就是为了过一个消停的春节。可是这毕竟十天左右不在公司，要是模块真出了什么意外肯定没法第一找到日志分析问题，毕竟这几天都在串门拜年和醉生梦死中度过，走到哪都要再背一个笔记本实在太不方便了。 那么这个时候，我就琢磨使用手机端来启动服务器里脚本，让这个脚本可以去获取当前的日志，然后再把结果返回到手机端。这样就不用到哪里都带那个一看就很扫兴的公司笔记本电脑了。 使用手机端启动服务器里脚本？我又不会开发android和ios，那么肯定就要使用第三方工具，我条件反射的想到了jenkins，因为jenkins是用手机可以登录的，那么在手机端得到结果用什么呢？在微信公众号和钉钉机器人里，我选择了钉钉机器人。 创造钉钉机器人我的钉钉版本是4.2.6.37，首先在左上角头像的三角菜单有一个机器人管理，如图： 然后选择自定义机器人，给它起个名又换一个图标之后，添加到一个群聊里，如图： 添加的时候，这个机器人会生成一个webhook，它的结构应该是：https://oapi.dingtalk.com/robot/send?access_token=XXX，后面的XXX是标识符，不同的标识符代表不同的机器人，这个标识符如果丢了，可以在机器人头像点击一下然后选择机器人设置重新看到。 编写机器人脚本机器人的官方说明网址就是https://open-doc.dingtalk.com/docs/doc.htm?spm=a219a.7629140.0.0.zZIvnt&amp;treeId=257&amp;articleId=105735&amp;docType=1，这里面已经把使用方法写的够清楚了。我这里的这个python脚本是用json的格式，如下： 1234567891011121314151617181920212223242526272829303132#!/bin/python#coding: utf-8import json,urllib2#这里是机器人对应的Webhook地址url = \"https://oapi.dingtalk.com/robot/send?access_token=这里输入你机器人的标识符#这里是头，原样复制就好header = &#123; \"Content-Type\": \"application/json\", \"charset\": \"utf-8\" &#125;#这里是传送的消息data = &#123; \"msgtype\": \"text\", \"text\": &#123; \"content\": \"这里是消息正文！\" &#125;, \"at\": &#123; \"atMobiles\": [ \"A的手机号\", \"B的手机号\" ]， \"isAtAll\":False #这里True代表要发给所有人，False的话，要代表消息只发给A和B这两个人 &#125; &#125;sendData = json.dumps(data)request = urllib2.Request(url,data = sendData,headers = header)urlopen = urllib2.urlopen(request)print urlopen.read() 直接执行这个脚本，就会看到我刚新建的钉钉机器人在群聊里说话了。 机器人搭配nginx上面那个脚本已经可以初步实现我们的目的，但是有一个缺点，就是正文内容不能过长。但是我想多打印一点日志，至少50行，怎么办？我想了想，可以把日志放进nginx的一个网页里，然后用钉钉机器人反馈这个网页地址啊，这样内容想写多少就可以写多少了。 假设我现在获取到的日志的文件写进一个叫chairmanmao.html里，在浏览器打开看是这样的： 那么上面那个机器人的python脚本就要改成这样： 1234567891011121314151617181920212223242526272829303132#!/bin/python#coding: utf-8import json,urllib2,commandscommands.getstatusoutput('echo -e \"THIS IS TEST MESSAGE！ \\n\" &gt; /路径/chairmantail.html') #这里可以给网页加一个标题commands.getstatusoutput('cat /路径/chairmanmao.txt &gt;&gt; /路径/chairmanmao.html') #这里就是把诗词写进html文件里#这里是机器人的webhook地址url = \"https://oapi.dingtalk.com/robot/send?access_token=这里输入你机器人的标识符\"header = &#123; \"Content-Type\": \"application/json\", \"charset\": \"utf-8\" &#125;data = &#123; \"msgtype\": \"link\", \"link\": &#123; \"text\": \"点击网址就可获取到本次日志查询的结果\", \"title\": \"日志查询结果已经生成！\", \"picUrl\": \"http://p1x3hd2at.bkt.clouddn.com/nanshen.jpg\", #这里可以加一个缩略图片 \"messageUrl\": \"http://服务器外网IP地址/chairmanmao.html\" &#125;, \"at\": &#123; \"isAtAll\":True # at为非必须 &#125; &#125;sendData = json.dumps(data)request = urllib2.Request(url,data = sendData,headers = header)urlopen = urllib2.urlopen(request)print urlopen.read() 执行这个脚本可以看到机器人发送的信息如下： 然后打开这个网址，就看到完整的网页信息： 到时候把毛主席诗词换成实际的日志文件就好了，不用一口气打印所有的日志出来，tail -n 50 日志文件名，50行足够用了。 配置Jenkins脚本写完了，机器人也写完了，这个时候就要添加“启动端”。安装Jenkins的步骤我这里就不写了，直接可以去看https://rorschachchan.github.io/2018/02/05/Jenkins安装与创建简单任务/。现在去登录Jenkins的网页，去添加一个新的Job，比如我这个Job就叫“获取模块日志”，如图： 如果是要在Jenkins上去读取其他服务器的日志，就可以在构建project的时候选择参数化构建过程，然后配置参数ip，到时候把这些ip传递给目标脚本。如果觉得这样hold不住，可以不用jenkins的这个功能，把ip写到脚本里去，一了百了： 在构建那一步，选择Execute Shell，然后里面写上具体的shell命令，如果在上面使用了参数，那么参数就可以在这里使用，我的脚本里是没有ip这个参数的，在图里写$ip就是做一个例子讲解一下用法而已： 在构建后操作这一步可以选择E-mail Notification，这样如果失败了会发送邮件通知。如果用不着就什么都不用选。然后就是保存好这个project，点击左侧菜单栏的立即构建，就会看到下面Build History会多一个#1出来，同时钉钉机器人也在群里发消息，这个#1就是构建的记录，这个纪录多了的话，新纪录会覆盖掉老的记录。 点击这个#1，选择控制台输出，就能看到具体的操作结果了，跟在shell界面里执行的效果差不多的。可见操作成功，目的已经达到了！ 以后需要调用脚本，就在手机端浏览器里登陆jenkins，然后构建一下这个project，同时就可以看到钉钉里机器人有反馈了。 参考资料https://xu3352.github.io/linux/2017/05/01/jenkins-restart-remote-server-tomcathttps://github.com/typ431127/zabbix_dingding","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"jenkins","slug":"jenkins","permalink":"http://yoursite.com/tags/jenkins/"},{"name":"钉钉","slug":"钉钉","permalink":"http://yoursite.com/tags/钉钉/"}]},{"title":"一次官网打不开的经历","slug":"一次官网打不开的经历","date":"2018-02-06T06:10:12.000Z","updated":"2018-02-06T06:32:48.000Z","comments":true,"path":"2018/02/06/一次官网打不开的经历/","link":"","permalink":"http://yoursite.com/2018/02/06/一次官网打不开的经历/","excerpt":"","text":"今天有人反映官网在登陆的时候，chrome浏览器不能正常打开页面，反而会出现一个下载框。我使用IE浏览器尝试登录官网，页面也不是正常的页面，而是下面的内容： 由于官网的域名跳转是在阿里云的域名解析的地方配置的，于是就登陆到阿里云的域名解析地方，查看了一下发现，这里的配置是www.lechange.com会302跳转到home.lechange.com，而ping一下home.lechange.com得到的ip地址是一个负载均衡的地址，然后在阿里云的控制台查询这个负载均衡的情况，发现这个负载均衡后面挂载的是两台服务器A和B。 于是我在浏览器里面直接输入负载均衡的ip地址，发现还是像上面那样错误的php界面，而浏览器地址栏使用两个服务器的外网ip却是正常可以打开的。这个时候初步怀疑是SLB的问题，而我当时就觉得就凭上面这一点就去跟阿里撕逼不太妥当，但是事实告诉我们事情不是那么简单的。 我检查一下slb的端口配置情况，分别是http 80转8080和https 443转80，可见这个网站有两个协议，一个是http的而一个是https的，我们刚才虽然在浏览器里直接使用A和B的外网ip访问是可以正常打开页面，只能说明http协议是OK的，我们还要测试一下https协议访问的效果。 我就在浏览器地址栏里进一步尝试，发现使用A外网ip：8080访问是OK的，而使用B外网ip：8080访问就是PHP的文字界面。于是基本问题定位到B服务器里有文件的配置错误。 登陆到B服务器里，在nginx的conf文件夹里发现一个多余的文件，打开内容如下： 12345678910111213141516server &#123; listen 8080; server_name www.lechange.com (file://www.lechange.com/) www.lechangebuy.com (file://www.lechangebuy.com/); index index.html index.htm index.php; root /data/www/ecstore; add_header pos 'web2'; # location / &#123; # rewrite ^/(.*)$ https://www.lechangebuy.com/$1; # &#125; location /public &#123; root /data/www/ecstore; &#125; access_log /data/logs/nginx/access.log; #access_log off; &#125; 而原来nginx是有正常的conf文件，现在又多余了一个这个文件，可见是因为没有无法正常解析.php的文件，两个文件都在占用8080端口时出现了冲突，所以就导致这样php download界面的情况。删除这个多余的文件后，重启nginx，清除浏览器缓存，再重新尝试就正常打开页面了。 为什么会多一个这样的文件，后来把各位运维人员严刑拷打一顿才知道，原来有一次某运维小弟在B服务器里面做跳转的测试，测试完毕之后忘记了把这个多余的文件删除，原本这一切是没有问题的，但是可能服务器nginx经历了重启，于是就加载了这两个conf文件，就把这个隐藏的问题暴露了。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"往github里上传代码","slug":"往github里上传一个代码","date":"2018-02-05T14:40:22.000Z","updated":"2018-02-06T02:15:00.000Z","comments":true,"path":"2018/02/05/往github里上传一个代码/","link":"","permalink":"http://yoursite.com/2018/02/05/往github里上传一个代码/","excerpt":"","text":"说来惭愧，使用hexo博客这么久了，但是真正使用github保存代码却是第一次。因为要打算自己搞一个jenkins试试自动化部署，所以就打算把我那些不堪入目的代码放在github上，然后用jenkins去执行。今天这篇文章就是来记录如何把本地的代码文件上传到github上的过程，本次过程是在windows下操作的。 建立远端仓库首先登录github的界面，然后建立一个新的仓库（repository），如图： 在建立仓库的时候，要注意最好选择一下Initialize this repository with a README这个选项，这样可以省去一些麻烦，如图： 在这里就用我刚建立的仓库—chentest。 建立本地仓库首先我们先去http://windows.github.com/上下载git工具，在安装的时候你还可以顺便登陆，如果没有github账号的话这一步可以跳过的。 安装完毕你的鼠标右键应该多了一个功能Git Bash Here，此时，可以在电脑找一个文件夹，这个文件夹不推荐安装在C盘，假设我就在E盘根目录下叫chentest的文件夹，这个文件夹名称应该与我们刚刚建立的github仓库名称相同。不然的话，可能在git pull的时候爆fatal: refusing to merge unrelated histories这个错误。 在这个chentest的空文件夹空白处，右键鼠标，然后选择Git Bash Here，就会出现一个类似dos的命令行窗口，此时需要输入git init，这个时候发现chentest文件夹里多一个隐藏文件叫.git，这就代表本地仓库已经创建成功了。 配置公私钥然后就是建立一个SSH key，以后你上传任何东西到远端仓库的时候都要输入这个key，那么在命令窗口输入ssh-keygen -t rsa -C &quot;你的GitHub注册邮箱&quot;，此时会让你输入一个文件路径，这个路径就是存放SSH key公钥和私钥的地方，由于我这个电脑已经在默认的/c/user/33664/.git/id_rsa已经存放了hexo博客的上传密钥了，于是我就手动把路径改成了/c/user/33664/.git/id_rsa-github，如图： 这里注意！如果你也之前有一个git id_rsa密钥的话，我个人强烈推荐这个密钥跟之前的id_rsa密钥是一样的。 在浏览器里返回到github的settings主页，在SSH and GPG keys里点击New SSH key，然后就把刚刚生成密钥的pub版输入进去，这个公钥是可以告诉别人的，但是私钥要保密好。如图： 再命令行里输入ssh -T git@github.com，这时候会让你输入一下/c/user/33664/.git/id_rsa的密钥，由于我刚刚把id_rsa-github密钥和id_rsa密钥内容是一样的，所以就输入正确了。如图： 进一步配置此时，再在命令行里输入如下的语句： 12345git config --global user.name \"your name\"git config --global user.email \"your_email@youremail.com\"git remote add origin git@github.com:用户名/Git仓库名称.git #我这个例子里就是chentest.gitgit config branch.master.remote origin git config branch.master.merge refs/heads/master 一个项目可以同时拥有好几个远端仓库为了能够区分，通常会起不同的名字。通常主远端仓库被称为origin。 加完之后进入.git，打开config，这里会多出一个remote “origin”内容，这就是刚才添加的远程地址，也可以直接修改config来配置远程地址。如图： 下载与上传由于这次是我们第一次上传，那么按照惯例，我们需要先下载一下，使用git pull origin master --allow-unrelated-histories，然后输入id_rsa密钥，看见chentest就多了那个README.md文件了。把这个README.md文件改成这样： 12# chentest这是一个做测试的仓库，做好了之后，就先尝试把代码传上去，然后结合Jenkins来搞！ 同时也写一个新的代码，比如这个文件就叫test1.md，里面内容是： 1234#/bin/bashecho \"hello,chrisChan!\"echo \"this is your first git\"ifconfig 这个shell脚本内容就是输出两个废话，然后打印ip地址。保存test1.md，然后在命令行里输入如下的内容： 123git add README.mdgit commit -m \"提交注释\" #这个注释内容是会在网站上体现出来的git push origin master git push命令会将本地仓库推送到远程服务器，而之前说过的git pull命令则相反。同样的输入id_rsa密钥，然后就会看到文件成功上传了！如图： 来到github网站里一看，果然刚刚写的那个test1.md出现了，如图： 结语通过刚才的操作，我想各位应该对github操作有一点初步的了解。其实Git命令行是一个版本控制工具，Github是一个用Git做版本控制的项目托管平台。形象解释的话Git相当于是弓，GitHub是靶，你的代码是箭，弓把箭射到靶上。 参考资料https://www.jianshu.com/p/0fce531dba31http://blog.csdn.net/zhangmingbao2016/article/details/73478899http://www.cnblogs.com/findingsea/archive/2012/08/27/2654549.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"}]},{"title":"Jenkins与Github组合成持续集合环境","slug":"Jenkins与Github组合成持续集合环境","date":"2018-02-05T09:12:22.000Z","updated":"2018-02-05T13:55:54.000Z","comments":true,"path":"2018/02/05/Jenkins与Github组合成持续集合环境/","link":"","permalink":"http://yoursite.com/2018/02/05/Jenkins与Github组合成持续集合环境/","excerpt":"","text":"生成Token码首先登录github，在首页选择settings，如图： 然后点击最下面的Developer settings，点击Personal access tokens，最后点击Generate new token，如图： 输入名称和权限，权限选择repo和admin:repo_hook这俩，如图： 然后就会生成一个token密码，这个token密码请妥善保存，丢失或者删除就GG了。 将Token码配置到Jenkins浏览器返回到Jenkins界面，在首页里点击系统管理，然后选择系统配置，在系统配置里面添加一个GitHub Servers，在Add Credentials这一步的时候，要把kind改成Secret text，如图： 这里Secret的地方就是填写刚刚生成的Token码。 保存之后，点击一下test connection，如果出现Credentials verified for user xxx, rate limit: xxx的字样就是成功了，如图： 设置webhooks在github里找一个源码库，选择settings，然后点击小菜单栏里的Webhooks，再点击右边的Add Webhook即可，如图：","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://yoursite.com/tags/Jenkins/"},{"name":"持续集成","slug":"持续集成","permalink":"http://yoursite.com/tags/持续集成/"}]},{"title":"Jenkins的安装与创建简单任务","slug":"Jenkins安装与创建简单任务","date":"2018-02-05T03:23:04.000Z","updated":"2018-11-06T03:38:46.000Z","comments":true,"path":"2018/02/05/Jenkins安装与创建简单任务/","link":"","permalink":"http://yoursite.com/2018/02/05/Jenkins安装与创建简单任务/","excerpt":"","text":"安装与启动环境：CentOS 7.0 + java 1.8 安装方式： 12345yum install yum-fastestmirror -y #安装自动选择最快源的插件#添加Jenkins源:sudo wget -O /etc/yum.repos.d/jenkins.repo http://jenkins-ci.org/redhat/jenkins.reposudo rpm --import http://pkg.jenkins-ci.org/redhat/jenkins-ci.org.keyyum install jenkins #安装jenkins 启动方式：sudo service jenkins start，如果没有java是无法启动的。 Jenkins默认端口是8080，如果要更改端口，需要先vim /etc/sysconfig/jenkins，然后修改JENKINS_PORT=&quot;8080&quot;为自己想要的端口号即可。 访问方式：浏览器输入http://your server ip:8080/，然后会看到这样的一个界面，打开这个文件，输入里面的key就可以访问jenkins了。 然后就是让你安装插件，如果是新手的话，可以安装系统推荐的插件，如果插件安装失败不要怕，可以日后手动补上。 插件安装完毕之后，就是自己创建一个管理员账号和密码，输入之后，点击右下角保存并完成。 然后就可以看到Jenkins初始化的首页。 镜像安装docker安装jenkins也很简单粗暴，但是官方的jenkins镜像可能拉取比较慢，推荐先去加速，国内docker加速的方法在此：https://rorschachchan.github.io/2018/04/20/%E5%9B%BD%E5%86%85Docker%E7%9A%84%E5%8A%A0%E9%80%9F%E6%96%B9%E6%B3%95/ 。 安装步骤如下： 123456docker pull jenkins cd /data/docker run -d --name jenkins -p 8080:8080 -v /data/jenkins:/var/jenkins_home jenkins #做了一个挂载chown -R 1000 /data/jenkins #将权限打开，不然的话jenkins无法正常启动docker start jenkinscat /data/jenkins/secrets/initialAdminPassword #网页需要的验证码 此时登录http://your server ip:8080/就会正常访问了，其余的步骤跟上面的一致。不过镜像安装有点瑕疵，就是tag是V2.60.3，有点老，有些插件已经不支持了。 创建任务假设现在要创建一个Job(任务)，这个任务就是输出当前服务器的外网IP地址，那么就点击首页里的新建任务，然后输入任务名，补充一句，生产环境里的Job名最好不用中文，不做死就不会死，然后选择构建一个自由风格的软件项目，如图： 在源码管理的地方，我们暂时选择None，待日后把jenkins与github相关联之后，就可以通过github来配置源码了。在构建触发器的地方，我们选择Poll SCM，这里说一下这几个触发器选项的意思： 1234Build after other projects are built： Build periodically ： 周期进行项目构建（它不关心源码是否发生变化），可以配置如下：0 2 * * *（每天2:00 必须build一次源码）Build when a change is pushed to GitHub： 只要github上有提交了，jenkins没有自动检测到并构建，这设置之后在github中也需要设置才能生效Poll SCM：定时检查源码变更（根据SCM软件的版本号），如果有更新就checkout最新code下来，然后执行构建动作。可以配置如下：*/10 * * * * （每5分钟检查一次源码变化） 构建步骤这里有很多的选项，我们选择Execute Shell，里面可以写shell命令也可以写shell脚本，这里我就写入一个很简单的ifconfig命令去查看一下IP地址，如图： 构建后操作这里也有很多的选项，这里我选择E-mail Notification，然后输入自己的邮箱地址，这样如果构建失败了，就可以发邮件提醒。如图： 配置完毕之后，点击左下角保存即可。 查看任务效果返回到Jenkins的首页，我们看到多了那个刚才新建的任务，然后点击任务名旁边的小三角，选择立即构建，如图： 然后就会看到构建的历史，点击任意历史记录的控制台输出，就会看到效果，的确是操作了ifconfig命令的效果：","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Jenkins","slug":"Jenkins","permalink":"http://yoursite.com/tags/Jenkins/"},{"name":"持续集成","slug":"持续集成","permalink":"http://yoursite.com/tags/持续集成/"}]},{"title":"Zookeeper集群的搭建与配置","slug":"Zookeeper集群的搭建与配置","date":"2018-02-05T02:15:21.000Z","updated":"2018-05-30T19:10:34.000Z","comments":true,"path":"2018/02/05/Zookeeper集群的搭建与配置/","link":"","permalink":"http://yoursite.com/2018/02/05/Zookeeper集群的搭建与配置/","excerpt":"","text":"Zookeeper的下载地址：https://github.com/apache/zookeeper/archive/master.zipzkclient的下载地址：https://github.com/sgroschupf/zkclient 至于zookeeper的作用和原理我这里就不多赘述了，大家有兴趣可以去查查，这里主要就是动手操作。 搭建集群首先先看一下本次zk实验服务器的名称和IP情况，这里我们选择了三台服务器作zkserver，因为三台是标配，一台的话就只有leader没有follower，不是很稳定的结构，当然啦如果你的公司土豪的话是可以玩三十台： 123dvl-mrszk-001 10.117.0.125dvl-mrszk-002 10.117.1.158dvl-mrszk-003 10.168.152.227 对这三台服务器都要进行如下的步骤: 1)先把zookeeper.zip传到linux里，然后解压到/usr文件夹下； 2)进入/usr/zookeeper/conf文件夹，vim zoo.cfg，在最下面补充上面的三个zkserver，见图： 3)再来到/usr/zookeeper/data文件夹，如果里面有文件就清空所有文件，如果是1号zkserver就echo 1 &gt; myid，如果当前机器是2号zkserver就echo 2 &gt; myid，依次类推，这里一定要注意，不可以都写一样。 4)vim /etc/hosts，还要把这三台机器的ip地址和名字都写进去，如下： 12345127.0.0.1 localhost::1 localhost localhost.localdomain localhost6 localhost6.localdomain610.117.0.125 dvl-mrszk-00110.117.1.158 dvl-mrszk-00210.168.152.227 dvl-mrszk-003 5)再来/usr/zookeeper/bin文件夹，./zkServer.sh start启动zk，然后再./zkServer.sh status查看进程情况，如图看见第一台和第三台zkserver的身份是follower，第二台是leader： 至此整个zk集群就搭建并且启动完成了。注意：zookeeper集群时，zookeeper要求半数以上的机器可用，zookeeper才能提供服务。 故障排除如果这里有启动失败的情况，比如Error contacting service. It is probably not running.这样的字样，那么有这么几种可能：1）data文件夹下的myid有数字重复或者是数字漏写的情况；2）zoo.cfg里的指定日志文件夹没有手动创建；3）/etc/hosts下的名字与zoo.cfg里的server字段不相符，注意一下，/etc/hosts里的127.0.0.1的名字不要与本ip后面的名字一模一样，不然zk也无法识别！4）/etc/hosts名字使用了中文，java系对中文是很不友好的。 如果出现的Cannot open channel to X at election address /A.B.C.D:3888的日志报错，检查一下zoo.cfg里的123与myid的123是否一致。 配置文件详解1.tickTime：这个时间是作为 Zookeeper 服务器之间或客户端与服务器之间维持心跳的时间间隔，也就是每个 tickTime 时间就会发送一个心跳。2.dataDir：顾名思义就是 Zookeeper 保存数据的目录，默认情况下，Zookeeper 将写数据的日志文件也保存在这个目录里。3.clientPort：这个端口就是客户端连接 Zookeeper 服务器的端口，Zookeeper 会监听这个端口，接受客户端的访问请求。4.initLimit：这个配置项是用来配置 Zookeeper 接受 客户端（这里所说的客户端不是用户连接 Zookeeper 服务器的客户端，而是 Zookeeper 服务器集群中连接到 Leader 的 Follower 服务器）初始化连接时最长能忍受多少个心跳时间间隔数。当已经超过 5个心跳的时间（也就是 tickTime）长度后 Zookeeper 服务器还没有收到客户端的返回信息，那么表明这个客户端连接失败。总的时间长度就是 52000=10秒。5.syncLimit：这个配置项标识 Leader 与 Follower 之间发送消息，请求和应答时间长度，最长不能超过多少个 tickTime 的时间长度，总的时间长度就是22000=4秒。6.server.A=B：C：D：其中 A 是一个数字，表示这个是第几号服务器；B 是这个服务器的 ip 地址；C 表示的是这个服务器与集群中的 Leader 服务器交换信息的端口；D 表示的是万一集群中的 Leader 服务器挂了，需要一个端口来重新进行选举，选出一个新的 Leader，而这个端口就是用来执行选举时服务器相互通信的端口。如果是伪集群的配置方式，由于 B 都是一样，所以不同的 Zookeeper 实例通信端口号不能一样，所以要给它们分配不同的端口号。 验证成果Zookeeper的配置工具叫Zooinspector，下载地址是：https://issues.apache.org/jira/secure/attachment/12436620/ZooInspector.zip，下载完直接解压缩就可以在windows里使用。 我们实验的这三台服务器只有内网，但是如果要连接zooinspector，还是需要通过外网权限连接的，这里可以配一个iptables转发规则，配iptables的步骤在这里：http://chenx1242.blog.51cto.com/10430133/1875950 ，照葫芦画瓢即可，但是要注意，zk的端口是2181。 当然，如果不想费事的话，就直接给zkserver配一个外网IP，直接连接。 成功连接到zooinspector，就会看到这样的内容，这里的lcconfig是手动添加的，右击鼠标，选择add node，然后直接写上lcconfig就行，这个名字是根据实际需要填写的： 上面我们已经配置了zkserver集群而且还启动zkserver进程，现在还需要zkclient，zkclient就是请求发起的一方，然后我们可以在各个的模块服务器上部署zkclient服务，通过启动zkclient服务，来让这些模块统一从zooinspector里取值，这样就达到了批量配置，同时保证一致性的效果。 zk的模板文件是_tpl.properties为结尾的文件，我这里模块的名字叫mrs，那么在实验里这个模板文件就是mrs_tpl.properties，这个mrs_tpl.properties里有这样的一个字段，如图： 而我们在zooinspector里对应就这么填写： 保存zooinspector，然后从windows返回到linux，启动zkclient服务和对应的模块进程，如果配置都正常的话，那么程序就会正常启动，ps -ef|grep java就会看到一个叫lczk.AppServerDaemon的进程。这个时候在去看一下mrs的配置文件： 可以看到areaAk取得值就是zk里面data_center里面access_key里面的ak的值，其他的几个值也是同理。可见整个zk已经配置成功，模块都进行了统一配置，而且这些配置既然能被一个接受，同时也会被其他相同的模块服务器所接受。这样就达到了批量配置的效果。 拓展阅读http://ibruce.info/2014/10/23/zookeeper/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"},{"name":"zookeeper","slug":"zookeeper","permalink":"http://yoursite.com/tags/zookeeper/"}]},{"title":"Uwsgi的安装和简单使用","slug":"Uwsgi的安装和简单使用","date":"2018-02-02T10:41:29.000Z","updated":"2018-02-02T10:50:20.000Z","comments":true,"path":"2018/02/02/Uwsgi的安装和简单使用/","link":"","permalink":"http://yoursite.com/2018/02/02/Uwsgi的安装和简单使用/","excerpt":"","text":"正文运维平台的搭建已经提上日程，而我选用了大家比较常用的Uwsgi+nginx+django的架构，这里先记录一下安装Uwsgi的过程。 这里解释一下Uwsgi+nginx+django，我们整个流程如下图： 这里我们可以看出，web server是无法与我们的app（django等等）进行直接对话，他需要通过uwsgi这个桥梁，这个桥梁很重要，虽然我们使用django的runserver功能也会打开一个页面，但是这个页面是很脆弱的，小规模使用还好，要是放在网络上供很多人点击的话，根本就是脆不经风。 uwsgi是啥，请查看文末的参考资料，写的已经非常好了。我这里就简单说下： uwsgi 实际上也是一个http服务器，只不过它只面向python网络应用程序。虽然uwsgi也是http服务器，但是却不能直接使用它部署python web应用程序，否则会出错。 在本文中，uwsgi所扮演的的角色是后端http服务器，nginx扮演的角色是前端http服务器，hello.py是客户端应用程序。用户从网页浏览器中发出请求，nginx服务器收到请求后，会通过它的uwsgi模块将用户的请求转发给uwsgi服务器，uwsgi服务器处理完毕后将结果返回给 nginx，浏览器将最终的结果展现给用户。 Uwsgi的安装比较简单，推荐使用yum install Uwsgi直接下载使用，而不推荐用pip install uwsgi，因为pip安装的话，虽然也能成功（如下图红框），是没有uwsgi.ini文件的，其实没有这个uwsgi.ini是无足轻重的，因为这个文件可以自己写，但是对于生手来说，没有这个文件可能会心里发毛，就无法按照攻略继续下去，所以我更推荐用yum安装，如图： 为了纪念我们的金刚狼同志，我们就写一个叫logan.py，里面的内容是这样的： 123def application(env, start_response): start_response('200 OK', [('Content-Type','text/html')]) return \"good bye,Logan...\" 然后我们就可以启动这个uwsgi看看效果，使用uwsgi --http :8001 --wsgi-file logan.py，把端口设定为8001，同时指定协议是http，然后加载的文件就是logan.py，启动之后，如图： 遇到这种情况，你就yum install uwsgi-plugin-python，然后把命令做一点点修改，改成：uwsgi --plugin python --http-socket :8001 --wsgi-file logan.py。 屏幕会出现一大堆文字，然后提示，uwsgi已经启动成功了。在浏览器输入服务器外网地址:8001看一下效果，如图： 我们在root目录下再写一个测试的文件，这次我们写一个比较老实的python脚本来测试，这个脚本就叫test.py，里面的内容如下： 12345678910#!/usr/bin/python#coding=utf-8import osimport sysdef application(environ, start_response): status = '200' output = 'this is a test for uwsgi,HOHO~' response_headers = [('Content-type', 'text/plain'),('Content-Length', str(len(output)))] start_response(status, response_headers) return output 还是用刚才的方法，依旧可以打开网页，其实上面这个简单的uWSGI程序更好理解整个套路，只需要实现一个名为application的函数就可以了，该函数有两个参数，environ为包含有http请求的环境变量，start_response为一个函数，用来设置http头。在这个函数里，我们只需要调用一次start_response函数，设置一下HTTP返回头，再return一个HTTP body即可。 至此，整个uwsgi就安装成功了。 参考资料http://xiaorui.cc/2017/02/16/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3uwsgi%E5%92%8Cgunicorn%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%9E%8B%E4%B8%8A/http://uwsgi-docs.readthedocs.io/en/latest/tutorials/Django_and_nginx.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"uwsgi","slug":"uwsgi","permalink":"http://yoursite.com/tags/uwsgi/"}]},{"title":"从excel的大单元格里快速提取内容","slug":"从excel的大单元格里快速提取内容","date":"2018-02-01T02:42:54.000Z","updated":"2018-02-05T04:24:48.000Z","comments":true,"path":"2018/02/01/从excel的大单元格里快速提取内容/","link":"","permalink":"http://yoursite.com/2018/02/01/从excel的大单元格里快速提取内容/","excerpt":"","text":"我公司的服务器信息会保存在一份高加密的excel里，由于历史遗留问题，里面的格式节选一部分出来是这样的： 注意看，ip地址不分内网外网是放在一个大的单元格里，中间是用空格隔开的，造成了这样的视觉效果。 现在公司需要把所有的服务器重新更换到新的zookeeper，那么使用ansible在批量处理的时候，就需要提取这些服务器的内网ip地址录入到/etc/hosts文件里，但是由于服务器实在太多不可能一个一个手动从excel的单元格挑选出“内网IP地址”复制粘贴，那么就需要进行一下批量挑选内网IP地址的操作。 首先我们先把整个IP的单元列里的”（公）””（内）”的字样去掉，然后把整列全部拷贝，粘贴到notepad里，看到它们变成了这样的样子： 在notepad里，双引号之间的内容会被认为同一行，所以这里我们需要使用“替换”功能把所有的双引号去掉，让它变成下面这样： 这样就可以把上面的内容复制到一个新的excel去，发现每一个内容对应了一行，即一个小单元格： 然后我们把第一行染成黄色，第二行染成绿色，当然颜色你可以选择自己的口味，然后使用excel的“格式刷”功能，一拉到底，让他们变成条纹状： 然后在excel里找到“筛选”功能，先选择住这一条纹块，然后选择“按颜色筛选“，由于我们需要内网IP，那么我们就留下绿色内容即可，如图： 得到效果如下： 这样就可以把整个内容拷贝进ansible的hosts文件里，然后搭配ansible批处理这些内网IP，双管齐下，大大的提升了提取数据的效率。 如果遇到偶尔三行（即中间有空格行）的情况，那么就在notepad那一步的时候，把空格行干掉，不如下图的情况里，第五行和第八行是空格行，可能是当初记录人员复制的时候自带了空格： 如果是空格很多的情况，那么就需要批处理一次性的把所有空格都干掉。干掉的方法，还是使用notepad的“替换功能”，选择“正则表达式”，然后把\\n[\\s|]*\\r替换成空值就可以了。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://yoursite.com/tags/ansible/"},{"name":"excel","slug":"excel","permalink":"http://yoursite.com/tags/excel/"}]},{"title":"再见，魔兽世界","slug":"再见，魔兽世界","date":"2018-02-01T01:56:20.000Z","updated":"2018-02-02T10:35:32.000Z","comments":true,"path":"2018/02/01/再见，魔兽世界/","link":"","permalink":"http://yoursite.com/2018/02/01/再见，魔兽世界/","excerpt":"","text":"var ap = new APlayer({ element: document.getElementById(\"aplayer0\"), narrow: false, autoplay: false, showlrc: 0, music: { title: \"暴风城主题音乐\", author: \"World of Warcaft\", url: \"http://p1x3hd2at.bkt.clouddn.com/stormwind.mp3\", pic: \"http://p1x3hd2at.bkt.clouddn.com/wow.jpg\", } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 这张月卡马上就要用完了，我想我的《魔兽世界》生涯也要到头了。 地球时代我是从大学的时候就开始接触《魔兽世界》，当时是在同寝的xur同学的推荐下，注册账号买了CDKey，然后跟着他在六区黑翼之巢创建了角色，那是一个留着武士头和山羊胡的暗夜精灵德鲁伊，起了个带有劲舞团性质的ID叫“删除过去”。记得德鲁伊刚出生是人形态，泰达希尔里背着一个木棒棒，靠着“愤怒”这个技能打人。于是乎，我就搓出了一个又一个原谅色的冲击波，波遍了泰达希尔的每一个角落，波倒了一个又一个萨特和野熊。当时我作为一个萌新，什么都不懂，后来在一个另外的德鲁伊的帮助下，开始做任务升级，顺便粗略的了解了魔兽最基本的操作。这个德鲁伊是我在游戏里认识的第一个朋友，是一个萌妹子，ID叫什么我忘了，不过后来她游戏上的很少了，依稀记得后来某一个半夜我在西瘟疫之地变成小豹子一个一个挠亡灵的时候，她上过一次线，等级好像是20~30级的样子，我俩说了一会话，具体说的是什么我已经记不清了，那就是我俩最后一次说话。 从泰达希尔港出来，我就开始了艾泽拉斯的冒险之路：去月光林地学变熊变豹子，拖尸到血色修道院，打过那么一两次诺莫瑞根，在荆棘谷的森林里穿梭，长期蹲在塔纳利斯刷“XD求组祖尔法拉克”。 当时寝室里没有电脑装wow，总去学府三和学府四那两条街的网吧玩，就这样我成了被盗号的重灾户。记得最过分的那次上号发现角色干脆消失了，还有一回上号发现，角色被扒的就剩下一个裤衩、一个披风和一个狼头样子的皮甲头，还别说，这造型跑出去比较拉风。后来九城推出了密保卡，就是充值卡后面的8x8的数字卡，虽然有一小段时间遏制了盗号，不过缺点就是要随身带着密保卡。在网吧开机坐下了发现没带密保卡，又跑回寝室取卡的事情，我当初可没少干。 这个德鲁伊就这样摸爬滚打到了六十级满级的时候，开始刷三大本（前后斯坦索姆，通灵学院，黑石塔上层），那时候的黑下是一个冷门本，黑石深渊更不要说了，打一次就花费了几乎一下午的时光。那段反复的刷斯坦索姆和通灵学院的日子给银色十字军捐过不少亡灵印记。后来加入了工会跟工会开始打熔火之心，记得公会团长叫火枪队长，一个男人类战士，其他的一团的队员我现在还能记住名字的有：京乐春水（德鲁伊）、Hater（女人类牧师），魂之血杀（暗夜大元帅战士）。那时候的MC已经没有DOT限制了，但是还要做水元素任务，带着圣水去灭火。接触的第一个G团是祖尔格拉布，当时德鲁伊是一个稀缺职业，我就开始去打工兼消费挣俩小钱，用那点G去买拍爪子的材料。在祖格G团认识了同大学的一个哥们，叫阿尔萨斯之心，是一个女人类圣骑士，他那个时候就有祖格龙了，但是没玩太久，60级没完事就把号给卖了…MC通了后，公会团开始打黑翼之巢，我记得当时的BWL老1还有BUG，远程和治疗可以跳在窗户上。到了老2就卡的死去活来，好不容易过了老2，接下来的三个就一片通途。然后又花了一个晚上打掉了克洛玛古斯。我那时候奈法利安和克洛玛古斯打得不多，仅有的几次击杀也没有掉落怒风胸和怒风肩，这成了我60级的一个怨念。 在打BWL的时候，安其拉版本已经开始了。G团也开始做安其拉废墟的生意，我也在其中一次无疤者奥斯利安的身上得到了废墟法杖，换掉了之前埃克索图斯的挖掘锤，为了这个废墟法杖我还卖了一张卡，那时候一张卡是300G，那次好像是我唯一的一次卖卡。说到卖卡我想起来，我人生的第一只千金虎是一个暗夜盗贼赞助的，ID好像叫小什么哥，当时的G真的很值钱，非常非常感谢他。 我在地球时代RAID的最高纪录就是安其拉神殿到公主、NAXX打了蜘蛛区前二、DK区到了老1、憎恶区的帕奇维克好像是没过，反正就是一个很一般的进度啦。然后公会团就有了一些动荡，我个人总觉得德鲁伊打人不爽，还是拿起大刀砍人过瘾，于是就开始了玩战士小号的生涯，ID叫燕小鱼。战士满级后不久就开了“远征前夕”，也就是那个全民刷战场换大元帅的时代。我那时候也在YY里加入了联盟军校，开始了没日没夜刷大奥的日子，先换了猪头锤，又换了雷矛羊，最后拿着一堆牌子去换一身漂亮的大元帅，直到现在我的YY名称依旧是以“联盟军校”开头。 我玩战士的时候还认识了一个男矮人牧师，叫赤红丹朱，这个哥们手法很骚，以前是玩部落的，记得有一次我俩要去荒芜之地，在莫高雷的高原上，他说这里曾经是他玩部落开始的地方，然后看着脚下这片大草原心潮澎湃，我俩一起战斗过不少副本，从斯坦索姆到祖尔格拉布，他没有坚持到70级就不玩了，账号也给我了…我后来去他的新浪博客看过，背景音乐是王若琳的《有你的快乐》，后来的某一天，发现他的新浪博客内容就被全删光了。 燃烧的远征记得那是7月份，大二刚开学没多久，我就穿过黑暗之门开始了燃烧的远征。那时候我先升的是战士，在地狱火堡垒里面拿大砍刀砍来砍去。七十级的raid就是先从卡拉赞开始，当时我的小战士就当主t，当时跟的团团长ID是叫小豆宝宝，一个侏儒术士。那时候卡拉赞的bug很多，埃兰可以卡门，马克扎尔王子也可以卡地点。我个人对于卡拉赞比较有印象的是虚空龙，那是这个十人小团队一个比较有成就感的boss。 往后就是打格鲁尔，那个时候我记得隔壁寝室的老朱已经开始练他的女暗夜盗贼了，那个时候我俩开始比较频繁的厮混在一起，肩并肩的不上课跑去网吧打魔兽，我印象最深的一次就是他当时为了刷一个午夜护腿在沙塔斯找了一个猎人，但是这个猎人不是很靠谱，在奴里围栏一个人忙乎从早上八点到晚上八点，结果还没出，给老朱气得牙痒痒。 TBC的时候，就有了日常任务的概念，每天早上要做奥格瑞拉和虚空龙任务，后来又有了奎岛日常，日复一日的刷声望。玛瑟里顿这个副本公会团当时没有正经打，直接就开始打风暴要塞，当时打掉了凤凰和奥术师和机器人。而毒蛇神殿我跟公会打得不多，记得有打过瞎子外加鱼斯拉。这个时候，邪神禁地祖阿曼上线了，开始了有事没事冲箱子的新征程。我印象里整个70级就是一个很多bug的版本，祖阿曼体现的尤为明显，里面BUG有术士副本拉人以及祖尔金跳柱子。但是即使这样我也只冲成功过一次四箱，那一次是t6级别队伍带队，完全没用bug。除了那一次剩下的基本就是两箱，三箱屈指可数。 然后我现实的一个的哥们由于学业的问题不能继续跟团队RAID无奈只能把账号暂给我打理，于是我改玩了他的暗夜女精灵牧师，ID叫外面下雨了（后面简称下雨）。我开始跟《荣耀》公会活动，会长就是鼎鼎有名的震撼。荣耀公会最早是桑德兰服务器的，后来由于想当联通区的第一工会，就集体转服到泰拉尔。当时我也是第一次接触牧师，完全是抱大腿的姿势跟他们一团打掉阿克和伊利丹。他们打阿克因为要录视频所以是不用bug的，真真的要考验跑火的功力。第一次打伊利丹我印象很深，当时寝室里有电脑了，由于很多人当时进度很慢，所以打伊利丹的时候，全楼道的wower都来看，然后啧啧惊叹。 跟着震撼一边打进度团也一边打公会的G团，记得当时t5一套是五万金，t6一套是十五万金。再加上卖武器饰品，一趟下来也分到不少，而且还能直接跟老板换卡，据说公会当时用的付费ts语音也是用老板的钱买的。 那时候打进度团主要就是开荒太阳井，我用那个牧师号拿了全服第一个t6鞋，首down双子的战报也上了nga，地址在：http://nga.178.com/read.php?tid=1644774 ，视频也被传上了优酷，但是现在那个视频找不到了，不过记得BGM还是很好听的。当时进度团活动时间是晚上七点到早上五点，真的很累人，最后击杀基尔加丹我并没有参与。但是震撼的指挥和语音口头禅给我留下了很深的记忆，他的确是一个很赞的指挥。 燃烧的远征也是我寝室山哥沉迷魔兽并且活跃的日子，当时山哥投奔了部落玩德鲁伊。我记得他们团第一次过血沸很惊险，当时血沸还有大约5%的血，T都躺光了，就在BOSS准备大肆屠杀的时候，结果血沸那时候点名，好巧不巧的点名了一个盗贼，那贼开着闪避上去顶掉了最后5%的血。其实FD就是这样，需要实力的同时也需要那么一点运气。 巫妖王之怒当时由于大陆魔兽推迟开巫妖王，那时候我跟老朱、涛哥、永森、老刘、阿俊、小勇几个寝室的哥们还有那个下雨一起转战去了台服，改玩部落。当时我是防骑，老朱改玩牧师，涛哥是法师，老刘是盗贼兼指挥，小勇是术士、阿俊是德鲁伊、永森是萨满，下雨依旧是牧师，不过老朱主要玩的是神牧，下雨主要是暗牧，必要的时候会切奶。 老朱的魔兽之路开始于60级，当时他第一个职业是法师，最开始的时候他跟xur打赌会尽快的把等级练到骑小马的等级，话说老朱练号的速度是很快的，他也是我们几个人里玩职业好象最多的。从法师到萨满，然后还有盗贼，但是直到这次玩上了牧师，他终于找到了灵魂的归属，发现原来牧师才是他的本命。 除了老朱我多说说老刘，老刘原名刘义超，是我们年级的一个牛人，很瘦，戴个眼镜，走路有点发飘。用他话说从小身体就不好，所以不是很喜欢运动，除了打魔兽打dota就是看漫画再不然就是用psp打麻将，老刘的经典语录就是“对于我来说，每一把DOTA都是一把新的DOTA”。老刘是一个很聪明的人，打游戏思路很清晰，很少反重复的错误。他为了游戏也肯砸钱，那时候都是老刘给我们搞代理。老刘巅峰的时候在第七天堂打主力牧师，我也亲眼见过他那时候打便当二十五人英雄十字军，后来由于要带我们几个就放弃了第七天堂，转来跟我们一起组团队。当时我们几个人一边小团队打十人icc，一边也跟个工会活动。 不过后来老刘觉得公会团打得不爽，揭竿而起，自立门户开起了25人H ICC金团。每周四，都会看到一个叫德意忘形的德鲁伊在达拉然喊人刷屏，喊满了就向冰冠堡垒浩浩荡荡的出发，由老刘带队指挥，当然我们也会偷偷摸摸的黑下几件装备和一点金。老刘指挥虽然不如震撼激情，但是思路很有条理，基本上战斗力不算很差的团一个下午就打掉2到3个区。当时我已经大四下半学期了，由于有驾校考试，所以当时老刘的金团我参与了也就一半，不过在金团里我得到了大盾冰冠冰川之墙，当时好像是花了4万金。最可惜的一次就是他们有一次开出了英雄的异物逐除，卖了17万金，按当时的物价换算是二千多块人民币!那次的金团真是赚翻了。 我们十人团的进度是“十人十字军试炼最高差两次就大十字军”、“ICC普通全通”、“h我记得没过冰龙”，因为不久就要毕业了，就没有很全力的去开荒。毕业后从此我们几个战友就四散天涯：老刘回齐齐哈尔，永森和阿俊回佳木斯，涛哥留在哈尔滨，我、小勇和老朱回大庆上班，而下雨就一直在国外，直到现在也没有回来。 现在除了涛哥和老朱，我还有联系之外，其他人我已经联系不上了，也不知道他们过得好不好。 魔兽的八十级之前的版本可以说陪伴了我在大学的大多数时光，那也是我魔兽生涯唯一玩部落的时光。 大地的裂变到了八十五级我又回归国服了，重返联盟命。由于大学里各位同学都开始了新的生活，我也开始直到现在的魔兽独行侠之路，独自练级独自打战场。 也从此之后，我就再也没有正经的跟过公会团，要么是打随机本看看剧情，要么就是打金团。其实我对八十五级的印象不多了。不过要说一下，八十五刚开始的5h真的很难，经常小怪的治疗一个打断不到就满血了，记得那时候打一个影牙城堡就累的死去活来。硬要说大裂变里印象比较深的，也就是打托尔巴拉德和打巨龙之魂，比如很多战士一起开剑刃风暴一起命令怒吼，场面非常壮观。那个时候我也把战士的种族转成了狼人，也背上了触手剑爬在地上跑来跑去。最后没事干，就趁此机会又练起来一个牧师和一个女人类圣骑士，开始了我的圣光追寻之旅。 熊猫人之谜到了九十级，朋友也多了起来。主要是跟单位里的磊哥、建哥、亮哥和迪哥一起在奥拉基尔服务器玩。磊哥原先是亡灵贼，后来投奔了联盟转了女人类，但是一直都纠结女人类的动作不如男亡灵飘逸。磊哥自封外号“阿拉希小王子”，长期在农场神出鬼没，也善于在战歌抗旗。迪哥是男德莱尼萨满，满地插柱子，他是一个个性男人，死活不去网吧，坚持就在家里玩。不过迪哥玩魔兽的时间并不长，也就几个月的时间他就投奔去三国杀和单机游戏了。健哥是一个猎人，单刷无敌，他那时候是我们几个里最有G的，输出也最为残暴，不过后来他由于工作原因也忍痛割爱了。亮哥是血DK，号称“通信公司第一DK”，不过我们四个很少玩在一起，毕竟上线时间其实是错开的。 熊猫人的本我印象比较深的就是“攻打奥格瑞玛”，至于之前的恐惧之心、永春台神马的我压根就没参与过。当时我的小牧师也算练的不错了，主要得益于我下班没事经常混迹在NGA看帖子，再加上那个版本对戒律牧也特别的友好，偶尔在金团也能拿到治疗第一的补助。而磊哥一直想要箱子BOSS的马刀，最后他也算圆梦了。至于建哥一直眼馋的火鹰，好像一直都是没有达成。 这里我要感谢磊哥，当时我俩在祖尔格拉布翻新之前去刷过祖格虎，结果出虎的时候，磊哥高风亮节让给我了，满足了我开上“红色法拉利”的梦想。 德拉诺之王一百级给我的游戏感觉就是高开低走，尤其是要塞，从最开始新鲜成了后期的累赘。虽然它给了我很多战火装备，但是也让我越来越少出去。整个德拉诺之王我最喜欢的副本就是黑石铸造厂，很有六十级副本的味道，容错率很低。那个时候也认识了以骄傲纹身为首的几个朋友，也打了金团攒了不少钱，这些钱后来也都被我换成了点卡。 至于地狱火堡垒这个副本我印象不多，翻来覆去就打了两三遍h，还都是跟G团，最后过了h的阿克蒙德，m难度我压根没尝试，后来由于公司里各个朋友们由于现实各种情况AFK，我也开始改玩单机游戏，上号就是刷刷阿什兰和四本刷金，消磨时间休闲娱乐。 军团再临到了一百一十级，几乎整个一百级都没玩的老朱重返魔兽，一口气练了牧师、死骑和恶魔猎手三个职业，我俩也配合打了几个高层大秘境，没有老朱的日子就是我自己慢慢肝神器，每周争取打一次低保，再混一次世界BOSS。也就是这张点卡玩完，我觉得魔兽已经对于我来说没有什么留恋的了，该体验的我差不多都体验过了，没体验到了我也不在乎了。我把牧师停在暴风大教堂，把战士停在暴风要塞，把圣骑士停在激流堡，下线。 至此，我整个魔兽的生涯就算总结完了。 PVP有关地球时代的野德不算很强，除了战歌抗旗好像就是补刀了。那时候我看过一个叫dazeroth的暗夜德鲁伊Unstoppable系列视频，觉得很吊，他的视频不算很多，但是打得很棒，然后再看德鲁伊就是一个中国风很浓的暗夜德鲁伊视频，但是我忘了他的名字了。改玩了战士之后，就看Swifty的视频和苹果牛的视频，看直播就看太极龙。牧师的话，看Hydra是最多的。 我个人认为PVP是魔兽的一个重要的玩法，不过这种玩法随着玩家属性暴涨而变得不再公平（不过有几个乱斗还是挺好玩的）。我竞技场打得不算多，从70年代组织55战队去每周去混10场到现在，加起来不超过200场的JJC实战经验。不过战场混得经验丰富，打一些战场也有自己的心得，比如征服之岛要上来抢车间，大奥如果速推不成功就要抢冰雪墓地耐心打平推，打战歌中场压制住了等于赢了8成，风暴之眼先抢墓地再抢骑，控制了地盘后第一时间去墓地堵人等等等等。但是战场毕竟各位玩家PK水平参差不齐，打战场其实更多就是一个图个乐。 至于搏击俱乐部，我没玩太多，不过金牌挑战我还是很喜欢的。 结束语魔兽世界陪伴了我12年的时光，现在回首来看，我个人最喜欢的是WLK，因为那个版本装备比较好看，其次相对来说各个职业的能力都比较平均，最重要的就是身边有一堆战友并肩作战；其次就是TBC，他在一定程度上弥补了很多60级的缺陷，而且极大地提升了惩戒骑、野德、元素萨等混合职业的存在感，不过TBC的BUG实在太多（我重复几次了？），光一个阿克我就见识过不下4种BUG打法，这一点是TBC的败笔；再其次就是90级和地球时代；大灾变和军团再临他们俩并列再后面一点。 我爱魔兽，他是我的另一个世界，因为我觉得在现实世界里能做的事情，在魔兽世界能做的更多。不可否认，我曾经在魔兽世界上投入了大量的时间，这耽误了我很多现实中的事儿，不过我还是认可它给我带来了不少的快乐。我还记得在06年的路边书摊会买魔兽世界带副本地图和掉落的攻略的那个宅男；我也记得当初那个小德鲁伊在灰谷，一边看着新浪魔兽任务详解，一边在地图上费劲的查找线索；我也记得当初圣骑士到了查索拉盆地的时候，被那种仙剑风的音乐陶醉；我也记得在阿什兰和奥特兰克山谷，战士那一身部落血的豪爽。但是一切缘分都有到头的时候（或许我将来会有机会到网易的魔兽世界部门上班，不过这个暂且不提），虽然我不能亲眼看见联盟一统艾泽拉斯，但是我还是要说，谢谢暴雪做的这款精良的游戏，感谢你陪我走过的这12年，谢谢跟我并肩作战过的战友，没有你们，我也无法享受这段丰富而美好的时光。 最后，我要用《军团再临》里面伊利丹的那个口信内容作为我整个魔兽世界生涯的结尾： 我留下的水晶里其实有三条口信 最后一条是给你的，勇士 你证明了你对艾泽拉斯的忠诚 你的奉献和牺牲都足以与我媲美 但你还得付出许多，更多! 此刻敌人正在集结，阴云正在汇聚 从今天起，守护我们的世界和亲人的重任 就交给你了 再见了，那些一路陪伴我的NPC们，我要离开你们了，去开始新的征程。","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"魔兽世界","slug":"魔兽世界","permalink":"http://yoursite.com/tags/魔兽世界/"}]},{"title":"浅谈raid0,raid1,raid10,raid01等等硬盘阵列搭配","slug":"简析raid0-raid1-raid10-raid01等等硬盘搭配","date":"2018-01-31T06:43:03.000Z","updated":"2018-01-31T13:14:12.000Z","comments":true,"path":"2018/01/31/简析raid0-raid1-raid10-raid01等等硬盘搭配/","link":"","permalink":"http://yoursite.com/2018/01/31/简析raid0-raid1-raid10-raid01等等硬盘搭配/","excerpt":"","text":"RAID 0RAID 0可用于两个或更多硬盘或SSD。目标是提高读的性能。 数据以特定大小（通常为64KB）的块写入，并在可用驱动器中平均分配。下图显示了带有三个硬盘的RAID 0阵列的示意图。RAID控制器将第一个数据块写入硬盘1，第二个数据块写入硬盘2，第三个数据块写入硬盘3，第四个数据块再次写入硬盘1,以此类推，RAID 0中的三个1TB硬盘提供3TB的存储空间。 由于数据分布均匀，所以在访问的时候会从硬盘1~硬盘3提取数据，然后拼接在一起就是一个完整的数据。理论上从3个硬盘的RAID 0阵列读取数据比从一个硬盘读取要快3倍，换言之，使用RAID 0读数据的能力跟磁盘数量成正比。 RAID 0也有缺点：如果其中一个磁盘出现故障，从其他磁盘上的数据拼起来就不再是一个完整的数据了。另外，磁盘越多，则发生磁盘故障的可能性也越高。所以如果磁盘阵列里包含着对您来说很重要的数据，则最好创建频繁的备份。 RAID 1RAID 1用于创建数据的自动副本。RAID 1会将同一份数据写入两个单独的磁盘，如果A盘出现故障，仍然可以在B磁盘上读取所有数据，当然这是比较壕的，毕竟做一件事用了两块盘。这里要注意！镜像和备份可不是一样！！！如果你不小心从一个磁盘A上删除了一个文件，或者某个文件被病毒侵蚀了，那它再另一个磁盘B上也是一样的待遇。只有真正的备份才能使所有文件保持其保存状态。因此，如果想不让宝贵数据陷入灾难，创建频繁的备份是必须的。 RAID 1中的读性能通常与单独的硬盘差不多—-从A和B里一起读数据，谁出数据快就采用谁的，写的话就是要同时写到两个盘里去。因此，使用RAID 1来获得额外更多的读写性能是不太可能的。以下是RAID 1的工作原理图，如果HDD1坏了，那么HDD2直接上任，若HDD1里的东西被删除了，那么HDD2也会被删除，即使它上任了也是坏的。 RAID 10和RAID 01所谓RAID 10,其实就是磁盘阵列先RAID 1,后RAID 0,同理，RAID 01也是先RAID 0,后RAID 1。无论是1+0还是0+1，都至少需要4个硬盘。 这里先看一下RAID 10和RAID 01的效果图： 就像图里说的“在六个硬盘列里，RAID 10比RAID 01更安全”。的确，RAID 10也凭借很棒的容错能力和恢复能力当选了大多数的RAID配置，为什么不要RAID 01呢？那就是如果在RAID 0那一步磁盘就坏了，那RAID 1那步就没有意义了，因为生成的镜像全是坏镜像。 RAID 3RAID 3是这样的：若有n块盘，其中拿出1块盘作为校验盘，剩余n-1块盘相当于作RAID 0同时读写，当n-1那里的其中一块盘坏掉时，可以通过校验码还原出坏掉盘的原始数据。这个校验方式比较特别，事奇偶检验，1 XOR 0 XOR 1=0，0 XOR 1 XOR 0=1，最后的数据是校验数据，当中间缺了一个数据时，可以通过其他盘的数据和校验数据推算出来。但是这存在了问题，由于n-1块盘做了RAID 0，每一次读写都要牵动所有盘来服务，而且万一校验盘坏掉就完蛋了。 RAID 5 and 6上面说了RAID 10是一个很棒的方案，但是它的实现至少需要4个硬盘，这一点太伤钱了，于是就出现了RAID 5。与RAID 0一样，数据被分成块并执行写入处理，同时把RAID 3的“校验盘”也分成块分散到所有的盘里。同时，产生并写入称为“奇偶校验”的冗余代码。因此，即使其中的一个硬盘出现故障，也可以根据剩余的数据和奇偶校验来计算出丢失的数据，然后生成完整的状态数据。由于无论需要配置多少个硬盘，保存校验只使用一台设备的容量，容量效率随着待配置硬盘数量的增加而提高。RAID 5模式下硬盘读取数据的速度很快，因为它是从多个驱动器同时处理的。预计速度将与要配置的驱动器的数量成比例地增加。但是，数据的写入/更新涉及奇偶校验的创建/更新，所以写入性能不高。 RAID 5已经提供了一定程度的可靠性,然而也牺牲了一定的读取速度。RAID 5的局限性还表现在RAID 5仅能在一块硬盘发生故障的情况下修复数据,如果2块硬盘同时发生故障,RAID 5则无能为力。于是RAID 6应需诞生了，RAID 6同RAID 5最大的区别就是在RAID 5的基础上除了具有P校验位以外,还加入了第2个校验位Q位。当一块磁盘出现数据错误或者丢失的时候,恢复方法同RAID 5,无须使用Q校验位。当两块磁盘上的数据出现错误或者丢失的时候,恢复方法为:利用上边给出的P,Q的生成公式,联立方程组,无论受损的数据是否包括P或者Q,总是能够解出损失的两位的数据。 RAID 50 and 60在硬盘数量较少的情况下，RAID 5是极好的选择，如7-8块硬盘组成的RAID。但是，当硬盘的数量更多的时候，如10块、20块甚至100块，那么RAID 5就无法胜任了。RAID 50是在RAID 5的基础上，将多个RAID 5组以RAID 0的形式组成在一起。可以这么认为，一个RAID 5组在这里就是一个“大硬盘”，再把这些“大硬盘”以RAID 0的形式组成在一起。而RAID 60的组成就是在RAID 6组的上面组成一个RAID 0。理论上说在写入性能方面，RAID 50相比RAID 5要好太多，而RAID 50相比性能冠军RAID 10要差一点，考虑到RAID 5在一些负载面前的平庸性能，RAID 50是个不错的中间选择。和RAID 5和RAID 10一样，RAID 50也提供极好的读性能，同时RAID 50即使使用最低配置，也需要六个硬盘，所以安装成本很高。 如果担心一个RAID组里面同时有2块硬盘发生故障，导致数据丢失，那么可以选择使用RAID 60。RAID 60提供更高的安全性，相应的其可用容量会比RAID 50少点，RAID 60即使使用最少的配置，也需要8个硬盘，所以安装成本相当高。 结语以上几个磁盘阵列，从读的能力来说：RAID 5 ≈ RAID 6 ≈ RAID 60 &gt; RAID 0 ≈ RAID 10 &gt; RAID 3 ≈ RAID 1从写的能力来说:RAID 10 &gt; RAID 50 &gt; RAID 1 &gt; RAID 3 &gt; RAID 5 ≈ RAID 6 ≈ RAID 60如果将来有一天你对这篇文章记得不是很清晰了，那么但愿你可以记住下面这张图，这几幅图虽然对于RAID 上不是完全的准确，但是已经很大的表达清楚了各种RAID的特点了。 参考资料https://us.hardware.info/reviews/4123/raid-0-raid-1-raid-10-and-raid-5-how-do-they-actually-workhttp://support.huawei.com/enterprise/zh/knowledge/KB1000149118/https://zh.wikipedia.org/wiki/RAIDhttp://www.hpc.co.jp/raid_kaisetsu.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"raid","slug":"raid","permalink":"http://yoursite.com/tags/raid/"},{"name":"磁盘阵列","slug":"磁盘阵列","permalink":"http://yoursite.com/tags/磁盘阵列/"}]},{"title":"Ansible-playbook如何获取ip","slug":"Ansible-playbook如何获取ip","date":"2018-01-31T05:54:08.000Z","updated":"2018-01-31T06:21:36.000Z","comments":true,"path":"2018/01/31/Ansible-playbook如何获取ip/","link":"","permalink":"http://yoursite.com/2018/01/31/Ansible-playbook如何获取ip/","excerpt":"","text":"公司的模块都新加了加密算法，现在就是需要把约100台机器的/etc/hosts文件里的zookeeper server的ip调整成新的ip 地址，目前在ansible控制机上已经写好了带有新的zookeeper server的ip的/etc/hosts文件，然后计划是把这个新文件下发到大约100台具体模块的服务器里，然后这100台机器的文件中把他们各自的ip和hostname添加到这个新的/etc/hosts文件上。 于是就写了一个ansible-playbook: 123456789101112---- hosts: all tasks: - name: 将原有的hosts文件备份 shell: mv /etc/hosts /etc/hosts_bak - name: 将ansible端的hosts复制到各自机器上 copy: src=/root/hosts dest=/etc/ owner=root group=root mode=0544 - name: 在新的hosts文件后面追加各自机器内网ip和hostname lineinfile: dest=/etc/hosts line=\"`ansible_all_ipv4_addresses` `ansible_hostname`\" 但是写完之后执行出来，却是这样的效果： 而我想要的是这样的效果： 遇到这种情况怎么办？ 后来调整了一下，变量用IP: ““，而不是ansible_all_ipv4_addresses。 修改了之后的playbook 如下： 1234567891011121314---- hosts: all vars: IP: \"&#123;&#123; ansible_eth0['ipv4']['address'] &#125;&#125;\" tasks: - name: 将原有的hosts文件备份 shell: mv /etc/hosts /etc/hosts_bak - name: 将ansible端的hosts复制到各自机器上 copy: src=/root/hosts dest=/etc/ owner=root group=root mode=0644 - name: 在新的hosts文件后面追加各自机器内网ip和hostname lineinfile: dest=/etc/hosts line=\"`IP` `ansible_hostname`\" 这样就达到目的了。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://yoursite.com/tags/ansible/"}]},{"title":"mysql查看实时语句和慢sql","slug":"mysql查看实时语句和慢sql","date":"2018-01-30T12:50:14.000Z","updated":"2018-01-30T13:40:04.000Z","comments":true,"path":"2018/01/30/mysql查看实时语句和慢sql/","link":"","permalink":"http://yoursite.com/2018/01/30/mysql查看实时语句和慢sql/","excerpt":"","text":"查看实时语句Mysql除了手动执行的语句，还有很多在后台由其他模块执行的语句，按理来说，那些由其他模块执行的语句是不能实时查看的，因为这个资源消耗特别的大，但是当我们实在需要查看实时sql语句的时候也不是做不到，需要手动开启一个日志开关general_log。 首先登陆mysql，然后执行show variables like &quot;general_log%&quot;;，看一下反馈的结果，如下： 12345678mysql&gt; show variables like \"general_log%\";+------------------+-------+| Variable_name | Value |+------------------+-------+| general_log | OFF || general_log_file | |+------------------+-------+2 rows in set (0.04 sec) 发现这个Value是off，那么就说明实时记录general_log没有开启，如果我们要开启它很简单，如下： 123mysql&gt; set global log_output = file;mysql&gt; set global general_log = 'ON';mysql&gt; set global general_log_file = '/tmp/mysql/general_log.log'; 可见我们不仅打开了general_log的开关，而且设置日志输出方式为文件（如果设置log_output=table的话，则日志结果会记录到名为gengera_log的表中，这表的默认引擎都是CSV）。同时规定它的保存位置是/tmp/mysql/general_log.log。 但是这个是临时方法，如果mysql重启了那么就会失效，如果想要永久有效的话，就要编辑my.cnf，添加下面两句话： 12general_log = 1general_log_file = /tmp/mysql/general_sql.log 这里要注意！开启general_log会影响性能，谨慎使用!正式系统用完要关闭!!!关闭的语句SET GLOBAL general_log = &#39;OFF&#39;;。 查看慢sql慢sql的意思就是那些执行很慢的sql，这些sql拖慢进程的执行效率而且有很大的优化空间。默认的来说，执行时间超过1秒就算慢sql了，在mysql里输入show variables like &#39;long%&#39;，就会看到如下的内容： 1234567mysql&gt; show variables like 'long%';+-----------------+----------+| Variable_name | Value |+-----------------+----------+| long_query_time | 1.000000 |+-----------------+----------+1 row in set (0.00 sec) 这个long_query_time是可以更改的，这里是1，那就是代表查询时间大于(不是大于等于)1秒的都是记录到日志，最大值是10。如果写的是0，那么就是输出所有的语句。 这里多说一句，使用命令set global long_query_time=4修改慢查询阈值为4秒后，需要重新连接或新开一个会话才能看到修改值。你用show variables like &#39;long_query_time&#39;查看是当前会话的变量值，你也可以不用重新连接会话，而是用show global variables like &#39;long_query_time&#39;;。 那么记录这些慢日志的地方在哪呢？使用show variables like &#39;%slow_query_log%&#39;;看看： 12345678mysql&gt; show variables like '%slow_query_log%';+---------------------+-----------------------------------------------+| Variable_name | Value |+---------------------+-----------------------------------------------+| slow_query_log | OFF || slow_query_log_file | /tmp/mysql/DB-Server-slow.log |+---------------------+-----------------------------------------------+2 rows in set (0.00 sec) 这里说明慢日志的地址是/tmp/mysql/DB-Server-slow.log，但是慢日志记录的功能没有启动。如果要启动，语句是：set global slow_query_log=1;，跟上面开启实时日志general_log一样，这个方法仅仅是一个临时方法，重启了mysql就会失效，如果要长期生效，还是在my.cnf文件里添加如下两句话： 12slow_query_log =1slow_query_log_file=/tmp/mysql/DB-Server-slow.log 慢日志还有一个系统变量叫log-queries-not-using-indexes，它的意思是未使用索引的查询也被记录到慢查询日志中，哪怕他可能执行的非常快（可选项）。如果调优的话，建议开启这个选项。另外，开启了这个参数，其实使用full index scan的sql也会被记录到慢查询日志。如下： 12345678910mysql&gt; show variables like 'log_queries_not_using_indexes';+-------------------------------+-------+| Variable_name | Value |+-------------------------------+-------+| log_queries_not_using_indexes | OFF |+-------------------------------+-------+1 row in set (0.00 sec)mysql&gt; set global log_queries_not_using_indexes=1;Query OK, 0 rows affected (0.00 sec) 如果你想自己试试慢sql是否被记录，那么可以使用select sleep(5);这样的语句，执行效果如下： 123456789101112131415mysql&gt; select sleep(5) ;+----------+| sleep(5) |+----------+| 0 |+----------+1 row in set (5.00 sec)mysql&gt; select * from mysql.slow_log;+---------------------+---------------------------+------------+-----------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+| start_time | user_host | query_time | lock_time | rows_sent | rows_examined | db | last_insert_id | insert_id | server_id | sql_text | thread_id |+---------------------+---------------------------+------------+-----------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+| 2018-01-30 21:45:23 | root[root] @ localhost [] | 00:00:05 | 00:00:00 | 1 | 0 | | 0 | 0 | 1 | select sleep(5) | 2 |+---------------------+---------------------------+------------+-----------+-----------+---------------+----+----------------+-----------+-----------+-----------------+-----------+1 rows in set (0.00 sec) 参考资料http://www.cnblogs.com/kerrycode/p/5593204.htmlhttps://www.cnblogs.com/qmfsun/p/4844472.htmlhttp://www.cnblogs.com/jasondan/p/3491258.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"}]},{"title":"Goaccess---良心nginx日志分析工具","slug":"Goaccess-良心nginx日志分析工具","date":"2018-01-30T07:42:33.000Z","updated":"2018-01-30T07:53:28.000Z","comments":true,"path":"2018/01/30/Goaccess-良心nginx日志分析工具/","link":"","permalink":"http://yoursite.com/2018/01/30/Goaccess-良心nginx日志分析工具/","excerpt":"","text":"Goaccess是一个非常良心的开源软件，它的良心之处体现在如下方面： 安装简单； 操作容易； 界面酷炫； 安装安装Goaccess十分的简单，在centos里直接yum install goaccess，如果yum源里没有goaccess，可以先安装epel。安装epel的方法如下： 123wget http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpmwget http://rpms.famillecollet.com/enterprise/remi-release-6.rpmrpm -Uvh remi-release-6*.rpm epel-release-6*.rpm 配置和使用安装完goaccess之后，我们需要在/etc/goaccess.conf里添加如下几句话： 123time-format %Tdate-format %d/%b/%Ylog-format %h %^[%d:%t %^] “%r” %s %b “%R” “%u” 保存退出之后，我们就可以通过goaccess来分析nginx日志了，语句格式也很简单：goaccess -f nginx日志的绝对路径。比如我的nginx日志是access-chen.log，查看一下里面的内容： 虽然有规律，但是看上去很乱，需要在分析日志之前喝两瓶静心口服液。 然后我就goaccess -f access-chen.log，就会看到如下的界面： 这一下，整个日志看起来更加友好，更加直白，更加高大上。足以吸引周围人的羡慕目光。 但是这里面还是有一个注意点：goaccess默认支持的日志格式是nginx默认的日志格式，也就是nginx.conf里的如下格式： 如果你的日志格式是有过更改的，而且还不想改回来，那么就需要去/etc/goaccess.conf里对应的log-format进行更改。 这还没有完，goaccess还可以生成html，这里goaccess -f access-chen.log -a &gt; /nginx安装路径/html/chen.html。然后在浏览器里登陆到这个服务器的chen.html，就会看到整个日志情况的网页排版，如图： 这样的话，我们可以每一天都发一份当天的日志html去运维人员的信箱里，这样更加方便我们分析日志。 缺点虽然前面说了那么多goaccess的优点，但是缺点也是有的，比如goaccess的粒度太粗，只能按天分割，如果要按小时分割，需要先grep出来，这个做法比较挫我懂… 还有一个缺点，就是访问人的来源只能定位到国家，无法具体定位到省市县村屯… 参考资料http://blog.maxhemby.se/determine-the-apache-traffic-load/#respond","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"日志统计","slug":"日志统计","permalink":"http://yoursite.com/tags/日志统计/"}]},{"title":"处理掉积压过多的activemq持久化消息","slug":"处理掉积压过多的activemq持久化消息","date":"2018-01-29T06:27:26.000Z","updated":"2018-01-31T06:03:34.000Z","comments":true,"path":"2018/01/29/处理掉积压过多的activemq持久化消息/","link":"","permalink":"http://yoursite.com/2018/01/29/处理掉积压过多的activemq持久化消息/","excerpt":"","text":"问题描述在项目使用activemq 5.14时，客户端发送消息而没有得到回复（在不考虑消费者是什么问题的情况下），导致持久化消息不断积压而得不到释放，最后造成队列堵塞而嗝屁。 一般来说遇到这样的情况，可以在配置文件中配置消息的过期时间和死信处理来防止消息的积压，配置如下： 1234&lt;plugins&gt; &lt;!-- 86,400,000ms = 1 day --&gt; &lt;timeStampingBrokerPlugin ttlCeiling=\"10000\" zeroExpirationOverride=\"10000\"/&gt; &lt;/plugins&gt; 配置消息过期时间使用timeStampingBrokerPlugin插件,ttlCeiling：表示过期时间上限（模块程序写的过期时间不能超过此时间，超过则以此时间为准），zeroExpirationOverride：表示过期时间（给未分配过期时间的消息分配过期时间），一般来说这两个值是一样的。执行之后，message过期则客户端不能接收，那些已经过期的message将会保存在data/kahadb目录下。 但是最近发现了一个问题，就是data/kahadb这个目录最近越来越大，越积越多。但是这个topic和quere又依旧是“持续订阅”的，它的消费者还在。遇到这样的情况，如何在activemq里配置呢？ 解决办法 配置message过期自动丢弃策略 12345678910111213 &lt;borker&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;policyEntry topic=\"&gt;\" expireMessagesPeriod=\"60000\"&gt; &lt;deadLetterStrategy&gt; &lt;sharedDeadLetterStrategy processExpired=\"false\" /&gt; &lt;/deadLetterStrategy&gt; &lt;/policyEntry&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt;&lt;/borker&gt; 标签processExpired=&quot;false&quot;表示不保存过期消息到死信队列，处理手段为删除，为true则是保留。标签expireMessagesPeriod=&quot;60000&quot;属性表示每隔60秒钟检查message是否过期。topic=&quot;&gt;&quot;表示该策略对所有topic都生效。而topic=&quot;active.&gt;&quot;就表示该策略对以active.开头的所有topic生效，注意有个点号.。 message过期时间设置上面那步搞定了之后，再修改timeStampingBrokerPlugin标签里ttlCeiling=&quot;360000&quot; zeroExpirationOverride=&quot;360000&quot;表示过期时间为360000ms（1小时）。 123456&lt;borker&gt; &lt;plugins&gt; &lt;!-- 86,400,000ms = 1 day --&gt; &lt;timeStampingBrokerPlugin ttlCeiling=\"360000\" zeroExpirationOverride=\"360000\" /&gt; &lt;/plugins&gt;&lt;/borker&gt; 解决“空队列”的方法如果不是那种“持续订阅”的topic，那就简单了，配置如下： 123456789&lt;broker xmlns=\"http://activemq.apache.org/schema/core\" schedulePeriodForDestinationPurge=\"10000\"&gt; &lt;destinationPolicy&gt; &lt;policyMap&gt; &lt;policyEntries&gt; &lt;policyEntry queue=\"&gt;\" gcInactiveDestinations=\"true\" inactiveTimoutBeforeGC=\"30000\"/&gt; &lt;/policyEntries&gt; &lt;/policyMap&gt; &lt;/destinationPolicy&gt; &lt;/broker&gt; schedulePeriodForDestinationPurge执行清理任务的周期，gcInactiveDestinations=&quot;true&quot;表示启用清理功能，inactiveTimoutBeforeGC=&quot;30000&quot;这个是Topic或Queue超时时间,在规定的时间内，无有效订阅，没有入队记录，超时后就会被清理。 参考资料http://activemq.apache.org/timestampplugin.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"消息队列","slug":"消息队列","permalink":"http://yoursite.com/tags/消息队列/"},{"name":"activemq","slug":"activemq","permalink":"http://yoursite.com/tags/activemq/"}]},{"title":"Python里调用redis的方法","slug":"Python里调用redis的方法","date":"2018-01-29T04:38:39.000Z","updated":"2018-01-29T04:48:42.000Z","comments":true,"path":"2018/01/29/Python里调用redis的方法/","link":"","permalink":"http://yoursite.com/2018/01/29/Python里调用redis的方法/","excerpt":"","text":"正文Python 2.7里不是自带redis模块的，那么在调用redis的时候自然也会报错，比如： 遇到这种情况怎么办？ 第一种方法： 1pip install redis 第二种方法： 1easy_install redis 第三种方法：去登录https://github.com/andymccurdy/redis-py，下载包上传到linux里之后，python setup.py install。 flask模块的安装也是同理。 注意！这里只有Redis，如果使用StrictRedis会报错：AttributeError: &#39;Redis&#39; object has no attribute &#39;StrictRedis&#39;。这个是版本的问题。见https://github.com/andymccurdy/redis-py/issues/188 参考资料http://debugo.com/python-redis/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Ssh连接port 22: Connection refused","slug":"Ssh连接port-22-Connection-refused","date":"2018-01-29T03:30:18.000Z","updated":"2018-01-29T03:38:56.000Z","comments":true,"path":"2018/01/29/Ssh连接port-22-Connection-refused/","link":"","permalink":"http://yoursite.com/2018/01/29/Ssh连接port-22-Connection-refused/","excerpt":"","text":"金山云有一个服务器需要连接到数据库但是总是失败，检查之后发现它的VPC配错了，更改VPC之后，这台服务器也会更换一个新的内网IP地址，但是问题来了，更换了内网IP之后，从跳板机连接，提示port 22: Connection refused。 ssh -v 新的ip地址发现根本没有到Connection established。直接就提示port 22: Connection refused。这基本可以断定不是跳板机的问题了，那么就需要在远程机器里看配置。 但是远程机器是无法连接的啊，怎么办？从金山控制台“连接实例”。 然后键盘随便按一下，就会看到linux界面，输入账号名和密码，这里密码不支持复制粘贴，需要手动输入。然后就会看到如下界面。 这样，我们就可以登陆这台机器了，然后vim /etc/ssh/sshd_config，看到最上面有这样的内容。 这个listenaddress后面就是跳板机ssh的地址，但是这个地址还是老的，而不是更改过后的内网ip地址，所以ssh的连接自然就是refuse。所以我们只需要手动更改成新的内网ip地址就好了。 更改完之后，重启一下服务器或者/etc/init.d/sshd restart就可以从跳板机上正常连接了。 如果在/etc/init.d/sshd restart的时候爆出“address family must be specified before ListenAddress”的错误，那么就把AddressFamily移到ListenAddress上面就可以了，如图：","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"ssh","slug":"ssh","permalink":"http://yoursite.com/tags/ssh/"}]},{"title":"SFTP不能连接服务器怎么办？","slug":"SFTP不能连接服务器怎么办？","date":"2018-01-27T08:19:55.000Z","updated":"2018-01-29T04:35:54.000Z","comments":true,"path":"2018/01/27/SFTP不能连接服务器怎么办？/","link":"","permalink":"http://yoursite.com/2018/01/27/SFTP不能连接服务器怎么办？/","excerpt":"","text":"今天在跳板机上传送文件，发现使用SFTP连接的时候，出现了这样的一个拒绝情况： 登陆到这个跳板机里，使用tail /var/log/secure，看到了拒绝的具体信息，如下： 这个时候，我就需要locate sftp-server，用locate定位一下sftp文件，但是发现服务器竟然回答我-bash: locate: command not found。 于是就yum -y install mlocate，安装mlocate之后执行updatedb，需要等待一小会，然后再次执行locate sftp-server，就可以得到sftp-server的文件路径了，如下图： 打开sshd的配置文件，vi /etc/ssh/sshd_config，把Subsystem这一行前面的#去掉： 然后重启启动ssh服务，语句是/etc/init.d/sshd reload，重新连接一下，发现就恢复正常了。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"sftp","slug":"sftp","permalink":"http://yoursite.com/tags/sftp/"}]},{"title":"Ansible部署模块的时候出现中文乱码的问题","slug":"Ansible部署模块的时候出现中文乱码的问题","date":"2018-01-27T05:58:49.000Z","updated":"2018-01-27T06:02:18.000Z","comments":true,"path":"2018/01/27/Ansible部署模块的时候出现中文乱码的问题/","link":"","permalink":"http://yoursite.com/2018/01/27/Ansible部署模块的时候出现中文乱码的问题/","excerpt":"","text":"今天在部署服务的时候遇到了一个很罕见的现象，线上有15台服务器是手机推送消息的服务，新来的小运维使用ansible批量跑部署脚本的时候，发现手机端接收到来的消息全是乱码，然后登陆到服务器，查看日志发现，日志里面就是乱码，如图： 由于这个问题用户是有感知的，所以属于“事故”级别了，于是小boss大怒，叫运维赶快回滚，然后让开发赶紧重新检查代码，然后开骂测试都是吃屎的么这么大的一个问题都看不出来真是一群猪伤不起啊。 开发看了半天自己的代码，发现没有任何问题，战战兢兢跑来跟新来的小运维窃窃私语，结果我发现这个模块用手动单独部署，日志却是正常的，中文显示十分OK。 这一下开发就腰杆硬了，说这不是我的锅啊我是无辜的啊老子天天辛苦加班没有功劳也有苦劳没有苦劳也有疲劳老子的代码经得住考验这一切就是部署的问题。 于是我就查看了一下ansible的配置文件，vim /etc/ansible/ansible.cfg，发现了问题所在： 这里最后三行需要改成下面的样子，这样就解决了乱码问题。 1234#module_lang = C#module_set_locale = Falsemodule_lang = zh_CN.UTF-8module_set_locale = True","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"ansible","slug":"ansible","permalink":"http://yoursite.com/tags/ansible/"},{"name":"自动化部署","slug":"自动化部署","permalink":"http://yoursite.com/tags/自动化部署/"}]},{"title":"CentOS 6.x安装php 5.6和redis扩展的全过程","slug":"CentOS-6-x安装php-5-6和redis扩展的全过程","date":"2018-01-26T10:00:08.000Z","updated":"2018-07-10T10:08:00.000Z","comments":true,"path":"2018/01/26/CentOS-6-x安装php-5-6和redis扩展的全过程/","link":"","permalink":"http://yoursite.com/2018/01/26/CentOS-6-x安装php-5-6和redis扩展的全过程/","excerpt":"","text":"安装PHP 5.6过程如下： 123456789101112yum clean allyum update 整体升级一下yum包yum install -y epel-releaseyum list installed | grep php 检查时候安装过PHPrpm -Uvh http://mirror.webtatic.com/yum/el6/latest.rpm yum -y install php56w.x86_64yum -y --enablerepo=webtatic install php56w-develyum -y install php56w-xml.x86_64 php56w-gd.x86_64 php56w-ldap.x86_64 php56w-mbstring.x86_64 php56w-mcrypt.x86_64 php56w-mysql.x86_64 php56w-pdo.x86_64 php56w-opcache.x86_64yum -y install php56w-fpmchkconfig php-fpm on 开机自启动/etc/init.d/php-fpm start 启动进程php -v 查看是否安装成功 注1：如果想更换到php5.5或5.4版本, 直接把上面的56w换成55w或者54w就可以了；注2：php-opcache和php-xcache会有效的提高php执行速度； 装php的扩展其实不是很麻烦，主要的步骤如下：1）在扩展模块的客户端文件夹里面使用phpize，这样会生成一个configure文件；2）执行configure文件，后面要加上php的路径；3）将“模块.so”文件名添加到php.ini文件里，重启php-fpm进程；4）通过so文件去调用扩展模块的客户端，实现连接对应的模块； 安装redis扩展过程如下： 123456redis-cli -v 检查是否安装了redisredis-server -vwget http://pecl.php.net/get/redis-2.2.8.tgz tar -zxvf redis-2.2.8.tgzcd redis-2.2.8 phpize 一个专门挂接php扩展的工具，该命令一定要使用在php的模块文件夹主目录下，这里报错Cannot find config.m4。因为phpize要根据模块生成模块的配置文件放在模块文件夹下面 12345./configure --with-php-config=/usr/bin/php-configmake &amp;&amp; make installmake testvim /etc/php.ini 在php.ini里添加一句“extension=\"redis.so\"”service php-fpm restart","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"centos","slug":"centos","permalink":"http://yoursite.com/tags/centos/"},{"name":"php","slug":"php","permalink":"http://yoursite.com/tags/php/"},{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"一个连接两个文件的python脚本","slug":"一个连接两个文件的python脚本","date":"2018-01-26T07:13:26.000Z","updated":"2018-06-11T12:29:50.000Z","comments":true,"path":"2018/01/26/一个连接两个文件的python脚本/","link":"","permalink":"http://yoursite.com/2018/01/26/一个连接两个文件的python脚本/","excerpt":"","text":"背景交代公司在阿里云上有一个模块叫mrs，一共120台，它是跟云录像有关的，这个服务一直都是云服务器里没有公网但是购买了公网SLB，然后20个为一组配置到一个SLB里，这个SLB是按流量收费的。但是最近到了年末，各种账目审核，领导发现这个SLB的费用太惊人了，这么搞不够挣的。但是实在没办法，因为云录像嘛，肯定流量很大，如图： 纵然流量大，但是开源节流也是必须的，于是领导就责令开发赶快想出一个办法，减少SLB的费用。于是开发们拉上运维就吭哧吭哧的开始算经济账，最后确定每一个云服务器买7M带宽，然后流量全部走公网，把SLB的架构舍弃掉。 但是开发在这个模块V2.0里有一个变化，就是Zookeeper需要读取到每一台设备的外网IP，同时这个外网IP必须跟机器是一一对应的，这样模块才能正常工作。 原来的zookeeper在servermap是长这样的： 1234[\"内网IP\"] = &#123;app = \"mrs\", weight = 100&#125;,[\"内网IP\"] = &#123;app = \"mrs\", weight = 100&#125;,[\"内网IP\"] = &#123;app = \"mrs\", weight = 100&#125;,剩下略 而现在开发要求改成这样： 1234[\"内网IP\"] = &#123;app = \"mrs\",mrsReportIp = \"对应的外网IP\",weight = 100&#125;,[\"内网IP\"] = &#123;app = \"mrs\",mrsReportIp = \"对应的外网IP\",weight = 100&#125;,[\"内网IP\"] = &#123;app = \"mrs\",mrsReportIp = \"对应的外网IP\",weight = 100&#125;,剩下略 那么这就要把两个文件合并起来了，而且是在合并后做到一对一，不能把IP搭配串了。 准备工作首先，阿里云的网页控制台是无法做到“包年包月的服务器批量永久升级基础带宽”的，只能通过API实现。那么开启了外网IP之后，服务器就会有一个对应的外网IP地址，然后在控制台里，点击“导出资源列表”，只选择服务器名称、内网IP和外网IP。 然后在生成的excel表格里，剪除掉不需要的服务器以及服务器名称，然后保证“内网IP”在前，“外网IP”在后的样式，而且不要服务器名只保留IP,然后把这个文件复制到linux里，起个名，比如叫IP.txt,如图： 12345[root@paas-online-crs-001 tmp]# cat IP.txt10.161.236.231 3.3.3.310.161.235.150 2.2.2.210.51.10.182 4.4.4.410.117.219.72 1.1.1.1 再把已经使用的zookeeper复制一下，放到一个叫mingdan.txt的文件里，如图： 12345[root@paas-online-crs-001 tmp]# cat mingdan.txt[\"10.117.219.72\"] = &#123;app = \"mrs\", weight = 100&#125;,[\"10.161.235.150\"] = &#123;app = \"mrs\", weight = 100&#125;,[\"10.161.236.231\"] = &#123;app = \"mrs\", weight = 100&#125;,[\"10.51.10.182\"] = &#123;app = \"mrs\", weight = 100&#125;, 脚本思路我最开始打算用awk的NR、FNR去写，但是发现由于我这个文本的结构太过复杂。awk对付这样的力不从心，稍不好就把人搞得无法自拔，于是就考虑使用python的字典。 各位都知道，字典里key是不能重复的，而我又不想把这个脚本搞得太复杂，就想在mingdan.txt里的每一行加上序号，用这个序号去当key，而后面的内网IP就作为value，这样保证一一对应。加序号的方法很多，你可以在vim状态下:set number，然后手动复制粘贴。不过我是用的是如下两个命令： 12sed -i 's/^[ \\t]*//g' mingdan.txt #这一步是添加每一行序号sed -i 's/\\t/ /g' mingdan.txt #添加序号之后，会生成一个ta 然后mingdan.txt就成了这样： 12345[root@paas-online-crs-001 tmp]# cat mingdan.txt 1 [\"10.117.219.72\"] = &#123;app = \"mrs\", weight = 100&#125;,2 [\"10.161.235.150\"] = &#123;app = \"mrs\", weight = 100&#125;,3 [\"10.161.236.231\"] = &#123;app = \"mrs\", weight = 100&#125;,4 [\"10.51.10.182\"] = &#123;app = \"mrs\", weight = 100&#125;, 万事俱备，现在就要把IP.txt和mingdan.txt按照相同的内网IP整合成一个文件！ 脚本正文这个脚本是不怕mingdan.txt和IP.txt的IP顺序的。 1234567891011121314151617181920212223#!/usr/bin/env python#coding=utf-8import refd = &#123;&#125; #先设置一个新的空字典叫fd#以下都是最后拼字符串用的aaa = '[\"'bbb = '\"] = &#123;app = \"mrs\",mrsReportIp = \"'ccc = '\",weight = 100&#125;,' #首先先判断mingdan.txt里是否存在for l in open('mingdan.txt', 'r'): ar = re.split(r'[ \"\"]',l) #做分割，把内网IP切出来 print \"ip is :\" + ar[2] #确认是否分割出来的是内网IP地址 fd[ar[0]] = ar[2] #把这个内网IP地址当作value，前面的序号就是key with open('out.txt', 'w') as fw: for l in open('IP.txt', 'r'): ar = l.split() if ar[0] in fd.values(): #如果IP.txt里面的内网IP与字典fd里的value相符合 fw.write(aaa + ar[0] + bbb + ar[1] + ccc) #拼成一个完整的字符串 fw.write('\\n') #保存文件print('文件整合完毕，请查看out.txt的结果！') 执行结果执行效果输出如下： 123456[root@paas-online-crs-001 tmp]# cat out.txt [\"10.117.219.72\"] = &#123;app = \"mrs\",mrsReportIp = \"1.1.1.1\",weight = 100&#125;,[\"10.161.235.150\"] = &#123;app = \"mrs\",mrsReportIp = \"2.2.2.2\",weight = 100&#125;,[\"10.161.236.231\"] = &#123;app = \"mrs\",mrsReportIp = \"3.3.3.3\",weight = 100&#125;,[\"10.51.10.182\"] = &#123;app = \"mrs\",mrsReportIp = \"4.4.4.4\",weight = 100&#125;,[root@paas-online-crs-001 tmp]#","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"Zabbix-proxy的搭建和配置全过程","slug":"Zabbix-proxy的搭建和配置全过程","date":"2018-01-26T06:27:04.000Z","updated":"2018-01-26T07:06:38.000Z","comments":true,"path":"2018/01/26/Zabbix-proxy的搭建和配置全过程/","link":"","permalink":"http://yoursite.com/2018/01/26/Zabbix-proxy的搭建和配置全过程/","excerpt":"","text":"Zabbix-proxy的用途和构建图Zabbix-server是建立在金山云的，现在需要监控阿里云的redis，但是阿里云跟金山云之间通信是无法走内网的，如果直接让zabbix-server与redis直接联系，一旦公网的信息被截获的话，整个金山区的zabbix可能都会遭殃，那么既然有这种“远程监控+当监控的位置通信不便”的需求，就搭建一个zabbix-proxy来解决问题。 Zabbix-proxy是一个监控代理服务器，它收集监控到的数据，先存放在缓冲区，保存的时间可以通过配置文件设定，然后再传送到zabbix-server，这样也大大减缓了zabbix-server的压力，注意！监控代理需要一个单独的数据库，因为它的数据库表名与zabbix-server的数据库表名是一样的，如果不单独分开，后果就是数据错乱。 有人看到这里可能问了，说来说去你的zabbix-proxy跟阿里的redis依旧是走公网的啊！虽然这样也是走公网，我现在只需要配置一个防火墙规则来让他俩保证通信即可，通过防火墙来提升安全系数。架构如图： 安装Mysql 5.5Zabbix-proxy机器情况：金山云centos 6.5，安装zabbix版本：3.0.8 1234567891011[root@js-online-cjhmq-002 opt]yum list installed | grep mysql #列出已经安装过的mysql情况[root@js-online-cjhmq-002 opt]yum -y remove mysql-libs.x86_64 #把之前的mysql连根拔起[root@js-online-cjhmq-002 opt]# rpm -ivh http://repo.mysql.com/yum/mysql-5.5-community/el/6/x86_64/mysql-community-release-el6-5.noarch.rpmRetrieving http://repo.mysql.com/yum/mysql-5.5-community/el/6/x86_64/mysql-community-release-el6-5.noarch.rpmPreparing... ########################################### [100%] 1:mysql-community-release########################################### [100%][root@js-online-cjhmq-002 opt]groupadd zabbix #新建用户组zabbix[root@js-online-cjhmq-002 opt]useradd -g zabbix -u 808 -m zabbix#-g：指定用户所属的群组；#-u：指定用户id。#-m：自动建立用户的登入目录； 现在要修改一下/etc/yum.repos.d/mysql-community.repo这个文件，将5.5的enabled改为1,5.6的enabled改为0： 123456789101112131415# Enable to use MySQL 5.5[mysql55-community]name=MySQL 5.5 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.5-community/el/6/$basearch/enabled=1 #这里改成1gpgcheck=1 gpgkey=file:/etc/pki/rpm-gpg/RPM-GPG-KEY-mysql# Enable to use MySQL 5.6[mysql56-community]name=MySQL 5.6 Community Serverbaseurl=http://repo.mysql.com/yum/mysql-5.6-community/el/6/$basearch/enabled=0 #这里改成0gpgcheck=1gpgkey=file:/etc/pki/rpm-gpg/RPM-GPG-KEY-mysql 然后执行yum install mysql-community-client mysql-community-devel mysql-community-server php-mysql， 安装服务端和客户端，安装完毕之后可以mysql -h127.0.0.1看一下。 安装完毕之后，修改一下/etc/my.cnf，如图： 12innodb_buffer_pool_size = 512M #这个根据服务器性能填写，这个机器是2核2G的，所以我拿出半个G给mysqlinnodb_file_per_table=1 #这个是新增的字段，设置InnoDB为独立表空间模式，每个数据库的每个表都会生成一个数据目录 mysql安装完毕之后，我们还要导表进去，如图： 123456service mysqld startmysqladmin -uroot password '123456'mysql -uroot -p123456 -e 'create database zabbix_proxy character set utf8;'mysql -uroot -p123456 -e \"grant all privileges on zabbix_proxy.* to zabbix@localhost identified by 'zabbix';\"mysql -uroot -p123456 -e \"flush privileges;\"mysql -uzabbix -pzabbix zabbix_proxy &lt;/解压路径/zabbix-3.0.8/database/mysql/schema.sql 至此，mysql部分已经全部搞定。 安装Zabbix-proxy先去https://sourceforge.net/projects/zabbix/files/ZABBIX%20Latest%20Stable/3.0.8/下载zabbix-3.0.8.tar.gz，上传到proxy服务器里。 12tar -zxvf zabbix-3.0.8.tar.gz./configure --prefix=/usr/local/zabbix-3.0.8 --sysconfdir=/etc/zabbix --enable-proxy --enable-agent --enable-ipv6 --with-mysql=/usr/bin/mysql_config --with-net-snmp --with-libcurl --with-openipmi --with-unixodbc --with-ldap --with-ssh2 --enable-java 如果出现了configure: error: Invalid LDAP directory - unable to find ldap.h，解决方法就是： 1yum -y install openldap* Zabbix-proxy的配置打开/etc/zabbix/zabbix_proxy.conf，需要修改几个地方： 123456789101112ProxyMode=0 #0是主动模式，1是被动模式Server=A.B.C.D #这里填写zabbix-server的内网IPHostname=J.Q.K.A #这里要与/etc/hosts下的名字一模一样LogFile=/tmp/zabbix_proxy.logDBHost=localhostDBName=zabbix_proxyDBUser=zabbixDBPassword=zabbixConfigFrequency=120 #主动去server端去拉去配置更新的频率120秒一次DataSenderFrequency=60 #发送采集的监控数据到服务器端，默认是1秒，我们一分钟发送一次#ProxyLocalBuffer=0 #ProxyLocalBuffer表示数据传递给server之后还要在proxy里保存多久（单位为小时）。如果注释就是代表不删除。#ProxyOfflineBuffer=1 #ProxyOfflineBuffer表示数据没有传递给server的话还要在proxy里保存多久（单位为小时）。如果注释就是代表不删除。 然后就是启动proxy: 1# /usr/local/zabbix_proxy/sbin/zabbix_proxy 用netstat查看一下端口和进程是否都OK： Zabbix-server端的配置登入zabbix-server的网页，如图添加proxy： 点击“create proxy”之后，就对应填写资料吧： 这里对上面的几个选项多说几句： 12345678Connections to proxy：服务器如何连接到被动代理：无加密（默认），使用PSK（预共享密钥）或证书。Connections from proxy：从活动代理中选择允许的连接类型。 可以同时选择几种连接类型（用于测试和切换到其他连接类型）。 默认为“无加密”。#点击Certificate之后又两个参数：Issuer：允许颁发证书。 证书首先通过CA（认证机构）验证。 如果CA有效，则由CA签名，则可以使用Issuer字段来进一步限制允许的CA。 该字段是可选的，如果您的Zabbix安装使用多个CA的证书，则使用该字段。Subject：允许的证书。 证书首先通过CA验证。 如果它有效，由CA签名，则主题字段可用于仅允许Subject字符串的一个值。 如果此字段为空，则接受由配置的CA签名的任何有效证书。 #点击PSK之后又两个参数：PSK identity：预共享密钥身份字符串。PSK ： 预共享密钥（hex-string）。 如果Zabbix使用mbed TLS（PolarSSL）库，Zabbix将使用GnuTLS或OpenSSL库，64位十六进制（32字节PSK），最大长度为512位十六进制数（256字节PSK）。 示例：1f87b595725ac58dd977beef14b97461a7c1045b9a1c963065002c5473194952 保存之后，就在zabbix-server用zabbix-get去ping一下proxy，看看返回值是否是1，如果是zabbix_get [18290]: Check access restrictions in Zabbix agent configuration，就检查一下刚才的hostname等值是否正确。 被监控机器的配置在被监控的阿里云redis里安装zabbix-agent，在agentd.conf里把hostname写成自己在/etc/hosts里的hostname，Server地址和ServerActive的地址都要写成proxy的外网IP地址。保存之后启动agent进程，这个时候在proxy端是可以通过zabbix_get得到这台被监控机器的值，如图： 在Zabbix-Server的WEB界面里，为阿里云的redis新建一个host，Agent interface那里填写被监控的机器IP，端口是10050，Monitored by proxy的地方要写成刚刚添加的proxy。如图： 上面已经提到过，用proxy模式并且zabbix的客户端也是主动模式提交数据，这样能大大提高采集效率，降低zabbix服务器端和proxy端的压力。现在我们希望添加的还是使用zabbix_agent的方式，新加到zabbix_proxy里面的主机使用zabbix_agent（active）的方式。注意在模板的克隆要选择full clone，不要选“clone”，那样的话就仅仅是把iterm的名字克隆过去而已，如图： 然后在items选择具体的类型，根据需要，想改那个改哪个，如图，注意！我图里写的是Zabbix agent，但是type这里选择Zabbix agent (active)。 改完之后，保存一下，就会看到type都是zabbix agent（active）了。 最后在host里把这个机器添加到proxy的模板里，如图： 在Administration的Proxies也看到效果了，如果server与proxy没有正确连接的话，last seen的地方会是--，如果连接的话就会显示具体时间，如图: 返回到hosts里，查看那个被监控的redis机器也成功被监控到了，ZBX已经变绿。如图： 因为我们线上环境基本都是用的zabbix_proxy方式是active方式，然后客户端也是active方式，既然都是active方式，那么zabbix_agent的Hostname就很重要，打个比方如果再zabbix_server端把一个主机的Hostname改了，然后客户端那边也改了，服务端和客户端的Hostname是统一的，但是proxy那里还记录的是旧Hostname，然后就会在proxy日志里面看到下面一条： 1cannot send list of active checks to \"proxy内网IP地址\": host [virt_proxy内网IP地址] not found proxy主动模式下，ConfigFrequency默认的是3600秒一小时，显然有点大了，可以适当的调低一下，如10分钟或者几分钟什么的。然后出现问题多看看zabbix服务端和proxy的日志，对症下药。 参考资料http://www.51niux.com/?id=156http://www.cnblogs.com/wangxiaoqiangs/p/5336630.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"监控技术","slug":"监控技术","permalink":"http://yoursite.com/tags/监控技术/"}]},{"title":"centos服务器更改系统时间","slug":"阿里云服务器更改时区为utc","date":"2018-01-25T14:31:16.000Z","updated":"2018-07-03T03:01:48.000Z","comments":true,"path":"2018/01/25/阿里云服务器更改时区为utc/","link":"","permalink":"http://yoursite.com/2018/01/25/阿里云服务器更改时区为utc/","excerpt":"","text":"将时区改为utc开发提出需求说，某个模块是给洋人使用，于是把阿里云服务器里的时间改成UTC时间。我登陆到服务器里使用date查看了一下，发现目前使用的是东八区时间，如图： 首先先开启UTC，方法就是在/etc/sysconfig/clock的文件里修改这样一处：UTC=true。这样即使机器重启，UTC时间依旧会“BIOS ▶ UTC时区转换 ▶ 系统时间”的顺序正常使用。 在Centos 6.5里，各时区的时间是在一个叫/usr/share/zoneinfo/的文件夹下，在里面我们发现了我们的目标—-UTC，如图： 然后就是修改，方法如下： 12mv /etc/localtime /etc/localtime-bakln -s /usr/share/zoneinfo/UTC /etc/localtime 先把老的时间文件备份，然后把UTC文件做一个软连接过来即可。我们所熟悉的date命令就是/etc/localtime的输出结果。 现在去date一下，看看结果，果然改成了UTC： 这个时候，如果你服务器里装的是nginx的话，就会发现nginx日志里的时间也会变成UTC而不会再是CST了。 更改系统时间云服务器一般来说系统时间都是正确的，但是自己的服务器可能在安装系统之后的时间是不统一的，这样可能在集群里就会出问题。时间同步的步骤如下： 1234yum install -y ntpdate #下载ntp同步工具mv /etc/localtime /etc/localtime-bak #备份原有文件cp /usr/share/zoneinfo/Asia/Shanghai /etc/localtime #时区调整为上海ntpdate us.pool.ntp.org #与时区服务器同步时间 然后在crontab里添加一个每10分钟同步时间的命令：*/10 * * * * /usr/sbin/ntpdate us.pool.ntp.org | logger -t NTP。 如果服务器是没有公网的，那么也就无法下载ntpdate，此时只能用date -s命令手动更改时间，比如：date -s 23:40:00、date -s 20180703。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"linux","slug":"linux","permalink":"http://yoursite.com/tags/linux/"},{"name":"阿里云","slug":"阿里云","permalink":"http://yoursite.com/tags/阿里云/"}]},{"title":"阿里云购买、启动、停止ecs等等操作的python脚本","slug":"阿里云购买、启动、停止ecs的python脚本","date":"2018-01-24T14:52:41.000Z","updated":"2018-06-13T02:32:06.000Z","comments":true,"path":"2018/01/24/阿里云购买、启动、停止ecs的python脚本/","link":"","permalink":"http://yoursite.com/2018/01/24/阿里云购买、启动、停止ecs的python脚本/","excerpt":"","text":"以下所有脚本都是在python 2.7的环境亲自测试的。阿里云的ak/sk是没有地域概念的，在任何地域都可以使用。 购买服务器以在新加坡购买服务器为例子： 12345678910111213141516171819202122232425262728#!/usr/bin/env python#coding=utf-8#注意！服务器创建完毕之后，状态是关机的。from aliyunsdkcore import clientfrom aliyunsdkcore.acs_exception.exceptions import ClientExceptionfrom aliyunsdkcore.acs_exception.exceptions import ServerExceptionfrom aliyunsdkecs.request.v20140526 import CreateInstanceRequest# 创建 Client 实例clt = client.AcsClient('阿里云ak','阿里云sk','新加坡的地域') #各地域的缩写请看：https://help.aliyun.com/document_detail/40654.html?spm=5176.doc25499.2.14.yh6n8c# 创建 request，并设置参数request = CreateInstanceRequest.CreateInstanceRequest()# 设置ECS细节request.set_ImageId(\"centos_7_04_64_20G_alibase_201701015.vhd\") #这里是镜像request.set_InstanceName(\"xjp-test-001\") #这里写名称xjp-test-001request.set_SecurityGroupId(\"sg-23t6c6mjw\") #这里是安全组request.set_Password(\"W2.bi7FX1dyb)T3Wh^,[\") #这里是密码，推荐使用https传输，安全request.set_InstanceChargeType(\"PrePaid\") #确定是包年包月request.set_Period(\"2\") #先买两个月的request.set_SystemDiskCategory(\"cloud_efficiency\") #注意，如果是海外的机器的话，要额外说明，海外的机器只有高速云盘和SSD盘# 设置实例规格request.set_InstanceType(\"ecs.s2.large\")# 发起 API 请求并打印返回response = clt.do_action_with_exception(request)print response 服务器停机停止ECS的脚本如下： 1234567891011121314#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import StopInstanceRequestlist1 = ['要停机的ecs id1','要停机的ecs id2','要停机的ecs id3'...]clt = client.AcsClient('阿里云ak','阿里云sk','地域名')for i in list1: shutdown = StopInstanceRequest.StopInstanceRequest() shutdown.set_InstanceId(i) action = clt.do_action_with_exception(shutdown) print \"现在停机:\" + i print action 服务器启动启动ECS的脚本如下： 1234567891011121314#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import StartInstanceRequestlist = ['要停机的ecs id1','要停机的ecs id2','要停机的ecs id3'...]clt = client.AcsClient('阿里云ak','阿里云sk','地域名')for i in list: start = StartInstanceRequest.StartInstanceRequest() start.set_InstanceId(i) action = clt.do_action_with_exception(start) print \"现在启动:\" + i print action 查询阿里云镜像查询ECS镜像的脚本如下： 123456789101112131415#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import DescribeImagesRequestimport aliyunsdkcore.requestclt = client.AcsClient('阿里云ak','阿里云sk','地域名')request = DescribeImagesRequest.DescribeImagesRequest()request.set_accept_format('json')# 发起请求response = clt.do_action_with_exception(request)print response 查询服务器规格查询ECS规格的脚本如下： 123456789101112131415#!/usr/bin/env python#coding=utf-8from aliyunsdkcore import clientfrom aliyunsdkecs.request.v20140526 import DescribeInstanceTypesRequestimport aliyunsdkcore.requestclt = client.AcsClient('阿里云ak','阿里云sk','地域名')request = DescribeInstanceTypesRequest.DescribeInstanceTypesRequest()request.set_accept_format('json')# 发起请求response = clt.do_action_with_exception(request)print response 参考资料https://help.aliyun.com/document_detail/25499.html?spm=5176.doc25501.6.857.wR0MHP","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"阿里云api","slug":"阿里云api","permalink":"http://yoursite.com/tags/阿里云api/"}]},{"title":"Crontab里解决脚本时间重叠的问题","slug":"Crontab里解决脚本时间重叠的问题","date":"2018-01-24T06:17:32.000Z","updated":"2018-01-24T06:26:58.000Z","comments":true,"path":"2018/01/24/Crontab里解决脚本时间重叠的问题/","link":"","permalink":"http://yoursite.com/2018/01/24/Crontab里解决脚本时间重叠的问题/","excerpt":"","text":"正文Linux里的Crontab是一个好东西，但是它的默认最小执行频率是1分钟，但是我们在实际生产环境里有的时候遇到的脚本执行时间是大于1分钟的，这样就会出现一个很尴尬的情况，就是在1分钟过后，系统进程会出现多个脚本，neck and neck式的在后台运行，比如这样： 从上面的图可以看到，10点36分log499.sh没有执行完毕，10点37又开始了执行了一个新的log499.sh脚本。这种脚本冲突肯定不是我们所希望的，那么如何才能保证后台只是在一段时间里只执行一个脚本呢？ 这个时候我们就要使用文件锁，flock，这种方法要比判断pid高大上的多。 首先假设我们的脚本名字叫abc.sh，这个脚本文件的执行时间是要大于1分钟的，同时我们再设定一个锁文件，位置就叫/tmp/abc.lock,这个文件可以是空的，然后crontab -e，添加一句命令如下： 1* * * * * flock -xn /tmp/abc.lock -c 'sh /路径/abc.sh &gt;&gt; /记录日志的路径 2&gt;&amp;1' 这个时候静候crontab启动abc.sh，通过ps -ef|grep abc，发现在后台始终只有一个abc进程。 但是有的时候会有这样的一个问题，就是abc执行一次之后，在下一次该执行的时候却没有执行，好像crontab失效了一样，对于这样的情况，就需要添加下面的语句到abc.sh末尾： 123rm -rf /tmp/abc.lock #删除掉原有的锁文件sleep n #睡n秒touch /tmp/abc.lock #再新建一个锁文件 这样不断地更新lock锁文件，就会保证crontab每次都会按期执行。 这里要注意一下，里面我加了一句sleep n，这里的n是为了跨分钟的存在，这是为了防止没有走到下一个分钟又会生成一个新的lock锁文件，这样还是会出现重复启动脚本的情况。 这里就涉及到flock的一个原理：在每一次执行任务的时候都会先去尝试取到锁文件，如果取到了锁文件，那么就会下一步，反之就会放弃执行。A任务在运行的时候已经占据了lock文件，那么B任务来了，发现没有lock了，就不会执行任务。 这里我们使用了flock的三个参数： 123-x, --exclusive: 获得一个独占锁-n, --nonblock: 如果没有立即获得锁，直接失败而不是等待-c, --command: 在shell中运行一个单独的命令 当然，flock还是有很多丰富的参数可以供各位使用，大家就各自去google一下吧。 参考资料http://blog.csdn.net/fdipzone/article/details/38284009http://chuansong.me/n/285635151949https://segmentfault.com/q/1010000008039907","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"crontab","slug":"crontab","permalink":"http://yoursite.com/tags/crontab/"},{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"}]},{"title":"yum提示Error: rpmdb open failed","slug":"yum提示Error-rpmdb-open-failed","date":"2018-01-24T06:09:35.000Z","updated":"2018-01-25T09:35:22.000Z","comments":true,"path":"2018/01/24/yum提示Error-rpmdb-open-failed/","link":"","permalink":"http://yoursite.com/2018/01/24/yum提示Error-rpmdb-open-failed/","excerpt":"","text":"今天在一台机器里，使用yum安装的时候，出现了如下的故障： 这种情况就是RPM数据库被破坏了，这个时候就需要我们重建数据库，于是就输入如下的命令： 1234cd / var / lib / rpm /for i in ` ls | grep 'db.' ` ; do mv $i $i .bak ; donerpm -- rebuilddbyum clean all 重新cleanup就正常了。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"},{"name":"yum","slug":"yum","permalink":"http://yoursite.com/tags/yum/"}]},{"title":"由一个实例浅析sed用法","slug":"由一个实例浅析sed用法","date":"2018-01-23T14:27:54.000Z","updated":"2018-01-24T05:57:00.000Z","comments":true,"path":"2018/01/23/由一个实例浅析sed用法/","link":"","permalink":"http://yoursite.com/2018/01/23/由一个实例浅析sed用法/","excerpt":"","text":"首先，假设我们有一个文件，叫123.txt，cat一下看到里面的内容是这样的： 12345678[root@func-lms-001 ~]# cat 123.txt jamescurry durantwadeyaoming messi[root@func-lms-001 ~]# 如果我们想在james前面加上lebron，那么采用的sed语句就是：sed -i &#39;/^james/s/^/lebron /&#39; 123.txt，如果要在curry后面加上champion，那么采用的语句就是：sed -i &#39;/^curry/s/$/ champion!/&#39; 123.txt。 使用完上面两句话之后，再#cat一下，看下效果： 12345678[root@func-lms-001 ~]# cat 123.txt lebron jamescurry champion! durantwadeyaoming messi[root@func-lms-001 ~]# 现在我们要把durant前面加上FMVP这几个字母，按照上面的语句找葫芦画瓢的话，应该是：sed -i &#39;/^durant/s/^/FMVP /&#39; 123.txt。但是很抱歉，这个语句是错误的！因为^是匹配开头durant的意思，而我们再看一下durant那一行的开头是空格。 那么就要用liunx的正则来匹配空格，于是这句话就变成了：sed -i &#39;/^\\s\\+durant/s/^/FMVP/&#39; 123.txt，^\\s\\+这个就是正则里匹配空格的意思 。 cat一下： 12345678[root@func-lms-001 ~]# cat 123.txt lebron jamescurry champion!FMVP durantwadeyaoming messi[root@func-lms-001 ~]# 那么现在要在messi后面加上”GOAL !!!”，就很简单了。语句是：sed -i &#39;/^\\s\\+messi/s/$/ GOAL !!!/&#39; 123.txt。 以上我们把有/无空格情况下的首尾添加字符都练习了一遍，下面我们要看看如果要在中间添加怎么办？ 比如说，有一天苦逼的运维接到开发PL的邮件，说”由于安全基线要求，现在需要监听内网端口“，具体的需求就是把所有含tomcat的模块里的server.xml的文件里添加上内网IP。 原有的server.xml的节选如下： 12345678910&lt;Service name=\"LMS\"&gt; &lt;Connector port=\"8080\" connectionTimeout=\"20000\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" redirectPort=\"8443\" enableLookups=\"false\" disableUploadTimeout=\"true\" maxThreads=\"500\" minSpareThreads=\"20\" acceptCount=\"100\"/&gt; &lt;Connector port=\"8088\" connectionTimeout=\"20000\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" redirectPort=\"8443\" enableLookups=\"false\" disableUploadTimeout=\"true\" maxThreads=\"500\" minSpareThreads=\"20\" acceptCount=\"100\"/&gt; &lt;Connector port=\"8099\" protocol=\"AJP/1.3\" redirectPort=\"8443\" /&gt; &lt;Engine defaultHost=\"localhost\" name=\"Catalina\"&gt; &lt;Realm className=\"org.apache.catalina.realm.LockOutRealm\"&gt; &lt;Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\" resourceName=\"UserDatabase\" /&gt; &lt;/Realm&gt; 现在要把&lt;Connector port=&quot;8099&quot; protocol=&quot;AJP/1.3&quot; redirectPort=&quot;8443&quot; /&gt;这一句里面加上内网IP:1.2.3.4，改成这样： 12345678910&lt;Service name=\"LMS\"&gt; &lt;Connector port=\"8080\" connectionTimeout=\"20000\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" redirectPort=\"8443\" enableLookups=\"false\" disableUploadTimeout=\"true\" maxThreads=\"500\" minSpareThreads=\"20\" acceptCount=\"100\"/&gt; &lt;Connector port=\"8088\" connectionTimeout=\"20000\" protocol=\"org.apache.coyote.http11.Http11NioProtocol\" redirectPort=\"8443\" enableLookups=\"false\" disableUploadTimeout=\"true\" maxThreads=\"500\" minSpareThreads=\"20\" acceptCount=\"100\"/&gt; &lt;Connector port=\"8099\" address=\"1.2.3.4\" protocol=\"AJP/1.3\" redirectPort=\"8443\" /&gt; &lt;Engine defaultHost=\"localhost\" name=\"Catalina\"&gt; &lt;Realm className=\"org.apache.catalina.realm.LockOutRealm\"&gt; &lt;Realm className=\"org.apache.catalina.realm.UserDatabaseRealm\" resourceName=\"UserDatabase\" /&gt; &lt;/Realm&gt; 请问怎么做？ 答案1： 1sed -i '/&lt;Connector port=\"8099\"/s/port=\"8099\"/port=\"8099\" address=\"1.2.3.4\"/g' server.xml 答案2： 1sed -i 's@Connector port=\"8099\"@&amp; address=\"1.2.3.4\"@' server.xml","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}]},{"title":"Zabbix添加网卡内外流量监控","slug":"Zabbix添加网卡内外流量监控","date":"2018-01-23T13:41:12.000Z","updated":"2018-01-23T13:51:46.000Z","comments":true,"path":"2018/01/23/Zabbix添加网卡内外流量监控/","link":"","permalink":"http://yoursite.com/2018/01/23/Zabbix添加网卡内外流量监控/","excerpt":"","text":"现在笔者想对host名单里面的zabbix_server进行网卡的内外流量情况的一个监控，首先登录zabbix之后，configuration—hosts，出现如下的菜单： 现在可以看到这个zabbix_server后面link了很多个模板，正是因为link了很多的模板，所以导致它的items非常多，42个。现在是要在zabbix_server里添加两个新的监控项，这一步跟模板其实没有什么关系，只需要在items里直接添加items即可。 我们先添加网卡外流量的items，整个配置如图所示： 里面具体的数值可以自己更换，比如Applications什么的，key\\units\\Use custom multiplier这些是固定的，全部写完之后就可以save。 找葫芦画瓢，我们可以再添加一个网卡的内流量监控，也是一样的套路，如图所示： 有了items，就要有trigger，有了items里的key，那么trigger也很简单，这里的expression多时候各位都是从网上ctrl+c下来，却不能ctrl+v，因为会红字报错—-Incorrect item key &quot;net.if.in[eth0,bytes]&quot; provided for trigger expression on &quot;服务器名称&quot;，于是就有很多不明真相的吃瓜群众就走“add”路线，然后发现要走add路线还要先把服务器添加到对应的模板上去。其实大可不必，这个expression是可以自己写的，但是一定要确定trigger跟items是配对的。以外网流量所示： 在这里我添加成了1K，这样是为了方便监控，具体数值因情况而异，而且重要性我选择了无。 最后就是要形成图表来糊弄领导，让领导感受一下什么叫做高大上，在graph的界面里选择create graph，然后就如图所示的填写： 一个是红色线，一个是绿色线，双龙戏珠，save。 最后来到Monitoring—Graphs里，找到正确的host,group和graph，就会看到激动人心的图表了： 这里要注意几点，有时候zabbix反应较慢，可能写好的key会出现not support的情况，这个时候可以先登录zabbix_server去zabbix_get一下，zabbix_get的方法之前有讲过，请见http://chenx1242.blog.51cto.com/10430133/1738820 ，如果zabbix_get是成功返回值的，先检查对应的单位（结果是浮点值，但是units设定是一个整数值肯定会not support）,如果单位检查正确，就修改zabbix重新check的时间，实在不行就重新建立一个items。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"服务器监控","slug":"服务器监控","permalink":"http://yoursite.com/tags/服务器监控/"}]},{"title":"使用Nessus进行漏洞扫描的过程","slug":"使用Nessus进行漏洞扫描的过程","date":"2018-01-23T04:53:51.000Z","updated":"2018-01-23T06:04:54.000Z","comments":true,"path":"2018/01/23/使用Nessus进行漏洞扫描的过程/","link":"","permalink":"http://yoursite.com/2018/01/23/使用Nessus进行漏洞扫描的过程/","excerpt":"","text":"对于一个服务器运维工作者，掌握和运用一门漏洞扫描的工具也是行走江湖的必备项，Nessus就是漏洞扫描的强力武器。Nessus为一款当下比较流行的系统弱点扫描与分析软件，他的优点是操作简单（配置几乎全web化），而且页面精美、扫描项广泛；缺点就是目前不支持中文… 下载与安装要安装Nessus，需要登陆https://www.tenable.com/products/nessus/select-your-operating-system,选择对应的系统，我这个服务器是centos 7，那么就选择下图里红色的那个rpm包： 点击之后，出来一个同意条款，同意之后就开始自动下载。但是要安装nessus仅仅有程序是不够的，还需要一个对应的验证码，在上面那个界面里，下拉一点有一个get an activation code的check，点击之后跳转到https://www.tenable.com/products/nessus/nessus-plugins/obtain-an-activation-code，里选择家用free版，点击下面的register now： 注册是很简单的，填写名称和电邮就可以了。不久后就会在电子邮件里面获得一个校验码。 把下载的那个Nessus-6.11.1-es7.x86_64.rpm包上传到centos之后，rpm -ivh Nessus-6.11.1-es7.x86_64.rpm进行安装，安装完成之后，service nessusd start启动进程，启动完毕之后，使用netstat -lnpt|grep 8834，来检查一下8834端口是否被监听，如图： 端口监听OK，那么在浏览器里输入https://服务器外网IP地址:8834打开控制web界面，如果有提示当前连接不安全，无视掉就可以。nessus的欢迎界面如下： 注册一个账号之后，在这个界面里面选择home那一条，输入邮箱里面获得的那个注册码： 整个的配置就完事了，继而就是nessus自动安装的过程，大约需要几分钟： 整个安装完毕之后，就会看到nessus的主界面，简单明了的风格： 至此整个nessus的安装过程结束。 配置扫描策略以及启动扫描任务nessus扫描漏洞的流程很简单：需要先”制定策略”，然后在这个策略的基础上建立”扫描任务”，然后执行任务。首先，我们先建立一个policy，如图： 点击New Policy之后，就会出现很多种扫描策略，这里我们选择Advanced Scan(高级扫描)： 我给这个测试的扫描策略，起名叫”chenchenchen”，如图： 对于上面这个图，Permissions是权限管理，是否可以准许其他的nessus用户来使用你这个策略；Discovery里面有主机发现、端口扫描和服务发现等功能；assessment里面有对于暴力攻击的一些设定；Report里面是报告的一些设定；Advanced里面是一些超时、每秒扫描多少项等基础设定，一般来说这里默认就好。我们主要来看看那个plugins。 Plugins里面就是具体的策略，里面有父策略，具体的父策略下面还有子策略，把这些策略制定得体的话，使用者可以更加有针对性的进行扫描。比如我这个策略是针对于centos系统的扫描策略，那么一些冗余的项目大可以完全不要，举个例子： 在上面这个图里面，我不需要amazon linux local security checks这个“亚马逊linux本地安全检查”父策略，那就把它disabled掉，而对于centos local security checks这个父策略呢，我又不需要那几个关于bind的子策略，那我就单独把那些子策略disabled掉，这样等等操作，就搭配成为了一个用时不长但是又包含了所有制定的检查项的策略，然后点击save保存。 保存完后，我们就发现policy里多了一条chenchenchen的记录： 既然策略有了，现在我们就来制定一个任务。在主界面里选择My Scans,点击New Scans,这个时候还是有很多个图标，但是我们选择后面的User defined，如图： 这里我们就看到了我们已经制定好的那个chenchenchen策略，点击这个chenchenchen之后，就要给这个依赖chenchenchen策略的任务起名字以及需要扫描的网络段，由于我这个测试机的内网ip段是10.132.27.0，于是我就写了“10.132.27.0/24”，任务名字叫chentest： 启动扫描任务点击save保存之后，就会看到My Scans里多了这个chentest的任务，点击三角播放箭头，那么这个任务就开始执行了！如图： 从该界面可以看到扫描任务的状态为Running（正在运行），表示chentest扫描任务添加成功。如果想要停止扫描，可以单击方块（停止一下）按钮。如果暂停扫描任务，单击暂停按钮。 扫描完毕之后，我们就会看到一个结果反馈，如图： 具体的颜色代表，在旁边有描述，例子里这些蓝色的info代表没有重大漏洞，点击一下蓝色，还会出现更加详细的信息，包括IP地址、操作系统类型、扫描的起始时间和结束时间： 同时，nessus还支持pdf、web、csv等多种方式汇报扫描结果，至此，整个nessus漏洞扫描的全过程就结束了。 Nessus配置smtpNessus漏洞扫描是提供邮件服务，可以将扫描的结果发送给指定的邮箱。配置它的方法很简单，先登陆Nessus的界面，点击左上角的settings，然后选择左侧菜单栏里的Smtp server，如图： 再就是填写对应的项目，我这里发送邮件的地址是：chenx3314@sina.com，接受的地址是124208739@qq.com，由于发送邮件使用的是新浪的邮箱，那么host就填写新浪的smtp服务器，即smtp.sina.com，如果是要SSL加密的话，端口写465，同时在Encryption那里选择Force SSL，在Auth Method那里选择login的鉴权方式，然后输入chenx3314@sina.com的账号密码，如图： 点击Send Test Email，然后输入接收的邮箱，如果是多个邮箱那么就用英文逗号隔开。看到成功的提示就是OK了： 然后就可以到邮箱里面看到那个测试的邮件内容：","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"},{"name":"nessus","slug":"nessus","permalink":"http://yoursite.com/tags/nessus/"}]},{"title":"mysql清除磁盘碎片","slug":"mysql清除磁盘碎片","date":"2018-01-23T02:44:23.000Z","updated":"2018-01-23T06:47:50.000Z","comments":true,"path":"2018/01/23/mysql清除磁盘碎片/","link":"","permalink":"http://yoursite.com/2018/01/23/mysql清除磁盘碎片/","excerpt":"","text":"任务背景接到金山云报警短信，说某数据库的容量已经达到了90%的水位线，于是登陆控制台查看详细情况。 在控制台首先发现，每一天的磁盘容量的确有所波动，那么就证明开发人员写的“资源回收”模块是在正常运行的，如图： 那么就说明没有什么数据是可以删的，既然删不掉多余的数据又不想多掏钱扩磁盘容量，只能从“磁盘碎片”下手了。而InnoDB引擎清理磁盘碎片的命令就是OPTIMIZE。 具体操作首先我先查询一下所有的“磁盘碎片情况”，使用语句如下： 1select CONCAT(TABLE_SCHEMA,'.',TABLE_NAME) as 数据表名,concat(truncate(sum(DATA_LENGTH+DATA_FREE+INDEX_LENGTH)/1024/1024,2),' MB') as total_size, concat(truncate(sum(DATA_LENGTH)/1024/1024,2),' MB') as data_size,concat(truncate(sum(DATA_FREE)/1024/1024,2),' MB') as data_free, concat(truncate(sum(INDEX_LENGTH)/1024/1024,2),'MB') as index_size from information_schema.tables group by TABLE_NAME order by data_length desc; 或者使用select table_schema, table_name, data_free, engine from information_schema.tables where table_schema not in (&#39;information_schema&#39;, &#39;mysql&#39;) and data_free &gt; 0;也可以，这个是查询data_free大于0的所有表。 然后看到我这个叫history_device_flow_day的表里情况如下： 表里的data_free就是磁盘碎片的量，比如我现在要干掉history_device_flow_day里所有的磁盘碎片，是975MB，于是先查询一下这个history_device_flow_day的存储引擎，使用语句如下： 1show table status from jsonlinefssrds where name='history_device_flow_day'; 上面语句里的jsonlinefssrds是对应的数据库，看到的效果如下： 存储引擎是InnoDB，那么就可以启动清除碎片的语句了：OPTIMIZE TABLE 数据表表名;，因为OPTIMIZE TABLE只对MyISAM、BDB和InnoDB表起作用。 再执行了OPTIMIZE TABLE history_device_flow_day;之后，大约9分钟，就会看到“OK”的字样： 估计有的朋友会问，那上面不是明明写了“Table does not support optimize, doing recreate + analyze instead”吗？这个其实无妨，实际上磁盘碎片已经被清除掉了。我们可以再用一次查询磁盘碎片的命令看一下，如图： 的确释放了900多M。 或者使用ALTER TABLE 表名 ENGINE = Innodb;（只是InnoDB的表可以这么做，而且据说这么做更友好）来达到清理磁盘碎片的目的，这个命令表面上看什么也不做,实际上是重新整理碎片了。当执行优化操作时,实际执行的是一个空的ALTER命令,但是这个命令也会起到优化的作用,它会重建整个表,删掉未使用的空白空间。 补充为什么会产生磁盘碎片？那是因为某一个表如果经常插入数据和删除数据，必然会产生很多未使用的空白空间，这些空白空间就是不连续的碎片，这样久而久之，这个表就会占用很大空间，但实际上表里面的记录数却很少，这样不但会浪费空间，并且查询速度也更慢。 注意！OPTIMIZE操作会暂时锁住表,而且数据量越大,耗费的时间也越长,它毕竟不是简单查询操作。所以把OPTIMIZE命令放在程序中是不妥当的,不管设置的命中率多低,当访问量增大的时候,整体命中率也会上升,这样肯定会对程序的运行效率造成很大影响。比较好的方式就是做个shell,定期检查mysql中 information_schema.TABLES字段,查看DATA_FREE字段,大于0的话,就表示有碎片，然后启动脚本。 参考资料http://pengbotao.cn/mysql-suipian-youhua.htmlhttp://irfen.me/mysql-data-fragmentation-appear-and-optimization/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"http://yoursite.com/tags/mysql/"},{"name":"数据库","slug":"数据库","permalink":"http://yoursite.com/tags/数据库/"}]},{"title":"一道传说中是百度面试的shell试题","slug":"一道传说中是百度面试的shell试题","date":"2018-01-23T01:37:31.000Z","updated":"2018-01-23T01:45:16.000Z","comments":true,"path":"2018/01/23/一道传说中是百度面试的shell试题/","link":"","permalink":"http://yoursite.com/2018/01/23/一道传说中是百度面试的shell试题/","excerpt":"","text":"【问题】写脚本实现，可以用shell、perl等。把文件b中有的，但是文件a中没有的所有行，保存为文件c，并统计c的行数。翻译成人话就是，假设有一个文件a是:abcd 文件b是:1234ab 现在要求输出“b有a没有”的行，即1 2 3 4，然后wc -l一下。 【思路】两个文件比较，第一想法就是diff，但是diff无论是-c还是-y会牵扯进大量的&gt; &lt; + -不说，而且diff命令是直白对比，即使字母相同但所在行不同，也会被diff记录。如果再用for in语句然后一项一项对比也不会很清晰的解决这个问题，所以要换个方法。 第二个方法就是comm命令，但是这个命令有一个前提，就是要sort排序，comm比diff高明之处在于它只比较内容而不在意是否同一行，但是要注意对比文件的先后。comm -12 a b是找”a和b都有”的项，comm -23 a b就是找”a有而b没有”。 【解答】perl我不会，我就用shell写： 123456#!/bin/bash#written by ChrisChan @ 2016-4-21sort a.txt&gt;a1.txt #排序，不然会有提示sort b.txt&gt;b1.txtcomm -23 b1.txt a1.txt &gt;c.txt #由于是要找b有a没有的,就要b写在前，a写在后echo $(cat c.txt|wc -l) 其实还有一个更简单的，只用一句话: 1grep -v -x b.txt -f a.txt|wc -l 很多书上不写grep -x -f的意思，这里补一下：-f:指定范本文件，其内容含有一个或多个范本样式，让grep查找符合范本条件的文件内容，格式为每列一个范本样式。-x:只显示全列符合的列。 从一个题就能轻松看出shell的能力级别，用diff死纠缠就是初级，用comm就是中级，而grep就是高级。的确是一个好题。 【补充】如果考python，求这种类似“你有我没有”的东西，用set里面的差集算法。 12345678910&gt;&gt;&gt;A=&#123;1，2，3，4&#125;&gt;&gt;&gt;B=&#123;3，4，5，6&#125;&gt;&gt;&gt;print(A-B)set([1,2]) #A有B没有&gt;&gt;&gt;print(A ^ B)set([1,2,5,6]) #差集的补集&gt;&gt;&gt; A&amp;B&#123;3, 4&#125; #交集&gt;&gt;&gt; A|B&#123;1, 2, 3, 4, 5, 6&#125; #全集","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"面试经验","slug":"面试经验","permalink":"http://yoursite.com/tags/面试经验/"},{"name":"shell","slug":"shell","permalink":"http://yoursite.com/tags/shell/"}]},{"title":"解决Zabbix在web界面中文显示的问题","slug":"解决Zabbix在web界面中文显示的问题","date":"2018-01-22T03:31:40.000Z","updated":"2018-01-22T04:42:34.000Z","comments":true,"path":"2018/01/22/解决Zabbix在web界面中文显示的问题/","link":"","permalink":"http://yoursite.com/2018/01/22/解决Zabbix在web界面中文显示的问题/","excerpt":"","text":"注意！这个是解决web界面中文显示乱码的问题，不是zabbix web界面全中文汉化的问题。 2.2版本的处理方法zabbix里给host或者item等项目起中文名字的时候，可能在graph上无法正确显示中文字符，如图： 那么遇到这样的情况其实很简单，就是zabbix的web界面没有安装中文字库的问题，那就对症下药，下载中文字库。 中文字库的下载地址在这里：http://linux.linuxidc.com/2012%E5%B9%B4%E8%B5%84%E6%96%99/11%E6%9C%88/22%E6%97%A5/Zabbix%E4%B8%AD%E6%96%87%E4%B8%8D%E8%83%BD%E6%98%BE%E7%A4%BA%E9%97%AE%E9%A2%98/ ，下载“LinuxIDC.com下载-kaiti.tar.gz”。 后把这个文件改一下名，可能很多linux不识别那个中文字“下载”,mv LinuxIDC.com下载-kaiti.tar.gz kaiti.tar.gz，tar -zxvf kaiti.tar.gz 然后就会发现当前路径里生成了一个叫kaiti.ttf，这个就是我们所需要的中文“楷体”字体文件。 来到zabbix的web字体路径，在我的机器里，这个负责字体的文件夹叫/usr/local/nginx/html/zabbix/fonts/。虽然各位安装zabbix的路径各有差别，但是这个文件夹一般都是在nginx or apache的html下，所以很好找的。 在这个fonts文件夹里默认已经有一个叫DejaVuSans.ttf的文件了，于是就把这个kaiti.tff也放到这个文件夹下。 光有字体文件没有用，还需要在配置文件里使用这个字体文件，于是就vim一下同样在nginx or apache/html/zabbix/include的defines.inc.php。把里面所有的DejaVuSans替换成kaiti，.tff这个后缀是不用加的。然后保存退出，重新刷一下界面就看到效果了。 vim的替换语句 :%s/DejaVuSans/kaiti/g 3.x版本的处理方法现在zabbix已经升级到3.x了，上述的方法已经失效了，这里记录一下新的中文配置方法。 首先从windows里，拷贝一个中文字体的文件到zabbix的服务器的/usr/share/zabbix/fonts文件夹里，比如我先择了“楷体”，这个文件叫simkai.ttf，chmod +x simkai.ttf 给予可执行权限。 然后vim /usr/share/zabbix/include/defines.inc.php，修改两处地方，分别是第四十五行，把原来的改成simkai，如图： 还有一处就是第九十三行，也是改成SIMKAI： 保存文件之后，刷新一下zabbix界面即可。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"运维与监控","slug":"运维与监控","permalink":"http://yoursite.com/tags/运维与监控/"}]},{"title":"防盗链的等等相关","slug":"防盗链的等等相关","date":"2018-01-22T01:48:38.000Z","updated":"2018-01-22T02:27:02.701Z","comments":true,"path":"2018/01/22/防盗链的等等相关/","link":"","permalink":"http://yoursite.com/2018/01/22/防盗链的等等相关/","excerpt":"","text":"为什么网站们都要限制流量？无论是网站服务器亦或是游戏服务器还是邮件服务器，说穿了也是一台电脑，也有CPU和内存。只不过服务器的CPU功能比个人电脑的CPU功能强大，比如个人电脑的CPU一秒钟能算1亿个数，那么服务器的CPU一秒钟就能算十亿个数。毕竟个人电脑只针对个人，但是服务器是要“接客”的，有了强大的硬件做后盾，网页/游戏/邮箱才不会那么轻易的Down掉。 但是CPU不是人类大脑，人脑是越用越聪明，CPU是越用越磨损，毕竟始终在连电的环境下。于是乎，没有必要的运算能省就省，一个人省一次，十万个人就省十万次，一千万个人就省一千万次，这样达到积少成多的目的。 CPU计算的是各种数据，而这些数据也叫作流量。有用的流量、有价值的流量通过CPU计算无可厚非，但是出现了没有用的流量或者是别人盗用我们的资源，那么这种情况能避免都要避免。什么叫盗用我们的资源，比如自己网站（网站A）上的图片或者视频，被其他人直接复制网站然后粘贴到他们的主页（网站B）上，其他用户登录了B网站，然后点击了那个图片和视频，由于是网址重链接，里外里提供数据的还是我们的服务器。也就是说B网站就是一个中介，而真正提供服务的是网站A，但是广告费和点击率都要网站B赚走了，这事儿实在是叔可忍婶不可忍。 什么是盗链？如何发现被盗链？什么叫盗链，上面已经说的差不多了，如果上面的文字没有看懂的话，举个例子，如果您看到了这两个图片，证明这个网站就是在盗链。 这两个就是一个盗取的是QQ空间的图片，另一个就是百度的图片。用其他网站的图片这事儿本身是无所谓的，只要不涉及版权问题，都希望自己的作品能广泛传播，但是请不要直接通过网址重定向，厚道一点的行为应该是：“图片另存为”，然后到目标网站上去重新上传一下。 这里再多说一点网站的基础知识。 PV值：PV=page view，网站是有少则一个网页多则N多网页组成的一个整体，PV值就是统计用户访问网站的总页数。比如www.JQK.com这个网站，今天有100个用户登录，平均每个用户翻阅了里面5个网页。那么这个网站的PV值就是500。若一个IP地址，对一个页面刷新10000次，PV值也是1.要查询网站的PV值登陆http://www.alexa.cn就行。 Hit值：这个就是对网页里每个元素的点击量，一个网页里的图片就是一个元素，一个flv文件也是一个元素，一首歌曲也是一个元素。这些的总量就是hit值，hit值越高就证明这个网站被人查看的情况越高，那么也证明网站的高人气，那么自然广告也会卖出去很多钱。 因为建网站这事儿关心到了金钱利益，网站越被人关注，自然价值也越大。于是会有一个公式来评判网站的“每日贡献”：总流量=访问流量+下载流量= Page view值 x 页面大小+下载文件大小 x 下载次数 作为管理者，每天观察一下自己一亩三分地儿的网站数据情况是本职工作。但是有时候也会遇到网站流量很惊人的情况，一般来说，网站流量过大（CPU运转很多）的原因如下： 1）网站是一个很大的网站：比如说淘宝，京东，网易，youtube,facebook那种大网站，里面成万上亿的网页，而且每天又有那么多人登陆，自然浏览量很大。虽然这些大集团的服务器也是少则几千，多则上万，甚至在不同地区也会有不少的服务器集群，但是这几万台服务器需要提供的数据会很多也是不争的事实。这种现象是正常的。 2）网页内容太大：可能本身网站是一个小网站，加起来也就十页二十页的内容，但是每一天的流量依旧很惊人，那么很有可能是单页或者某几页的字节太大。比如网页里有太多的图片，太多的视频，太多的其他链接，也有可能是前端码农们给这个网页的规划不合理。导致这个网页每一次被点击都要大费周折（hit值和PV值不高，但是日流量很高），长此以往不仅会耽误用户的整体体验，对服务器也是一个重大伤害。 3）搜索引擎产生了大量的数据流量：网站需要推广，于是就在各种搜索引擎上打广告，也有自己网站的很多图片用于外部调用。这样的结果就是本身来观摩网站的人很少，但是“借着引擎经过”的人很多，所以就会有PV值不高，但是Hit值和日流量很高的现象出现。 4）图片或者其他元素被盗链：第一部分就说过了，别人拿我们的图片去吸引别人关注，然后别人想要深入了解，还要来使用我们的服务器去提供详细数据。这种“用我们的牌子住我们的房，吃我们的饭却不给我们钱”的现象实在应该被弄死。这种现象的特征也是PV值不高（没人真正点击网站），但是Hit值和日流量很大（自己服务器的数据都给别的网站提供了）。 5）网站被DDos攻击了：被一些恶意的IP地址频繁登陆，来回的刷流量。这样迫使CPU做出运算的行为其实就是在远程的破坏服务器的硬件CPU，遇到这种现象，之前Nginx文章里有写，要么通过access.log找到这些IP封掉，要么就在配置文件里加上限制limit-rate。 服务器是如何知道图片是从站外而来的呢？在http协议里有一个重要的选项叫refer，这个选项的内容就是该元素的来源地址。如果这个元素是服务器自己提供的，那么头文件里是没有refer这个选项的。通过refer这个信息，我们也可以知道登陆网站的客户是从哪个网站点击链接而来的。这样方便进行一个统计和规划。 假如，我在QQ空间里面发现一个图，然后右键图片，选择”在新标签栏里打开图片”，这时候通过浏览器“审查元素”的功能，能查查看请求头信息和响应头信息，发现响应头信息里多了一个refer，里面的内容就是图片的源地址： 我在QQ空间里看腾讯的照片自然是可以的，但是如果我在别的网站里看腾讯的照片，加重了腾讯服务器的负担，自然腾讯公司会不满意。于是腾讯服务器发现当前要引用这个图片的地址与refer头信息不是一个来源之后，就不会把这个图片的数据传送过来，于是就看到那个“此图片来自QQ空间，未经准许不可饮用”的警告图片。 既然知道了服务器是如何判断文件是否盗链，那么只要伪装一个refer就可以欺骗服务器达到“反防盗链”的目的了。至于这部分，可以自己单独研究。如何使用Nginx反盗链？ 同样的使用Nginx.conf，在http的大括号下面，新建一个location，加入如下信息： 12345678910111213141516location ~ .*\\.(wma|wmv|asf|mp3|mmf|zip|rar|jpg|gif|png|swf|flv)$ &#123;#指定对以上几种类型的文件建立防盗链 valid_referers none blocked *.alala.com alala.com;#盗链的范围不包括alala.com和alala.com下的二级网站， if($invalid_referer) &#123; #rewrite ^/ http://www.alala.com/error.html; return403;#如果发现有引用以上文件的地址与refer头信息不符的情况，直接重定向成error.html这个网页，服务器返回403，forbidden。 &#125;&#125; 使用第三方模块ngx_http_accesskey_module实现Nginx防盗链实现方法如下： 下载NginxHttpAccessKeyModule模块文件：http://wiki.nginx.org/File:Nginx-accesskey-2.0.3.tar.gz； 解压此文件后，找到nginx-accesskey-2.0.3下的config文件。编辑此文件：替换其中的$HTTP_ACCESSKEY_MODULE为ngx_http_accesskey_module； 用一下参数重新编译nginx： ./configure –add-module=Nginx目录/to/nginx-accesskey然后执行: make &amp;&amp; make install 修改nginx的conf文件，添加以下几行： 123456location /download &#123; accesskey on; accesskey_hashmethod md5; accesskey_arg \"key\"; accesskey_signature \"mypass$remote_addr\";&#125; 其中：1.accesskey为模块开关；2.accesskey_hashmethod为加密方式MD5或者SHA-1；3.accesskey_arg为url中的关键字参数；4.accesskey_signature为加密值，此处为mypass和访问IP构成的字符串。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"http","slug":"http","permalink":"http://yoursite.com/tags/http/"},{"name":"网络相关","slug":"网络相关","permalink":"http://yoursite.com/tags/网络相关/"}]},{"title":"记录一次配置http跳转https的过程","slug":"记录一次配置http跳转https的过程","date":"2018-01-18T09:33:31.000Z","updated":"2018-03-06T14:06:46.000Z","comments":true,"path":"2018/01/18/记录一次配置http跳转https的过程/","link":"","permalink":"http://yoursite.com/2018/01/18/记录一次配置http跳转https的过程/","excerpt":"","text":"公司最近搞了一个数据运营平台，这个平台会以web界面的形式把各个数据展示出来，这个项目是我们一个经理的重点关照项目。把平台模块部署完毕并且启动之后，又把这个平台服务器的外网IP绑定到alkaid.lechange.com这个域名上，在浏览器里输入https://alkaid.lechange.com,就看到了前端同行们写的网页。 但是我们的霸气经理说这样不行，说要更多要求更高标准更好体验，于是乎提出一个需求就是：在输入alkaid.lechange.com的时候会自动跳转到https://alkaid.lechange.com。 既然如此，我们就在nginx上原有的nginx.conf里补充几个配置文件： 12345#include upstreaminclude upstream.conf;# include serversinclude alkaid.conf;include alkaid-https.conf; 这样在执行nginx.conf的时候，就会调用upstream.conf、alkaid.conf和alkaid-https.conf，我们主要看一下这三个文件。 alkaid.conf文件如下： 123456789server &#123; listen 80; server_name *.lechange.com; proxy_buffering off; location / &#123; rewrite ^/ https://alkaid.lechange.com permanent; client_max_body_size 100m; &#125;&#125; 这里我们监听了80端口，下面那个client_max_body_size 100m是用来设定nginx+php上传文件的大小，这里规定是100m，这个可以写进nginx.conf里，如果有对上传文件方面感兴趣，可以看http://www.cnblogs.com/zhwl/archive/2012/09/18/2690714.html 。 再来看看alkaid-https.conf，如下： 1234567891011server &#123; listen 10000; server_name *.lechange.com; proxy_buffering off; location / &#123; proxy_pass http://alkaid_backend; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; proxy_redirect off; &#125;&#125; 这里监听了10000端口，location写的是http://alkaid_backend,这个alkaid_backend是啥东西? 这个时候我们就需要看一下upstream.conf，里面内容是: 1234upstream alkaid_backend &#123; server X.X.X.X:JQK; check interval=5000 rise=2 fall=5 timeout=1000 type=tcp default_down=false;&#125; X.X.X.X是模块服务器的内网IP地址，而JQK是模块服务器的模块端口，这里要根据实际的情况来写。可见alkaid_backend对应的就是模块服务器和它的端口，下面是检查间隔等等数值。 现在我们启动nginx，然后把nginx的外网地址绑定去alkaid.lechange.com这个域名，在浏览器里输入alkaid.lechange.com，就会达到自动跳转的目的了！ 这里要额外多说一下，我们这里设定了80的配置文件也设置了443的文件，但是这俩文件的转发过程却不同：alkaid-https.conf文件把443的请求转向了平台模块服务器的服务，而alkaid.conf文件把凡是从80端口进来的请求直接全部永久重定向到https://alkaid.lechange.com ，但是这个alkaid.lechange.com还是会去访问平台模块服务器的服务，也就是说alkaid.conf文件多了一步重定向。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"https","slug":"https","permalink":"http://yoursite.com/tags/https/"}]},{"title":"将电商平台测试环境添加了域名和https","slug":"将电商平台测试环境添加了域名和https","date":"2018-01-18T06:42:12.000Z","updated":"2018-01-22T02:35:58.000Z","comments":true,"path":"2018/01/18/将电商平台测试环境添加了域名和https/","link":"","permalink":"http://yoursite.com/2018/01/18/将电商平台测试环境添加了域名和https/","excerpt":"","text":"情况描述今天电商平台来了新的产品经理。摸了一遍情况之后，提出了两个需求，第一个是要把测试环境也要上https，达到与线上一致；第二个就是测试环境要配上域名，不要再用IP地址登陆。 配置域名是很简单的，在阿里云的云解析上直接给测试环境新加一个域名，然后对应添加阿里云外网SLB的IP地址即可。进入页面也发现首页地址显示正常，但是再点点就发现了里面有点不对。 没错，现象就是“只有首页是域名，其他网站都是IP”， 遇到这个情况，我就跑去nginx.conf里，看一下server_name的配置，看到的确写得是func.lechange.com，如图： 于是就在页面上使用ctrl+shift+c查看具体情况，发现里面的代码是这个样的： 这就人赃俱获了，开发已经在html里把地址写死了，使用了绝对路径而不是相对路径，于是就打回让开发自己慢慢改。 然后又回到SLB界面，新增新的https监听，前端端口443，后端是80，搭配正确的证书，SLB保存之后，在浏览器输入测试环境的https://网址之后，发现整个界面全乱了，如图： 但是使用http://网址去访问还是正常的，如图： 很明显，这是因为https下跨协议调用http的是不行的，所以那些css、js如果不支持https的话就无法正常显示。使用ctrl+shift+c看错误更加明显。 遇到这个问题，就有如下几种方法： 第一种：将所有的访问路径都写死https，不过这个我们公司代码规范不准许;第二种：去掉URL中的http://或https://，将其替换为//，这样，浏览器就可以根据当前页面的请求方式来动态切换了；第三种：可以在&lt;head&gt;中添加&lt;meta http-equiv=&quot;Content-Security-Policy&quot; content=&quot;upgrade-insecure-requests&quot;&gt;,浏览器会在加载HTTP资源时自动替换成HTTPS请求；第四种：在nginx里写一个proxy_redirect跳转，这个就比较有技术含量了； 参考资料https://thehackernews.com/2015/04/disable-mixed-content-warning.htmlhttps://www.tuicool.com/articles/ARVVFjIhttps://developer.mozilla.org/en-US/docs/Web/Security/Mixed_content/How_to_fix_website_with_mixed_content","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"网络基础","slug":"网络基础","permalink":"http://yoursite.com/tags/网络基础/"}]},{"title":"Linux运维工程师笔试题第十四套","slug":"Linux运维工程师笔试题第十四套","date":"2018-01-17T14:18:33.000Z","updated":"2018-03-06T13:49:54.000Z","comments":true,"path":"2018/01/17/Linux运维工程师笔试题第十四套/","link":"","permalink":"http://yoursite.com/2018/01/17/Linux运维工程师笔试题第十四套/","excerpt":"","text":"前言这几天一边看着《nginx高性能WEB服务器详解》，一边看着基础知识。那么最容易入眼的基础知识是什么呢？当然是面试题了，于是乎就找出来一些阿里（含滴滴和蚂蚁金服）的运维面试题，以题带看。 看完之后觉得阿里真的不是盖的，面试题的质量比那些晚上乱七八糟的题质量好多了，细节抠的真是非常细。我记得曾经有一个前辈曾经说过，工作中我们经常注意一些奇淫技巧，但是忽视了基础知识的重要性，现在好多程序员不会认认真真地读本书，喜欢快餐文化，受了市面上很多培训机构的影响，这是要不得的。 最后再说一句，以下所有的题都属于“开放性”试题，可以根据基本点去发散，说出你的理解和认识。但是注意，不要避重就轻耍滑头，问A，可以发散到A1、A2…但是不要发散到X、Y、Z，然后大谈特谈XYZ，这种“小聪明”就是找死的行为。 废话到此为止，上题1）http一般是无状态的，怎么让它变成有状态的？[我的答案]http协议跟IP协议、UDP协议一样都是无状态的，http的无状态意思是“每次的请求都是独立的，它的执行情况和结果与前面的请求和之后的请求是无直接关系的，它不会受前面的请求应答情况直接影响，也不会直接影响后面的请求应答情况”。补充一下，TCP是有状态的，它的请求并不独立，它通过包头的一些控制字段来分别包的关系，这里可以自行脑补一下“三次握手”的图。 那么http是无状态的这一点是无法改变的，那么要变得“有状态”，就需要引入cookie和session，通过这两个机制去实现一个有状态的WEB应用。用一个表达式可以这么理解：Web应用=http协议+session、cookies等状态机制+其他辅助的机制。 2）解释一下cookie和session的区别[我的答案]session是在服务端保存的一个数据结构，用来跟踪用户的状态，这个数据可以保存在集群、数据库、文件中，session是一个抽象概念，开发者为了实现中断和继续等操作，抽象出来的一个“会话”，接上面那道题，session这个东西是有状态的，服务器要维护一个有状态的东西是很消耗资源的（比如内存和空间），我估计天猫京东那规模的电商，肯定有一个专门的session集群。 Cookie是客户端保存用户信息的一种机制，用来记录用户的一些信息，也是实现Session的一种方式，cookie是一个实际存在的东西，它是在http协议中定义在header中的字段。同一个域名给的cookie肯定是一样的，所以每一个cookie（key）对应的session（value）是唯一的。 session的常见实现要借助cookie来发送sessionID给客户端，如果浏览器禁用cookie，那么就要通过重写url来获取sessionid，各位可以联想一下电商的购物车，购物车可以实现在一个网站的不同页面把东西都放进一个购物车，这就是session的重点应用。现在也很流行一个token，其实token和sessionid是一个意思。 3）多进程和多线程的区别，自己喜欢用哪个？为什么？[我的答案]多进程：服务器每当接收到一个客户端信息的时候，从主进程里生成一个子进程与客户端建立连接开始交互，每一个子进程之间互相独立不受干扰，完成任务就收回资源，内存等也会被回收；多线程：服务器每当接收到一个客户端信息的时候，从主进程里生成一个线程与客户端建立连接开始交互,多个线程位于同一个进程内，可以互相访问同样的内存等资源，彼此之间会有影响；我个人更喜欢多进程，因为简单粗暴！ 关于多进程、多线程、同步、异步的原理，可以去看一下《nginx高性能WEB服务器详解》，第54页到56页的内容。 4) lvs脑裂如何解决，为什么会产生双master？双master时VIP通不通?[我的答案]产生双master的原因：1）服务器开启了iptables防火墙，阻碍了心跳信息传输；2）服务器心跳网卡等信息写错了，导致心跳信息发送失败；3）心跳方式不搭配，心跳广播冲突；4）软件出bug了； 额外补充一句，要排除脑裂问题，第一步是检查iptables,很可能是由于iptables把心跳信息隔断了，重要的话不说三遍也重要！ 其他两个问题不会了，我在实际工作里没有接触到。 5) 为什么TCP比UDP的信息更加可靠？详细说说tcp滑动窗口原理，窗口的大小如何确定。TCP可靠性由三个机制保证：1. 序号（TCP报文的序号）2. 确认（ACK机制）3. 重传（超时或者冗余的 ACK）tcp在传输的时候，因为接受方B能力有限，不可能一口气吃下所有发送方A所有的数据流信息，所以B要限制A每次发送的字节数量，并且一一确认，确认了之后A才可以继续发。这样的话，A的在发送数据流的时候就会有四种形态：1.已发送已确认；2.已发送但没被确认；3.未发送但是接受方已经准备好空间来接收；4.未发送但是接受方尚未准备好空间来接收；随着数据流的传输，这个形态是会时刻发生变化的，通过接受方B返回的确认信息来改变2的大小，同时B也会根据一次关于发送方A要发送多少字节确认自己的空间来改变3的大小。 6) 简单说说cdn的工作原理，如何评估一个cdn sp做的好不好。[我的答案]cdn的工作原理：通过权威dns服务器来实现优质节点的选择，通过缓存来减少源站的压力。 IT界有个很有名的比喻，正向代理是“找马云借钱”，反向代理是“给10086打电话”，而反向代理就是CDN的实现原理雏形的一部分。详情可以看：http://www.iweir.cn/zheng-xiang-dai-li-yu-fan-xiang-dai-li/ 。 7）dns查询的过程说一下，为什么要有cname而不是直接返回一个cdn边缘节点的ip。[我的答案]先说一句题外话，dns主要是基于udp的！dns查询的过程以www.taobao.com为例：1.在浏览器键入www.taobao.com,其实真正dns协议里用到的是www.taobao.com.最后还有一个点，可能是因为美观等原因，一般都不显示;2.查询本地缓存（host文件或者是浏览器的缓存）中有没有该域名对应的记录，有的话就直接用了;3.向运营商的DNS服务器发起dns解析的请求，一般称运营商的DNS服务器为local dns;4.local dns会查询本地的缓存，local dns设置的缓存时间是有讲究的，过长过短都不好。另外local dns的查询是运营商的事，这里面水很深，外部不可控(这也是天朝能搭建特色墙的根源的思想雏形)；5.local dns如果没有缓存，会把域名从右往左扫描，依次请求对应的服务器，例如对于域名www.taobao.com.，先去问负责.的根域名服务器，就是传说中全球只有几台的那些服务器，他们会答复.com是谁管理的，然后local dns又去找管理.com的服务器（假设名字为S1），去问问taobao.com是谁管，一般来说，在S1查到的记录是一条cname记录（阿里毕竟大公司，自己管理自己旗下的域名），然后就转到了阿里自己的DNS服务器上来了，一般称之为权威服务器；6.权威服务器是阿里自己建的，然后根据公司内部的一些配置啊，调整啊，查到www.taobao.com.对应的服务器是谁，返回一个IP地址；7.local dns缓存这个IP地址，并且回复浏览器；8.浏览器和对应的IP地址的服务器建立TCP连接，发送HTTP报文； 用图表示就是： 至于说为什么不返回cdn边缘节点IP，是因为使用CNAME记录可以很方便地变更IP地址，毕竟服务商掌握着IP的生杀大权，哪一天需要换IP了，在这方面很不方便。 8）举例说下正则表达式和扩展正则表达式、例如：url、ip、邮箱的正则表达式？[我的答案]这三个都是网上找的，正则这个东西还是要多练多写。url的正则表达式：([/w-]+/.)+[/w-]+.([^a-z])(/[/w- ./?%&amp;=]*)?|[a-zA-Z0-9/-/.][/w-]+.([^a-z])(/[/w- ./?%&amp;=]*)?ip的正则表达式：^(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|[1-9])\\.”+”(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|\\d)\\.”+”(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|\\d)\\.”+”(1\\d{2}|2[0-4]\\d|25[0-5]|[1-9]\\d|\\d)$邮箱的正则表达式：^[a-zA-Z0-9.!#$%&amp;’+\\/=?^_`{|}~-]+@a-zA-Z0-9?(?:.a-zA-Z0-9?)$ 9）解释raid0、raid1、raid01、raid10、raid5、raid6，并分析各自读写性能？[我的答案]https://rorschachchan.github.io/2018/01/31/简析raid0-raid1-raid10-raid01等等硬盘搭配/ 10）raid为什么不搞个raid50、raid15，不能搞是因为有什么冲突还是什么等等?[我的答案]raid50是有的，但是用途不广泛。raid15我是没听说过，因为raid1的写本身就不强（一样的内容要写两个盘里），raid5的写入能力更烂，那么raid15的磁盘写能力简直就是灾难。而且花了硬盘的钱只能存实际一半的量，正常人都不会这么做的。 拓展阅读https://segmentfault.com/a/1190000007243675http://mertensming.github.io/2016/10/19/cookie-session/https://wizardforcel.gitbooks.io/network-basic/content/index.htmlhttps://coolshell.cn/articles/11564.htmlhttps://coolshell.cn/articles/11609.htmlhttp://blog.sina.com.cn/s/blog_93b45b0f0101a4ix.htmlhttp://www.cnblogs.com/549294286/p/5172435.htmlhttps://wizardforcel.gitbooks.io/network-basic/content/7.html（这个墙裂推荐，基础知识）http://blog.jobbole.com/105500/http://www.austintek.com/LVS/LVS-HOWTO/HOWTO/LVS-HOWTO.failover.html","categories":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/categories/大牛之路/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://yoursite.com/tags/面试/"},{"name":"职场","slug":"职场","permalink":"http://yoursite.com/tags/职场/"}]},{"title":"实战Kibana的日志关键词搜索和日志可视化","slug":"实战Kibana的日志关键词搜索和日志可视化","date":"2018-01-17T07:44:01.000Z","updated":"2018-01-22T02:32:44.000Z","comments":true,"path":"2018/01/17/实战Kibana的日志关键词搜索和日志可视化/","link":"","permalink":"http://yoursite.com/2018/01/17/实战Kibana的日志关键词搜索和日志可视化/","excerpt":"","text":"准备工作首先，先下载一个elastic网站上下载一个它提供的demo—莎翁的《亨利四世》，下载地址是https://download.elastic.co/demos/kibana/gettingstarted/shakespeare.json 。 打开这个json字符串，里面就是《亨利四世》的话剧剧本，长得是这个样子： 可以看到里面有play_name、speaker、speech_number、line_id等等名称，每个名称后面都有一个对应的值。 然后启动elasticsearch，按照上面的文件格式生成索引。语句如下： 1234567891011121314curl -XPUT http://localhost:9200/shakespeare -d '&#123; \"mappings\" : &#123; \"_default_\" : &#123; \"properties\" : &#123; \"speaker\" : &#123;\"type\": \"string\", \"index\" : \"not_analyzed\" &#125;, #确定type是字符 \"play_name\" : &#123;\"type\": \"string\", \"index\" : \"not_analyzed\" &#125;, \"line_id\" : &#123; \"type\" : \"integer\" &#125;, #确定type是数字 \"speech_number\" : &#123; \"type\" : \"integer\" &#125; &#125; &#125; &#125;&#125;'; 导入刚刚下载的那个json：curl -XPOST &#39;localhost:9200/shakespeare/_bulk?pretty&#39; --data-binary @shakespeare.json 具体elasticsearch的增删改查语法可以参看阮大师的http://www.ruanyifeng.com/blog/2017/08/elasticsearch.html ，个人建议将elasticsearch和mysql对比一下，这样更方便理解。 然后后台启动kibana，确认5601端口已经stand by，如图： 然后在浏览器地址栏输入服务器外网ip：5601打开kibana。 导入数据结束之后，使用curl &#39;localhost:9200/_cat/indices?v&#39;，去查看一下效果，如果看到index里有shakespeare那一栏就是导入成功了，如图： 在启动Kibana后，Kibana会自动在配置的es中创建一个名为.kibana的索引（上图第二个），这个索引用来存储数据，注意！不要删除了它。 Kibana的界面搜索如果此时的kibana里是第一次配置的话，那么第一步就是配置新索引，我们之前在生成索引的时候写的是shakespeare，那么现在也写shakespeare，然后点击create，如图： 然后在菜单栏左侧的discover里选择刚刚建立的shakespeare，就会看到这样的东西： 在Search上就可以进行搜寻，比如说我搜寻freedom，如图： 如果我搜寻KING HENRY IV，他不分大小写的把所有king、henry、iv都搜索出来。 如果我想搜寻line_id的第一行到第三行，那么语句就是line_id:[1 TO 3]，如图： 如果想在上面的基础上进一步细化，比如说要在line_id是从第一行到第三行，同时_type是scene的语句：line_id:[1 TO 3] AND _type:scene： 假如不想要scene，那么就把AND改成NOT。 如果这个时候只想关注一些指定的字段，那么可以将鼠标移动到索引下面的字段上，然后选在add即可，同样的移动上面已经选择的字段选择remove进行移除，比如我们试一下这个speaker： add之后在点击右侧的具体的speaker，就会看到里面的细节，比如这位westmoreland（威斯摩兰伯爵）： 这个时候就能看见这位伯爵大哥的台词细节，在第几场的第几节，说的是什么台词。再返回菜单左侧点击这个speaker，我们还会看到一个比重： 从这里就很清晰的看到，FALSTAFF（法斯塔夫）这个哥们的台词最多，也符合书里塑造的那个嗜酒话痨的艺术形象。而我们的KING HENRY IV(亨利四世)的台词只是第四位，占比重11%而已… 这样具体的搭配搜索之后，可以点击界面右上侧的save进行保存搜寻结果，再搭配share分享搜索结果的url网址，如图： Kibana的图像化展示Kibana也能做到类似grafana那样的炫酷图象化展示，更加立体的表现日志情况，首先选择左侧菜单栏里的Visualize（可视化）： 然后点击Create a Visualization,里面既有很多种图形供你选择，有饼型，有箭头的，有文字的，有仪表盘的，如图： 我们这里先建立一个饼型的，还是上面那个台词多少的例子，首先选择shakespeare作为数据源，然后点击split slices，如图： 然后在Aggergation里选择Terms，然后在Field里选择Speaker,size那里写8,最后点击上面的那个三角播放键，看看结果： 这就很清晰的看出，亨利四世一共说了1086句话，占比11.11%。 如果我们再加一个Split Slices，这一次在原有的specker的基础上选择play_name，图象变成了一个同心圆，最外面的一层就是新增的“play_name”的情况，如图显示FALSTAFF的所有台词会在两个play_name里出现： 如果这个盘子里不想统计FALSTAFF这个话包，就添加一个过滤器，选择speaker is not，后面写上FALSTAFF即可，如图： 效仿刚才的方法也可以做一个仪表盘，如图： 可视化的数据也可以save和share，同样在web界面的右上角。保存的数据是可以在左侧菜单栏里的Dashboard里展示，做成一个类似zabbix那样的展示！","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"大数据","slug":"大数据","permalink":"http://yoursite.com/tags/大数据/"},{"name":"elk","slug":"elk","permalink":"http://yoursite.com/tags/elk/"}]},{"title":"工作所用的模块回滚脚本","slug":"工作所用的模块回滚脚本","date":"2018-01-17T04:25:25.000Z","updated":"2018-01-22T02:31:06.000Z","comments":true,"path":"2018/01/17/工作所用的模块回滚脚本/","link":"","permalink":"http://yoursite.com/2018/01/17/工作所用的模块回滚脚本/","excerpt":"","text":"前言与脚本内容部署中常备一个回滚脚本也是很有必要的，我所在公司的服务器模块名都是在初始化的时候写进/etc/role_install这个文件里，如下图的这个服务器就是fss服务器： 再比如下面这个服务器，虽然包含nginx的组件但是httpproxy的服务器： 那么有了这样的前提，整个回滚的脚本内容如下： 12345678910111213141516171819202122232425262728293031#!/bin/bash#Written by ChrisChan @July-4th-2017#Desription:这是一个回滚的脚本。module=$(cat /etc/role_install |grep -v zkclient|grep -v nginx)echo -e '\\033[31m现在将执行回滚操作，本次回滚只回滚普通模块，不包含nginx和zkclient!\\033[0m' echo \"回滚的模块名称：\"$moduleecho -e '\\033[33m如果想取消回滚操作，请ctrl+c立即停止本脚本...\\033[0m'sleep 5cd /dxpbackup/hswx/$module &amp;&amp; zip $module.zip -x \"*og*\" -r . #到备份的文件夹里去压缩mv /dxpbackup/hswx/$module/$module.zip /mnt/hswx echo $module\".zip文件已经生成！\" until [ \"$decision\" == \"Y\" -o \"$decision\" == \"y\" -o \"$decision\" == \"N\" -o \"$decision\" == \"n\" ]do read -p \"请问是否用回滚的压缩包覆盖到/mnt/hswx下？(y/n)\" decision echo \"您的选择是：\"$decision if [ $decision == Y -o $decision == y ] then echo \"现在已经开始覆盖...\" rm -rf /mnt/hswx/$module #先把原来的内容删除 unzip /mnt/hswx/$module.zip -d /mnt/hswx/$module #重新解压缩进去 echo -e '\\033[32m覆盖已经完成，可以直接执行/startall脚本!\\033[0m' elif [ $decision == N -o $decision == n ] then echo -e '\\033[32m生成的'$module'.zip文件保存在/root文件夹里\\033[0m' else echo -e '\\033[31m输入字符不符合!请重新输入!\\033[0m' fidone 新的知识点！1）zip在压缩文件夹的时候要过滤掉某些文件使用“-x”参数，比如说要在AAA文件夹里面过滤掉abc和jqk这两个文件，那么语句就是zip AAA.zip -x &quot;abc&quot; -x &quot;jqk&quot; -r .或者是zip -r -x=abc -x=jqk AAA.zip . 这样两个语句。 如果你要过滤掉的是一个文件夹，比如那么就要在文件夹后面名字加上一个，下图就是要压缩整个auc文件夹为456.zip但是又不想要lib这个文件夹，就使用了`zip 456.zip -x “lib“ -r .`： 不过如果文件夹里还有其他lib开头的文件夹也会被过滤掉，这一点要注意。 2）本shell里面涉及了逻辑判断，而[[和[的区别如下图： 3）如果if语句中出现报错“[: too many arguments”，很有可能就是字符串变量中可能存在空格，shell解析时将其认为是多个参数，再进行判断时，无法知道该获取哪个值，所以最好都用双引号括起来； 4）如果是“变量a等于aa且变量b等于bb 或者 变量c等于cc且变量d等于dd ” 这样的判断句怎么写？答曰： [ $a = “aa” -a $b = “bb” ] || [$c = “cc” -a $d = “dd” ] 参考资料https://zhangge.net/4776.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"Shell","slug":"Shell","permalink":"http://yoursite.com/tags/Shell/"}]},{"title":"Ansible的几个基本语句","slug":"Ansible的几个基本语句","date":"2018-01-17T03:43:52.000Z","updated":"2019-08-26T04:17:46.000Z","comments":true,"path":"2018/01/17/Ansible的几个基本语句/","link":"","permalink":"http://yoursite.com/2018/01/17/Ansible的几个基本语句/","excerpt":"","text":"开篇的废话批处理工具我最早接触的是pssh，因为它实在很简单粗暴，但是它由于太简单粗暴了，应付十台二十台机器还OK，应付五十台一百台服务器就心有余力不足了（而且xshell右键有一个“发送键入到所有会话”的功能，与pssh效果几乎一样），而且我还不太喜欢puppet，总觉得那玩意跟我八字不合，于是乎，在新头头的推荐下，我把目光放在了Ansible。 Ansible的安装很简单，在Redhat环境下直接yum install -y ansible就行。Redhat已经将Ansible公司收购了，所以在安装上提供了不小的便利。 Ansible在安装完毕之后，会在/etc/ansible/目录下看见一个叫hosts的文件，这里是所有你要控制的服务器的ip们，可以排列写，比如： 123192.168.1.122192.168.1.133192.168.1.144 也可以分组写，比如： 1234567[aliyun]10.22.33.4410.22.33.45[jinshanyun]121.23.45.66121.23.45.67121.23.45.68:2222 （这个不是使用ssh默认的22端口，就需要特别指出） 默认情况下，Ansible会把命令全用于这个hosts文件，比如 ansible all -m ping -u ashin这句话意思是整个hosts里的机器以ashin账户启动，而且都要ping 一下当前本机。 具体语句怎么连接主机与要控制的远程机器请按之前写的“http://chenx1242.blog.51cto.com/10430133/1763978”一文进行操作，这里先说几个命令语句： 1)ansible all -m shell -a &quot;/bin/echo hello&quot;对hosts里所有的机器一起使用”输出hello这个文字”。-m shell可以忽略不写，但是不是shell而是其他的模块就要写出来； 2)ansible aliyun -m copy -a &quot;src=~/projects/tests/t.py dest=~&quot;把hosts里aliyun组的机器的/projects/tests/t.py复制到~目录下；[注意！]copy模块不支持变量路径，也就是说如果目标服务器的部署路径不同，copy不会很智能的去访问.bash_profile来得到用户的自定义变量，写变量替换路径是不会达到目的的。 3)ansible jinshanyun[0:9] -i -m file -a &quot;dest=~/tests state=absent&quot;把hosts里jinshanyun组中从0~9这十台机器的/tests文件夹删除掉，absent是“缺席，不在”的意思； 4)ansible 192.168.1.133 -m ping这句话=ping 192.168.1.133； 5)ansible v1 -m service -a &quot;name=mysql state=started&quot; -u ashin --sudo -K以用户名为ashin登陆hosts里所有v1组的机器，然后检查mysql是否是started状态，若不是就start，同时要输入root的密码作为确认； 6)ansible 10.11.22.* -m user -a &quot;name=foo password=foo&quot; --sudo -Khosts文件里所有10.11.22开头的机器，都要添加一个新的用户名foo，同时密码是foo，并且输入root密码确认身份； 7)ansible v1:!v2 -m apt -a &quot;name=git state=latest&quot;检查所有属于v1组同时还不属于v2组的机器里的git文件是否是最新版本； 8)ansible webservers:&amp;dbservers -a &quot;/sbin/reboot&quot; -f 10 --sudo -K重新启动既是webservers组又是dbservers组的所有机器； 9)ansible webservers -m raw -a &#39;yum -y install python-simplejson&#39;用ansible去链接低版本的centos时，就乎出现“ansible requires a json module, none found! ”的错误，需要远程机安装samplejson包。raw模块是靠底层ssh的通讯，不依靠python的模块，所以如果碰到低版本的系统，如果command和shell模块无法使用，可以先用这条命令安装完需要的包。 10)ansible all -m synchronize -a &quot;src=/chenshuo/1.sh dest=/chenshuo delete=yes&quot;synchronize原意是“同步”，而这个模块是分发模块，这句话的意思是把控制端的/chenshuo/1.sh分发给host文件里的所有ip服务器，delete=yes意思是以控制端服务器的文件为准。 11)ansible 10.168.194.89 -m synchronize -a &quot;mode=pull src=/chenshuo/nba.txt dest=/chenshuo/a.txt&quot;将10.168.194.89这台服务器上的/chenshuo/nba.txt拉到控制服务器的/chenshuo文件夹下，顺便改名叫a.txt。 12)ansible all -m get_url -a &quot;url=https://pypi.python.org/packages/56/2b/9c9c113fb88082950067a42cc99e3c61f1df72035f89bb0bdf0a60308ca0/pexpect-4.1.0.tar.gz#md5=562a1a21f2a60b36dfd5d906dbf0943e dest=/chenshuo&quot;把那一大串网址的下载连接下载到host文件里的所有ip的/chenshuo文件夹下。 13)ansible 10.117.14.37 -m script -a &quot;/chenshuo/free.sh&quot;在10.117.14.37上执行操作端的free.sh，注意操作端必须要有free.sh这个脚本，而10.117.14.37这台机器上并不一定要有。 补充如果ansible启动的时候爆RequestsDependencyWarning: urllib3 (1.21.1) or chardet (2.2.1) doesn’t match a supported version!的错误，需要pip卸载urllib3和chardet，再pip安装requests即可。 参考资料http://blog.csdn.net/iloveyin/article/details/46982023","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Ansible","slug":"Ansible","permalink":"http://yoursite.com/tags/Ansible/"},{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"Zabbix用户密码忘记怎么办","slug":"Zabbix用户密码忘记怎么办","date":"2018-01-17T03:12:57.000Z","updated":"2018-01-22T02:29:30.000Z","comments":true,"path":"2018/01/17/Zabbix用户密码忘记怎么办/","link":"","permalink":"http://yoursite.com/2018/01/17/Zabbix用户密码忘记怎么办/","excerpt":"","text":"zabbix的超级用户也是人，人就难免会忘记密码（或者清除了当前浏览器的缓存），忘记密码不要怕，因为zabbix所有的用户数据都是保存在server机器上的mysql里，只要打开zabbix_server.conf，就会查得到mysql的登录账号密码以及zabbix对应的数据库。（这里多说一句，zabbix自带的guest基本就是一个废物，forget it~） 在zabbix_server机器上输入mysql的账号密码来到mysql里，USE zabbix，然后SELECT * FROM users,就会看到笔者的画面。 这个时候就可以使用数据库的update命令去更改密码，比如说新的密码是“woshitiancai”，就可以写update users set passwd=md5(&quot;woshitiancai&quot;) where userid=&#39;1&#39;;然后就可以用woshitiancai来登陆啦~ 但是！！！你以为这就结束了吗？nononono！！！ 很多人即使更改了密码还是登陆不上去，很简单，那就是你连用户名都忘记了！或者是用户名你记得但是你手贱在zabbix的administration里的users对原来的设定增加了新东西，而且这些东西还特么的是中文！！！于是就像我上面图那样出现了???的字样。 那些？？？很重要吗？当然了！！！因为那些才是zabbix的登录用户名！！！看见了吗，zabbix使用蛋疼的alias作为真正的登录名而不是用name or surname，这真是一个蛋疼的事儿！ 那么剩下的问题很简单了，就是把???改变成中文，使用语句set names utf8; 然后界面就成了这样： 这次再使用“主管理员”搭配新的密码就可以华丽的登录了！~~我他妈当时都差点要把这个user表格删掉然后重拽一个表格进来，但是终于还是被我识破了，啊哈哈哈哈，我真是个天才！！！","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"},{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"}]},{"title":"Docker出现客户端与服务端有差的错误...","slug":"Docker出现客户端与服务端有差的错误","date":"2018-01-16T00:36:32.000Z","updated":"2018-01-22T02:28:32.000Z","comments":true,"path":"2018/01/16/Docker出现客户端与服务端有差的错误/","link":"","permalink":"http://yoursite.com/2018/01/16/Docker出现客户端与服务端有差的错误/","excerpt":"","text":"今天用docker搞redis镜像的的时候，出现了这样的错误提示：Error response from daemon: client is newer than server (client API version: 1.24, server API version: 1.22)，如图： 可见使用了docker version的时候也有提示：当前docker客户端比服务端版本更新。这样是无法创建镜像的，遇到这个问题很简单，那就是重启一下docker，命令如下： 12systemctl stop dockersystemctl start docker 然后我们再docker version看一下效果： 我做这个的时候，docker升级了也一样可以读到原先的镜像，但是出于保险起见我们也应该学会如何保存和导入镜像，比如现在我现在有这个叫docker.io/ubuntu的镜像，如图： 如果要备份它的话，语句就是： 1docker save docker.io/ubuntu &gt; /root/ubuntu.image 这里备份后的文件名就是ubuntu.image。 如果要导入的话，语句就是： 1docker load &lt; /root/ubuntu.image 这样导入的话，images create时间是不变的。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"docker","slug":"docker","permalink":"http://yoursite.com/tags/docker/"},{"name":"容器","slug":"容器","permalink":"http://yoursite.com/tags/容器/"}]},{"title":"记录日志系统ELKB 5.6.4的搭建过程","slug":"记录日志系统ELKB-5-6-4的搭建过程","date":"2018-01-15T23:59:43.000Z","updated":"2018-07-10T09:56:04.000Z","comments":true,"path":"2018/01/16/记录日志系统ELKB-5-6-4的搭建过程/","link":"","permalink":"http://yoursite.com/2018/01/16/记录日志系统ELKB-5-6-4的搭建过程/","excerpt":"","text":"前言ELK是最近比较流行的免费的日志系统解决方案，注意，ELK不是一个软件名，而是一个解决方案的缩写，即Elasticsearch+Logstash+Kibana（ELK Stack）。这哥几个都是java系的产品，但是众所周知，java的东西很吃内存和CPU，Logstash在当作为收集日志的Agent时，就显得太过臃肿了。听说直播平台“斗鱼”团队很为logstash占用资源的情况很而苦恼，后来为了解决这个问题，他们自己写了一个agent。不过后来官方在logstash-forwarder的基础上推出了beat系列，里面包括四个兄弟，分别是：Packetbeat（搜集网络流量数据）；Topbeat（搜集系统、进程和文件系统级别的 CPU 和内存使用情况等数据）；Filebeat（搜集文件数据）；Winlogbeat（搜集 Windows 事件日志数据）。而Filebeat也就这样加入了“日志收集分析”的团队里，所以虽然大家还是习惯性的叫ELK，其实准确的说法已经是ELKB了。 ELKB这几个哥们的分工如下： Elasticsearch：分布式搜索和分析引擎，具有高可伸缩、高可靠和易管理等特点。基于 Apache Lucene 构建，能对大容量的数据进行接近实时的存储、搜索和分析操作。通常被用作某些应用的基础搜索引擎，使其具有复杂的搜索功能； Logstash：数据收集额外处理和数据引擎。它支持动态的从各种数据源搜集数据，并对数据进行过滤、分析、丰富、统一格式等操作，然后存储到用户指定的位置； Kibana：数据分析和可视化平台。通常与 Elasticsearch 配合使用，对其中数据进行搜索、分析和以统计图表的方式展示； Filebeat：ELK 协议栈的新成员，在需要采集日志数据的 server 上安装 Filebeat，并指定日志目录或日志文件后，Filebeat 就能读取数据，迅速发送到 Logstash 进行解析，亦或直接发送到 Elasticsearch 进行集中式存储和分析。 设计架构 本文的设计结构就是这样，其中红色的redis/RebbitMQ部分可以省略（我这个例子里暂省略），让日志直接传递到logstash，如果日志量较大，最好还是添加上redis，同时再横向扩容Elasticsearch，搞成一个集群。 对于这几个模块服务器多说几句：1）Logstash要选择计算能力强的，CPU和内存比较丰满的；2）Elasticsearch要选择磁盘容量大的，同时CPU和内存也比较丰满的； 实验软件版本Elasticsearch 5.6.4Logstash 5.6.4Kibana 5.6.4Filebeat 5.6.4Java 1.8+，安装方法：http://blog.51cto.com/chenx1242/2043924由于ELKB这几个东西都是墙外的，墙内的下载可能会比较费劲。所以我稍后会把所有ELKB的5.6.4程序都放在51CTO的存储空间里，需要的朋友可以去下载，还是那话，虽然ELK升级频率很快，但是5.6.4已经足够稳定了。 实验服务器情况 安装Elasticsearch 5.6.4以下所有操作都是root下进行的: 12curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.6.4.rpmrpm -ivh elasticsearch-5.6.4.rpm 然后编辑/etc/elasticsearch/elasticsearch.yml，不然的话logstash无法与之相连： 123cluster.name: my-application #如果是集群的es就把这个打开，Elasticsearch 启动时会根据配置文件中设置的集群名字（cluster.name）自动查找并加入集群，端口是9300network.host: 0.0.0.0 #取消注释，并且改成0.0.0.0http.port: 9200 #取消注释 保存之后，启动并且添加开机启动： 12systemctl start elasticsearch systemctl enable elasticsearch 使用curl localhost:9200能看到这样的情景就证明已经成功启动了： 安装kibana 5.6.4以下所有操作都是root下进行的: 1234curl -L -O https://artifacts.elastic.co/downloads/kibana/kibana-5.6.4-linux-x86_64.tar.gztar xzvf kibana-5.6.4-linux-x86_64.tar.gzcd kibana-5.6.4-linux-x86_64/vim config/kibana.yml 把kibana.yml里的server.host: localhost改成server.host: 0.0.0.0，然后保存退出，在kibana的bin文件夹里执行./kibana即可。如果要后台启动就是nohup /kibana安装路径/bin/kibana &amp;。 启动之后，如图： 安装Logstash 5.6.4以下所有操作都是root下进行的: 12curl -L -O https://artifacts.elastic.co/downloads/logstash/logstash-5.6.4.rpm rpm -ivh logstash-5.6.4.rpm 如果安装的时候爆错：/usr/share/logstash/vendor/jruby/bin/jruby: line 388: /usr/bin/java: No such file or directory。那么就先which java查看一下java的文件，然后做一个软连接过去，然后重装logstash即可，如图： 用户可以使用TLS双向认证加密Filebeat和Logstash的连接，保证Filebeat只向可信的Logstash发送加密的数据（如果你的logstash和filebeat是内网通信，而且你认可当前内网的安全度，这一步可以省略）。同样的，Logstash也只接收可信的Filebeat发送的数据。这个功能默认是关闭的，要开启的话需要先vim /etc/pki/tls/openssl.cnf，如图： 找到[ v3_ca ]的字段，在底下添加subjectAltName = IP:logstash的内网IP字段，保存退出来到/etc/pki/tls/，执行下面命令： 1openssl req -x509 -days 365 -batch -nodes -newkey rsa:2048 -keyout private/logstash-forwarder.key -out certs/logstash-forwarder.crt 来生成一个期限为365天的IP SAN证书对，如果想生成一个十年的证书，就把365改成3650即可，如图： 安装完毕之后，vim /etc/logstash/logstash.yml，编辑成如下的样子： 然后在/etc/logstash/下手动建立一个目录conf.d，在conf.d里新建一个logstash.conf的文件，如下： 123456789101112131415161718192021222324252627282930313233343536373839$ cat /usr/local/logstash/config/conf.d/logstash.conf#在输入部分，配置Logstash通信端口以及添加SSL证书，从而进行安全通信。input &#123; beats &#123; port =&gt; 5044 ssl =&gt; true ssl_certificate =&gt; \"/etc/pki/tls/certs/logstash-forwarder.crt\" ssl_key =&gt; \"/etc/pki/tls/private/logstash-forwarder.key\" &#125;&#125; #在过滤器部分，我们将使用Grok来解析这些日志，然后将其发送到Elasticsearch。以下grok过滤器将查找“syslog”标记的日志，并尝试解析它们，以生成结构化索引。filter &#123; if [type] == \"syslog\" &#123; grok &#123; match =&gt; &#123; \"message\" =&gt; \"%&#123;SYSLOGTIMESTAMP:syslog_timestamp&#125; %&#123;SYSLOGHOST:syslog_hostname&#125; %&#123;DATA:syslog_program&#125;(?:\\[%&#123;POSINT:syslog_pid&#125;\\])?: %&#123;GREEDYDATA:syslog_message&#125;\" &#125; add_field =&gt; [ \"received_at\", \"%&#123;@timestamp&#125;\" ] add_field =&gt; [ \"received_from\", \"%&#123;host&#125;\" ] &#125; syslog_pri &#123; &#125; date &#123; match =&gt; [ \"syslog_timestamp\", \"MMM d HH:mm:ss\", \"MMM dd HH:mm:ss\" ] &#125; &#125;&#125; #输出部分，我们将定义要存储的日志位置output &#123; elasticsearch &#123; hosts =&gt; [ \"10.162.80.192:9200\" ] #这个地址是elasticsearch的内网地址 index =&gt; \"filebeat-%&#123;+YYYY.MM.dd&#125;\" #设定这个是索引 #index =&gt; \"auclogstash-%&#123;+YYYY.MM.dd&#125;\" #这行是后来作实验的，可以忽视 user =&gt; elastic #这个是为了将来装x-pack准备的 password =&gt; changeme #同上 &#125;stdout &#123; codec =&gt; rubydebug &#125;&#125; 然后就是启动并且添加开机自启动: 12systemctl start logstash systemctl enable logstash 安装filebeat以下所有操作都是root下进行的,在模块服务器上安装filebeat的方法如下: 12curl -L -O https://artifacts.elastic.co/downloads/beats/filebeat/filebeat-5.6.4-x86_64.rpm rpm -ivh filebeat-5.6.4-x86_64.rpm 之前在logstash上生成了一个IP SAN证书，现在需要把这个证书传递给filebeat的机器里，使用scp语句如下： 1scp -pr root@10.162.80.171:/etc/pki/tls/certs/logstash-forwarder.crt /etc/ssl/certs/ #10.162.80.171就是logstash的内网IP 输入logstash的密码，并且密钥文件复制完毕之后，需要修改filebeat.yml，于是#vim /etc/filebeat/filebeat.yml： 12345678910111213141516[root@func-auc-001 log]# grep -iv '#' /etc/filebeat/filebeat.yml | grep -iv '^$'filebeat.prospectors:- input_type: log paths: - /mnt/hswx/auc/logs/*.log #这个是那个auc模块的路径 - /第二个日志路径/*.log #如果有第二个文件路径的话 tail_files: true #从文件末尾开始读取 document_type: \"newnginx-api\" #logstash那里已经设定了index，如果要使用了document_type，那么在logstash的index就要这么写：\"%&#123;type&#125;-%&#123;+YYYY.MM.dd&#125;\" # 以下是规避数据热点的优化参数： spool_size: 1024 # 积累1024条消息才上报 idle_timeout: \"5s\" # 空闲5s上报 output.logstash: hosts: [\"10.162.80.171:5044\"] #这个地方要写logstash的内网地址 ssl.certificate_authorities: [\"/etc/ssl/certs/logstash-forwarder.crt\"] #这里就是刚刚复制的那个密钥文件路径 #注意上面是ssl而不是tls，1.0版本才是tls，如果这个写错了，启动的时候会出现“read: connection reset by peer”的错误 注意！Filebeat的配置文件采用YAML格式，这意味着缩进非常重要！请务必使用与这些说明相同数量的空格。 保存之后，使用/etc/init.d/filebeat start启动filebeat，如图： 故障解决ELK几个部件现在都已经启动了，并且互相telnet端口都是通的，在elasticsearch的服务器上使用curl -XGET &#39;http://elasticsearch内网IP:9200/filebeat-*/_search?pretty&#39;却出现这样的情况： 而使用tailf /var/log/filebeat/filebeat去查看filebeat的日志是这样的： 再看看logstash-plain.log，里面的情况是这样的： 从此可见，filebeat与logstash的联系是error状态，那么停止filebeat的进程，改用/etc/init.d/filebeat start -c /etc/filebeat/filebeat.yml，重新在elasticsearch的服务器上使用curl -XGET &#39;http://elasticsearch内网IP:9200/filebeat-*/_search?pretty&#39;发现已经成功读到了我们之前配置的目录“/mng/hswx/auc/log”，如图： 配置kibana在浏览器输入kibana服务器外网IP：5601打开kibana的web界面，把idenx pattern的地方改成filebeat-*(同之前配置的index索引一致)，然后点击create，如图： 然后就得到了细节的web界面，如图： 点击左侧框的Discover，就会看到梦寐以求的日志web界面，如图： 看一下红色框的内容里面有时间，有host主机，有source来源，还有具体的日志信息，我们再去func-auc-001这个日志源主机上查询一下日志： 两个日志是一样的，可见实现了预期的日志展示的目标！ 最后一步，就是把kibana与nginx联系起来（也可以把kibana做阿里云负载均衡的后端服务器），这样通过nginx/负载均衡来访问kibana的界面，对kibana来说更安全。配置端口监听如图，再把kibana服务器挂在负载均衡后面即可。 参考资料https://www.ibm.com/developerworks/cn/opensource/os-cn-elk-filebeat/index.htmlhttps://www.ibm.com/developerworks/cn/opensource/os-cn-elk/http://www.jinsk.vip/2017/05/24/elksetup/https://renwole.com/archives/661https://www.zybuluo.com/dume2007/note/665868https://www.elastic.co/guide/en/beats/libbeat/5.6/getting-started.htmlhttps://discuss.elastic.co/search?q=ERR%20Failed%20to%20publish%20events%20caused%20by%3A%20read%20tcphttp://jaminzhang.github.io/elk/ELK-config-and-use-Filebeat/ （这个博主很好，但是就是博客无法留言，这点比较坑）","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"大数据分析","slug":"大数据分析","permalink":"http://yoursite.com/tags/大数据分析/"},{"name":"ELK","slug":"ELK","permalink":"http://yoursite.com/tags/ELK/"}]},{"title":"从“No space left on device”到删除海量文件","slug":"从“No-space-left-on-device”到删除海量文件","date":"2018-01-15T16:48:39.000Z","updated":"2018-07-05T05:54:24.000Z","comments":true,"path":"2018/01/16/从“No-space-left-on-device”到删除海量文件/","link":"","permalink":"http://yoursite.com/2018/01/16/从“No-space-left-on-device”到删除海量文件/","excerpt":"","text":"开发发现某个云服务器无法启动进程，提示“No space left on device”，但是使用df -h查看容量的时候，明明还有很多的空间。于是使用df -i，发现inode节点已经全部用光了，所以现在不能建立任何新的文件。如图： 既然如此就要查出来是哪个文件夹里会有如此多的文件来占用这些inode,使用一个小脚本：for i in /*; do echo $i; find $i | wc -l; done，获取到/mnt下有一个文件占用了绝大多数的inode，如图： 于是就进入到mnt这个文件夹里，慢慢找寻到底是哪个文件夹，用上面那个语句一点一点缩小范围，最后确定文件夹原来就是data文件夹，如图： 现在如果要rm -rf data/*的话，是没有效果的，有效果的话也很慢。而且很有可能报-bash: /bin/rm: Argument list too long的错，因为这个文件夹里面的小文件实在太多了，有足足两百五十多万个，那么怎么样处理这样的情况？ 用find搭配-type f -exec rm {} \\;可能会引起内存溢出，用文件夹重置命令搭配--reference也没什么效果。 这时最好的方法就是使用rsync! 先yum install rsync，当然了现在inode是饱和的状态，yum install是会报错的： 那么就需要手动删除一些文件，腾出来一部分inode供yum使用，安装完毕rsync之后，找到一个空文件夹，如果没有空文件夹，就手动建立一个。 使用命令：rsync --delete-before -a -H -v --progress --stats /空文件夹的路径/ /海量小文件的路径/ 说一下上面几个参数的意思： 123456–delete-before 接收者在传输之前进行删除操作–progress 在传输时显示传输过程-a 归档模式，表示以递归方式传输文件，并保持所有文件属性-H 保持硬连接的文件-v 详细输出模式-stats 给出某些文件的传输状态 如果你开了这个服务器的两个窗口，一个是执行上面的命令，另一个是在海量文件夹里执行ls，这个时候ls命令是卡死的，过了大约2分钟，就会看到ls展示的文件喷涌而出，整个电脑屏幕好比黑客帝国一样，异常壮观。 静等大约20分钟，整个文件夹删除干净，inode也释放了97%，世界恢复了清静。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"},{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"使用Google Authenticator给ssh进行登录验证","slug":"使用Google-Authenticator给ssh进行登录验证","date":"2018-01-15T16:39:26.000Z","updated":"2019-02-21T12:05:16.000Z","comments":true,"path":"2018/01/16/使用Google-Authenticator给ssh进行登录验证/","link":"","permalink":"http://yoursite.com/2018/01/16/使用Google-Authenticator给ssh进行登录验证/","excerpt":"","text":"普通情况下的服务器登录，是“服务器+密码”这种直白的验证方式，但是这种方式太过简单，一旦密码泄露，服务器就有危险，于是为了安全我们就要在登录上再加一把锁，那就是使用Google Authenticator（谷歌身份验证器）这个工具，在登录的时候进行一次验证，只有“验证通过了”+“密码正确”才能登陆服务器。 安装前准备1）关闭Selinux ：setenforce 02）安装依赖：yum -y install gcc make pam-devel libpng-devel libtool wget git3）添加阿里云epel 源： 1234RHEL 6/Centos 6wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-6.repoRHEL 7/Centos 7wget -O /etc/yum.repos.d/epel.repo http://mirrors.aliyun.com/repo/epel-7.repo 4）安装Qrencode，谷歌身份验证器需要调用该程序生成二维码并显示：yum install -y qrencode 安装谷歌身份验证器这个时候很多教程会让你去执行git clone https://github.com/google/google-authenticator.git，然而现在这个git里面已经不再含有libpam这个文件夹了，下载下来是一个错误的包，那么这个时候你可以使用yum install google-authenticator，不过yum安装的身份验证器的版本很老，这个时候可以执行wget https://github.com/google/google-authenticator-libpam/archive/1.04.tar.gz。 下载下来1.0.4版本的然后拆包解压缩，里面是这样几个文件： 然后就./bootstrap.sh &amp;&amp; ./configure &amp;&amp; make &amp;&amp; make install进行编译和安装。 安装过程完毕之后，还要复制google身份验证器pam模块到系统下，命令是：cp /usr/local/lib/security/pam_google_authenticator.so /lib64/security/。 调整登陆方式1）编辑/etc/pam.d/sshd这个文件，我这个centos的版本是7.0的，里面的内容可能跟centos 6.x的优点不同，不过没关系，就需要插入黄色框内的auth required pam_google_authenticator.so，如图： 修改完毕之后，保存退出。 注意！修改了这步之后，服务器千万不能断开连接，否则再连是需要google验证码的，而我们现在还没有生成码，所以肯定是无法连接服务器，如果是云服务器，可以通过登陆控制台的方式把这个文件修改回来，如果是实体服务器，那就呵呵呵了。 2）编辑/etc/ssh/sshd_config，就修改一个地方：ChallengeResponseAuthentication yes3）保存退出之后，重启一下ssh服务： 12RHEL6 /Centos6：Service sshd restartRHEL7 /Centos7：Systemctl resart sshd 生成登陆验证码这次以root用户为例，那么切换成root用户执行下面的过程。1）执行google-authenticator，由于我们之前已经安装了qrencode，那么这个时候会生成一个超级超级巨大的二维码，给各位感受一下： 红色内容是生成的密钥，很重要。绿色的内容是备用的紧急救助码，紧急救助码就是当你无法获取认证码时（比如手机丢了），可以当做认证码来用，每用一个少一个，但其实可以手动添加的，建议如果 root 账户使用 Google Authenticator 的话一定要把紧急救助码另外保存一份。 1Do you want me to update your \"/home/test/.google_authenticator\" file? (y/n) y 是否更新用户的 Google Authenticator 配置文件，选择 y 才能使上面操作对当前用户生效，其实就是在对应用户的 Home 目录下生成了一个 .google_authenticator 文件，如果你想停用这个用户的 Google Authenticator 验证，只需要删除这个用户 Home 目录下的 .google_authenticator 文件就可以了。 1Do you want to disallow multiple uses of the same authentication token? This restricts you to one login about every 30s, but it increases your chances to notice or even prevent man-in-the-middle attacks (y/n) y 每次生成的认证码是否同时只允许一个人使用？这里选择 y。 1By default, tokens are good for 30 seconds. In order to compensate for possible time-skew between the client and the server, we allow an extra token before and after the current time. If you experience problems with poor time synchronization, you can increase the window from its default size of +-1min (window size of 3) to about +-4min (window size of 17 acceptable tokens). Do you want to do so? (y/n) n 是否增加时间误差？这里随便选择， ny都可以。 1If the computer that you are logging into isn't hardened against brute-force login attempts, you can enable rate-limiting for the authentication module. By default, this limits attackers to no more than 3 login attempts every 30s. Do you want to enable rate-limiting (y/n) y 是否启用次数限制？这里选择 y，默认每 30 秒最多尝试登录 3 次。 如果想要写成脚本的话，那么上面交互式的设置也可用通过参数一次性设置：google-authenticator -t -f -d -l test@chen.super -i MR.chen -r 3 -R 30 -W。 -I和-i是可以随便写的，但是-i后期可以改，-I不能改。 搭配手机端如果手机是ios，就去apple store里搜索“Google Authenticator”，如果是安卓，就去应用商店搜索“谷歌动态口令”。 安装完后，打开App，点击“开始设置”，选择“扫描条形码”扫描上面google-authenticator命令生成的二维码，或者是选择“输入密钥”，然后手机上就能看到对应的六位数认证码了。 最后一步，返回xshell，修改登陆方式，设置登陆方法为Keyboard Interactive，如图： 这个时候，推荐各位保留原有的ssh不要动，在另外一个xshell窗口登陆一下看看效果，如果正常的话，这个时候会看到系统会让你先输入一个Verification code。这个值就是手机里的那个六位数，然后再输入密码，只有两个都是正确的，才能登陆！ 至此整个配置完成，如果登陆时遇到问题，请查看日志文件/var/log/secure。 更改存储位置在生成二维码那一步的时候，如果你错过了记住密钥也不要怕，系统会自动把密钥和紧急救助码保存在~/.google_authenticator这个文件里。 如果想要改变密钥存储位置，请使用–secret参数:google-authenticator --secret=&quot;/文件路径/用户名&quot;。 然后更改/etc/pam.d/sshd内的路径配置:auth required pam_google_authenticator.so user=root secret=/PATH_FOLDER/${USER}。 上面那句话里“user=root” 用于强制PAM使用root用户权限来搜索文件。 另外请注意，由于我们当时切换成了root用户，所以密钥文件的所有者是root，生成文件的用户只能读取文件(chmod: 400)： 12chown root.root /PATH_FILE/SECRET_KEY_FILESchmod 400 /PATH_FILE/SECRET_KEY_FILES 使用chrome浏览器查看mfa如果你没有带手机，如何查看mfa呢？请使用chrome的插件http://gauth.apps.gbraad.nl/ 。 然后手动添加即可，但是要注意，这台电脑不能断网太久哦，不然就会自动删除。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"},{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"记录一次处理https监听不正确的过程","slug":"记录一次处理https监听不正确的过程","date":"2018-01-12T11:58:54.000Z","updated":"2019-09-25T09:23:36.000Z","comments":true,"path":"2018/01/12/记录一次处理https监听不正确的过程/","link":"","permalink":"http://yoursite.com/2018/01/12/记录一次处理https监听不正确的过程/","excerpt":"","text":"今天开发反馈在测试金山云设备的时候遇到了这样的一个现象：123456wget https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 11:49:26-- https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 Resolving funchlscdn.lechange.cn... 120.92.158.134 Connecting to funchlscdn.lechange.cn|120.92.158.134|:443... connected. OpenSSL: error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol Unable to establish SSL connection. 爆error:140770FC:SSL routines:SSL23_GET_SERVER_HELLO:unknown protocol的错误，有两种可能，1）SSL证书没有配对；2）当向只提供http的服务发送https请求。 ping funchlscdn.lechange.cn，获得了这个域名对应的IP之后，返回到金山云的控制台查询这个IP，发现这个IP是一个负载均衡，但是这个负载均衡配置的时候对80端口是http协议，而对443端口还是http协议，于是更改成https，重新测试之后，发现错误变成了这样：123456[root@js-develop ~]# wget https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 16:08:15-- https://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Resolving funchlscdn.lechange.cn... 120.92.158.134Connecting to funchlscdn.lechange.cn|120.92.158.134|:443... connected.HTTP request sent, awaiting response... 502 Bad Gateway2017-07-26 16:08:15 ERROR 502: Bad Gateway. 在浏览器打开效果如图： 502 Bad GatewayThe proxy server received an invalid response from an upstream server. KSYUN ELB 1.0.0 同时发现金山云负载均衡里对nginx的8000健康检查是“异常”。但是使用http访问却是可以的，效果如下：12345678910111213[root@js-develop ~]# wget http://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 --2017-07-26 15:31:55-- http://funchlscdn.lechange.cn/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Resolving funchlscdn.lechange.cn... 120.92.158.134Connecting to funchlscdn.lechange.cn|120.92.158.134|:80... connected.HTTP request sent, awaiting response... 302 FoundLocation: http://120.92.133.76:8090/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8 [following]--2017-07-26 15:31:55-- http://120.92.133.76:8090/LCLR/2K02135PAK01979/0/0/20170726085033/dev_20170726085033_lpxh73ezzb92xxa8.m3u8Connecting to 120.92.133.76:8090... connected.HTTP request sent, awaiting response... 200 OKLength: 66 [application/x-mpegURL]Saving to: “dev_20170726085033_lpxh73ezzb92xxa8.m3u8”100%[========================================================================================================================================================&gt;] 66 --.-K/s in 0s 2017-07-26 15:31:55 (3.02 MB/s) - “dev_20170726085033_lpxh73ezzb92xxa8.m3u8” saved [66/66] 于是就叫来开发问一下http和https详细的流程，开发说在http里，设计路线如下：1http(80)-&gt;开发模块(9001) 而在https里，设计路线如下：1https(443)-&gt;nginx(8000)-&gt;开发模块(9001) 这时候就发现了问题，原来最早的时候金山云是没有配置https证书的，于是开发们就用nginx的8000端口去监听ssl这样达到https证书的效果，但是后来金山云控制台添加了https证书，就不再需要nginx去配置ssl证书了，再去https监听8000这一步也就是错误的了，于是在负载均衡那里改成了：1https(443)-&gt;开发模块(9001) 同时关闭了nginx，这时候再来测试一下https请求，就成功了！ 其实如果非要用nginx的ssl证书的话，那么的套路就是：开启nginx，但是在负载均衡那里使用tcp协议去监听nginx的8000端口，这样一样能达到效果。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"},{"name":"https","slug":"https","permalink":"http://yoursite.com/tags/https/"}]},{"title":"Next主题添加音乐和将侧栏移动到左边","slug":"next主题添加音乐和侧栏左移","date":"2018-01-12T07:56:38.000Z","updated":"2018-01-22T04:04:14.000Z","comments":true,"path":"2018/01/12/next主题添加音乐和侧栏左移/","link":"","permalink":"http://yoursite.com/2018/01/12/next主题添加音乐和侧栏左移/","excerpt":"","text":"玩Github博客也有一个多月的时间了，现在这个博客也被我折腾的有点样子了，目前博客里添加了如下功能：1.支持头像图片旋转，同时点击头像可以返回主页；2.背景图片随机出现，而且墙内用户也可以顺利访问；3.增加文章打分系统，觉得好可以给五星好评；4.开放评论系统，无需注册直接评论；5.添加了可视加载栏和公益404页面；6.添加桌面小宠物和访客统计；7.添加博客运行时间和代码橙色高亮； 目前欠缺的功能一个是“相册”，还有一个就是博客标题的加载方式希望更加高逼格。至于SEO和单独域名，我暂时还没有想去做，等将来再加上吧。而这篇文章里主要说的就是“博客添加音乐”和“侧栏左移”这两个事儿。 博客添加音乐Next主题添加网易云音乐不是一个很难的事儿，但是我发现对于非大陆的IP地址（比如我用的是公司VPN，香港IP），侧栏的网易云音乐就无法播放，而且打开博客页面就自动播放音乐这点对来访的用户来说，体验感觉是见仁见智。所以我打算把侧栏的网易云音乐撤掉，在“关于我”里单独放进音乐歌单。 若单独配置音乐同时不想被IP地址打扰的话可以使用由DIYgod所制作的APlayer。官方材料在这里：https://aplayer.js.org/docs/#/?id=options 。 要使用APlayer需要先在hexo根目录里安装插件：npm install aplayer --save 安装插件OK了后，具体在文章里添加的语法就是： 注意：如果lrc用的是这种URL形式，hexo g时请保持网络通畅，如果没有歌词，可以不用添加。 现在的世面上很少有在线提供歌曲MP3地址的网站了，很多都是下载mp3到本地，这里我推荐一个免费下载MP3的网站：https://www.tikitiki.cn 。里面有QQ音乐、网易云音乐和酷狗的资源，基本上大陆没有被封杀的艺人作品都能在里面找到（抱歉了，陈升先生和黄耀明先生）。然后再搭配七牛云，把下载的MP3和封面图片上传到七牛云存储里，然后搭配提供的外网域名就可以填写MP3地址和封面地址了。如图： 如果想做一个歌单，也很简单，如下：1234567891011121314151617181920212223&#123;% aplayerlist %&#125; &#123; \"autoplay\": false, \"showlrc\": 3, \"mutex\": true, \"music\": [ &#123; \"title\": \"歌曲名\", \"author\": \"歌手名\", \"url\": \"https://具体地址.mp3\", \"pic\": \"https://封面图.jpg\", \"lrc\": \"https://歌词.lrc\" #不愿意加歌词可以不写，注意逗号 &#125;, &#123; \"title\": \"歌曲名\", \"author\": \"歌手名\", \"url\": \"https://具体地址.mp3\", \"pic\": \"https://封面图.jpg\", \"lrc\": \"https://歌词.lrc\" &#125; ] &#125;&#123;% endaplayerlist %&#125; 不过我这个七牛云的账号比较挫，没有做https，只好用http了… 把侧栏移动到左边博客自从安装了宠物之后，发现小宠物与侧栏重叠，看上去感觉很不友好，但是很奇怪，默认的宠物即使调整了botton依旧无法移动，所以我就想那就把整个侧栏移动到了左边，但是发现更改next主题的_config.xml里的“sidebar的position属性”发现并没有效果，后来经过一顿查找，找到了改成左侧栏的方法(适用于next 5.1.3版本)。 首先，先更改\\themes\\next\\source\\css\\_common\\components\\sidebar\\sidebar.styl，把第三行的right改成left,如下：123.sidebar &#123; position: fixed; left: 0; 保存之后，打开\\themes\\next\\source\\js\\src\\motion.js，把101行和167行的paddingRight全改成paddingLeft,同时找到类似如下的代码，并替换成如下代码:123456789101112131415161718192021var sidebarToggleLine1st = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-first', status: &#123; arrow: &#123;width: '50%', rotateZ: '45deg', top: '2px', left: '5px'&#125;, close: &#123;width: '100%', rotateZ: '45deg', top: '5px', left: 0&#125; &#125;&#125;);var sidebarToggleLine2nd = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-middle', status: &#123; arrow: &#123;width: '90%'&#125;, close: &#123;opacity: 0&#125; &#125;&#125;);var sidebarToggleLine3rd = new SidebarToggleLine(&#123; el: '.sidebar-toggle-line-last', status: &#123; arrow: &#123;width: '50%', rotateZ: '-45deg', top: '-2px', left: '5px'&#125;, close: &#123;width: '100%', rotateZ: '-45deg', top: '-5px', left: 0&#125; &#125;&#125;); 保存完毕之后，hexo clean和hexo d -g。刷新一下页面，就大功告成了！ 参考资料https://reuixiy.github.io/technology/computer/computer-aided-art/2017/06/09/hexo-next-optimization.html#hcm=1515719347596232 （这篇文章强烈推荐！）http://www.lmnsyunhao.cn/2017/03/29/hexo-next-themes-left-sidebar/http://mashirosorata.vicp.io/HEXO-NEXT主题个性化配置.html","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"http://yoursite.com/categories/博客搭建/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"http://yoursite.com/tags/Hexo/"},{"name":"Next","slug":"Next","permalink":"http://yoursite.com/tags/Next/"},{"name":"博客美化","slug":"博客美化","permalink":"http://yoursite.com/tags/博客美化/"}]},{"title":"Zabbix监控ActiveMQ队列数以及结合Grafana展示","slug":"Zabbix监控ActiveMQ队列数以及结合Grafana展示","date":"2018-01-11T13:43:01.000Z","updated":"2018-01-22T09:08:18.000Z","comments":true,"path":"2018/01/11/Zabbix监控ActiveMQ队列数以及结合Grafana展示/","link":"","permalink":"http://yoursite.com/2018/01/11/Zabbix监控ActiveMQ队列数以及结合Grafana展示/","excerpt":"","text":"在ZABBIX上监控MQ队列众所周知，Zabbix是可以自定义监控项的，那么就代表只要能获得到的数字都可以进入Zabbix的监控范围内。作为消息队列，Activemq里的“消息堆积数”是监控的重点项目之一。 获取消息堆积数并不是一个很难的事儿，浏览器里登陆MQ的web网页控制台，输入账号密码之后，在Queues的网页里就能看到如下的界面： 其中Pending Messages就是“等待消息”，Consumers是“消费者”，Enqueued是“入队”，Dequeued是“出队”。入队数=出队数+等待数。 现在我们要获取到图中的队列叫AggregateQueue里的那个23596，很简单，shell语句是： 1curl -s -u网站用户名:网站密码 http://网站外网IP地址:8161/admin/queues.jsp | grep -A 5 \"具体的队列名&lt;/a&gt;&lt;/td&gt;\"|awk -F '&lt;' '&#123;print $2&#125;'|sed 's/td&gt;//g'|head -2|tail -1 这里curl有一个-s的参数，不然会显示curl的状态。如图： 语句在此，写脚本就很easy了。不过我这里就直接监控具体数字了，没有写脚本，如果要写python脚本的话，我推荐各位移步：http://blog.51cto.com/sfzhang88/1316789 ，看一下这篇文章。 现在把这个监控项添加到具体的zabbix_agentd.conf里吧，具体添加过程可以参看 http://blog.51cto.com/chenx1242/1839829 ，由于是curl网站，那么直接把这个监控项加到Zabbix-server里就好，然后使用zabbix_get检查一下。有的zabbix 3.x里没有zabbix_get，安装zabbix_get方法：yum install zabbix-get.x86_64。 zabbix_get检查情况和具体的trigger情况如下： 配置Zabbix结合Grafana我使用的Grafana版本是4.3.2，下载地址：https://s3-us-west-2.amazonaws.com/grafana-releases/release/grafana-4.3.2-1.x86_64.rpm ，下载完毕之后，直接yum install /路径/grafana-4.3.2-1.x86_64.rpm，由于Grafana使用的是AWS的云存储，可能在墙内的下载会比较吃力，有断开的情况就多试几次。话说Grafana的升级是比较频繁的，半年不到的时间升级了三次，现在最新版本已经是4.6.2。所以说这玩意，其实选择一个稳定的就好。 启动grafana的方法就是：systemctl start grafana-server.service，配置开机自启动的方法：chkconfig grafana-server on。然后在浏览器里输入grafana外网ip地址：3000就能看到grafana的界面，默认密码：admin/admin，grafana默认的日志存储路径是/var/log/grafana/。 Grafana与ZABBIX联系的插件下载方式：grafana-cli plugins install alexanderzobnin-zabbix-app，安装之后，重启一下grafana-server，在web界面就会看到插件已经成功安装，如图： 其他更多的插件下载可以在grafana的官方网站查看到：https://grafana.com/plugins ，用grafana-cli都能搞定，还是那话，墙里的同学速度要慢一点。 现在配置Zabbix作为Grafana的数据源，首选点击网站上面的红色漩涡标志，选择zabbix，点击Plugin Config，点击Enable，启动Zabbix插件。如图： 再次点击红色漩涡，这次选择Data Sources，点击Add data source，如果插件启动成功，那么在Type里是可以选择zabbix的，然后就是填各种东西，如图： 这里有一些要额外说明：1）url这个是zabbix的API地址http://ip/zabbix/api_jsonrpc.php，这个可以在zabbix服务端上可查找find / -name api_*.php；2）username和passwd是zabbix WEB界面的登录用户名和密码，有读的权限即可；3）alerting选择启动，min severity选择high； 然后点击save &amp; test，如果都正确的话，就会出现success，如图： 在Grafana展示趋势图点击左上方红色漩涡，Dashboards的地方点击+new，然后在小齿轮的地方选择Templating,如图： 在Templating里要建立4个模板，其中group的添加方法如下，如果Query正确的话，在点击Include All option的时候，就会有“组”显示出，而且和zabbix里完全一致： group添加完了，还有host、application、iteams，添加的大同小异，需要注意的是Query的不同：host的Query：$group.*application的Query: $group.$host.*iterm的Query:$group.$host.$application.* 以上四个template都搞定之后，应该是这个样子： 模板搞定了，下面就是图形展示，选择对应的hosts、application和items就自动有图像生成了！ 最后说一下页面自动刷新，点击右上角“Last 6 hours”, 在弹出的下拉框中，选择Time range下的Refreshing every选项，点击下拉框按钮，默认应该有“off”和“1m”两个选项。点击“1m” 然后Apply设置，即为每一分钟刷新一次数据的意思。设置成功后，在原来Last 6 hours的后面会出现Refresh every 1m的橙色文字！ 参考资料《实践MQ的小demo》http://www.jianshu.com/p/3a39c8dd4f29","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"grafana","slug":"grafana","permalink":"http://yoursite.com/tags/grafana/"}]},{"title":"在Python使用yaml的几个例子","slug":"在Python使用yaml的几个例子","date":"2018-01-11T02:11:17.000Z","updated":"2018-07-10T09:48:18.000Z","comments":true,"path":"2018/01/11/在Python使用yaml的几个例子/","link":"","permalink":"http://yoursite.com/2018/01/11/在Python使用yaml的几个例子/","excerpt":"","text":"python版本：2.7.5安装方法：pip install PyYaml “把变量写进yaml做配置文件，然后python脚本从yaml文件里面取到变量”的方法最近是在python编程里比较流行的配置项方法。yaml更加易读，而且通过缩进表示结构，这一点与python不谋而合。 Yaml有四个比较常用的用法，分别是load()、dump()、load_all()、dump_all()。这篇文章主要就是了解一下这四个方法。 首先我们先写一个很简单的test.py： 12345678910111213# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlyaml_str = \"\"\"name: Gakkiage: 29job: Actressrelationship: Wife\"\"\" aaa = yaml.load(yaml_str)print aaa 执行的话，看到的效果就是： 12[root@paas-online-crs-001 chentest]# python test.py &#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125; 这个aaa的类型是一个字典（dict），如果要得到里面那个”Gakki”，那么就是aaa[&#39;name&#39;]。通过load方法，一个字符串变成了一个字典。 现在把test.py换成如下： 123456789101112# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlyaml_dict = &#123;\"name\": \"Gakki\", \"age\": 29, \"job\": \"Actress\", \"relationship\": \"Wife\" &#125;aaa = yaml.dump(yaml_dict, default_flow_style=False)print aaaprint (type(aaa)) 执行后的效果如下： 123456[root@paas-online-crs-001 chentest]# python test.py age: 29job: Actressname: Gakkirelationship: Wife&lt;type 'str'&gt; 可见，通过dump方法，把一个dict变成了一个字符串。 现在写一个配置文件，假如它叫test.yaml: 1234- Gakki- 29 - Actress- Wife 再来一个test.py，内容如下: 1234567# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yaml aaa = yaml.load(file('test.yaml', 'r'))print aaaprint (type(aaa)) 执行这个test.py： 123[root@paas-online-crs-001 chentest]# python test.py ['Gakki', 29, 'Actress', 'Wife']&lt;type 'list'&gt; #得到了一个列表 如果把那个test.yaml升级成字典和列表的混合结构，如下： 1234567- name: Chris age: 29 job: OM Engineer- name: Gakki age: 29 job: Actress relationship: Wife 执行test.py的效果如下： 123[root@paas-online-crs-001 chentest]# python test.py [&#123;'job': 'OM Engineer', 'age': 29, 'name': 'Chris'&#125;, &#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125;]&lt;type 'list'&gt; 既然获得的结果是一个包含字典的列表，那么如果要获得“Gakki”就是aaa[1][&#39;name&#39;] 如果想要复制和引用，那么要用&amp;和*，比如把test.yaml改成这样： 12name: &amp;name Gakkiwife: *name 执行test.py的效果如下： 123[root@paas-online-crs-001 chentest]# python test.py &#123;'name': 'Gakki', 'wife': 'Gakki'&#125;&lt;type 'dict'&gt; 在同一个yaml文件中，可以用 — 来分段，这样可以将多个文档写在一个文件中： 123456789--- name: Chris age: 29 job: OM Engineer--- name: Gakki age: 29 job: Actress relationship: Wife 再写一个新的test.py如下: 123456# -*- coding: utf-8 -*-#!/usr/bin/env pythonimport yamlys = yaml.load_all(file('gakki.yaml', 'r')) #load_all() 方法会生成一个迭代器，可以用for输出出来for y in ys: print y 执行这个py的效果： 123[root@paas-online-crs-001 chentest]# python test.py &#123;'job': 'OM Engineer', 'age': 29, 'name': 'Chris'&#125;&#123;'job': 'Actress', 'age': 29, 'relationship': 'Wife', 'name': 'Gakki'&#125; 参考文档：https://huilansame.github.io/huilansame.github.io/archivers/recommond-case-file-type-yaml","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"},{"name":"编程","slug":"编程","permalink":"http://yoursite.com/tags/编程/"}]},{"title":"使用Zabbix去监控Redis","slug":"使用Zabbix去监控Redis","date":"2018-01-10T14:49:04.000Z","updated":"2019-07-03T12:54:18.000Z","comments":true,"path":"2018/01/10/使用Zabbix去监控Redis/","link":"","permalink":"http://yoursite.com/2018/01/10/使用Zabbix去监控Redis/","excerpt":"","text":"了解Redis的info要获得Redis的当前情况，使用info命令即可。具体用法：redis-cli -h 127.0.0.1 -p 6379 -a redis_passwd info [参数] 。针对不同的参数就会看到具体的数字，如果没有带参数，那么就会把默认情况写出来，如果带上all参数，那么就会把所有情况都写出来。比如：redis-cli -h 127.0.0.1 -p 6379 -a redis_passwd info server，就会看到redis关于server的一些数据，如下：可以看出，从server里可以查询到的是版本号、pid号、配置文件路径等等东西。 如果参数是client，记录了是客户端的相关信息： 123456[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info clients# Clientsconnected_clients:64 #已连接客户端的数量（不包括通过从属服务器连接的客户端）client_longest_output_list:0 #当前连接的客户端当中，最长的输出列表client_biggest_input_buf:0 #当前连接的客户端当中，最大输入缓存blocked_clients:0 #正在等待阻塞命令（BLPOP、BRPOP、BRPOPLPUSH）的客户端的数量 如果参数是memory，记录的是内存的相关信息： 12345678910[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info memory# Memoryused_memory:2252984 #由 Redis 分配器分配的内存总量，以字节（byte）为单位used_memory_human:2.15M #上面的数字加上了单位used_memory_rss:9293824 #常驻集大小，即Redis已分配的内存总量。这个值和top、ps等命令的输出一致used_memory_peak:2607520 #Redis 的内存消耗峰值（以字节为单位）used_memory_peak_human:2.49M #上面的数字加上了单位used_memory_lua:33792 #Lua 引擎所使用的内存大小（以字节为单位）mem_fragmentation_ratio:4.13 #used_memory_rss 和 used_memory 之间的比率mem_allocator:jemalloc-3.2.0 #在编译时指定的，Redis所使用的内存分配器。可以是libc、jemalloc或者tcmalloc。 这里要注意！在理想情况下， used_memory_rss 的值应该只比 used_memory 稍微高一点儿（我这个机器就已经属于严重的级别了）。当 rss &gt; used ，且两者的值相差较大时，表示存在（内部或外部的）内存碎片。内存碎片的比率可以通过 mem_fragmentation_ratio 的值看出。当 used &gt; rss 时，表示 Redis 的部分内存被操作系统换出到交换空间了，在这种情况下，操作可能会产生明显的延迟。 如果参数是stats，那就是统计的相关信息： 12345678910111213141516[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info stats# Statstotal_connections_received:150383 #服务器已接受的连接请求数量total_commands_processed:500935 #服务器已执行的命令数量instantaneous_ops_per_sec:0 #服务器每秒钟执行的命令数量rejected_connections:0 #因为最大客户端数量限制而被拒绝的连接请求数量sync_full:0 sync_partial_ok:0 sync_partial_err:0 #查找数据库键成功的次数expired_keys:41 #因为过期而被自动删除的数据库键数量evicted_keys:0 #因为最大内存容量限制而被驱逐（evict）的键数量keyspace_hits:78121 #查找数据库键成功的次数keyspace_misses:56 #查找数据库键失败的次数pubsub_channels:0 #目前被订阅的频道数量pubsub_patterns:0 #目前被订阅的模式数量latest_fork_usec:878 #最近一次 fork() 操作耗费的微秒数 如果参数是CPU，那么就会返回CPU的相关信息： 123456[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info cpu# CPUused_cpu_sys:63.95 #Redis服务器耗费的系统CPUused_cpu_user:129.54 #Redis服务器耗费的用户CPU used_cpu_sys_children:1.70 #子进程耗费的系统CPUused_cpu_user_children:1.03 #子进程耗费的用户CPU 如果参数是keyspace，那么就会返回数据库相关的统计信息： 123[root@func-redis-001 ~]# redis-cli -h 127.0.0.1 -p 6379 info keyspace# Keyspacedb0:keys=262,expires=183,avg_ttl=284091259423 #据库的键数量、数据库设置有过期时间的key的数量（这个值减少是正常的） 除了以上之外其他还有更多信息，请移步：http://redisdoc.com/server/info.html 。感谢前人栽树！！！ 使用zabbix监控redis用zabbix监控redis是一个很简单的事儿，只需要把需要监控的数据提取出来即可。而提取数据的方法就是利用info去得到对应的数值。 首先先来一个判断redis服务器连接的脚本： 1234567891011[root@func-redis-001 ~]# cat check_redis.sh#这个脚本是用来zabbix监控自建redis的#!/bin/bashPORT='6379'PASSWD=‘REDIS密码’ STATUS_redis=$(redis-cli -h '127.0.0.1' -p $PORT -a $PASSWD ping)if [ \"$STATUS_redis\" == 'PONG' ];then echo '1'else echo '0'fi 然后更改zabbix_agentd.conf,如下： 12UserParameter=redis_status[*],redis-cli -h '127.0.0.1' -p $1 info | grep -w $2 | awk -F':' '&#123;print $NF&#125;'UserParameter=redis_ping,sudo sh /root/check_redis.sh 修改/etc/sudoers文件如下： 1234## Allow root to run any commands anywhereroot ALL=(ALL) ALLzabbix ALL=(ALL) NOPASSWD:ALL #这个是新增Defaults:zabbix !requiretty #这个是新增 保存之后，重启zabbix-agent服务，由于我这个redis是通过zabbix-proxy监控的，所以在zabbix-proxy一端用zabbix_get来查看结果： 然后在zabbix-proxy的模板里面添加一些需要监控的item即可，有必要的话可以设置trigger+action用来报警，如图： 最后就是grafana搞一个炫酷的图表来，如图： 最后一点，关于redis的内存优化，各位可以来看看：https://cachecloud.github.io/2017/02/16/Redis%E5%86%85%E5%AD%98%E4%BC%98%E5%8C%96/ ，写的很全面了。还有zabbix各种模板整理，有需要的同学也可以去下载：https://monitoringartist.github.io/zabbix-searcher/ 。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"},{"name":"redis","slug":"redis","permalink":"http://yoursite.com/tags/redis/"}]},{"title":"通过nginx配置修改网页cookie属性","slug":"通过nginx配置修改网页cookie属性","date":"2018-01-10T07:48:08.000Z","updated":"2018-01-22T02:33:38.000Z","comments":true,"path":"2018/01/10/通过nginx配置修改网页cookie属性/","link":"","permalink":"http://yoursite.com/2018/01/10/通过nginx配置修改网页cookie属性/","excerpt":"","text":"需求与具体配置公司的电子商城在十九大等保安检时期被折腾出去，结果这几天又折腾回来了，据说还会是明年大数据研究院的主要开发项目。结果回来没几天被测试中心的人在cookie方面发现了几个问题，如下： cookie没有使用http-only； cookie没有携带secure属性； http头中需要配置“X-Frame-Options：SAMEORIGIN”； 以上这几点可以通过nginx的配置来轻松实现，具体方法就是在需要更改的网页server的配置里面添加下面几句话。如图： 123add_header Set-Cookie \"HttpOnly\";add_header Set-Cookie \"Secure\";add_header X-Frame-Options \"SAMEORIGIN\"; 然后保存配置文件，nginx -s reload平滑重启即可，通过chrome在目标网页里按下ctrl+shift+c，先选择好network，然后重新刷新一下界面，选择域名，对应域名下点击headers，就会看到cookie的配置情况，如图： 扩展内容看到配置已经生效。那么这几个配置主要是干什么的呢？其实主要都是防范XSS攻击（跨域脚本攻击）的。 Cookie的Secure属性，意味着保持Cookie通信只限于加密传输，指示浏览器仅仅在通过安全/加密连接才能使用该Cookie。如果一个Web服务器从一个非安全连接里设置了一个带有secure属性的Cookie，当Cookie被发送到客户端时，它仍然能通过中间人攻击来拦截。 Cookie的HttpOnly属性，指示浏览器不要在除HTTP（和HTTPS)请求之外暴露Cookie。一个有HttpOnly属性的Cookie，是不可以通过例如调用JavaScript(引用document.cookie)这种非HTTP方式来访问。因此，也不可能通过跨域脚本（一种非常普通的攻击技术）来偷走这种Cookie。 X-Frame-Options HTTP 响应头是用来给浏览器指示允许一个页面可否在frame, iframe或者object中展现的标记。网站可以使用此功能，来确保自己网站的内容没有被嵌到别人的网站中去，也从而避免了点击劫持 (clickjacking) 的攻击。它有三个可选择项： 123DENY：表示该页面不允许在 frame 中展示，即便是在相同域名的页面中嵌套也不允许；SAMEORIGIN：表示该页面可以在相同域名页面的 frame 中展示；ALLOW-FROM uri地址：表示该页面可以在指定来源的 frame 中展示； 如果设置为 DENY，不光在别人的网站 frame 嵌入时会无法加载，在同域名页面中同样会无法加载。另一方面，如果设置为 SAMEORIGIN，那么页面就可以在同域名页面的 frame 中嵌套。 这里还要额外注意一下！配置了Cookie的HttpOnly属性和Secure属性之后，如果测试中心的人使用的协议是http而不是https的话，会有“浏览器请求后端服务时header不会带上cookie参数”的现象，那是因为“由于secure属性的存在，导致浏览器在与服务器通信时不会使用该cookie”。这个时候就需要把secure=”true”这个配置去掉才可以达到正确测试的目的。 参考资料https://imququ.com/post/my-nginx-conf-for-security.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维技术","slug":"运维技术","permalink":"http://yoursite.com/tags/运维技术/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"django新增class的时候数据库格式出错","slug":"django新增class的时候数据库格式出错","date":"2018-01-10T07:33:06.000Z","updated":"2018-01-22T02:27:46.000Z","comments":true,"path":"2018/01/10/django新增class的时候数据库格式出错/","link":"","permalink":"http://yoursite.com/2018/01/10/django新增class的时候数据库格式出错/","excerpt":"","text":"这几天开发频繁要求查看生产环境zookeeper的配置，于是就想在django里添加一个新的栏，以文本的形式随时更新zookeeper的情况。 于是我就登陆了django，在model.py里添加一个新的class，如下： 12345678#建立杭州测试ZK配置class HZfunczk(models.Model): hzfunczk_remark = models.CharField(verbose_name='杭州测试ZK配置',max_length=50000,blank=true) hzfunczk_signer = models.CharField(verbose_name='登记人',max_length=30,default='system') hzfunczk_signtime = models.DateField(auto_now_add=True) def __unicode__(self): return self.domain_name 然后在django的目录下执行python manage.py makemigrations，这一步没问题，但是在执行python manage.py migrate的时候，就出现了下面的错误： 我开始认为是charfield写错了，应该写Textfield，于是更改了一下，但是保存之后，再执行python manage.py migrate还是出错。其实这个错误主要原因就是因为我那个50000设置错了，因为字段hzfunczk_remark定义的长度50000超出了mysql的varchar的最大长度21845（在utf8编码情况下）。于是我就在model.py里把这个长度改成20000，保存之后，还是执行到python manage.py migrate这一步，依旧爆上面的错误。于是我就干脆把这个class先删除掉，没想到都删除光了，还是在make的时候会爆错。 这就很奇怪了，我已经删掉了为啥还有这样的事儿？于是就干脆进入到数据库去看，由于我现在只知道列名叫hzfunczk_remark，所以我要根据这个列名去查它所在的表，maria反馈如下： 12MariaDB [abccs]&gt; select TABLE_SCHEMA, TABLE_NAME from information_schema.columns where COLUMN_NAME = 'hzfunczk_remark'; Empty set (0.02 sec) 好尴尬呀，数据库里压根就没有列名为“hzfunczk_remark”的表。然后由于python manage.py migrate报错，现在无法启动django。怎么办？ 遇到这种状况，就去django里的migrations文件夹，这个文件夹里有很多的以时间命名的py文件，它们记录着数据库的每一步操作，不过这里面的py还没有真正执行到数据库里，我找到当时添加class那个时间段的py文件，里面是这样的： 先把里面CharField改成TextField，然后把50000改成小于21845的就行了。如果你性子比较烈，那就干脆把这个文件以及之后产生的所有文件都删除掉。重新的去make。 如果还是实在不行，还有一个万不得已的办法，几乎所有的数据库错误都可以用这个方法解决：将migrations文件夹下的文件除了init.py全部删掉，然后将数据库drop掉，重新建数据库。然后make和migrate，就可以使用一个新的数据库（但愿你永远用不到这个方法）。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"django","slug":"django","permalink":"http://yoursite.com/tags/django/"},{"name":"python","slug":"python","permalink":"http://yoursite.com/tags/python/"}]},{"title":"通道信息加密工具--Qtunnel","slug":"通道信息加密工具-Qtunnel","date":"2018-01-10T04:20:01.000Z","updated":"2018-01-22T02:33:28.000Z","comments":true,"path":"2018/01/10/通道信息加密工具-Qtunnel/","link":"","permalink":"http://yoursite.com/2018/01/10/通道信息加密工具-Qtunnel/","excerpt":"","text":"前言数据库做异地容灾是一个很常见的现象，既然信息要跨地域传递，要么就很土豪的打通机房之间的链路或者动用VPN，要不然就不可避免的走公网网络传输信息。既然选择了公网，那么数据库的语句就很容易被人监听到，所以把那些明文加密是必不可少的环节。 mysql支持tls/ssl加密方法对信息进行加密，这个方法的配置也很简单，就是两边各加上一个nginx，一个是正向代理一个是反向代理，配上ssl证书，然后就像配置网站https协议那样，在nginx.conf里开启ssl监听即可。 但是这种方法有一点小问题，就是在进行SSL握手之前，mysql会发送Server Greeting和Login Request数据包，然后才有可能使用SSL握手。这样步骤就多了一步鉴权，对访问性能有所影响。所以这个时候，我选择了另一个用于加密client和server之间链路通信的工具—-Qtunnel，因为它直接加密，速度更快。 Git的地址在这里：https://github.com/arstercz/qtunnel ，感谢arstercz大神的再加工！ 上面说过了Qtunnel是不需要认证的，默认加密方法是RC4，以字节流的方式加密明文的每一个字节，而且密钥长度最长支持256位，可以很好的抵御暴力搜索密钥的攻击，总而言之，Qtunnel是一个轻量且快速的加解密工具，而且还可以搭配atlas等数据库中间件使用。 下载与准备由于Qtunnel是用go语言写的，所以需要先安装golang，centos服务器的yum安装方法如下: 12rpm -Uvh http://dl.fedoraproject.org/pub/epel/6/x86_64/epel-release-6-8.noarch.rpmyum install -y golang go语言安装完毕之后，我们就git clone https://github.com/arstercz/qtunnel.git ，获得qtunnel文件夹，文件夹内容如下： make，如果没有任何报错，那么就是安装成功了，使用./bin/qtunnel -h语句验证一番： 本次实验的计划是这样的：用A机器访问B机器的mysql，并且插入数据，在B机器上的3306端口抓包，查看数据是否是明文；然后再在A机器和B机器上都安装qtunnel并且启动，然后重新插入数据，在B机器上的端口抓包，查看数据是否被加密。流程图如下： 实验开始A机器和B机器都是使用阿里云虚拟服务器，版本都是centos 6.4，现在我们的加密实验正式开始。 首先A和B机器上都不启动qtunnel，然后我们在A机器上登陆B机器的数据库，如果之前没有授权，那么授权语句是： GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;A机器的IP地址&#39; IDENTIFIED BY &#39;密码&#39; WITH GRANT OPTION; 登陆mysql之后，我们随意的插一个语句，然后通过抓包发现无论这个语句还是数据库的反馈都是以明文的形式呈现，如图： 这种让数据裸奔的行为无疑于找死，那么这个时候我们就要配置一下qtunnel，来看一下它的加密效果。 在A服务器上，我们设定qtunnel是客户端，手动建立一个conf文件，比如vim /etc/conn.conf，内容如下： 123456[client1]faddr = 10.252.215.108:3309 #这里是qtunnel客户端的IPbaddr = 10.175.193.239:3310 #这里是qtunnel服务端的IPcryptoMethod = rc4 #这里选用rc4的方式加密secret = 3301_test%Iad #rc4密钥，服务端的密码必须跟这个一致！clientmode = true #表示这端是客户端 然后使用./bin/qtunnel -conf=/etc/conn.conf -daemon -logto=syslog启动qtunnel，看一下进程和端口情况，如图： 在B服务器上，同样手动建立一个配置文件，假设也叫conn.conf，内容如下： 123456[server1]faddr = 10.175.193.239:3310 #这里是qtunnel服务端的IPbaddr = 10.175.193.239:3306 #这里是数据库的地址，由于在同一台机器上，所以地址一样cryptoMethod = rc4 secret = 3301_test%Iad #rc4密钥，跟client密钥一致clientmode = false #表示这是服务器端 也用同样的语句启动qtunnel，查看3310这个端口已经被监听了： 现在，我们在A服务器上来重新连接B数据库，但是要注意！这个时候mysql里的-h不能再是B的IP地址了，而是A的地址！因为qtunnel现在已经打通了一个通道，访问qtunnel的3310端口就等于是访问B数据库的3306端口（有点类似atlas的意思）。 连上之后，我们随意插入一些语句，看一下qtunnel的能力: 可见这个时候，抓包显示都是加密的文字了，实验成功！ 总结与参考资料总结一下：qtunnel采用rc4加密，在算法强度和速度方面是很好的选择，不会引起slave太大的延迟，对管理员或开发而言数据都是透明的（如果在上面的实验启动了qtunnel之后，不监听3310端口，而是监听3306端口，得到的依旧是明文），只是在两端传输的过程中增加了加解密处理。核心的业务(比如用户和充值)在做异地架构的时候可以考虑该方式增强数据的安全性。 《mysql使用ssl简析》：https://hsulei.com/2017/10/19/mysql%E4%BD%BF%E7%94%A8ssl%E7%AE%80%E6%9E%90/《使用ssl加密mysql 5.6的官方文档》：https://dev.mysql.com/doc/refman/5.6/en/encrypted-connections.html","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"加密技术","slug":"加密技术","permalink":"http://yoursite.com/tags/加密技术/"},{"name":"Qtunnel","slug":"Qtunnel","permalink":"http://yoursite.com/tags/Qtunnel/"}]},{"title":"Zabbix3.0搭配微信企业号报警","slug":"Zabbix3-0搭配微信企业号报警","date":"2018-01-10T03:18:02.000Z","updated":"2018-01-22T02:28:58.000Z","comments":true,"path":"2018/01/10/Zabbix3-0搭配微信企业号报警/","link":"","permalink":"http://yoursite.com/2018/01/10/Zabbix3-0搭配微信企业号报警/","excerpt":"","text":"Zabbix搭配微信企业号报警是一个很流行的手段，这里说一下如何配置。 准备工作建立一个企业号以及具体应用的链接在此：http://chenx1242.blog.51cto.com/10430133/1954634，里面写的都很明白了。 现在打开微信企业号的官方网站https://work.weixin.qq.com，然后扫描一下微信二维码登录到企业号的控制台。 在控制台网页里，需要查找几个元素，分别是CorpID、应用AgentId、应用Secret还有用户账号。 首先，在控制台里选择“我的企业”，然后就可以看见CorpID，如图： 然后点击“企业应用”，如果没有应用，那么就新建立一个应用。比如我已经建立了一个应用叫“zabbix告警”，那么应用AgentId和应用Secret就在如图的位置： 有了上面的CropID和Secret，就可以去验证一下accesstoken，登录http://qydev.weixin.qq.com/debug ，后在填入对应的CropID和Secret，看一下返回结果是否是“HTTP/1.0 200 OK”，如图： 在这个“zabbix告警”的应用里可见范围里添加对应需要通知的人，然后在“通讯录”里，找到对应的人，记录他们的账号，如图： 材料已经俱备完毕，现在需要做的是更改zabbix-server配置。 首先，在zabbix-server.conf里添加一句AlertScriptsPath=/usr/lib/zabbix/alertscripts，这是为了说明一下脚本所在的路径。当然，这个路径你可以自己更改，然后重启一下zabbix-server。 编写脚本cd /usr/lib/zabbix/alertscripts，在这个目录下我们要新写一个微信脚本，比如脚本名称叫wechat.py。 这个python脚本是需要requests模块的，所以需要先安装这个模块，安装方法如下： 12pip install requestspip install --upgrade requests 而python脚本内容如下，感谢https://github.com/X-Mars/Zabbix-Alert-WeChat/的脚本： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546#!/usr/bin/python2.7#_*_coding:utf-8 _*_#this script is used for alarm by WECHATimport requests,sys,jsonimport urllib3urllib3.disable_warnings()reload(sys)sys.setdefaultencoding('utf-8')def GetToken(Corpid,Secret): Url = \"https://qyapi.weixin.qq.com/cgi-bin/gettoken\" Data = &#123; \"corpid\":Corpid, \"corpsecret\":Secret &#125; r = requests.get(url=Url,params=Data,verify=False) Token = r.json()['access_token'] return Token def SendMessage(Token,User,Agentid,Subject,Content): Url = \"https://qyapi.weixin.qq.com/cgi-bin/message/send?access_token=%s\" % Token Data = &#123; \"touser\": User, # 企业号中的用户帐号，在zabbix用户Media中配置，如果配置不正常，将按部门发送。 #\"totag\": Tagid, # 企业号中的部门id，群发时使用。 \"msgtype\": \"text\", # 消息类型。 \"agentid\": Agentid, # 企业号中的应用id。 \"text\": &#123; \"content\": Subject + '\\n' + Content &#125;, \"safe\": \"0\" &#125; r = requests.post(url=Url,data=json.dumps(Data),verify=False) return r.text if __name__ == '__main__': User = sys.argv[1] # zabbix传过来的第一个参数 Subject = sys.argv[2] # zabbix传过来的第二个参数 Content = sys.argv[3] # zabbix传过来的第三个参数 Corpid = \"这里填写Corpid\" Secret = \"这里填写Secret\" Agentid = \"这里填写应用的agentid\" Token = GetToken(Corpid, Secret) Status = SendMessage(Token,User,Agentid,Subject,Content) print Status 脚本保存后，chown -R zabbix:zabbix wechat.py，然后小试一下，上面看到“Zabbix告警”这个微信应用里有一个用户账号叫ChenShuo，那么wechat.py执行语句是：python wechat.py ChenShuo 这个是标题 这里是正文！！ 然后看一下微信，如图： 正确出现了微信提示，可见这个脚本是OK的了。 配置zabbix现在我们要登录到zabbix网站，最上面的“Administration”里选择“Media types”，新建立一个Media type，如图： 保存之后，在“Administration”里选择“Users”，在Admin用户里点击“media”,把刚刚新增的“微信告警”这个media type添加进去，如图： 通知手段配置完毕，现在就是要在具体的Trigger上把微信告警这个新手段添加到active里。首先打开Configuration里的actions界面。此时假设现在有一个告警Trigger叫“模块发生了重启”，判断模块是否重启的依据就是pid值是否发生了变化。那么点击这个Trigger，在action里把“微信告警”添加到报警手段里，如图： 保存之后，整个的微信告警配置就完成了。为了验证配置是否生效，我冒死重启了一台生产环境的服务器，当然啦，好孩子千万不要效仿。 收到微信提示如图：不过考虑到微信告警可能会有所延迟，所以在这建议大家把告警阈值配置稍微早一点，避免“孩子死了奶来了”这种尴尬的情况。 参考资料http://www.yfshare.vip/2017/04/13/Zabbix%E4%B9%8B%E5%BE%AE%E4%BF%A1-Wechat-%E5%91%8A%E8%AD%A6/https://github.com/X-Mars/Zabbix-Alert-WeChat/","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"},{"name":"zabbix","slug":"zabbix","permalink":"http://yoursite.com/tags/zabbix/"}]},{"title":"自己动手搭建一个hexo博客demo","slug":"自己动手搭建一个hexo博客demo","date":"2018-01-10T02:54:51.000Z","updated":"2018-02-11T06:29:08.000Z","comments":true,"path":"2018/01/10/自己动手搭建一个hexo博客demo/","link":"","permalink":"http://yoursite.com/2018/01/10/自己动手搭建一个hexo博客demo/","excerpt":"","text":"曾几何时，自己动手做一个博客的想法愈加强烈，想在里面放一些更多除了技术之外的东西，比如烹饪的美食，比如PVP的视频，比如拍摄的照片，比如篮球足球的评论。在这种需求下，我从众多博客框架里面选择了hexo，原因就是“很多人都推荐hexo”….（囧）于是乎我在windows里搞一个，由于我在公司的网络是可以跨越长城的，所以搞github有一点天然的优势。而且github的博客不用花钱搞域名，他直接免费提供… 在搞github的时候墙裂推荐各位去用命令行，有linux的基本基础就可以很熟练的使用命令行搞github， 它的客户端真的不如命令行好用。 准备工作先去注册一个github，然后去https://git-scm.com 上下载一个最新的git windows的客户端，我下载的是2.15.1版本，如图： 下载完毕之后，就把这个exe文件安装，然后在“开始”里找到git再打开“Git Bash”，我的github账号是RorschachChan，电子邮件也已经配置过，所以现在就在这个bash窗口里写入如下语句： 12git config --global user.name \"RorschachChan\"git config --global user.email \"chenx1242@163.com\" 上面git config --global参数，表示你这台机器上所有的Git仓库都会使用这个配置。 再去https://nodejs.org/en/download/上根据自己windows的情况，下载最新的nodejs，下载完了之后就一路next，然后需要退出重进一下git bash，在bash的命令行里输入node -v，看到版本号就是OK，同时输入node，$会变成&gt;，然后输入.exit就可以退出返回到bash。 然后就是安装hexo，hexo的安装比较简单，就是在git bash里输入npm install -g hexo-cli和npm install -g hexo，然后需要等待一会，如果出现了npm ERR!不要怕，重新输入一次应该就会好了，安装完毕之后，输入hexo -v查看hexo的版本，如图： 然后建立一个github ssh密钥，在git bash里输入ssh-keygen -t rsa -C &quot;你的邮箱&quot;，然后告诉密钥生成的路径（下图黄框）以及会让你输入对应的口诀（红色箭头），这个口诀很重要，要妥善保存，如图： 这个密码会在你提交项目（hexo d）时使用，如果为空的话提交项目时则不用输入。这个设置是防止别人往你的项目里提交内容。这时候去C:\\Users\\33664\\.ssh的路径里就会看到一对钥匙，id_rsa是私钥，不能泄露出去，id_rsa.pub是公钥，可以放心地告诉任何人。 来到github的个人配置里，选择SSH and GPG keys，然后输入title和id_rsa.pub的内容，点击add ssh key。如图：准备工作的最后一步，就是建立一个文件夹，我的文件夹建立在E盘下，名字就叫hexo。 开始搭建博客首先在git bash里进入/e/hexo，然后输入hexo init，这个命令是初始化命令，再输入hexo -g来生成静态文件，执行之后，hexo就会在public文件夹生成相关html文件，这些文件将来都是要提交到github上你的用户名.github.io的仓库上去的。然后可以输入hexo s来本地启动hexo，这个时候跑到浏览器里输入localhost:4000就会看到hexo博客最初的一个样子，如图： 这个默认的主题比较难看，我们去https://github.com/iissnan/hexo-theme-next下载最近一个比较火爆的主题next,并且把这个下载到hexo文件夹里的themes/next里，语句是：git clone https://github.com/iissnan/hexo-theme-next.git themes/next 然后打开hexo文件夹里的_config.xml，把原有的theme注释，换成新的next，注意，中间是有空格的！ 12#theme: landscapetheme: next 然后hexo clean和hexo g清除 Hexo 的缓存和重新生成静态文件，再次hexo s启动进程，来到浏览看一下发现博客的样子就变成下面的样子了： 这个看上去就简单大方很多了吧。 把博客上传到github现在有人问了，这个博客看上去好像很美，但是有两个致命的缺陷：第一，内容都是在我的windows里，如果我这个电脑坏了/出差/换新硬盘，那么如何保证我以前文件？第二，我启动进程需要执行 hexo -s，如果我电脑关机了，岂不是博客无法打开？ 需要解决就要把磁盘上的内容传递到github库里了，同时github是常开进程的，这样既可以更新我们的内容又不会关闭博客进程，除非github这个网站黄了。 先去github网站去建立一个库（repository），这里我直接选择了公共读，如图： 然后在hexo文件夹里面，修改一下_config.xml的几个地方： 1234567891011121314# Sitetitle: 石锤淡啤酒 #这个是网站在标签页的标题subtitle: 生活就是等待戈多 #这个是副标题description: 这里记录的不只有代码，还有生活和思想！ #这里也可以写网站的关键词，也可以矫情的写点别的author: Chris Chan #这个作者会在网页最下面显示language: zh-Hans #这里表示简体中文timezone:# Deployment## Docs: https://hexo.io/docs/deployment.htmldeploy: type: git repository: git@github.com:RorschachChan/RorschachChan.github.io.git #这里写的就是刚刚申请的库名 branch: master 建立完库以及修改保存了_config.xml之后，我们执行一句hexo d部署命令，在执行的时候需要输入当时你建立id_rsa时候的口诀，刚刚申请的那个口诀不会这么快就忘了吧。 返回到github的网站就看到hexo里所有的内容都上传到了github网站里了，如图: 在浏览器里输入“https://你的用户名.github.io”，就看到了博客界面： 同理，如果你的github用户名是test，建立的是test.github.io的仓库（必须是你的用户名，其它名称无效），将来你的网站访问地址就是http://test.github.io了，每一个github账户最多只能创建一个这样可以直接使用域名访问的仓库。 至此，建立一个博客demo就到此结束了！ 参考资料https://baoyuzhang.github.io/2017/04/28/【Hexo搭建独立博客全纪录】（一）使用Git和Github/https://github.com/iissnan/hexo-theme-nexthttp://opiece.me/2015/04/09/hexo-guide/http://shenzekun.cn/hexo的next主题个性化配置教程.html 强烈推荐这篇文章，可以让你把next主题的博客做的更加漂亮！","categories":[{"name":"博客搭建","slug":"博客搭建","permalink":"http://yoursite.com/categories/博客搭建/"}],"tags":[{"name":"hexo","slug":"hexo","permalink":"http://yoursite.com/tags/hexo/"},{"name":"博客搭建","slug":"博客搭建","permalink":"http://yoursite.com/tags/博客搭建/"},{"name":"github","slug":"github","permalink":"http://yoursite.com/tags/github/"}]},{"title":"Query String跟Arg的差异","slug":"Query-String跟arg的异同","date":"2018-01-09T12:47:40.000Z","updated":"2018-01-22T02:29:06.000Z","comments":true,"path":"2018/01/09/Query-String跟arg的异同/","link":"","permalink":"http://yoursite.com/2018/01/09/Query-String跟arg的异同/","excerpt":"","text":"前言与需求在https://rorschachchan.github.io/2018/01/09/记一次配置rewrite和return的经历/ 里记录了一次rewrite和return的故事，不过我当时在最后的return里是把域名给写死了：rewrite ^.*$ http://dvlshop.lechange.com/index.php/wap/$id$query last;。 现在新的需求又来了，说域名不要写死，http://dvlshop.lechange.com/index.php/这部分要跟整个uri的state部分保持一致。 于是我这里再把整个uri贴出来，辣一下各位的眼睛：http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp; #满足条件的话把这个改成+auto+scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 也就是说现在只需要变量state那点部分，那么这个时候就不能再使用$query_string了，要使用$arg。 $arg可以精确匹配变量，比如说我有一个参数（uri里？后面的那部分全叫参数）：&amp;p=你大爷&amp;q=你大娘，用$query_string和$arg就是获取所有，而使用$arg_p就是可以获取“你大爷”。 于是说动手就动手，把nginx.conf改成了：123456789101112131415161718location ~ .*\\.php.*&#123; include php_fcgi.conf; include pathinfo.conf; set $flag \"0\"; if ( $args ~ \"source_type=lc_app\" ) &#123; set $flag \"1\"; &#125; if ( $args ~ \"(.*)response_type(.*)\" )&#123; set $Flag \"$flag$flag\"; set $id $1; set $query $2; &#125; if ($Flag = \"11\")&#123; set $flag \"0\"; return 301 $arg_state$id+auto+$query; &#125;&#125; 但是通过日志查看，发现$arg_state得到的是/http%3A%2F%2Fdvlshop.lechange.com%2Fproduct-79.html,这就很囧了，我希望获取http%3A%2F%2Fdvlshop.lechange.com%2Fproduct-79.html（不要前面的反斜杠）或者是/product-79.html（不要中间的网站）。这可怎么办？ 答案是，原生的nginx是做不到这一点，因为nginx不参与业务层逻辑方面的业务。如果说要达到改写的目的，就要搭配lua或者把nginx换成openresty。于是乎就让开发修改一下传递的state来达到目的。 扩展与补充看到这个结果突然让我想起来一道面试题，说开发有一个模块，同时这个模块会给nginx提供几个状态码，比如状态码是111，那就是代表OK，状态码不是111，那就是代表不OK，现在想写一个语句，如果nginx获得的状态码不是111，返回一个404的页面，怎么写？ 没错，答案也是“原生nginx写不了”，原因跟上面的一样，应用模块状态码是业务层的，nginx是http层的，不在一层压根就无法交流。 在这里也顺道补充一下“在浏览器中输入一个URL后都发生了什么？”，以下是一个大概流程： 浏览器向DNS服务器查找输入URL对应的IP地址； DNS服务器返回网站的IP地址； 浏览器根据IP地址与目标web服务器建立TCP连接； 发送HTTP请求； 服务器处理请求； 返回响应结果； 关闭TCP连接； 浏览器解析HTML； 浏览器布局渲染；","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"},{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"记一次配置rewrite和return的经历","slug":"记一次配置rewrite和return的经历","date":"2018-01-09T08:39:10.000Z","updated":"2019-06-20T05:56:22.000Z","comments":true,"path":"2018/01/09/记一次配置rewrite和return的经历/","link":"","permalink":"http://yoursite.com/2018/01/09/记一次配置rewrite和return的经历/","excerpt":"","text":"前言与需求自动电商平台归属了大数据研究院之后，我又恢复了那个“把nginx当成爸爸”的日子。开发不断地提出了的要求，我一样一样的疲命应付，并且在应付后记录下来，就怕以后再遇到类似的问题。 这次的需求是一个跳转，满足某个条件之后把“http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp;scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 ”改成“http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;=code&amp;scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27” 具体条件是: 先判断是否有source_type=lc_app； 再判断是否有response_type； 如果以上两个都满足，将“response_type”改成“+auto+”； 各位看官，我理解你们此时不想继续看下去的心情，其实我当初看着那么一大坨uri心里也直犯闹，但是没办法，“食君之禄，分君之忧”，我只能耐着性子一个一个的拆开，还别说，拆开的话就清晰许多了，如下：http://dvlshop.lechange.com/index.php/wap/?client_id=lc_mall_m&amp;redirect_uri=https%3A%2F%2Fdvlshop.lechange.com%2Fopenapi%2Ftrustlogin_api%2Fparse%2Fwap_trustlogin_lecheng%2Fcallback&amp;response_type=code&amp; #满足条件的话把这个改成+auto+scope=read&amp;state=http%3A%2F%2Fdvlshop.lechange.com%2Findex.php%2Fwap&amp;user=token%2Flcid_9f9lmo2u6i7hkl6t6eaodn2blmg5jbsg&amp;expire=1514191636&amp;source_type=lc_app&amp;nonce=cdizHO6uvSx5JK79Kmtz5RBpSi0ROhpF&amp;signature=VeCceYCWDE6BZjIdni/68YCmhqc=%27 开始操作针对这次需求我的计划是这样的：把原地址看成”$1+ response_type +$2”这样的一个样式，确定$1和$2，然后rewrite成”$1+ +auto+ +$2”不就搞定了么？ 于是乎我就凭着我那二把刀的nginx技术开始动手。折腾了大约半个小时，拿出来这样一个配置： 123456789101112131415161718location ~ .*\\.php.* &#123; include php_fcgi.conf; include pathinfo.conf; set $flag \"0\"; if ( $request_uri ~ \"source_type=lc_app\" ) &#123; set $flag \"1\"; &#125; if ( $request_uri ~ \"(.*)response_type(.*)\" )&#123; set $Flag \"$flag$flag\"; set $id $1; set $query $2; &#125; if ($Flag = \"11\")&#123; #注意这个地方是11 set $flag \"0\"; rewrite ^.*$ http://dvlshop.lechange.com/index.php/wap/$id$query last; #前面那一段是写死的 &#125; &#125; 但是很不幸，nginx -s reload之后的结果是“$1+$2+$1+ response_type +$2”的格式（地址太长太恶心了，我就不写了）。 然后在arstercz大神的指点下，把那句rewrite改成了return 301 http://dvlshop.lechange.com/index.php/wap/?$id$query;。就达到了效果。 原因确定后来追寻原因，原来是： rewrite后面接的$uri不需要$args，因为$args会被自动带过来。而return的则会丢失$args，需要手动补上$args。而我上面的$1,$2恰巧就是$args，所以用rewrite的话就会重复。举个例子，比如请求「http://localhost/?a=1」想被 301 到「https://localhost/?a=1?a=1」，要么 1234server &#123; listen 80; rewrite / https://$host$uri permanent;&#125; 要么就 1234server &#123; listen 80; return 301 https://$host$request_uri;&#125; 补充说明这里补充一下uri、request_uri、document_uri之间的区别： $request_uri: /stat.php?id=1585378&amp;web_id=1585378 $uri: /stat.php (不带？后面) $document_uri: /stat.php （与uri完全相同） 注意！$uri和$document_uri同是不带参数的，但是是解码之后请求的路径，而$request_uri是没有解码的完整uri。这样就有一个问题，就是$uri是解码的，这样就可能包含换行符，CRLF就会注入漏洞。详情可见 https://www.leavesongs.com/PENETRATION/nginx-insecure-configuration.html 。 所以说，不要偷懒少打几个字母，最好都要用$request_uri。 参考资料https://www.cnblogs.com/bigberg/p/7715020.htmlhttps://blog.csdn.net/yxl0011/article/details/72818409https://blog.csdn.net/aliencsdn/article/details/54668552","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"},{"name":"Nginx","slug":"Nginx","permalink":"http://yoursite.com/tags/Nginx/"}]},{"title":"Linux运维工程师面试题第一套","slug":"Linux运维工程师面试题第一套","date":"2018-01-04T08:46:41.000Z","updated":"2018-07-10T09:42:10.000Z","comments":true,"path":"2018/01/04/Linux运维工程师面试题第一套/","link":"","permalink":"http://yoursite.com/2018/01/04/Linux运维工程师面试题第一套/","excerpt":"","text":"这套题的出处是http://blog.51cto.com/nolinux/1670406 ，看到了闲着没事周末就做一做，答案都是我自己在工作里得到的，不一定百分百准确，只是无聊的时候做做，现在拿出来跟各位分享一番。 1、请写出五种系统性能分析工具，并简述其作用和特点[我的答案] top、free、vmstat、iostat、perf等等等等，如果你想装逼，可以回答fio,blktrace，oprofile。具体的作用和特点这里不多说了，但是我着重要推荐vmstat，很实用很棒的一个命令。 2、请写出web服务器的调优要点[我的答案]以nginx为例，个人总结有如下几个要点：1）尽可能的少用http，因为http是有开销的；2）尽可能的使用CDN；3）添加Expire/Cache-Control头，这个头是缓存用的，可以缓存图片和flash那样不轻易更改的文件，减少访问时间；4）启动gzip压缩，这个没啥好说的了；5）尽可能少的重定向，能rewrite就不要return，我也知道return比rewrite好写，但是重定向是需要时间的，增加一次重定向就会多一次web需求；6）如果可以，把ajax也做缓存；7）减少dns查询，很多网页会有外站的广告，这些广告也是会启动dns查询的，所以如果不缺钱，减少这种广告；8）调好服务器里的TCP协议栈，这个无论是web服务器还是应用服务器都是必须的； 3、请写出你知道或使用过的nginx扩展模块（注意标注知道和使用）[我的答案] 随便说几个，这玩意到时候结合工作过的情况说说吧：Nginx负载均衡模块：nginx-upstream-fair非阻塞访问redis模块：redis2-nginx-module分布式图片实时动态压缩：ngx-fastdfs 4、请简述你了解的自动化配置管理工具特点和运行原理[我的答案]我用的最多的就是ansible和saltstack，这俩都是python的，对于我这个半路出家的更亲切。ansible基于SSH协议传输数据，不用装agent，配置比较简单，对windows支持惨不忍睹；saltstack使用消息队列zeroMQ传输数据，如果1000台以上的话它速度比ansible还要快,要安装agent，对windows支持同样惨不忍睹； 5、目前，有一个文件，内容如下： 172.16.100.1 172.16.100.2 172.16.100.3 172.16.100.4 请使用while和ssh命令，登录文件内的ip并执行hostname命令[我的答案]这个我还真没有什么思路，不过应该是跟“&lt;”输入重定向命令结合的一个脚本吧。PS,为啥不用ansible…哪怕pssh也可以啊！ 6、请使用awk命令将如下两份文件中名字相同的两行合并起来 A文件： 大广州 21岁 广州大 23岁 州广大 22岁 广州大 24岁 B文件： 广州大 男 大广州 男 州广大 男 广州大 男输出效果： 大广州 21岁 男[我的答案]awk ‘NR==FNR{a[$1]=$2}NR&gt;FNR{print $0,a[$1]}’ 第2个文件名 第1个文件名PS，做完这道题，我已经不认识“广”“州”这两个字了… 7、请使用绘图的方式简述TCP/IP三次握手和四次断开的交互过程[我的答案]这种图满大街都是了，我这个灵魂画师在这里就不污染各位的眼睛，不过这里推荐各位去看一篇文章：https://mp.weixin.qq.com/s?__biz=MjM5NzA1MTcyMA==&amp;mid=2651160450&amp;idx=2&amp;sn=1128438fa5287b6cee503880698642b2&amp;scene=21 对原理讲的浅显易懂。多说一句，网易招聘java的时候也问这个问题，不过他们问的是“为什么要三次握手？” 8、请根据你的理解，简述高可用服务体系的相关组件，并列举该组件的具体实现服务名字[我的答案] 我觉得这个题是要问一些架构上的东西，以我工作环境为例：统一配置:zookeeper、Consul、Etcd+Confd(这俩比较常见于动态管理nginx)前端展示:nginx消息队列:activemq、kafka读写分离中间件:atlas日志分析:elk 9、请根据你的理解，简述负载均衡的实现方式[我的答案]负载均衡主要分为两种，硬件（F5）和软件（NGINX、Haproxy、LVS），硬件效果比较牛逼，它是把4-7层的负载均衡功能做到一个硬件里面，但是价格昂贵最近用的越来越少了。软件的负载均衡又分两种，四层和七层：四层是在IP/TCP协议栈上把网络包的IP地址和端口进行修改，达到转发的目的；七层就是在应用层里把HTTP请求、URL等具体的应用数据发送到具体的服务器上。四层的效率比七层的高，四层一般安排在架构的前端，七层一般就是在具体服务器的前端。软件负载均衡比较常见的几个分配方式如下：轮询：访问请求依序分发给后端服务器；加权轮询：访问请求依序分发后端服务器，服务器权重越高被分发的几率也越大；最小连接数： 将访问请求分发给当前连接数最小的一台后端服务器，服务器权重越高被分发的几率也越大； 10、请根据你的理解，简述数据迁移工具和数据存储服务有哪些以及相关特点[我的答案]由于我公司主要都放在了阿里云，数据库用过的就这么几个:mysql、redis和elasticsearch。对于Storm和Hadoop这俩我还是初学者。mysql:关系型数据库elasticsearch:全文检索框架，这玩意逐渐向一个数据库靠拢了redis:键值储存数据库 mysql的数据迁移最常见的就是mysqldump，但是要注意使用不当会锁表，redis的数据迁移最稳妥的方法就是主从同步：在slave端启动redis，然后执行slaveof master机器IP地址 6379，然后使用info的时候查看master_link_status如果是up那就是OK了，再执行slaveof no one,提示OK就是OK了；Elasticsearch的数据迁移工具就是Elasticsearch-Exporter，不过我对它仅仅只是了解，用的并不多； 总结这套题不算难，方向是偏应用的，但是对云端服务的运维来说不算很友好，因为云厂商基本都把数据备份和数据迁移都做成自己的工具（比如阿里云的DTS），所以很多云服务的运维对这种东西了解不多。","categories":[{"name":"大牛之路","slug":"大牛之路","permalink":"http://yoursite.com/categories/大牛之路/"}],"tags":[{"name":"面试","slug":"面试","permalink":"http://yoursite.com/tags/面试/"},{"name":"职场","slug":"职场","permalink":"http://yoursite.com/tags/职场/"}]},{"title":"Nginx动态编译新的模块","slug":"Nginx动态编译新的模块","date":"2018-01-03T13:44:44.000Z","updated":"2018-07-10T09:38:12.000Z","comments":true,"path":"2018/01/03/Nginx动态编译新的模块/","link":"","permalink":"http://yoursite.com/2018/01/03/Nginx动态编译新的模块/","excerpt":"","text":"开始动手打算给电脑上的nginx添加一个当时没有编译安装的echo-nginx-module模块，这是一个第三方模块，要知道nginx要添加模块是需要重新编译的，这一点跟apache不同，apache是在配置文件里引用.so文件的。 首先先nginx -V，查看一下nginx已经编译的模块都有啥，如图： 于是我就git clone https://github.com/openresty/echo-nginx-module，但是发现竟然告诉我“git: command not found”。oh shit，原来这台nginx实验机器压根就没有装过git啊！而yum源里的软件基本上已经过时的太久了，就拿git来说吧，使用yum info git看到的版本是1.8.3.1。但是在https://github.com/git/git/releases 里可以看到，git的版本现在已经丧心病狂的到达了2.16的版本了。 那么我们先安装git!通过yum install curl-devel expat-devel gettext-devel openssl-devel zlib-devel和yum install gcc perl-ExtUtils-MakeMaker来安装依赖库。wget https://github.com/git/git/archive/v2.16.0-rc0.tar.gz来下载2.16的git保存到centos里。tar -xzvf v2.9.2.tar.gz -C /目标目录/，然后在目标目录里面执行make prefix=/usr/local/git all和make prefix=/usr/local/git install，编译过程可能会比较长，请耐心等待。 编译结束之后，echo &quot;export PATH=$PATH:/usr/local/git/bin&quot; &gt;&gt; /etc/bashrc，把git添加到环境变量，再source /etc/bashrc让它实时生效，最后再一次看看git --version，大功告成！ 编译新模块git搞定了之后，重新git clone https://github.com/openresty/echo-nginx-module，然后在nginx的configure文件夹里面，把echo-nginx-module模块添加上。命令如下：./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module --with-pcre=/root/pcre-8.41 --with-http_v2_module --add-module=/root/echo-nginx-module-0.61,我这里还附赠了一个“http_v2_module”。 configure完毕之后，去make一下就可以了，不要轻易make install，不然就是重新安装了。原来的nginx.conf等配置都没了。 养成替换nginx二进制文件的好习惯，如下： 12cp /usr/local/nginx/sbin/nginx /usr/local/nginx/sbin/nginx.bakcp nginx编译目录/objs/nginx /usr/local/nginx/sbin/ 然后再打开看一下nginx -V","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"git","slug":"git","permalink":"http://yoursite.com/tags/git/"},{"name":"nginx","slug":"nginx","permalink":"http://yoursite.com/tags/nginx/"}]},{"title":"从vmstat命令里看服务器瓶颈","slug":"从vmstat命令里看服务器瓶颈","date":"2018-01-03T12:56:56.000Z","updated":"2018-01-22T02:29:32.000Z","comments":true,"path":"2018/01/03/从vmstat命令里看服务器瓶颈/","link":"","permalink":"http://yoursite.com/2018/01/03/从vmstat命令里看服务器瓶颈/","excerpt":"","text":"这几天重新翻看基础知识，看到了vmstat，我认为它是一个非常优秀的命令,因为它包括了top和free，甚至还包含了一些io的信息，可以说是运维人员常备命令之一。常用方法：vmstat (-a) 多少秒刷一次 刷多少次。 对上面这个图来一个简单的解释： r: 运行队列中进程数量，这个值长期大于1就要判断是否需要增加CPU。b: 等待IO的进程数量 swpd: 使用虚拟内存大小(如果swpd的值不为0，但是SI，SO的值长期为0，这种情况不会影响系统性能）free: 空闲物理内存大小buff: 用作缓冲的内存大小cache: 用作缓存的内存大小(如果cache的值大的时候，说明cache处的文件数多，如果频繁访问到的文件都能被cache处，那么磁盘的读IO bi会非常小)inact: 非活跃内存大小（当使用-a选项时显示）active: 活跃的内存大小（当使用-a选项时显示） si: 每秒从交换区写到内存的大小，由磁盘调入内存so: 每秒写入交换区的内存大小，由内存调入磁盘注意：内存够用的时候，这2个值都是0，如果这2个值长期大于0时，系统性能会受到影响，磁盘IO和CPU资源都会被消耗。有些朋友看到空闲内存（free）很少的或接近于0时，就认为内存不够用了，不能光看这一点，还要结合si和so，如果free很少，但是si和so也很少（大多时候是0），那么不用担心，系统性能这时不会受到影响的。 bi: 每秒读取的块数bo: 每秒写入的块数注意：随机磁盘读写的时候，这2个值越大（如超出1024k)，能看到CPU在IO等待的值也会越大。 in: 每秒中断数，包括时钟中断。cs: 每秒上下文切换数。注意：上面2个值越大，会看到由内核消耗的CPU时间会越大。 us: 用户进程执行时间百分比(user time)注意： us的值比较高时，说明用户进程消耗的CPU时间多，但是如果长期超50%的使用，那么我们就该考虑优化程序算法或者进行加速。 sy: 内核系统进程执行时间百分比(system time)注意：sy的值高时，说明系统内核消耗的CPU资源多，这并不是良性表现，我们应该检查原因。 wa: IO等待时间百分比注意：wa的值高时，说明IO等待比较严重，这可能由于磁盘大量作随机访问造成，也有可能磁盘出现瓶颈（块操作）。 id: 空闲时间百分比 最后总结：如果r经常大于4 ，且id经常少于40，表示cpu的负荷很重。如果bi，bo长期不等于0，表示内存不足。 r（运行队列）展示了正在执行和等待CPU资源的任务个数。当这个值超过了CPU数目，就会出现CPU瓶颈了。 CPU 100%并不能说明什么，Linux总是试图要CPU尽可能的繁忙，使得任务的吞吐量最大化。唯一能够确定CPU瓶颈的还是r（运行队列）的值。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"运维","slug":"运维","permalink":"http://yoursite.com/tags/运维/"},{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"}]},{"title":"关于阿里云CDN的两个故障解决","slug":"CDN网站一次打不开的问题","date":"2017-12-28T09:34:57.000Z","updated":"2018-01-22T02:27:44.000Z","comments":true,"path":"2017/12/28/CDN网站一次打不开的问题/","link":"","permalink":"http://yoursite.com/2017/12/28/CDN网站一次打不开的问题/","excerpt":"","text":"测试中心今天在测试时候发现了一个问题：官方的A网站做了域名跳转，跳转到阿里云CDN，但是在浏览器里输入A地址栏的时候，发现域名的确变成了CDN的域名，但是页面是403。 如图： 但是奇怪的是，再在浏览器点击一下回车，网页就神奇的打开了。 这个原因就是阿里云的CDN有一个“Refer防盗链”，需要在防盗链里面把A域名添加到白名单，这样的话就可以直接访问了。至于为什么第二次回车就可以访问，是因为那时候域名已经成CDN自己的域名了，当然可以访问。 但是这个防盗链也要注意！毕竟白/黑名单添加都是一个危险举动，一定三思后行。有可能你的css\\js是用cdn加速的，一旦加上了白名单，可能css就会变得很难看。 不就之后，商城也下来一个需求，说公司有两个多年不用的域名B和C，打算废物利用，两个都要达到直接“跳转官网”的目的。 于是我就到阿里云域名管理的那里搜索一下，发现目前官网域名后端绑定的是一个CDN，于是也把域名B和域名C做一个CNAME到这个域名，不过登陆浏览器发现域名B和域名C都反馈502。 于是我就到电子商城后端的nginx.conf里查看，确认server_name字段没有写错，然后把域名B和域名C的CNAME直接改成了CDN的域名，再通过了dig确认。但是等于浏览器还是发现502。 最后找了阿里云的人了解，原来阿里云规定“一个CDN只能绑定一个域名，因为节点上没有那两个域名的配置，所以只要不符合节点上有配置文件信息的，全部502”。所以B和C是无法访问的。要解决这个问题有两招，1）把域名B和域名C直接A记录绑定CDN后面的SLB上，但是代价就是访问速度不如CDN快；2）重新购买两个CDN，都绑定SLB，然后把这两个CDN分别绑定到域名B和域名C上，代价是多收一点流量费…","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"CDN","slug":"CDN","permalink":"http://yoursite.com/tags/CDN/"},{"name":"网站技术","slug":"网站技术","permalink":"http://yoursite.com/tags/网站技术/"}]},{"title":"screen的用法","slug":"screen的用法","date":"2017-12-21T07:59:44.000Z","updated":"2018-07-10T09:34:28.000Z","comments":true,"path":"2017/12/21/screen的用法/","link":"","permalink":"http://yoursite.com/2017/12/21/screen的用法/","excerpt":"","text":"很多时候在Linux要后台执行程序，都是使用“&amp;”，或者是nohup，不过这两个更多应用于临时的脚本。一个比较高科技的方法就是使用screen。 安装screen的方法很简单：yum install -y screen。 如果新建一个screen，就输入screen -S name，这样会新开一个窗口，然后执行命令。比如我要启动django，那么就输入python manage.py runserver 0.0.0.0:9000即可。 这个重开一个窗口，列出所有screen进程，就这样： 123[root@docker ~]# screen -lsThere are screens on: 3029.xiedi (Attached) 如果想链接上之前那个django，执行命令screen -r 3029即可。","categories":[{"name":"工作与技术","slug":"工作与技术","permalink":"http://yoursite.com/categories/工作与技术/"}],"tags":[{"name":"Linux","slug":"Linux","permalink":"http://yoursite.com/tags/Linux/"},{"name":"其他软件","slug":"其他软件","permalink":"http://yoursite.com/tags/其他软件/"}]},{"title":"pictest","slug":"pictest","date":"2017-12-13T13:40:06.000Z","updated":"2018-01-03T07:06:28.000Z","comments":true,"path":"2017/12/13/pictest/","link":"","permalink":"http://yoursite.com/2017/12/13/pictest/","excerpt":"这是一个我用来测试图片上传的文章","text":"这是一个我用来测试图片上传的文章 啊！五环，你比四环多一环！啊！五环，你比六环少一环！终于有一天，你会修到七环","categories":[{"name":"用来保护视力的图片","slug":"用来保护视力的图片","permalink":"http://yoursite.com/categories/用来保护视力的图片/"}],"tags":[{"name":"美女","slug":"美女","permalink":"http://yoursite.com/tags/美女/"},{"name":"图片","slug":"图片","permalink":"http://yoursite.com/tags/图片/"}]},{"title":"这里记录的不只有代码，还有生活和思想！","slug":"这里记录的不只有代码，还有生活和思想！","date":"2017-12-13T06:17:22.000Z","updated":"2018-01-12T07:53:14.000Z","comments":true,"path":"2017/12/13/这里记录的不只有代码，还有生活和思想！/","link":"","permalink":"http://yoursite.com/2017/12/13/这里记录的不只有代码，还有生活和思想！/","excerpt":"","text":"var ap = new APlayer({ element: document.getElementById(\"aplayer1\"), narrow: false, autoplay: false, showlrc: 0, music: { title: \"一个人去旅行\", author: \"陈升\", url: \"http://p1x3hd2at.bkt.clouddn.com/一个人去旅行.mp3\", pic: \"http://p1x3hd2at.bkt.clouddn.com/五十米深蓝.jpg\", } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 你说要一个人去旅行 但是归期却没有约定 亚得里亚海边风中的吉他声你说你带着苍白的回忆 却谢谢能与我相逢 我怕你在异乡夜里孤独醒来要拒绝两人单调的生活 想寻找自由 迷信了爱情 就迷失了我自己你就这样 离开吧 抛弃吧 他乡的旅人你就那样 离开吧 抛弃吧 一个人生活 你说要一个人去旅行 眼里藏着一朵乌云 知道你藏不住秘密 天空就会飘着雨你说你带着一本日记 却不想再拥有回忆 我怕你在异乡孤独的醒来要拒绝两人单调的生活 不想再随波逐流 迷信了孤独 就软弱的抛弃了我的等待 你就这样 离开吧 抛弃吧 他乡的旅人你就那样 离开吧 抛弃吧 让我孤独生活 你就这样 离开吧 抛弃我 孤独的旅人你就这样 离开我 抛弃我 让我孤独生活 我想要一个人去旅行 但愿归期会有约定 每个人都在问我 是否可以找到自由的你亚得里亚海边他乡的人和风中的吉他声 我怕你一个人在异乡孤独醒来我会带着你回来","categories":[{"name":"坠乱花天","slug":"坠乱花天","permalink":"http://yoursite.com/categories/坠乱花天/"}],"tags":[{"name":"音乐","slug":"音乐","permalink":"http://yoursite.com/tags/音乐/"},{"name":"感悟","slug":"感悟","permalink":"http://yoursite.com/tags/感悟/"}]}]}